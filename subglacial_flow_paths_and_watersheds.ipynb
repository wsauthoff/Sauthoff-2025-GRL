{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d6caff2-89b9-43f7-bc46-df8ab7d73e39",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Using earthaccess access pattern for direct access of cloud-hosted \n",
    "# MEaSUREs BedMachine Antarctica bed/ice topography dataset\n",
    "# Calculates hydropotential fields, flow paths and delineates subglacial water drainage basins\n",
    "# \n",
    "# Code  written to run on CryoCloud cloud-computing JupyterHub\n",
    "# Learn more: https://cryointhecloud.com/\n",
    "# \n",
    "# Written 2023-11-15 by Wilson Sauthoff (wsauthoff.github.io)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d9c6e41-8b8f-4dbd-bcef-d1cb3c253f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Goal: get figure similar to Figs 3, 4 of Willis and others, 2016, Annals of Glaciology (https://doi.org/10.1017/aog.2016.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37d0ae23-f6f2-4131-a816-5819296a04e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pysheds in /srv/conda/envs/notebook/lib/python3.11/site-packages (0.3.5)\n",
      "Requirement already satisfied: affine in /srv/conda/envs/notebook/lib/python3.11/site-packages (from pysheds) (2.4.0)\n",
      "Requirement already satisfied: geojson in /srv/conda/envs/notebook/lib/python3.11/site-packages (from pysheds) (3.1.0)\n",
      "Requirement already satisfied: numba in /srv/conda/envs/notebook/lib/python3.11/site-packages (from pysheds) (0.58.1)\n",
      "Requirement already satisfied: numpy in /srv/conda/envs/notebook/lib/python3.11/site-packages (from pysheds) (1.23.5)\n",
      "Requirement already satisfied: pandas in /srv/conda/envs/notebook/lib/python3.11/site-packages (from pysheds) (2.2.1)\n",
      "Requirement already satisfied: pyproj in /srv/conda/envs/notebook/lib/python3.11/site-packages (from pysheds) (3.6.1)\n",
      "Requirement already satisfied: rasterio>=1 in /srv/conda/envs/notebook/lib/python3.11/site-packages (from pysheds) (1.3.9)\n",
      "Requirement already satisfied: scikit-image in /srv/conda/envs/notebook/lib/python3.11/site-packages (from pysheds) (0.19.3)\n",
      "Requirement already satisfied: scipy in /srv/conda/envs/notebook/lib/python3.11/site-packages (from pysheds) (1.9.3)\n",
      "Requirement already satisfied: attrs in /srv/conda/envs/notebook/lib/python3.11/site-packages (from rasterio>=1->pysheds) (23.1.0)\n",
      "Requirement already satisfied: certifi in /srv/conda/envs/notebook/lib/python3.11/site-packages (from rasterio>=1->pysheds) (2024.2.2)\n",
      "Requirement already satisfied: click>=4.0 in /srv/conda/envs/notebook/lib/python3.11/site-packages (from rasterio>=1->pysheds) (8.1.7)\n",
      "Requirement already satisfied: cligj>=0.5 in /srv/conda/envs/notebook/lib/python3.11/site-packages (from rasterio>=1->pysheds) (0.7.2)\n",
      "Requirement already satisfied: snuggs>=1.4.1 in /srv/conda/envs/notebook/lib/python3.11/site-packages (from rasterio>=1->pysheds) (1.4.7)\n",
      "Requirement already satisfied: click-plugins in /srv/conda/envs/notebook/lib/python3.11/site-packages (from rasterio>=1->pysheds) (1.1.1)\n",
      "Requirement already satisfied: setuptools in /srv/conda/envs/notebook/lib/python3.11/site-packages (from rasterio>=1->pysheds) (68.2.2)\n",
      "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /srv/conda/envs/notebook/lib/python3.11/site-packages (from numba->pysheds) (0.41.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /srv/conda/envs/notebook/lib/python3.11/site-packages (from pandas->pysheds) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /srv/conda/envs/notebook/lib/python3.11/site-packages (from pandas->pysheds) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /srv/conda/envs/notebook/lib/python3.11/site-packages (from pandas->pysheds) (2024.1)\n",
      "Requirement already satisfied: networkx>=2.2 in /srv/conda/envs/notebook/lib/python3.11/site-packages (from scikit-image->pysheds) (2.8.8)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /srv/conda/envs/notebook/lib/python3.11/site-packages (from scikit-image->pysheds) (10.2.0)\n",
      "Requirement already satisfied: imageio>=2.4.1 in /srv/conda/envs/notebook/lib/python3.11/site-packages (from scikit-image->pysheds) (2.34.0)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /srv/conda/envs/notebook/lib/python3.11/site-packages (from scikit-image->pysheds) (2024.2.12)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /srv/conda/envs/notebook/lib/python3.11/site-packages (from scikit-image->pysheds) (1.4.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /srv/conda/envs/notebook/lib/python3.11/site-packages (from scikit-image->pysheds) (23.2)\n",
      "Requirement already satisfied: six>=1.5 in /srv/conda/envs/notebook/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->pysheds) (1.16.0)\n",
      "Requirement already satisfied: pyparsing>=2.1.6 in /srv/conda/envs/notebook/lib/python3.11/site-packages (from snuggs>=1.4.1->rasterio>=1->pysheds) (3.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pysheds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "903e4f5a-f24b-4eeb-9c44-69d79d1594e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /srv/conda/envs/notebook/lib/python3.11/site-packages (4.9.0.80)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /srv/conda/envs/notebook/lib/python3.11/site-packages (from opencv-python) (1.23.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fa69304-06f3-4b03-b31c-bf4c8af1d77c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import cv2\n",
    "import earthaccess\n",
    "import geopandas as gpd\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from pysheds.grid import Grid\n",
    "from shapely.geometry import LineString, mapping, MultiPoint, Point, Polygon\n",
    "import xarray as xr\n",
    "\n",
    "# Magic functions\n",
    "%matplotlib widget\n",
    "\n",
    "# Define data directories dependent on home environment\n",
    "if os.getenv('HOME') == '/home/jovyan':\n",
    "    DATA_DIR = '/home/jovyan/data'\n",
    "    SCRIPT_DIR = '/home/jovyan/my_repos/script_dir'\n",
    "    OUTPUT_DIR = '/home/jovyan/1_outlines_candidates/output/'\n",
    "\n",
    "# Define utility func's\n",
    "def multipoint_to_centroid(geometry):\n",
    "    '''\n",
    "    Function to convert multipoint to its centroid\n",
    "    '''\n",
    "    if isinstance(geometry, MultiPoint):\n",
    "        # Calculate the centroid of the multipoint geometry\n",
    "        return geometry.centroid\n",
    "    else:\n",
    "        # Return the original geometry if it's not a MultiPoint\n",
    "        return geometry\n",
    "\n",
    "def apply_affine_to_polygon(polygon, affine):\n",
    "    '''\n",
    "    Function to apply affine transformation to polygon vertices\n",
    "    '''\n",
    "    # Define a function that applies the affine transformation to a point\n",
    "    def transform_point(point):\n",
    "        # Apply affine transformation: affine * (col, row)\n",
    "        return affine * (point[0], point[1])\n",
    "\n",
    "    # Apply the transformation to all exterior points of the polygon\n",
    "    exterior_coords = [transform_point((x, y)) for x, y in np.array(polygon.exterior.coords)]\n",
    "    \n",
    "    # If the polygon has interior holes, transform their coordinates as well\n",
    "    interior_coords = [[transform_point((x, y)) for x, y in np.array(interior.coords)] for interior in polygon.interiors]\n",
    "    \n",
    "    # Create a new polygon with the transformed coordinates\n",
    "    return Polygon(exterior_coords, holes=interior_coords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a2b999-bc6c-4a22-87c9-541f31a07a20",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "262d4473-b069-4e67-b4ac-7be47627f6dc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "DriverError",
     "evalue": "/home/jovyan/1_outlines_candidates/Sauthoff-2024-J.Glaciol./output/lake_outlines/static_outlines/lakes_gdf.geojson: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCPLE_OpenFailedError\u001b[0m                      Traceback (most recent call last)",
      "File \u001b[0;32mfiona/ogrext.pyx:136\u001b[0m, in \u001b[0;36mfiona.ogrext.gdal_open_vector\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mfiona/_err.pyx:291\u001b[0m, in \u001b[0;36mfiona._err.exc_wrap_pointer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mCPLE_OpenFailedError\u001b[0m: /home/jovyan/1_outlines_candidates/Sauthoff-2024-J.Glaciol./output/lake_outlines/static_outlines/lakes_gdf.geojson: No such file or directory",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mDriverError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Import subglacial lake outlines \u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m lakes_gdf \u001b[38;5;241m=\u001b[39m \u001b[43mgpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_file\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/home/jovyan/1_outlines_candidates/Sauthoff-2024-J.Glaciol./output/lake_outlines/static_outlines/lakes_gdf.geojson\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.11/site-packages/geopandas/io/file.py:281\u001b[0m, in \u001b[0;36m_read_file\u001b[0;34m(filename, bbox, mask, rows, engine, **kwargs)\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    279\u001b[0m         path_or_bytes \u001b[38;5;241m=\u001b[39m filename\n\u001b[0;32m--> 281\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read_file_fiona\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_bytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_bytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbbox\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbbox\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munknown engine \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mengine\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.11/site-packages/geopandas/io/file.py:322\u001b[0m, in \u001b[0;36m_read_file_fiona\u001b[0;34m(path_or_bytes, from_bytes, bbox, mask, rows, where, **kwargs)\u001b[0m\n\u001b[1;32m    319\u001b[0m     reader \u001b[38;5;241m=\u001b[39m fiona\u001b[38;5;241m.\u001b[39mopen\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m fiona_env():\n\u001b[0;32m--> 322\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mreader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_bytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m features:\n\u001b[1;32m    323\u001b[0m         crs \u001b[38;5;241m=\u001b[39m features\u001b[38;5;241m.\u001b[39mcrs_wkt\n\u001b[1;32m    324\u001b[0m         \u001b[38;5;66;03m# attempt to get EPSG code\u001b[39;00m\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.11/site-packages/fiona/env.py:457\u001b[0m, in \u001b[0;36mensure_env_with_credentials.<locals>.wrapper\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    454\u001b[0m     session \u001b[38;5;241m=\u001b[39m DummySession()\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m env_ctor(session\u001b[38;5;241m=\u001b[39msession):\n\u001b[0;32m--> 457\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.11/site-packages/fiona/__init__.py:292\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, driver, schema, crs, encoding, layer, vfs, enabled_drivers, crs_wkt, allow_unsupported_drivers, **kwargs)\u001b[0m\n\u001b[1;32m    289\u001b[0m     path \u001b[38;5;241m=\u001b[39m parse_path(fp)\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 292\u001b[0m     colxn \u001b[38;5;241m=\u001b[39m \u001b[43mCollection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdriver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdriver\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m        \u001b[49m\u001b[43menabled_drivers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menabled_drivers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_unsupported_drivers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_unsupported_drivers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    303\u001b[0m     colxn \u001b[38;5;241m=\u001b[39m Collection(\n\u001b[1;32m    304\u001b[0m         path,\n\u001b[1;32m    305\u001b[0m         mode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    314\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    315\u001b[0m     )\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.11/site-packages/fiona/collection.py:243\u001b[0m, in \u001b[0;36mCollection.__init__\u001b[0;34m(self, path, mode, driver, schema, crs, encoding, layer, vsi, archive, enabled_drivers, crs_wkt, ignore_fields, ignore_geometry, include_fields, wkt_version, allow_unsupported_drivers, **kwargs)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession \u001b[38;5;241m=\u001b[39m Session()\n\u001b[0;32m--> 243\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession \u001b[38;5;241m=\u001b[39m WritingSession()\n",
      "File \u001b[0;32mfiona/ogrext.pyx:588\u001b[0m, in \u001b[0;36mfiona.ogrext.Session.start\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mfiona/ogrext.pyx:143\u001b[0m, in \u001b[0;36mfiona.ogrext.gdal_open_vector\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mDriverError\u001b[0m: /home/jovyan/1_outlines_candidates/Sauthoff-2024-J.Glaciol./output/lake_outlines/static_outlines/lakes_gdf.geojson: No such file or directory"
     ]
    }
   ],
   "source": [
    "# Import subglacial lake outlines \n",
    "lakes_gdf = gpd.read_file('/home/jovyan/1_outlines_candidates/Sauthoff-2024-J.Glaciol./output/lake_outlines/static_outlines/lakes_gdf.geojson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6442216a-67d2-4e31-aaa5-f6c39fb1296b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Log into NASA Earthdata to search for datasets\n",
    "earthaccess.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b349d900-3be8-4071-8bde-c41300955ce3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Find cloud-hosted BedMachine Antarctica bed/ice geometry dataset, Version 3\n",
    "# DOI from https://nsidc.org/data/NSIDC-0754/versions/1\n",
    "results = earthaccess.search_data(\n",
    "    doi='10.5067/FPSU0V1MWUB6',\n",
    "    cloud_hosted=True,\n",
    "    bounding_box=(1, -89, -1, -89)  # (lower_left_lon, lower_left_lat , upper_right_lon, upper_right_lat))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66047357-ce0e-4904-b725-15fb03e3e11f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Open data granules as s3 files to stream\n",
    "files = earthaccess.open(results)\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485863e1-95c4-442f-b90f-491945ca6eb6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Print file name to ensure expected dataset\n",
    "print(files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e6c8a0-0dc9-4c9f-9a75-e35149a2782f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Open file into xarray dataset\n",
    "bedmachine = xr.open_dataset(files[0])\n",
    "bedmachine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d411bba8-e6ca-4fc0-ab8f-5963d467e798",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Specify the variables to keep\n",
    "variables_to_keep = ['x', 'y', 'surface', 'thickness', 'bed']\n",
    "\n",
    "variables_to_drop = [var for var in bedmachine.variables if var not in variables_to_keep]\n",
    "\n",
    "# Drop variables to reduce memory consumption\n",
    "bedmachine = bedmachine.drop_vars(variables_to_drop)\n",
    "bedmachine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edd4424-b07f-45b0-baa3-b4de6b0fbddb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use BedMachine bed topography for Zbed; static BedMachine surface topogrpahy for static Zsurf\n",
    "rho_water = 997\n",
    "rho_ice = 917\n",
    "bedmachine = bedmachine.assign(static_hydropotential_kPa = (9.8 * ((rho_ice*bedmachine['surface']) + (rho_water-rho_ice)*bedmachine['bed']))/1e3)\n",
    "\n",
    "# Display xarray.Dataset metadata\n",
    "bedmachine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec338b2-98f2-4d60-9d3f-9b9c06b7ef19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Scripps Grounding Line\n",
    "# https://doi.pangaea.de/10.1594/PANGAEA.819147\n",
    "Scripps_gl = gpd.read_file(DATA_DIR + \n",
    "    '/boundaries/Depoorter2013/Antarctica_masks/scripps_antarctica_polygons_v1.shp')\n",
    "\n",
    "# Isolate only land ice\n",
    "Scripps_landice = Scripps_gl[Scripps_gl['Id_text'] == 'Grounded ice or land']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478f2863-f93d-4710-87e9-ecdd9e598241",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Clip BedMachine to grounding line to limit drainage basin delineation to only below grounded ice\n",
    "# Add 1000 m buffer to grounding line so that branches extend outward from grounding line \n",
    "# so that we can find the intersection points of the branches and the grounding line for basin delineation\n",
    "bedmachine.rio.write_crs(\"epsg:3031\", inplace=True)\n",
    "bedmachine_clipped = bedmachine.rio.clip(Scripps_landice.geometry.values.buffer(20000), Scripps_landice.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02babf6-9981-4882-996b-54aa97d12641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Detele intermediary file to reduce memory usage\n",
    "# del bedmachine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0365d176-544c-4796-9600-b0fd9dd4b163",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# MEaSUREs Antarctic Boundaries for IPY 2007-2009 from Satellite Radar V002 (IMBIE ice drainage basins)\n",
    "# https://doi.org/10.5067/AXE4121732AD\n",
    "# https://nsidc.org/sites/default/files/nsidc-0709-v002-userguide.pdf\n",
    "IMBIE_basins = gpd.read_file(DATA_DIR + '/boundaries/measures_Antarctic_boundaries/Basins_IMBIE_Antarctica_v02.shp')\n",
    "refined_basins = gpd.read_file(DATA_DIR + '/boundaries/measures_Antarctic_boundaries/Basins_Antarctica_v02.shp')\n",
    "# ice_boundaries = gpd.read_file(DATA_DIR + '/boundaries/measures_Antarctic_boundaries/IceBoundaries_Antarctica_v02.shp')\n",
    "# grounded_ice_boundaries = ice_boundaries[ice_boundaries[\"TYPE\"]=='GR']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4689cd62-2d37-4584-a699-bce186ce156f",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7438c43-7288-4bbe-9bc8-bb01c0c04b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ideas for how to tackle this:\n",
    "# Use scikit contour to make polygon around catchment (do not trim grid to catchment first)\n",
    "# Trying making for loop of pour points where flow is predicted to cross grounding line (GL) for watershed delineation\n",
    "# https://github.com/mdbartos/pysheds/issues/64#issuecomment-462951248\n",
    "\n",
    "# Additional blog resource\n",
    "# https://www.meteomatics.com/en/blog/watershed-delineation-with-pysheds/\n",
    "\n",
    "# This notebook may be a solution for the following stackexchange questions:\n",
    "# https://gis.stackexchange.com/questions/9237/methodology-for-creating-accurate-drainage-networks-and-catchments-from-high-r\n",
    "\n",
    "# Perhaps you could write this into medium or substack post like this one but gets watershed boundary:\n",
    "# https://medium.com/@ilmachairas/basin-delineation-on-python-5e9da00a3534"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210b1834-8597-47d2-9245-1a1b0d73dbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create temporary tif of hydropotential field\n",
    "# Define array\n",
    "# arr = bedmachine_clipped['static_hydropotential_kPa']\n",
    "arr = bedmachine['static_hydropotential_kPa']\n",
    "\n",
    "# Write CRS\n",
    "arr3031 = arr.rio.write_crs(\"EPSG:3031\")\n",
    "\n",
    "# Specify the output raster file path\n",
    "output_raster_path = 'temp_raster.tif'\n",
    "\n",
    "# Convert xarray DataArray to raster and save it\n",
    "arr3031.rio.to_raster(output_raster_path)\n",
    "\n",
    "# Initialize a grid and DEM from a raster\n",
    "grid = Grid.from_raster('temp_raster.tif')#, nodata=np.nan)\n",
    "dem = grid.read_raster('temp_raster.tif')#, nodata=np.nan)\n",
    "\n",
    "# Delete temp tif file\n",
    "os.remove('temp_raster.tif')\n",
    "\n",
    "# Fill pits in hydropotential DEM\n",
    "pit_filled_dem = grid.fill_pits(dem)\n",
    "\n",
    "# Fill depressions in hydropotentialDEM\n",
    "flooded_dem = grid.fill_depressions(pit_filled_dem)\n",
    "    \n",
    "# Resolve flats in hydropotential DEM\n",
    "inflated_dem = grid.resolve_flats(flooded_dem)\n",
    "\n",
    "# Specify directional mapping for the type of routing algo you wish to use\n",
    "# dirmap = (64, 128, 1, 2, 4, 8, 16, 32)\n",
    "fdir = grid.flowdir(inflated_dem)#, dirmap=dirmap)  # Don't specify dirmap to use default dirmap (not sure which this is - D-infinity? D-8?)\n",
    "\n",
    "# Calculate flow accumulation\n",
    "acc = grid.accumulation(fdir)#, dirmap=dirmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f860ee08-94f8-4eb2-864f-2e2bc86c9f8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # To extract river network, you can use a threshold on the flow accumulation\n",
    "# threshold = 15000  # This value depends on your specific application\n",
    "# branches = grid.extract_river_network(fdir, acc > threshold)#, dirmap=dirmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caefae36-41f8-4ce1-bb1a-ebdf1e7b18b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Larger basins to debug method\n",
    "\n",
    "# To extract river network, you can use a threshold on the flow accumulation\n",
    "threshold = 10000  # This value depends on your specific application\n",
    "branches = grid.extract_river_network(fdir, acc > threshold)#, dirmap=dirmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65cd5d7-7126-4bd6-b229-5edf13f00a19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Store\n",
    "line_strings = []\n",
    "\n",
    "for branch in branches['features']:\n",
    "    line_coords = branch['geometry']['coordinates']\n",
    "    line = LineString(line_coords)\n",
    "    line_strings.append(line)\n",
    "\n",
    "flow_paths_gdf = gpd.GeoDataFrame(geometry=line_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ad2532-32db-483f-9e09-eca90cef82dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set the CRS for gdf if it's not set\n",
    "if flow_paths_gdf.crs is None:\n",
    "    flow_paths_gdf.set_crs(\"EPSG:3031\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157adbce-3d19-4e37-923c-f54afd652fca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Visualize \n",
    "fig, ax = plt.subplots()\n",
    "flow_paths_gdf.plot(ax=ax)\n",
    "Scripps_landice.boundary.plot(ax=ax, color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64fec5b-80ae-4627-ae94-37146e5a5224",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Finding intersections of the flow paths at the grounding line\n",
    "# We will use these as \"pour points\" to delineate subglacial water drainage basins\n",
    "intersections = flow_paths_gdf.intersection(Scripps_landice.boundary.unary_union)\n",
    "\n",
    "# Many rows of intersections_gdf are LINESTRING EMPTY because the the flow path branch row in \n",
    "# clipped_flow_paths_gdf did not have an intersection with Scripps_landice grounding line,\n",
    "# so filtering for 'Point' and 'MultiPoint' geometries, where an intersection was found\n",
    "filtered_intersections = intersections[intersections.type.isin(['Point', 'MultiPoint'])]\n",
    "\n",
    "# Converting the GeoSeries to a GeoDataFrame with 'geometry' as the geometry column name\n",
    "intersections_gdf = gpd.GeoDataFrame(geometry=filtered_intersections, crs=clipped_flow_paths_gdf.crs)\n",
    "\n",
    "# Delete intermediary geoseries for memory conservation\n",
    "del filtered_intersections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef5bf2a-de46-4435-8f73-3ad1b5978a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure no loss of points/multipoints\n",
    "print(len(intersections_gdf))\n",
    "print(len(intersections_gdf[intersections_gdf.geometry.type.isin(['MultiPoint'])])\n",
    "    + len(intersections_gdf[intersections_gdf.geometry.type.isin(['Point'])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33140ea3-b879-4f00-bcfa-036fff3aed18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Visualize \n",
    "fig, ax = plt.subplots()\n",
    "flow_paths_gdf.plot(ax=ax, edgecolor='blue')\n",
    "Scripps_landice.plot(ax=ax, color='none', edgecolor='red')\n",
    "intersections_gdf.plot(ax=ax, color='green', markersize=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29f32c9-095f-4fc9-a347-16b7192d5973",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Visualize \n",
    "fig, ax = plt.subplots()\n",
    "flow_paths_gdf.plot(ax=ax, edgecolor='blue')\n",
    "Scripps_landice.plot(ax=ax, color='none', edgecolor='red')\n",
    "intersections_gdf[intersections_gdf.geometry.type.isin(['Point'])].plot(ax=ax, color='green', markersize=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1f454c-3ee2-4f60-b3a5-4d2db2fcd3e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Visualize \n",
    "fig, ax = plt.subplots()\n",
    "flow_paths_gdf.plot(ax=ax, edgecolor='blue')\n",
    "Scripps_landice.plot(ax=ax, color='none', edgecolor='red')\n",
    "intersections_gdf[intersections_gdf.geometry.type.isin(['MultiPoint'])].plot(ax=ax, color='green', markersize=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85692a1c-6dda-4334-9511-181231d89dc6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# intersections_gdf contains mulipoints, which will not work for using a single pour point\n",
    "# to delineate subglacial watershed, so we convert each multipoint geometry to its centroid point\n",
    "intersections_gdf['geometry'] = intersections_gdf['geometry'].apply(multipoint_to_centroid)\n",
    "\n",
    "# Print geodataframe length to ensure no multipoints/points were lost\n",
    "print(len(intersections_gdf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8751e5c2-8100-4773-84a8-9850f64cd13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the index\n",
    "intersections_gdf=intersections_gdf.reset_index()\n",
    "intersections_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbea2b4-df66-45d7-af24-056e690f7600",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Trying to do just on multipoint gdf because was moving or destorying some points\n",
    "\n",
    "# # Function to convert multipoint to its centroid\n",
    "# def multipoint_to_centroid(geometry):\n",
    "#     if isinstance(geometry, MultiPoint):\n",
    "#         # Calculate the centroid of the multipoint geometry\n",
    "#         return geometry.centroid\n",
    "#     else:\n",
    "#         # Return the original geometry if it's not a MultiPoint\n",
    "#         return geometry\n",
    "\n",
    "# # Apply the function to each geometry in the GeoDataFrame\n",
    "# intersections_multi_gdf['geometry'] = intersections_multi_gdf['geometry'].apply(multipoint_to_centroid)\n",
    "# intersections_multi_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9a138c-fb22-460d-9940-9db0de3c473e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Concatenate\n",
    "# intersections_gdf_combined = pd.concat([intersections_multi_gdf, intersections_point_gdf], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b438c8bc-bf57-4d63-8dc9-7315000eb3fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(len(intersections_gdf))\n",
    "# print(len(intersections_gdf_combined))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf98361-1147-4a76-84fc-bf0fc2d2e07c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Visualize \n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "flow_paths_gdf.plot(ax=ax, edgecolor='blue')\n",
    "Scripps_landice.plot(ax=ax, color='none', edgecolor='red')\n",
    "# bedmachine['static_hydropotential_kPa'].plot(ax=ax, cmap='terrain')  # Slow to plot\n",
    "intersections_gdf.plot(ax=ax, color='green', markersize=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2906c4c1-3051-4ea4-86da-4d8736f59780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming intersections_gdf is a GeoDataFrame with points of interest\n",
    "\n",
    "# Initialize a list to hold the transformed polygons for all points\n",
    "watershed_polygons = []\n",
    "\n",
    "# Store total for displaying for loop progess\n",
    "total = len(intersections_gdf)\n",
    "\n",
    "for idx, row in intersections_gdf.iterrows():\n",
    "\n",
    "    # Display progress\n",
    "    print(f'Processing {idx} of {total}...')  # Display current index out of total\n",
    "    \n",
    "    # Extract x, y coords from points from geometry column and snap to mask \n",
    "    point = row.geometry\n",
    "    x, y = point.x, point.y\n",
    "    x_snap, y_snap = grid.snap_to_mask(acc > threshold, (x, y))\n",
    "    \n",
    "    # Delineate the catchment for the current point\n",
    "    raster = grid.catchment(x=x_snap, y=y_snap, fdir=fdir, #dirmap=dirmap, \n",
    "        xytype='coordinate')\n",
    "    \n",
    "    # Convert True/False to 0/255 and ensure the type is np.uint8 for cv2 contouring step\n",
    "    raster = (raster > 0).astype(np.uint8) * 255\n",
    "    \n",
    "    # Find contours\n",
    "    contours, hierarchy = cv2.findContours(raster, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Convert contours to polygons for the current point\n",
    "    polygons = [Polygon(contour.reshape(-1, 2)) for contour in contours if len(contour) > 2]\n",
    "    \n",
    "    # if polygons:\n",
    "    # Apply affine transformation to the largest polygon\n",
    "    watershed_polygon = apply_affine_to_polygon(polygons[0], raster.affine)\n",
    "    \n",
    "    # Store the transformed polygon\n",
    "    watershed_polygons.append(watershed_polygon)\n",
    "    # else:\n",
    "    #     # Handle cases where no polygon was found\n",
    "    #     watershed_polygons.append(None)\n",
    "\n",
    "    # Clear output of each loop\n",
    "    clear_output(wait=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca63512-b1af-4357-980e-a3dca08f7b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to GeoDataFrame\n",
    "watersheds_gdf = gpd.GeoDataFrame(geometry=watershed_polygons)\n",
    "\n",
    "# Set the CRS for the GeoDataFrame\n",
    "watersheds_gdf.set_crs(Scripps_landice.crs, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10706d9d-abfe-481c-b154-9aea21752eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for invalid geometries\n",
    "watersheds_gdf[~watersheds_gdf.is_valid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9c6504-d3b3-4814-9c11-74bb687ef2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repair invalid geometries\n",
    "watersheds_gdf.loc[~watersheds_gdf.is_valid, 'geometry'] = watersheds_gdf[~watersheds_gdf.is_valid].geometry.buffer(0)\n",
    "\n",
    "# Check if there are still any invalid geometries\n",
    "print(watersheds_gdf[~watersheds_gdf.is_valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d8548f-49f8-4d5b-b611-e3f152fb6025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "Scripps_landice.plot(ax=ax, color='white', edgecolor='red')\n",
    "flow_paths_gdf.plot(ax=ax, edgecolor='lightblue')\n",
    "lakes_gdf.plot(ax=ax, color='cyan')\n",
    "watersheds_gdf.plot(ax=ax, color='none', edgecolor='blue')\n",
    "intersections_gdf.plot(ax=ax, color='green', markersize=50)\n",
    "\n",
    "# Iterate through the GeoDataFrame to annotate each polygon\n",
    "# for idx, row in lakes_gdf.iterrows():\n",
    "#     # Use the centroid of each polygon for the annotation location\n",
    "#     centroid = row['geometry'].centroid\n",
    "#     ax.annotate(text=row['name'], xy=(centroid.x, centroid.y), xytext=(3, 3), textcoords=\"offset points\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12000b64-7260-41de-b704-01506be3aa6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize\n",
    "fig, ax = plt.subplots()\n",
    "watersheds_gdf.plot(ax=ax, color='none', edgecolor='blue')\n",
    "Scripps_landice.plot(ax=ax, color='white', edgecolor='red', alpha=0.75)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf20164f-fd46-4dee-840a-558c74d69a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some watershed polygons extend seaward of GL because of complex routing pathways\n",
    "# that intersect the GL but then go seaward vs. inland (e.g., the peninsula on the\n",
    "# Siple Coast), so will clip watershed_gdf to the GL so that the watersheds are all\n",
    "# inland of the GL\n",
    "clipped_watersheds_gdf = gpd.clip(watersheds_gdf, Scripps_landice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490145c5-52b7-45ce-b1fc-0e0602357ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize\n",
    "fig, ax = plt.subplots()\n",
    "clipped_watersheds_gdf.plot(ax=ax, color='none', edgecolor='blue')\n",
    "Scripps_landice.plot(ax=ax, color='white', edgecolor='red', alpha=0.75)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfe7e79-dc47-492f-9674-7544de5de026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export geodataframe to geojson for future use\n",
    "clipped_watersheds_gdf.to_file('output/subglacial_watersheds.geojson', driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8f3aff-d655-42f7-8bb5-e27dd9baaaa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similarly clip flow paths and export\n",
    "# Clip flow path branches to grounding line\n",
    "clipped_flow_paths_gdf = gpd.clip(flow_paths_gdf, Scripps_landice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2769d61-0073-489d-834c-4c79cdbb9569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export geodataframe to geojson for future use\n",
    "clipped_flow_paths_gdf.to_file('output/subglacial_flow_paths.geojson', driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5509c3e5-05e5-4dd7-88ab-578032befb99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import geojsons to geodataframes to ensure export worked properly\n",
    "clipped_watersheds_gdf_readin = gpd.read_file('output/subglacial_watersheds.geojson')\n",
    "clipped_flow_paths_gdf_readin = gpd.read_file('output/subglacial_flow_paths.geojson', driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04543175-f431-47aa-9492-82dd008e7971",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Visualize\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "\n",
    "Scripps_landice.plot(ax=ax, color='none', edgecolor='red')\n",
    "clipped_watersheds_gdf_readin.boundary.plot(ax=ax, color='blue')\n",
    "clipped_flow_paths_gdf_readin.plot(ax=ax, color='lightblue')\n",
    "intersections_gdf.plot(ax=ax, color='green', markersize=50)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1cce20-47a8-4623-9749-e0ebe434ace8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# Siple Coast peninsula has flow path with one intersection point, but\n",
    "# there is another downstream that should come up as an intersection point\n",
    "# Think about how to remedy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d596ce-da8b-4969-b5e2-7722b3b26fb5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Visualize\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "Scripps_landice.plot(ax=ax, color='none', edgecolor='red')\n",
    "IMBIE_basins.boundary.plot(ax=ax, color='white')\n",
    "# refined_basins.boundary.plot(ax=ax, color='gray')\n",
    "lakes_gdf.boundary.plot(ax=ax, color='turquoise', edgecolor='red')\n",
    "clipped_watersheds_gdf_readin.boundary.plot(ax=ax, color='blue')\n",
    "clipped_flow_paths_gdf_readin.plot(ax=ax, color='lightblue')\n",
    "# intersections_gdf.plot(ax=ax, color='green', markersize=50)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98163c34-ac9d-4975-a6b7-99605867e899",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Visualize\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "Scripps_landice.plot(ax=ax, color='none', edgecolor='red')\n",
    "# IMBIE_basins.boundary.plot(ax=ax, color='gray')\n",
    "refined_basins.boundary.plot(ax=ax, color='gray')\n",
    "lakes_gdf.boundary.plot(ax=ax, color='turquoise', edgecolor='red')\n",
    "clipped_watersheds_gdf_readin.boundary.plot(ax=ax, color='blue')\n",
    "# clipped_flow_paths_gdf_readin.plot(ax=ax, color='lightblue')\n",
    "# intersections_gdf.plot(ax=ax, color='green', markersize=50)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3c6cc8-2652-4a23-b17f-f5c5eb172804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# Find overlaps between watershed and IMBIE refined basins to name watersheds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
