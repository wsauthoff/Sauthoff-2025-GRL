{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# calc off-lake dh/dt to subtract from on-lake dh/dt like SF18 to remove secular change; start by quantifying off-lake dh/dt to see if significant?\n",
    "# add functions that plot agg var outlines on 1) ice surface imagery, 2) BedMachine Antarctica bed topography, 3) hydropotential calculated with BedMachine Antarctica and Bedmap2 and BEDMAP\n",
    "# from lake-hydropotential.ipynb, import function 'SF18lakes_hydropot' to plot \n",
    "    # 1) hydropotential with agg plot to see if time-evolving outlines follow hydropotential contours and \n",
    "    # 2) make a time-variable plot with changing hydropotential and each time slice with its corresponding variable outline\n",
    "# filter CS_dh to use at least 0.5/1? data point to not view highly interpolated areas\n",
    "# find faster thresholding method to use CS2 count to look at data based on a threshold of data points\n",
    "# convert polys[i].area to calc geodesic area instead\n",
    "# tried variable outline code on ATL11 data\n",
    "# overlay ATL11 data points on ATL15 interpolated data to know where data points are\n",
    "# overlay ICESat tracks to see where we see new lakes\n",
    "# add PIG and AP lakes as well as ones I've found to new gpd dataframe called Sauthoff 2023 (S23); add upper slessor lakes (get outlines from matt); Rec7?\n",
    "# -> make column that indicates if there's SARIn coverage\n",
    "# -> make functions intake a list of S09 and a list of SF18 lakes to be included in plot (to create bbox around multiple lakes)\n",
    "# -> may need to create new gpd dataframe that has corresponding S09 and SF18 lakes in same row that can be indexed in the function call\n",
    "# change all plots to have km scale; make sure using np.round to get nice round tick labels\n",
    "# ensure SiegfriedFricker2018_SF18outlines being plotted instead of SiegfriedFricker2018_outlines\n",
    "# make dh/dt planview 1x2 aggregated variable outlines that compares CS2 and IS2 variable outlines over the IS2 era\n",
    "# create and heavily comment introductory cell on the general outline delineation procedure\n",
    "# modify S09SF18varoutlines_agg_plot to also create animation building agg plot with agg plot as last frame; save animation; save last frame as separate file\n",
    "# modify S09SF18varoutlines_dhdt_plot_anim for last frame to be agg plot of variable outlines \n",
    "# modify S09SF18varoutlines_agg_plot to plot using S09 lake name; examine Recovery_8\n",
    "# have animations end on last frame and can pause (make into mp4 vs gif) \n",
    "# make legend dynamic where it will include S09 citation if there is a S09 lake within the bounding box; same with SF18; perhaps with gpd.contains?\n",
    "# have dv/dt 2D line plots label the threshold level selected\n",
    "# plots for combined Mac 4+5 and Slessor 4+5 since so close and hard to disentangle (use arg of bbox coords vs using lake name)\n",
    "# make dvdt plots have symbols for actual data points and dotted lines between\n",
    "# when making contours, perhaps clip to buffer area around lake outline (vs. square bbox) once you know rough bounds of where off-lake extensions will be so you can clip out other nearby actvity?\n",
    "# add gl to plots\n",
    "# change S09SF18varoutlines_dhdvdt_anim to add buffer to ylimits that is alternative to *1.1, which doesn't work for zero (fix on others); i think i've already done this in other functions; find and put into all\n",
    "# investigate why S09SF18varoutlines_dhdvdt_CS2vsIS2_anim trips on 'Mac5'\n",
    "# have functions append volume change time series into a pandas data frame (and/or export to csv)\n",
    "# change x-limits to start at 2nd time step, eg date_time_obj + datetime.timedelta(days=ds_sub.time.values[1]) so that vol change time series starts at left xaxis limit?\n",
    "# S09SF18varoutlines_dhdvdt_CS2vsIS2_anim: should clip vmax,min to only CS2 cycs in IS2 era vs. all cycles\n",
    "# make explicit bounding box coords optional arg as list to func\n",
    "# change colormap limits to reflect rounded min and max instead of highest abs value of two; fix weird tick marks\n",
    "# horizontal colorbar to look more like timescale for agg outline plots: pl.colorbar(orientation=\"h\", cax=cax); put vertical line in to indicate time slice being plotted\n",
    "# perhaps add an empty colorbar to plots without colorbar so that size of all the plots is the same regardless of whether it has a colorbar or not\n",
    "# S09SF18varoutlines_dhdvdt_CS2vsIS2_anim overwrites each plot (being name the same date); look into why this is happening\n",
    "# create mean lake outline from variable outlines\n",
    "# interpolate between outlines at time resolution of passes over AOI to see if individual IS2 tracks match interpolated outlines\n",
    "# some functions calc v = np.round(max_height_anom_abs), but don't end up using it; delete that code\n",
    "# -> dh/dt plots should have vmax and vmin that reflect actual vs. the max of one\n",
    "# clb = fig.colorbar(m, ticks=np.array([2019,2020,2021]),  cax=cax); why assign to clb; where is 'Year' label added?\n",
    "# Make colorbar appear horizontally and/or w/in plot like a legend? For shoreline agg plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to delineate subglacial lakes using variable outlines based on \n",
    "# ice surface height deformation contours, visualize and quantify lake \n",
    "# average dh/dt and lake dv/dt. \n",
    "#\n",
    "# Written 2022-06-06 by W. Sauthoff (sauthoff@mines.edu)\n",
    "\n",
    "# import packages\n",
    "import rioxarray\n",
    "import geopandas as gpd\n",
    "from matplotlib import animation\n",
    "import matplotlib.pyplot as plt\n",
    "import cmocean\n",
    "from skimage import measure\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import datetime\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.path as mpath\n",
    "from matplotlib.patches import Ellipse, Rectangle\n",
    "import math\n",
    "import time\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "# define data and script directory (replace with your data directory file path) and file path\n",
    "data_dir = '/Volumes/ExtremeSSD/data'\n",
    "script_dir = '/Users/Wilson/Documents/0-code/scripts'\n",
    "\n",
    "def datetime2fracyear(date):\n",
    "    start = datetime.date(date.year, 1, 1).toordinal()\n",
    "    year_length = datetime.date(date.year+1, 1, 1).toordinal() - start\n",
    "    return date.year + float(date.toordinal() - start) / year_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><svg style=\"position: absolute; width: 0; height: 0; overflow: hidden\">\n",
       "<defs>\n",
       "<symbol id=\"icon-database\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M16 0c-8.837 0-16 2.239-16 5v4c0 2.761 7.163 5 16 5s16-2.239 16-5v-4c0-2.761-7.163-5-16-5z\"></path>\n",
       "<path d=\"M16 17c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "<path d=\"M16 26c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "</symbol>\n",
       "<symbol id=\"icon-file-text2\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M28.681 7.159c-0.694-0.947-1.662-2.053-2.724-3.116s-2.169-2.030-3.116-2.724c-1.612-1.182-2.393-1.319-2.841-1.319h-15.5c-1.378 0-2.5 1.121-2.5 2.5v27c0 1.378 1.122 2.5 2.5 2.5h23c1.378 0 2.5-1.122 2.5-2.5v-19.5c0-0.448-0.137-1.23-1.319-2.841zM24.543 5.457c0.959 0.959 1.712 1.825 2.268 2.543h-4.811v-4.811c0.718 0.556 1.584 1.309 2.543 2.268zM28 29.5c0 0.271-0.229 0.5-0.5 0.5h-23c-0.271 0-0.5-0.229-0.5-0.5v-27c0-0.271 0.229-0.5 0.5-0.5 0 0 15.499-0 15.5 0v7c0 0.552 0.448 1 1 1h7v19.5z\"></path>\n",
       "<path d=\"M23 26h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 22h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 18h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "</symbol>\n",
       "</defs>\n",
       "</svg>\n",
       "<style>/* CSS stylesheet for displaying xarray objects in jupyterlab.\n",
       " *\n",
       " */\n",
       "\n",
       ":root {\n",
       "  --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1));\n",
       "  --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54));\n",
       "  --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38));\n",
       "  --xr-border-color: var(--jp-border-color2, #e0e0e0);\n",
       "  --xr-disabled-color: var(--jp-layout-color3, #bdbdbd);\n",
       "  --xr-background-color: var(--jp-layout-color0, white);\n",
       "  --xr-background-color-row-even: var(--jp-layout-color1, white);\n",
       "  --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee);\n",
       "}\n",
       "\n",
       "html[theme=dark],\n",
       "body.vscode-dark {\n",
       "  --xr-font-color0: rgba(255, 255, 255, 1);\n",
       "  --xr-font-color2: rgba(255, 255, 255, 0.54);\n",
       "  --xr-font-color3: rgba(255, 255, 255, 0.38);\n",
       "  --xr-border-color: #1F1F1F;\n",
       "  --xr-disabled-color: #515151;\n",
       "  --xr-background-color: #111111;\n",
       "  --xr-background-color-row-even: #111111;\n",
       "  --xr-background-color-row-odd: #313131;\n",
       "}\n",
       "\n",
       ".xr-wrap {\n",
       "  display: block !important;\n",
       "  min-width: 300px;\n",
       "  max-width: 700px;\n",
       "}\n",
       "\n",
       ".xr-text-repr-fallback {\n",
       "  /* fallback to plain text repr when CSS is not injected (untrusted notebook) */\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-header {\n",
       "  padding-top: 6px;\n",
       "  padding-bottom: 6px;\n",
       "  margin-bottom: 4px;\n",
       "  border-bottom: solid 1px var(--xr-border-color);\n",
       "}\n",
       "\n",
       ".xr-header > div,\n",
       ".xr-header > ul {\n",
       "  display: inline;\n",
       "  margin-top: 0;\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-obj-type,\n",
       ".xr-array-name {\n",
       "  margin-left: 2px;\n",
       "  margin-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-obj-type {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-sections {\n",
       "  padding-left: 0 !important;\n",
       "  display: grid;\n",
       "  grid-template-columns: 150px auto auto 1fr 20px 20px;\n",
       "}\n",
       "\n",
       ".xr-section-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-section-item input {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-item input + label {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label {\n",
       "  cursor: pointer;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label:hover {\n",
       "  color: var(--xr-font-color0);\n",
       "}\n",
       "\n",
       ".xr-section-summary {\n",
       "  grid-column: 1;\n",
       "  color: var(--xr-font-color2);\n",
       "  font-weight: 500;\n",
       "}\n",
       "\n",
       ".xr-section-summary > span {\n",
       "  display: inline-block;\n",
       "  padding-left: 0.5em;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in + label:before {\n",
       "  display: inline-block;\n",
       "  content: '►';\n",
       "  font-size: 11px;\n",
       "  width: 15px;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label:before {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label:before {\n",
       "  content: '▼';\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label > span {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-summary,\n",
       ".xr-section-inline-details {\n",
       "  padding-top: 4px;\n",
       "  padding-bottom: 4px;\n",
       "}\n",
       "\n",
       ".xr-section-inline-details {\n",
       "  grid-column: 2 / -1;\n",
       "}\n",
       "\n",
       ".xr-section-details {\n",
       "  display: none;\n",
       "  grid-column: 1 / -1;\n",
       "  margin-bottom: 5px;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked ~ .xr-section-details {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-array-wrap {\n",
       "  grid-column: 1 / -1;\n",
       "  display: grid;\n",
       "  grid-template-columns: 20px auto;\n",
       "}\n",
       "\n",
       ".xr-array-wrap > label {\n",
       "  grid-column: 1;\n",
       "  vertical-align: top;\n",
       "}\n",
       "\n",
       ".xr-preview {\n",
       "  color: var(--xr-font-color3);\n",
       "}\n",
       "\n",
       ".xr-array-preview,\n",
       ".xr-array-data {\n",
       "  padding: 0 5px !important;\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-array-data,\n",
       ".xr-array-in:checked ~ .xr-array-preview {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-array-in:checked ~ .xr-array-data,\n",
       ".xr-array-preview {\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".xr-dim-list {\n",
       "  display: inline-block !important;\n",
       "  list-style: none;\n",
       "  padding: 0 !important;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list li {\n",
       "  display: inline-block;\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list:before {\n",
       "  content: '(';\n",
       "}\n",
       "\n",
       ".xr-dim-list:after {\n",
       "  content: ')';\n",
       "}\n",
       "\n",
       ".xr-dim-list li:not(:last-child):after {\n",
       "  content: ',';\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-has-index {\n",
       "  font-weight: bold;\n",
       "}\n",
       "\n",
       ".xr-var-list,\n",
       ".xr-var-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-var-item > div,\n",
       ".xr-var-item label,\n",
       ".xr-var-item > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-even);\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-var-item > .xr-var-name:hover span {\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-var-list > li:nth-child(odd) > div,\n",
       ".xr-var-list > li:nth-child(odd) > label,\n",
       ".xr-var-list > li:nth-child(odd) > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-odd);\n",
       "}\n",
       "\n",
       ".xr-var-name {\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-var-dims {\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-var-dtype {\n",
       "  grid-column: 3;\n",
       "  text-align: right;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-preview {\n",
       "  grid-column: 4;\n",
       "}\n",
       "\n",
       ".xr-var-name,\n",
       ".xr-var-dims,\n",
       ".xr-var-dtype,\n",
       ".xr-preview,\n",
       ".xr-attrs dt {\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-var-name:hover,\n",
       ".xr-var-dims:hover,\n",
       ".xr-var-dtype:hover,\n",
       ".xr-attrs dt:hover {\n",
       "  overflow: visible;\n",
       "  width: auto;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".xr-var-attrs,\n",
       ".xr-var-data {\n",
       "  display: none;\n",
       "  background-color: var(--xr-background-color) !important;\n",
       "  padding-bottom: 5px !important;\n",
       "}\n",
       "\n",
       ".xr-var-attrs-in:checked ~ .xr-var-attrs,\n",
       ".xr-var-data-in:checked ~ .xr-var-data {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       ".xr-var-data > table {\n",
       "  float: right;\n",
       "}\n",
       "\n",
       ".xr-var-name span,\n",
       ".xr-var-data,\n",
       ".xr-attrs {\n",
       "  padding-left: 25px !important;\n",
       "}\n",
       "\n",
       ".xr-attrs,\n",
       ".xr-var-attrs,\n",
       ".xr-var-data {\n",
       "  grid-column: 1 / -1;\n",
       "}\n",
       "\n",
       "dl.xr-attrs {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  display: grid;\n",
       "  grid-template-columns: 125px auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt,\n",
       ".xr-attrs dd {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  float: left;\n",
       "  padding-right: 10px;\n",
       "  width: auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt {\n",
       "  font-weight: normal;\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-attrs dt:hover span {\n",
       "  display: inline-block;\n",
       "  background: var(--xr-background-color);\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-attrs dd {\n",
       "  grid-column: 2;\n",
       "  white-space: pre-wrap;\n",
       "  word-break: break-all;\n",
       "}\n",
       "\n",
       ".xr-icon-database,\n",
       ".xr-icon-file-text2 {\n",
       "  display: inline-block;\n",
       "  vertical-align: middle;\n",
       "  width: 1em;\n",
       "  height: 1.5em !important;\n",
       "  stroke-width: 0;\n",
       "  stroke: currentColor;\n",
       "  fill: currentColor;\n",
       "}\n",
       "</style><pre class='xr-text-repr-fallback'>&lt;xarray.Dataset&gt;\n",
       "Dimensions:  (y: 4451, x: 5451, time: 45)\n",
       "Coordinates:\n",
       "  * y        (y) float64 2.265e+06 2.264e+06 2.263e+06 ... -2.184e+06 -2.185e+06\n",
       "  * x        (x) float64 -2.665e+06 -2.664e+06 ... 2.784e+06 2.785e+06\n",
       "  * time     (time) float64 2.01e+03 2.011e+03 2.011e+03 ... 2.021e+03 2.022e+03\n",
       "Data variables:\n",
       "    mask     (y, x) float64 nan nan nan nan nan nan ... nan nan nan nan nan nan\n",
       "    delta_h  (time, y, x) float64 nan nan nan nan nan ... nan nan nan nan nan\n",
       "    count    (time, y, x) float64 nan nan nan nan nan ... nan nan nan nan nan\n",
       "Attributes:\n",
       "    fileName:  mos_2010.5_2021.5.h5</pre><div class='xr-wrap' style='display:none'><div class='xr-header'><div class='xr-obj-type'>xarray.Dataset</div></div><ul class='xr-sections'><li class='xr-section-item'><input id='section-53193ed9-c926-44dc-98b4-3d43e6cd4679' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-53193ed9-c926-44dc-98b4-3d43e6cd4679' class='xr-section-summary'  title='Expand/collapse section'>Dimensions:</label><div class='xr-section-inline-details'><ul class='xr-dim-list'><li><span class='xr-has-index'>y</span>: 4451</li><li><span class='xr-has-index'>x</span>: 5451</li><li><span class='xr-has-index'>time</span>: 45</li></ul></div><div class='xr-section-details'></div></li><li class='xr-section-item'><input id='section-4f165a3e-dc00-470c-bfca-0eee6c889da2' class='xr-section-summary-in' type='checkbox'  checked><label for='section-4f165a3e-dc00-470c-bfca-0eee6c889da2' class='xr-section-summary' >Coordinates: <span>(3)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>y</span></div><div class='xr-var-dims'>(y)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>2.265e+06 2.264e+06 ... -2.185e+06</div><input id='attrs-79919d49-d1f8-4b38-94f6-ff1e6da94486' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-79919d49-d1f8-4b38-94f6-ff1e6da94486' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-1fa0200c-85c0-4566-8cba-c3b83f1eaed2' class='xr-var-data-in' type='checkbox'><label for='data-1fa0200c-85c0-4566-8cba-c3b83f1eaed2' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([ 2265000.,  2264000.,  2263000., ..., -2183000., -2184000., -2185000.])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>x</span></div><div class='xr-var-dims'>(x)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>-2.665e+06 -2.664e+06 ... 2.785e+06</div><input id='attrs-8f5ab361-3326-4536-be59-584735c8e6bd' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-8f5ab361-3326-4536-be59-584735c8e6bd' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-4b1bf91b-fe52-4f0c-ad15-902a78db7100' class='xr-var-data-in' type='checkbox'><label for='data-4b1bf91b-fe52-4f0c-ad15-902a78db7100' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([-2665000., -2664000., -2663000., ...,  2783000.,  2784000.,  2785000.])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>time</span></div><div class='xr-var-dims'>(time)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>2.01e+03 2.011e+03 ... 2.022e+03</div><input id='attrs-e8ef05b7-3b55-42a7-81e9-605e403a9c50' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-e8ef05b7-3b55-42a7-81e9-605e403a9c50' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-79505b67-2359-4cfd-a858-de9b59e5adcd' class='xr-var-data-in' type='checkbox'><label for='data-79505b67-2359-4cfd-a858-de9b59e5adcd' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([2010.5 , 2010.75, 2011.  , 2011.25, 2011.5 , 2011.75, 2012.  , 2012.25,\n",
       "       2012.5 , 2012.75, 2013.  , 2013.25, 2013.5 , 2013.75, 2014.  , 2014.25,\n",
       "       2014.5 , 2014.75, 2015.  , 2015.25, 2015.5 , 2015.75, 2016.  , 2016.25,\n",
       "       2016.5 , 2016.75, 2017.  , 2017.25, 2017.5 , 2017.75, 2018.  , 2018.25,\n",
       "       2018.5 , 2018.75, 2019.  , 2019.25, 2019.5 , 2019.75, 2020.  , 2020.25,\n",
       "       2020.5 , 2020.75, 2021.  , 2021.25, 2021.5 ])</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-53e72b46-8305-4908-bc7a-fa787585af4c' class='xr-section-summary-in' type='checkbox'  checked><label for='section-53e72b46-8305-4908-bc7a-fa787585af4c' class='xr-section-summary' >Data variables: <span>(3)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span>mask</span></div><div class='xr-var-dims'>(y, x)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>nan nan nan nan ... nan nan nan nan</div><input id='attrs-70e5e3a4-2c29-48dd-8004-fa613d81cf39' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-70e5e3a4-2c29-48dd-8004-fa613d81cf39' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-469d7d25-f800-4ccb-a958-6f147456bb71' class='xr-var-data-in' type='checkbox'><label for='data-469d7d25-f800-4ccb-a958-6f147456bb71' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>description: :</span></dt><dd>Data mask. 0: unknown, 1: unknown, nan: nan</dd></dl></div><div class='xr-var-data'><pre>array([[nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       ...,\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan]])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>delta_h</span></div><div class='xr-var-dims'>(time, y, x)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>nan nan nan nan ... nan nan nan nan</div><input id='attrs-63107b7a-1494-4844-ada2-0bba9ef8d7af' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-63107b7a-1494-4844-ada2-0bba9ef8d7af' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-17892ea5-9cf0-4c4a-8578-68ddc7ee6d7d' class='xr-var-data-in' type='checkbox'><label for='data-17892ea5-9cf0-4c4a-8578-68ddc7ee6d7d' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>description: :</span></dt><dd>Height change relative to the datum (2016) surface</dd><dt><span>units :</span></dt><dd>m</dd></dl></div><div class='xr-var-data'><pre>array([[[nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        ...,\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan]],\n",
       "\n",
       "       [[nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        ...,\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan]],\n",
       "\n",
       "       [[nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        ...,\n",
       "...\n",
       "        ...,\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan]],\n",
       "\n",
       "       [[nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        ...,\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan]],\n",
       "\n",
       "       [[nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        ...,\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan]]])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>count</span></div><div class='xr-var-dims'>(time, y, x)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>nan nan nan nan ... nan nan nan nan</div><input id='attrs-df086292-5fb0-47e6-92e4-881fbdaa40c2' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-df086292-5fb0-47e6-92e4-881fbdaa40c2' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-ce5dfa55-e230-46e1-8ac4-bfce6cbf7129' class='xr-var-data-in' type='checkbox'><label for='data-ce5dfa55-e230-46e1-8ac4-bfce6cbf7129' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>description: :</span></dt><dd>Data mask. 0: bare ground or ocean?, 1: ice?, nan: nan</dd></dl></div><div class='xr-var-data'><pre>array([[[nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        ...,\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan]],\n",
       "\n",
       "       [[nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        ...,\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan]],\n",
       "\n",
       "       [[nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        ...,\n",
       "...\n",
       "        ...,\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan]],\n",
       "\n",
       "       [[nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        ...,\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan]],\n",
       "\n",
       "       [[nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        ...,\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan]]])</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-d06a8126-5464-4346-aab1-36c33f11965f' class='xr-section-summary-in' type='checkbox'  checked><label for='section-d06a8126-5464-4346-aab1-36c33f11965f' class='xr-section-summary' >Attributes: <span>(1)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><dl class='xr-attrs'><dt><span>fileName :</span></dt><dd>mos_2010.5_2021.5.h5</dd></dl></div></li></ul></div></div>"
      ],
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:  (y: 4451, x: 5451, time: 45)\n",
       "Coordinates:\n",
       "  * y        (y) float64 2.265e+06 2.264e+06 2.263e+06 ... -2.184e+06 -2.185e+06\n",
       "  * x        (x) float64 -2.665e+06 -2.664e+06 ... 2.784e+06 2.785e+06\n",
       "  * time     (time) float64 2.01e+03 2.011e+03 2.011e+03 ... 2.021e+03 2.022e+03\n",
       "Data variables:\n",
       "    mask     (y, x) float64 nan nan nan nan nan nan ... nan nan nan nan nan nan\n",
       "    delta_h  (time, y, x) float64 nan nan nan nan nan ... nan nan nan nan nan\n",
       "    count    (time, y, x) float64 nan nan nan nan nan ... nan nan nan nan nan\n",
       "Attributes:\n",
       "    fileName:  mos_2010.5_2021.5.h5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import CryoSat-2 data (closed-source data acquired from Ben Smith)\n",
    "CS2_data = open(script_dir + '/Smith_CS2.py')\n",
    "read_file = CS2_data.read()\n",
    "exec(read_file)\n",
    "\n",
    "# view data set\n",
    "CS2_dh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><svg style=\"position: absolute; width: 0; height: 0; overflow: hidden\">\n",
       "<defs>\n",
       "<symbol id=\"icon-database\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M16 0c-8.837 0-16 2.239-16 5v4c0 2.761 7.163 5 16 5s16-2.239 16-5v-4c0-2.761-7.163-5-16-5z\"></path>\n",
       "<path d=\"M16 17c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "<path d=\"M16 26c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "</symbol>\n",
       "<symbol id=\"icon-file-text2\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M28.681 7.159c-0.694-0.947-1.662-2.053-2.724-3.116s-2.169-2.030-3.116-2.724c-1.612-1.182-2.393-1.319-2.841-1.319h-15.5c-1.378 0-2.5 1.121-2.5 2.5v27c0 1.378 1.122 2.5 2.5 2.5h23c1.378 0 2.5-1.122 2.5-2.5v-19.5c0-0.448-0.137-1.23-1.319-2.841zM24.543 5.457c0.959 0.959 1.712 1.825 2.268 2.543h-4.811v-4.811c0.718 0.556 1.584 1.309 2.543 2.268zM28 29.5c0 0.271-0.229 0.5-0.5 0.5h-23c-0.271 0-0.5-0.229-0.5-0.5v-27c0-0.271 0.229-0.5 0.5-0.5 0 0 15.499-0 15.5 0v7c0 0.552 0.448 1 1 1h7v19.5z\"></path>\n",
       "<path d=\"M23 26h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 22h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 18h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "</symbol>\n",
       "</defs>\n",
       "</svg>\n",
       "<style>/* CSS stylesheet for displaying xarray objects in jupyterlab.\n",
       " *\n",
       " */\n",
       "\n",
       ":root {\n",
       "  --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1));\n",
       "  --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54));\n",
       "  --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38));\n",
       "  --xr-border-color: var(--jp-border-color2, #e0e0e0);\n",
       "  --xr-disabled-color: var(--jp-layout-color3, #bdbdbd);\n",
       "  --xr-background-color: var(--jp-layout-color0, white);\n",
       "  --xr-background-color-row-even: var(--jp-layout-color1, white);\n",
       "  --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee);\n",
       "}\n",
       "\n",
       "html[theme=dark],\n",
       "body.vscode-dark {\n",
       "  --xr-font-color0: rgba(255, 255, 255, 1);\n",
       "  --xr-font-color2: rgba(255, 255, 255, 0.54);\n",
       "  --xr-font-color3: rgba(255, 255, 255, 0.38);\n",
       "  --xr-border-color: #1F1F1F;\n",
       "  --xr-disabled-color: #515151;\n",
       "  --xr-background-color: #111111;\n",
       "  --xr-background-color-row-even: #111111;\n",
       "  --xr-background-color-row-odd: #313131;\n",
       "}\n",
       "\n",
       ".xr-wrap {\n",
       "  display: block !important;\n",
       "  min-width: 300px;\n",
       "  max-width: 700px;\n",
       "}\n",
       "\n",
       ".xr-text-repr-fallback {\n",
       "  /* fallback to plain text repr when CSS is not injected (untrusted notebook) */\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-header {\n",
       "  padding-top: 6px;\n",
       "  padding-bottom: 6px;\n",
       "  margin-bottom: 4px;\n",
       "  border-bottom: solid 1px var(--xr-border-color);\n",
       "}\n",
       "\n",
       ".xr-header > div,\n",
       ".xr-header > ul {\n",
       "  display: inline;\n",
       "  margin-top: 0;\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-obj-type,\n",
       ".xr-array-name {\n",
       "  margin-left: 2px;\n",
       "  margin-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-obj-type {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-sections {\n",
       "  padding-left: 0 !important;\n",
       "  display: grid;\n",
       "  grid-template-columns: 150px auto auto 1fr 20px 20px;\n",
       "}\n",
       "\n",
       ".xr-section-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-section-item input {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-item input + label {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label {\n",
       "  cursor: pointer;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label:hover {\n",
       "  color: var(--xr-font-color0);\n",
       "}\n",
       "\n",
       ".xr-section-summary {\n",
       "  grid-column: 1;\n",
       "  color: var(--xr-font-color2);\n",
       "  font-weight: 500;\n",
       "}\n",
       "\n",
       ".xr-section-summary > span {\n",
       "  display: inline-block;\n",
       "  padding-left: 0.5em;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in + label:before {\n",
       "  display: inline-block;\n",
       "  content: '►';\n",
       "  font-size: 11px;\n",
       "  width: 15px;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label:before {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label:before {\n",
       "  content: '▼';\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label > span {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-summary,\n",
       ".xr-section-inline-details {\n",
       "  padding-top: 4px;\n",
       "  padding-bottom: 4px;\n",
       "}\n",
       "\n",
       ".xr-section-inline-details {\n",
       "  grid-column: 2 / -1;\n",
       "}\n",
       "\n",
       ".xr-section-details {\n",
       "  display: none;\n",
       "  grid-column: 1 / -1;\n",
       "  margin-bottom: 5px;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked ~ .xr-section-details {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-array-wrap {\n",
       "  grid-column: 1 / -1;\n",
       "  display: grid;\n",
       "  grid-template-columns: 20px auto;\n",
       "}\n",
       "\n",
       ".xr-array-wrap > label {\n",
       "  grid-column: 1;\n",
       "  vertical-align: top;\n",
       "}\n",
       "\n",
       ".xr-preview {\n",
       "  color: var(--xr-font-color3);\n",
       "}\n",
       "\n",
       ".xr-array-preview,\n",
       ".xr-array-data {\n",
       "  padding: 0 5px !important;\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-array-data,\n",
       ".xr-array-in:checked ~ .xr-array-preview {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-array-in:checked ~ .xr-array-data,\n",
       ".xr-array-preview {\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".xr-dim-list {\n",
       "  display: inline-block !important;\n",
       "  list-style: none;\n",
       "  padding: 0 !important;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list li {\n",
       "  display: inline-block;\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list:before {\n",
       "  content: '(';\n",
       "}\n",
       "\n",
       ".xr-dim-list:after {\n",
       "  content: ')';\n",
       "}\n",
       "\n",
       ".xr-dim-list li:not(:last-child):after {\n",
       "  content: ',';\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-has-index {\n",
       "  font-weight: bold;\n",
       "}\n",
       "\n",
       ".xr-var-list,\n",
       ".xr-var-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-var-item > div,\n",
       ".xr-var-item label,\n",
       ".xr-var-item > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-even);\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-var-item > .xr-var-name:hover span {\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-var-list > li:nth-child(odd) > div,\n",
       ".xr-var-list > li:nth-child(odd) > label,\n",
       ".xr-var-list > li:nth-child(odd) > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-odd);\n",
       "}\n",
       "\n",
       ".xr-var-name {\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-var-dims {\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-var-dtype {\n",
       "  grid-column: 3;\n",
       "  text-align: right;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-preview {\n",
       "  grid-column: 4;\n",
       "}\n",
       "\n",
       ".xr-var-name,\n",
       ".xr-var-dims,\n",
       ".xr-var-dtype,\n",
       ".xr-preview,\n",
       ".xr-attrs dt {\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-var-name:hover,\n",
       ".xr-var-dims:hover,\n",
       ".xr-var-dtype:hover,\n",
       ".xr-attrs dt:hover {\n",
       "  overflow: visible;\n",
       "  width: auto;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".xr-var-attrs,\n",
       ".xr-var-data {\n",
       "  display: none;\n",
       "  background-color: var(--xr-background-color) !important;\n",
       "  padding-bottom: 5px !important;\n",
       "}\n",
       "\n",
       ".xr-var-attrs-in:checked ~ .xr-var-attrs,\n",
       ".xr-var-data-in:checked ~ .xr-var-data {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       ".xr-var-data > table {\n",
       "  float: right;\n",
       "}\n",
       "\n",
       ".xr-var-name span,\n",
       ".xr-var-data,\n",
       ".xr-attrs {\n",
       "  padding-left: 25px !important;\n",
       "}\n",
       "\n",
       ".xr-attrs,\n",
       ".xr-var-attrs,\n",
       ".xr-var-data {\n",
       "  grid-column: 1 / -1;\n",
       "}\n",
       "\n",
       "dl.xr-attrs {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  display: grid;\n",
       "  grid-template-columns: 125px auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt,\n",
       ".xr-attrs dd {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  float: left;\n",
       "  padding-right: 10px;\n",
       "  width: auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt {\n",
       "  font-weight: normal;\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-attrs dt:hover span {\n",
       "  display: inline-block;\n",
       "  background: var(--xr-background-color);\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-attrs dd {\n",
       "  grid-column: 2;\n",
       "  white-space: pre-wrap;\n",
       "  word-break: break-all;\n",
       "}\n",
       "\n",
       ".xr-icon-database,\n",
       ".xr-icon-file-text2 {\n",
       "  display: inline-block;\n",
       "  vertical-align: middle;\n",
       "  width: 1em;\n",
       "  height: 1.5em !important;\n",
       "  stroke-width: 0;\n",
       "  stroke: currentColor;\n",
       "  fill: currentColor;\n",
       "}\n",
       "</style><pre class='xr-text-repr-fallback'>&lt;xarray.Dataset&gt;\n",
       "Dimensions:              (y: 4521, x: 5521, band: 1, time: 12)\n",
       "Coordinates:\n",
       "  * y                    (y) float64 2.32e+06 2.319e+06 ... -2.199e+06 -2.2e+06\n",
       "  * x                    (x) float64 -2.72e+06 -2.719e+06 ... 2.799e+06 2.8e+06\n",
       "  * band                 (band) int64 1\n",
       "    Polar_Stereographic  int64 0\n",
       "  * time                 (time) float64 273.9 365.2 ... 1.187e+03 1.278e+03\n",
       "Data variables:\n",
       "    cell_area            (band, y, x) float32 ...\n",
       "    delta_h              (time, y, x) float32 ...\n",
       "    delta_h_sigma        (time, y, x) float32 ...\n",
       "    ice_mask             (band, y, x) float32 ...\n",
       "    data_count           (time, y, x) float32 ...\n",
       "    misfit_rms           (time, y, x) float32 ...\n",
       "    misfit_scaled_rms    (time, y, x) float32 ...\n",
       "Attributes: (12/118)\n",
       "    description:                        This data set (ATL15) contains season...\n",
       "    identifier:                         atl15_qa_util\n",
       "    pulse_rate:                         10000 pps\n",
       "    type:                               Spacecraft\n",
       "    wavelength:                         532 nm\n",
       "    Description:                        Describe the group\n",
       "    ...                                 ...\n",
       "    summary:                            The purpose of ATL15 is to provide an...\n",
       "    time_coverage_duration:             70616089.15128851\n",
       "    time_coverage_end:                  2021-06-23T16:19:43.177120Z\n",
       "    time_coverage_start:                2019-03-29T08:44:54.025831Z\n",
       "    time_type:                          CCSDS UTC-A\n",
       "    vertical_datum:                     WGS84</pre><div class='xr-wrap' style='display:none'><div class='xr-header'><div class='xr-obj-type'>xarray.Dataset</div></div><ul class='xr-sections'><li class='xr-section-item'><input id='section-f49ed70e-8489-47c8-8900-5fbc1e8b4140' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-f49ed70e-8489-47c8-8900-5fbc1e8b4140' class='xr-section-summary'  title='Expand/collapse section'>Dimensions:</label><div class='xr-section-inline-details'><ul class='xr-dim-list'><li><span class='xr-has-index'>y</span>: 4521</li><li><span class='xr-has-index'>x</span>: 5521</li><li><span class='xr-has-index'>band</span>: 1</li><li><span class='xr-has-index'>time</span>: 12</li></ul></div><div class='xr-section-details'></div></li><li class='xr-section-item'><input id='section-d7a3cfc7-f648-410c-a5ad-4d3f18c1713a' class='xr-section-summary-in' type='checkbox'  checked><label for='section-d7a3cfc7-f648-410c-a5ad-4d3f18c1713a' class='xr-section-summary' >Coordinates: <span>(5)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>y</span></div><div class='xr-var-dims'>(y)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>2.32e+06 2.319e+06 ... -2.2e+06</div><input id='attrs-42b37364-225c-48df-8c59-653f2ef30336' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-42b37364-225c-48df-8c59-653f2ef30336' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-9edf6ed1-c6f3-4620-a767-fc41ea288b41' class='xr-var-data-in' type='checkbox'><label for='data-9edf6ed1-c6f3-4620-a767-fc41ea288b41' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([ 2320000.,  2319000.,  2318000., ..., -2198000., -2199000., -2200000.])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>x</span></div><div class='xr-var-dims'>(x)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>-2.72e+06 -2.719e+06 ... 2.8e+06</div><input id='attrs-fe939e4d-39b0-4bea-8077-658932f91507' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-fe939e4d-39b0-4bea-8077-658932f91507' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-d693ad87-cee7-4d9a-88b5-38c33148c2f9' class='xr-var-data-in' type='checkbox'><label for='data-d693ad87-cee7-4d9a-88b5-38c33148c2f9' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([-2720000., -2719000., -2718000., ...,  2798000.,  2799000.,  2800000.])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>band</span></div><div class='xr-var-dims'>(band)</div><div class='xr-var-dtype'>int64</div><div class='xr-var-preview xr-preview'>1</div><input id='attrs-2a2803f8-cd1e-4ebb-a556-09d1c4116576' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-2a2803f8-cd1e-4ebb-a556-09d1c4116576' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-d3013fc3-8a1d-400d-a770-20a81a3a2f98' class='xr-var-data-in' type='checkbox'><label for='data-d3013fc3-8a1d-400d-a770-20a81a3a2f98' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([1])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>Polar_Stereographic</span></div><div class='xr-var-dims'>()</div><div class='xr-var-dtype'>int64</div><div class='xr-var-preview xr-preview'>0</div><input id='attrs-63e81b6a-5cd7-4364-849c-376142e62dda' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-63e81b6a-5cd7-4364-849c-376142e62dda' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-6c84d633-d1e9-438a-9f1c-e5ba6e56bdaf' class='xr-var-data-in' type='checkbox'><label for='data-6c84d633-d1e9-438a-9f1c-e5ba6e56bdaf' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>crs_wkt :</span></dt><dd>PROJCS[&quot;WGS 84 / Antarctic Polar Stereographic&quot;,GEOGCS[&quot;WGS 84&quot;,DATUM[&quot;WGS_1984&quot;,SPHEROID[&quot;WGS 84&quot;,6378137,298.257223563,AUTHORITY[&quot;EPSG&quot;,&quot;7030&quot;]],AUTHORITY[&quot;EPSG&quot;,&quot;6326&quot;]],PRIMEM[&quot;Greenwich&quot;,0,AUTHORITY[&quot;EPSG&quot;,&quot;8901&quot;]],UNIT[&quot;degree&quot;,0.0174532925199433,AUTHORITY[&quot;EPSG&quot;,&quot;9122&quot;]],AUTHORITY[&quot;EPSG&quot;,&quot;4326&quot;]],PROJECTION[&quot;Polar_Stereographic&quot;],PARAMETER[&quot;latitude_of_origin&quot;,-71],PARAMETER[&quot;central_meridian&quot;,0],PARAMETER[&quot;false_easting&quot;,0],PARAMETER[&quot;false_northing&quot;,0],UNIT[&quot;metre&quot;,1,AUTHORITY[&quot;EPSG&quot;,&quot;9001&quot;]],AXIS[&quot;Easting&quot;,EAST],AXIS[&quot;Northing&quot;,NORTH],AUTHORITY[&quot;EPSG&quot;,&quot;3031&quot;]]</dd><dt><span>semi_major_axis :</span></dt><dd>6378137.0</dd><dt><span>semi_minor_axis :</span></dt><dd>6356752.314245179</dd><dt><span>inverse_flattening :</span></dt><dd>298.257223563</dd><dt><span>reference_ellipsoid_name :</span></dt><dd>WGS 84</dd><dt><span>longitude_of_prime_meridian :</span></dt><dd>0.0</dd><dt><span>prime_meridian_name :</span></dt><dd>Greenwich</dd><dt><span>geographic_crs_name :</span></dt><dd>WGS 84</dd><dt><span>horizontal_datum_name :</span></dt><dd>World Geodetic System 1984</dd><dt><span>projected_crs_name :</span></dt><dd>WGS 84 / Antarctic Polar Stereographic</dd><dt><span>grid_mapping_name :</span></dt><dd>polar_stereographic</dd><dt><span>standard_parallel :</span></dt><dd>-71.0</dd><dt><span>straight_vertical_longitude_from_pole :</span></dt><dd>0.0</dd><dt><span>false_easting :</span></dt><dd>0.0</dd><dt><span>false_northing :</span></dt><dd>0.0</dd><dt><span>spatial_ref :</span></dt><dd>PROJCS[&quot;WGS 84 / Antarctic Polar Stereographic&quot;,GEOGCS[&quot;WGS 84&quot;,DATUM[&quot;WGS_1984&quot;,SPHEROID[&quot;WGS 84&quot;,6378137,298.257223563,AUTHORITY[&quot;EPSG&quot;,&quot;7030&quot;]],AUTHORITY[&quot;EPSG&quot;,&quot;6326&quot;]],PRIMEM[&quot;Greenwich&quot;,0,AUTHORITY[&quot;EPSG&quot;,&quot;8901&quot;]],UNIT[&quot;degree&quot;,0.0174532925199433,AUTHORITY[&quot;EPSG&quot;,&quot;9122&quot;]],AUTHORITY[&quot;EPSG&quot;,&quot;4326&quot;]],PROJECTION[&quot;Polar_Stereographic&quot;],PARAMETER[&quot;latitude_of_origin&quot;,-71],PARAMETER[&quot;central_meridian&quot;,0],PARAMETER[&quot;false_easting&quot;,0],PARAMETER[&quot;false_northing&quot;,0],UNIT[&quot;metre&quot;,1,AUTHORITY[&quot;EPSG&quot;,&quot;9001&quot;]],AXIS[&quot;Easting&quot;,EAST],AXIS[&quot;Northing&quot;,NORTH],AUTHORITY[&quot;EPSG&quot;,&quot;3031&quot;]]</dd><dt><span>GeoTransform :</span></dt><dd>-2720500.0 1000.0 0.0 2320500.0 0.0 -1000.0</dd></dl></div><div class='xr-var-data'><pre>array(0)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>time</span></div><div class='xr-var-dims'>(time)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>273.9 365.2 ... 1.187e+03 1.278e+03</div><input id='attrs-0882da04-ec58-4f03-b43d-879822792a74' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-0882da04-ec58-4f03-b43d-879822792a74' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-df1156e0-a76a-4a7b-992e-f35d1aef4edc' class='xr-var-data-in' type='checkbox'><label for='data-df1156e0-a76a-4a7b-992e-f35d1aef4edc' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([ 273.9375,  365.25  ,  456.5625,  547.875 ,  639.1875,  730.5   ,\n",
       "        821.8125,  913.125 , 1004.4375, 1095.75  , 1187.0625, 1278.375 ])</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-50e069db-889e-4c49-b85d-b6d42bd8ae4c' class='xr-section-summary-in' type='checkbox'  checked><label for='section-50e069db-889e-4c49-b85d-b6d42bd8ae4c' class='xr-section-summary' >Data variables: <span>(7)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span>cell_area</span></div><div class='xr-var-dims'>(band, y, x)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-07c23be6-dd43-4db3-a746-5bb5b3b8cc1c' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-07c23be6-dd43-4db3-a746-5bb5b3b8cc1c' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-a834c88a-0486-4173-9198-459fd133feef' class='xr-var-data-in' type='checkbox'><label for='data-a834c88a-0486-4173-9198-459fd133feef' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>coordinates :</span></dt><dd>y x</dd><dt><span>datatype :</span></dt><dd>float32</dd><dt><span>description :</span></dt><dd>Ice-covered area of each 1x1 km grid cell, accounting for the area distortion in the polar-stereographic projections</dd><dt><span>dimensions :</span></dt><dd>y,x</dd><dt><span>least_significant_digit :</span></dt><dd>4</dd><dt><span>long_name :</span></dt><dd>cell area at 1 km</dd><dt><span>source :</span></dt><dd>ATBD section 3.4</dd><dt><span>units :</span></dt><dd>meters^2</dd><dt><span>scale_factor :</span></dt><dd>1.0</dd><dt><span>add_offset :</span></dt><dd>0.0</dd></dl></div><div class='xr-var-data'><pre>[24960441 values with dtype=float32]</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>delta_h</span></div><div class='xr-var-dims'>(time, y, x)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-c4ff23af-88f7-497e-a501-b6cfe95bf676' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-c4ff23af-88f7-497e-a501-b6cfe95bf676' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-6609ab59-7f23-4ac0-b68d-fbf6fb261464' class='xr-var-data-in' type='checkbox'><label for='data-6609ab59-7f23-4ac0-b68d-fbf6fb261464' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>coordinates :</span></dt><dd>time y x</dd><dt><span>datatype :</span></dt><dd>float32</dd><dt><span>description :</span></dt><dd>Height change relative to the datum (Jan 1, 2020) surface</dd><dt><span>dimensions :</span></dt><dd>time,y,x</dd><dt><span>least_significant_digit :</span></dt><dd>4</dd><dt><span>long_name :</span></dt><dd>quarterly height change  at 1 km</dd><dt><span>source :</span></dt><dd>ATBD section 3.4</dd><dt><span>units :</span></dt><dd>(&#x27;meters&#x27;, &#x27;meters&#x27;, &#x27;meters&#x27;, &#x27;meters&#x27;, &#x27;meters&#x27;, &#x27;meters&#x27;, &#x27;meters&#x27;, &#x27;meters&#x27;, &#x27;meters&#x27;, &#x27;meters&#x27;, &#x27;meters&#x27;, &#x27;meters&#x27;)</dd><dt><span>scale_factor :</span></dt><dd>1.0</dd><dt><span>add_offset :</span></dt><dd>0.0</dd></dl></div><div class='xr-var-data'><pre>[299525292 values with dtype=float32]</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>delta_h_sigma</span></div><div class='xr-var-dims'>(time, y, x)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-1d4bc07c-c80d-4b0b-bb5c-4730be672d3e' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-1d4bc07c-c80d-4b0b-bb5c-4730be672d3e' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-72372fb4-8a74-4f0b-a6eb-98bddee72417' class='xr-var-data-in' type='checkbox'><label for='data-72372fb4-8a74-4f0b-a6eb-98bddee72417' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>coordinates :</span></dt><dd>time y x</dd><dt><span>datatype :</span></dt><dd>float32</dd><dt><span>description :</span></dt><dd>Estimated error in height change relative to the datum (Jan 1, 2020) surface</dd><dt><span>dimensions :</span></dt><dd>time,y,x</dd><dt><span>least_significant_digit :</span></dt><dd>4</dd><dt><span>long_name :</span></dt><dd>quarterly height change uncertainty at 1 km</dd><dt><span>source :</span></dt><dd>ATBD section 3.4</dd><dt><span>units :</span></dt><dd>(&#x27;meters&#x27;, &#x27;meters&#x27;, &#x27;meters&#x27;, &#x27;meters&#x27;, &#x27;meters&#x27;, &#x27;meters&#x27;, &#x27;meters&#x27;, &#x27;meters&#x27;, &#x27;meters&#x27;, &#x27;meters&#x27;, &#x27;meters&#x27;, &#x27;meters&#x27;)</dd><dt><span>scale_factor :</span></dt><dd>1.0</dd><dt><span>add_offset :</span></dt><dd>0.0</dd></dl></div><div class='xr-var-data'><pre>[299525292 values with dtype=float32]</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>ice_mask</span></div><div class='xr-var-dims'>(band, y, x)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-8b04b9f4-1e0b-483f-be80-55f1c4aca92d' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-8b04b9f4-1e0b-483f-be80-55f1c4aca92d' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-4d26e1ec-95c9-4372-b0a8-52a44c35157f' class='xr-var-data-in' type='checkbox'><label for='data-4d26e1ec-95c9-4372-b0a8-52a44c35157f' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>coordinates :</span></dt><dd>y x</dd><dt><span>datatype :</span></dt><dd>int8</dd><dt><span>description :</span></dt><dd>Ice mask. 1: ice, 0: bare ground or ocean.</dd><dt><span>dimensions :</span></dt><dd>y,x</dd><dt><span>least_significant_digit :</span></dt><dd>4</dd><dt><span>long_name :</span></dt><dd>Ice mask at 1km</dd><dt><span>source :</span></dt><dd>ATBD section 3.3.2</dd><dt><span>units :</span></dt><dd>counts</dd><dt><span>scale_factor :</span></dt><dd>1.0</dd><dt><span>add_offset :</span></dt><dd>0.0</dd></dl></div><div class='xr-var-data'><pre>[24960441 values with dtype=float32]</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>data_count</span></div><div class='xr-var-dims'>(time, y, x)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-b64843c1-eeae-4e89-8bf9-638d7a637195' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-b64843c1-eeae-4e89-8bf9-638d7a637195' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-a12db293-feb6-4bbc-9e40-1fc650fa727b' class='xr-var-data-in' type='checkbox'><label for='data-a12db293-feb6-4bbc-9e40-1fc650fa727b' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>coordinates :</span></dt><dd>time y x</dd><dt><span>datatype :</span></dt><dd>float32</dd><dt><span>description :</span></dt><dd>Weighted number of data contributing to each node in the 1-km height-change grid</dd><dt><span>dimensions :</span></dt><dd>time,y,x</dd><dt><span>least_significant_digit :</span></dt><dd>4</dd><dt><span>long_name :</span></dt><dd>data count </dd><dt><span>source :</span></dt><dd>ATBD section 5.2.4.4</dd><dt><span>units :</span></dt><dd>(&#x27;counts&#x27;, &#x27;counts&#x27;, &#x27;counts&#x27;, &#x27;counts&#x27;, &#x27;counts&#x27;, &#x27;counts&#x27;, &#x27;counts&#x27;, &#x27;counts&#x27;, &#x27;counts&#x27;, &#x27;counts&#x27;, &#x27;counts&#x27;, &#x27;counts&#x27;)</dd><dt><span>scale_factor :</span></dt><dd>1.0</dd><dt><span>add_offset :</span></dt><dd>0.0</dd></dl></div><div class='xr-var-data'><pre>[299525292 values with dtype=float32]</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>misfit_rms</span></div><div class='xr-var-dims'>(time, y, x)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-7213a651-40f2-4c09-b1ed-8949b0e5ff58' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-7213a651-40f2-4c09-b1ed-8949b0e5ff58' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-e675386a-8dca-4db7-89ee-5f4ee1444a70' class='xr-var-data-in' type='checkbox'><label for='data-e675386a-8dca-4db7-89ee-5f4ee1444a70' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>coordinates :</span></dt><dd>time y x</dd><dt><span>datatype :</span></dt><dd>float32</dd><dt><span>description :</span></dt><dd>Misfit associated with each node in the 1-km height-change grid</dd><dt><span>dimensions :</span></dt><dd>time,y,x</dd><dt><span>least_significant_digit :</span></dt><dd>4</dd><dt><span>long_name :</span></dt><dd>rms misfit </dd><dt><span>source :</span></dt><dd>ATBD section 5.2.4.4</dd><dt><span>units :</span></dt><dd>(&#x27;meters&#x27;, &#x27;meters&#x27;, &#x27;meters&#x27;, &#x27;meters&#x27;, &#x27;meters&#x27;, &#x27;meters&#x27;, &#x27;meters&#x27;, &#x27;meters&#x27;, &#x27;meters&#x27;, &#x27;meters&#x27;, &#x27;meters&#x27;, &#x27;meters&#x27;)</dd><dt><span>scale_factor :</span></dt><dd>1.0</dd><dt><span>add_offset :</span></dt><dd>0.0</dd></dl></div><div class='xr-var-data'><pre>[299525292 values with dtype=float32]</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>misfit_scaled_rms</span></div><div class='xr-var-dims'>(time, y, x)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-49bed092-1d86-40b6-9666-2370d5522617' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-49bed092-1d86-40b6-9666-2370d5522617' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-6511494a-6e28-415b-87ff-c726fa3f9049' class='xr-var-data-in' type='checkbox'><label for='data-6511494a-6e28-415b-87ff-c726fa3f9049' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>coordinates :</span></dt><dd>time y x</dd><dt><span>datatype :</span></dt><dd>float32</dd><dt><span>description :</span></dt><dd>Scaled misfit associated with each node in the 1-km height-change grid</dd><dt><span>dimensions :</span></dt><dd>time,y,x</dd><dt><span>least_significant_digit :</span></dt><dd>4</dd><dt><span>long_name :</span></dt><dd>scaled rms misfit</dd><dt><span>source :</span></dt><dd>ATBD section 5.2.4.4</dd><dt><span>units :</span></dt><dd>(&#x27;counts&#x27;, &#x27;counts&#x27;, &#x27;counts&#x27;, &#x27;counts&#x27;, &#x27;counts&#x27;, &#x27;counts&#x27;, &#x27;counts&#x27;, &#x27;counts&#x27;, &#x27;counts&#x27;, &#x27;counts&#x27;, &#x27;counts&#x27;, &#x27;counts&#x27;)</dd><dt><span>scale_factor :</span></dt><dd>1.0</dd><dt><span>add_offset :</span></dt><dd>0.0</dd></dl></div><div class='xr-var-data'><pre>[299525292 values with dtype=float32]</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-5fd91e75-4a97-4aba-961e-913f337ffddb' class='xr-section-summary-in' type='checkbox'  ><label for='section-5fd91e75-4a97-4aba-961e-913f337ffddb' class='xr-section-summary' >Attributes: <span>(118)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><dl class='xr-attrs'><dt><span>description :</span></dt><dd>This data set (ATL15) contains seasonal, annual, and biennial gridded land ice elevation change.</dd><dt><span>identifier :</span></dt><dd>atl15_qa_util</dd><dt><span>pulse_rate :</span></dt><dd>10000 pps</dd><dt><span>type :</span></dt><dd>Spacecraft</dd><dt><span>wavelength :</span></dt><dd>532 nm</dd><dt><span>Description :</span></dt><dd>Describe the group</dd><dt><span>edition :</span></dt><dd>v1.0</dd><dt><span>publicationDate :</span></dt><dd>Feb 2020</dd><dt><span>title :</span></dt><dd>SET_BY_META</dd><dt><span>evaluationMethodType :</span></dt><dd>directInternal</dd><dt><span>measureDescription :</span></dt><dd>TBD</dd><dt><span>nameOfMeasure :</span></dt><dd>TBD</dd><dt><span>unitofMeasure :</span></dt><dd>TBD</dd><dt><span>value :</span></dt><dd>NOT_SET</dd><dt><span>scope :</span></dt><dd>NOT_SET</dd><dt><span>abstract :</span></dt><dd>The ICESat-2 ATL15 standard data product reports a land ice elevation change as comapred to an ice sheet digital elevation model (DEM).</dd><dt><span>characterSet :</span></dt><dd>utf8</dd><dt><span>creationDate :</span></dt><dd>2021-12-03T17:37:31.000000Z</dd><dt><span>credit :</span></dt><dd>The software that generates the ATL15 product was designed and implemented within the ICESat-2 Science Investigator-led Processing System at the NASA Goddard Space Flight Center in Greenbelt, Maryland.</dd><dt><span>fileName :</span></dt><dd>ATL15_AA_0311_01km_001_01.nc</dd><dt><span>language :</span></dt><dd>eng</dd><dt><span>originatorOrganizationName :</span></dt><dd>GSFC I-SIPS &gt; ICESat-2 Science Investigator-led Processing System</dd><dt><span>purpose :</span></dt><dd>The purpose of ATL15 is to provide an IceSat-2 gridded satellite summary of height changes of land-based ice.</dd><dt><span>shortName :</span></dt><dd>ATL15_META</dd><dt><span>spatialRepresentationType :</span></dt><dd>along-track</dd><dt><span>status :</span></dt><dd>onGoing</dd><dt><span>topicCategory :</span></dt><dd>geoscientificInformation</dd><dt><span>uuid :</span></dt><dd>305fa470-c888-4c58-97ce-02931bdae798</dd><dt><span>VersionID :</span></dt><dd>SET_BY_PGE</dd><dt><span>eastBoundLongitude :</span></dt><dd>180</dd><dt><span>northBoundLatitude :</span></dt><dd>-57.40598684329443</dd><dt><span>rangeBeginningDateTime :</span></dt><dd>2019-03-29T08:44:54.025831Z</dd><dt><span>rangeEndingDateTime :</span></dt><dd>2021-06-23T16:19:43.177120Z</dd><dt><span>southBoundLatitude :</span></dt><dd>-90</dd><dt><span>westBoundLongitude :</span></dt><dd>-180</dd><dt><span>version :</span></dt><dd>SET_BY_PGE</dd><dt><span>end_cycle :</span></dt><dd>[11. 11. 11. ... 11. 11. 11.]</dd><dt><span>end_geoseg :</span></dt><dd>[1443574. 1565327. 1611957. ... 1443585. 1565336. 1619112.]</dd><dt><span>end_orbit :</span></dt><dd>[14072. 14072. 14072. ... 15458. 15458. 15458.]</dd><dt><span>end_region :</span></dt><dd>[10. 11. 12. ... 10. 11. 12.]</dd><dt><span>end_rgt :</span></dt><dd>[1.000e+00 1.000e+00 1.000e+00 ... 1.387e+03 1.387e+03 1.387e+03]</dd><dt><span>start_cycle :</span></dt><dd>[3. 3. 3. ... 3. 3. 3.]</dd><dt><span>start_geoseg :</span></dt><dd>[1388506. 1443576. 1565329. ... 1433747. 1443595. 1565338.]</dd><dt><span>start_orbit :</span></dt><dd>[2976. 2976. 2976. ... 5749. 5749. 5749.]</dd><dt><span>start_region :</span></dt><dd>[10. 11. 12. ... 10. 11. 12.]</dd><dt><span>start_rgt :</span></dt><dd>[1.000e+00 1.000e+00 1.000e+00 ... 1.387e+03 1.387e+03 1.387e+03]</dd><dt><span>iso_19139_dataset_xml :</span></dt><dd>&lt;?xml version=&quot;1.0&quot;?&gt;\n",
       "&lt;gmd:DS_Series xsi:schemaLocation=&quot;http://www.isotc211.org/2005/gmi http://cdn.earthdata.nasa.gov/iso/schema/1.0/ISO19115-2_EOS.xsd&quot; xmlns:eos=&quot;http://earthdata.nasa.gov/schema/eos&quot; xmlns:gco=&quot;http://www.isotc211.org/2005/gco&quot; xmlns:gmd=&quot;http://www.isotc211.org/2005/gmd&quot; xmlns:gmi=&quot;http://www.isotc211.org/2005/gmi&quot; xmlns:gml=&quot;http://www.opengis.net/gml/3.2&quot; xmlns:gmx=&quot;http://www.isotc211.org/2005/gmx&quot; xmlns:gsr=&quot;http://www.isotc211.org/2005/gsr&quot; xmlns:gss=&quot;http://www.isotc211.org/2005/gss&quot; xmlns:gts=&quot;http://www.isotc211.org/2005/gts&quot; xmlns:srv=&quot;http://www.isotc211.org/2005/srv&quot; xmlns:xlink=&quot;http://www.w3.org/1999/xlink&quot; xmlns:xs=&quot;http://www.w3.org/2001/XMLSchema&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;&gt;\n",
       "  &lt;gmd:composedOf&gt;\n",
       "    &lt;gmd:DS_DataSet&gt;\n",
       "      &lt;gmd:has&gt;\n",
       "        &lt;gmi:MI_Metadata&gt;\n",
       "          &lt;gmd:fileIdentifier&gt;\n",
       "            &lt;gmx:FileName&gt;ATL15_AA_0311_01km_001_01.nc&lt;/gmx:FileName&gt;\n",
       "          &lt;/gmd:fileIdentifier&gt;\n",
       "          &lt;gmd:contact&gt;\n",
       "            &lt;gmd:CI_ResponsibleParty&gt;\n",
       "              &lt;gmd:organisationName&gt;\n",
       "                &lt;gco:CharacterString&gt;NSIDC DAAC &amp;gt; National Snow and Ice Data Center DAAC&lt;/gco:CharacterString&gt;\n",
       "              &lt;/gmd:organisationName&gt;\n",
       "              &lt;gmd:contactInfo&gt;\n",
       "                &lt;gmd:CI_Contact&gt;\n",
       "                  &lt;gmd:address&gt;\n",
       "                    &lt;gmd:CI_Address&gt;\n",
       "                      &lt;gmd:electronicMailAddress&gt;\n",
       "                        &lt;gco:CharacterString&gt;nsidc@nsidc.org&lt;/gco:CharacterString&gt;\n",
       "                      &lt;/gmd:electronicMailAddress&gt;\n",
       "                    &lt;/gmd:CI_Address&gt;\n",
       "                  &lt;/gmd:address&gt;\n",
       "                  &lt;gmd:onlineResource&gt;\n",
       "                    &lt;gmd:CI_OnlineResource&gt;\n",
       "                      &lt;gmd:linkage&gt;\n",
       "                        &lt;gmd:URL&gt;http://nsidc.org/daac/&lt;/gmd:URL&gt;\n",
       "                      &lt;/gmd:linkage&gt;\n",
       "                    &lt;/gmd:CI_OnlineResource&gt;\n",
       "                  &lt;/gmd:onlineResource&gt;\n",
       "                &lt;/gmd:CI_Contact&gt;\n",
       "              &lt;/gmd:contactInfo&gt;\n",
       "              &lt;gmd:role&gt;\n",
       "                &lt;gmd:CI_RoleCode codeList=&quot;http://www.isotc211.org/2005/resources/Codelist/gmxCodelists.xml#CI_RoleCode&quot; codeListValue=&quot;pointOfContact&quot;&gt;pointOfContact&lt;/gmd:CI_RoleCode&gt;\n",
       "              &lt;/gmd:role&gt;\n",
       "            &lt;/gmd:CI_ResponsibleParty&gt;\n",
       "          &lt;/gmd:contact&gt;\n",
       "          &lt;gmd:dateStamp&gt;\n",
       "            &lt;gco:DateTime&gt;2021-12-02T21:51:02.624829Z&lt;/gco:DateTime&gt;\n",
       "          &lt;/gmd:dateStamp&gt;\n",
       "          &lt;gmd:metadataStandardName&gt;\n",
       "            &lt;gco:CharacterString&gt;ISO 19115-2 Geographic information - Metadata - Part 2: Extensions for imagery and gridded data&lt;/gco:CharacterString&gt;\n",
       "          &lt;/gmd:metadataStandardName&gt;\n",
       "          &lt;gmd:metadataStandardVersion&gt;\n",
       "            &lt;gco:CharacterString&gt;ISO 19115-2:2009-02-15&lt;/gco:CharacterString&gt;\n",
       "          &lt;/gmd:metadataStandardVersion&gt;\n",
       "          &lt;gmd:identificationInfo&gt;\n",
       "            &lt;gmd:MD_DataIdentification&gt;\n",
       "              &lt;gmd:citation&gt;\n",
       "                &lt;gmd:CI_Citation&gt;\n",
       "                  &lt;gmd:title&gt;\n",
       "                    &lt;gmx:FileName&gt;ATL15_AA_0311_01km_001_01.nc&lt;/gmx:FileName&gt;\n",
       "                  &lt;/gmd:title&gt;\n",
       "                  &lt;gmd:date&gt;\n",
       "                    &lt;gmd:CI_Date&gt;\n",
       "                      &lt;gmd:date&gt;\n",
       "                        &lt;gco:DateTime&gt;2021-12-02T21:51:02.624829Z&lt;/gco:DateTime&gt;\n",
       "                      &lt;/gmd:date&gt;\n",
       "                      &lt;gmd:dateType&gt;\n",
       "                        &lt;gmd:CI_DateTypeCode codeList=&quot;http://www.isotc211.org/2005/resources/Codelist/gmxCodelists.xml#CI_DateTypeCode&quot; codeListValue=&quot;creation&quot;&gt;creation&lt;/gmd:CI_DateTypeCode&gt;\n",
       "                      &lt;/gmd:dateType&gt;\n",
       "                    &lt;/gmd:CI_Date&gt;\n",
       "                  &lt;/gmd:date&gt;\n",
       "                  &lt;gmd:identifier&gt;\n",
       "                    &lt;gmd:MD_Identifier&gt;\n",
       "                      &lt;gmd:code&gt;\n",
       "                        &lt;gco:CharacterString&gt;ATL15&lt;/gco:CharacterString&gt;\n",
       "                      &lt;/gmd:code&gt;\n",
       "                      &lt;gmd:description&gt;\n",
       "                        &lt;gco:CharacterString&gt;The ECS Short Name&lt;/gco:CharacterString&gt;\n",
       "                      &lt;/gmd:description&gt;\n",
       "                    &lt;/gmd:MD_Identifier&gt;\n",
       "                  &lt;/gmd:identifier&gt;\n",
       "                  &lt;gmd:identifier&gt;\n",
       "                    &lt;gmd:MD_Identifier&gt;\n",
       "                      &lt;gmd:code&gt;\n",
       "                        &lt;gco:CharacterString&gt;001&lt;/gco:CharacterString&gt;\n",
       "                      &lt;/gmd:code&gt;\n",
       "                      &lt;gmd:description&gt;\n",
       "                        &lt;gco:CharacterString&gt;The ECS Version ID&lt;/gco:CharacterString&gt;\n",
       "                      &lt;/gmd:description&gt;\n",
       "                    &lt;/gmd:MD_Identifier&gt;\n",
       "                  &lt;/gmd:identifier&gt;\n",
       "                  &lt;gmd:identifier&gt;\n",
       "                    &lt;gmd:MD_Identifier&gt;\n",
       "                      &lt;gmd:code&gt;\n",
       "                        &lt;gco:CharacterString&gt;ATL15_AA_0311_01km_001_01.nc&lt;/gco:CharacterString&gt;\n",
       "                      &lt;/gmd:code&gt;\n",
       "                      &lt;gmd:description&gt;\n",
       "                        &lt;gco:CharacterString&gt;ProducerGranuleId&lt;/gco:CharacterString&gt;\n",
       "                      &lt;/gmd:description&gt;\n",
       "                    &lt;/gmd:MD_Identifier&gt;\n",
       "                  &lt;/gmd:identifier&gt;\n",
       "                &lt;/gmd:CI_Citation&gt;\n",
       "              &lt;/gmd:citation&gt;\n",
       "              &lt;gmd:abstract&gt;\n",
       "                &lt;gco:CharacterString&gt;The ICESat-2 ATL15 standard data product reports ice sheet height change as compared to a digital elevation model (DEM).&lt;/gco:CharacterString&gt;\n",
       "              &lt;/gmd:abstract&gt;\n",
       "              &lt;gmd:status&gt;\n",
       "                &lt;gmd:MD_ProgressCode codeList=&quot;http://www.isotc211.org/2005/resources/Codelist/gmxCodelists.xml#MD_ProgressCode&quot; codeListValue=&quot;onGoing&quot;&gt;onGoing&lt;/gmd:MD_ProgressCode&gt;\n",
       "              &lt;/gmd:status&gt;\n",
       "              &lt;gmd:aggregationInfo&gt;\n",
       "                &lt;gmd:MD_AggregateInformation&gt;\n",
       "                  &lt;gmd:aggregateDataSetName&gt;\n",
       "                    &lt;gmd:CI_Citation&gt;\n",
       "                      &lt;gmd:title&gt;\n",
       "                        &lt;gco:CharacterString&gt;ATL15&lt;/gco:CharacterString&gt;\n",
       "                      &lt;/gmd:title&gt;\n",
       "                      &lt;gmd:date gco:nilReason=&quot;unknown&quot;/&gt;\n",
       "                      &lt;gmd:edition&gt;\n",
       "                        &lt;gco:CharacterString&gt;001&lt;/gco:CharacterString&gt;\n",
       "                      &lt;/gmd:edition&gt;\n",
       "                    &lt;/gmd:CI_Citation&gt;\n",
       "                  &lt;/gmd:aggregateDataSetName&gt;\n",
       "                  &lt;gmd:associationType&gt;\n",
       "                    &lt;gmd:DS_AssociationTypeCode codeList=&quot;http://www.isotc211.org/2005/resources/Codelist/gmxCodelists.xml#DS_AssociationTypeCode&quot; codeListValue=&quot;largerWorkCitation&quot;&gt;largerWorkCitation&lt;/gmd:DS_AssociationTypeCode&gt;\n",
       "                  &lt;/gmd:associationType&gt;\n",
       "                &lt;/gmd:MD_AggregateInformation&gt;\n",
       "              &lt;/gmd:aggregationInfo&gt;\n",
       "              &lt;gmd:language&gt;\n",
       "                &lt;gco:CharacterString&gt;eng&lt;/gco:CharacterString&gt;\n",
       "              &lt;/gmd:language&gt;\n",
       "              &lt;gmd:topicCategory&gt;\n",
       "                &lt;gmd:MD_TopicCategoryCode&gt;geoscientificInformation&lt;/gmd:MD_TopicCategoryCode&gt;\n",
       "              &lt;/gmd:topicCategory&gt;\n",
       "              &lt;gmd:extent&gt;\n",
       "                &lt;gmd:EX_Extent id=&quot;boundingExtent&quot;&gt;\n",
       "                  &lt;gmd:geographicElement&gt;\n",
       "                    &lt;gmd:EX_BoundingPolygon id=&quot;boundingPolygon0&quot;&gt;\n",
       "                     &lt;gmd:extentTypeCode&gt;\n",
       "                       &lt;gco:Boolean&gt;true&lt;/gco:Boolean&gt;\n",
       "                      &lt;/gmd:extentTypeCode&gt;\n",
       "                      &lt;gmd:polygon&gt;\n",
       "                        &lt;gml:Polygon gml:id=&quot;atl15_Poly0&quot;&gt;\n",
       "                          &lt;gml:exterior&gt;\n",
       "                            &lt;gml:LinearRing&gt;\n",
       "                              &lt;gml:posList srsDimension=&quot;2&quot; srsName=&quot;http://www.opengis.net/def/crs/EPSG/4326&quot;&gt;-57.405987  -180.000000   -57.405987   180.000000   -90.000000   180.000000   -90.000000  -180.000000   -57.405987  -180.000000&lt;/gml:posList&gt;\n",
       "                              &lt;/gml:LinearRing&gt;\n",
       "                            &lt;/gml:exterior&gt;\n",
       "                        &lt;/gml:Polygon&gt;\n",
       "                      &lt;/gmd:polygon&gt;\n",
       "                    &lt;/gmd:EX_BoundingPolygon&gt;\n",
       "                  &lt;/gmd:geographicElement&gt;\n",
       "                  &lt;gmd:temporalElement&gt;\n",
       "                    &lt;gmd:EX_TemporalExtent&gt;\n",
       "                      &lt;gmd:extent&gt;\n",
       "                        &lt;gml:TimePeriod gml:id=&quot;TIME_PERIOD_ID&quot;&gt;\n",
       "                          &lt;gml:beginPosition&gt;2019-03-29T08:44:54.025831Z&lt;/gml:beginPosition&gt;\n",
       "                          &lt;gml:endPosition&gt;2021-06-23T16:19:43.177120Z&lt;/gml:endPosition&gt;\n",
       "                        &lt;/gml:TimePeriod&gt;\n",
       "                      &lt;/gmd:extent&gt;\n",
       "                    &lt;/gmd:EX_TemporalExtent&gt;\n",
       "                  &lt;/gmd:temporalElement&gt;\n",
       "                &lt;/gmd:EX_Extent&gt;\n",
       "              &lt;/gmd:extent&gt;\n",
       "            &lt;/gmd:MD_DataIdentification&gt;\n",
       "          &lt;/gmd:identificationInfo&gt;\n",
       "          &lt;gmd:dataQualityInfo&gt;\n",
       "            &lt;gmd:DQ_DataQuality&gt;\n",
       "              &lt;gmd:scope&gt;\n",
       "                &lt;gmd:DQ_Scope&gt;\n",
       "                  &lt;gmd:level&gt;\n",
       "                    &lt;gmd:MD_ScopeCode codeList=&quot;http://www.isotc211.org/2005/resources/Codelist/gmxCodelists.xml#MD_ScopeCode&quot; codeListValue=&quot;dataset&quot;&gt;dataset&lt;/gmd:MD_ScopeCode&gt;\n",
       "                  &lt;/gmd:level&gt;\n",
       "                &lt;/gmd:DQ_Scope&gt;\n",
       "              &lt;/gmd:scope&gt;\n",
       "              &lt;gmd:lineage&gt;\n",
       "                &lt;gmd:LI_Lineage&gt;\n",
       "                  &lt;gmd:processStep&gt;\n",
       "                    &lt;gmi:LE_ProcessStep&gt;\n",
       "                      &lt;gmd:description&gt;\n",
       "                        &lt;gco:CharacterString&gt;SET_BY_PGE&lt;/gco:CharacterString&gt;\n",
       "                      &lt;/gmd:description&gt;\n",
       "                      &lt;gmd:dateTime&gt;\n",
       "                        &lt;gco:DateTime&gt;2021-12-02T21:51:02.624829Z&lt;/gco:DateTime&gt;\n",
       "                      &lt;/gmd:dateTime&gt;\n",
       "                    &lt;/gmi:LE_ProcessStep&gt;\n",
       "                  &lt;/gmd:processStep&gt;\n",
       "                &lt;/gmd:LI_Lineage&gt;\n",
       "              &lt;/gmd:lineage&gt;\n",
       "            &lt;/gmd:DQ_DataQuality&gt;\n",
       "          &lt;/gmd:dataQualityInfo&gt;\n",
       "        &lt;/gmi:MI_Metadata&gt;\n",
       "      &lt;/gmd:has&gt;\n",
       "    &lt;/gmd:DS_DataSet&gt;\n",
       "  &lt;/gmd:composedOf&gt;\n",
       "  &lt;gmd:seriesMetadata gco:nilReason=&quot;missing&quot;/&gt;\n",
       "&lt;/gmd:DS_Series&gt;\n",
       "</dd><dt><span>iso_19139_series_xml :</span></dt><dd>&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;\n",
       "&lt;gmd:DS_Series\n",
       "  xmlns:eos=&quot;http://earthdata.nasa.gov/schema/eos&quot;\n",
       "  xmlns:gco=&quot;http://www.isotc211.org/2005/gco&quot;\n",
       "  xmlns:gmd=&quot;http://www.isotc211.org/2005/gmd&quot;\n",
       "  xmlns:gmi=&quot;http://www.isotc211.org/2005/gmi&quot;\n",
       "  xmlns:gml=&quot;http://www.opengis.net/gml/3.2&quot;\n",
       "  xmlns:gmx=&quot;http://www.isotc211.org/2005/gmx&quot;\n",
       "  xmlns:gsr=&quot;http://www.isotc211.org/2005/gsr&quot;\n",
       "  xmlns:gss=&quot;http://www.isotc211.org/2005/gss&quot;\n",
       "  xmlns:gts=&quot;http://www.isotc211.org/2005/gts&quot;\n",
       "  xmlns:srv=&quot;http://www.isotc211.org/2005/srv&quot;\n",
       "  xmlns:xlink=&quot;http://www.w3.org/1999/xlink&quot;\n",
       "  xmlns:xs=&quot;http://www.w3.org/2001/XMLSchema&quot;\n",
       "  xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;\n",
       "  xsi:schemaLocation=&quot;http://www.isotc211.org/2005/gmi http://cdn.earthdata.nasa.gov/iso/schema/1.0/ISO19115-2_EOS.xsd&quot;&gt;\n",
       "  &lt;gmd:composedOf gco:nilReason=&quot;inapplicable&quot;/&gt;\n",
       "  &lt;gmd:seriesMetadata&gt;\n",
       "    &lt;gmi:MI_Metadata&gt;\n",
       "      &lt;gmd:fileIdentifier&gt;\n",
       "        &lt;gco:CharacterString&gt;ATL15.001&lt;/gco:CharacterString&gt;\n",
       "      &lt;/gmd:fileIdentifier&gt;\n",
       "      &lt;gmd:language&gt;\n",
       "        &lt;gco:CharacterString&gt;eng&lt;/gco:CharacterString&gt;\n",
       "      &lt;/gmd:language&gt;\n",
       "      &lt;gmd:characterSet&gt;\n",
       "        &lt;gmd:MD_CharacterSetCode codeList=&quot;http://cdn.earthdata.nasa.gov/iso/resources/Codelist/gmxCodelists.xml#MD_CharacterSetCode&quot; codeListValue=&quot;utf8&quot;&gt;utf8&lt;/gmd:MD_CharacterSetCode&gt;\n",
       "      &lt;/gmd:characterSet&gt;\n",
       "      &lt;gmd:hierarchyLevel&gt;\n",
       "        &lt;gmd:MD_ScopeCode codeList=&quot;http://cdn.earthdata.nasa.gov/iso/resources/Codelist/gmxCodelists.xml#MD_ScopeCode&quot; codeListValue=&quot;series&quot;&gt;series&lt;/gmd:MD_ScopeCode&gt;\n",
       "      &lt;/gmd:hierarchyLevel&gt;\n",
       "      &lt;gmd:contact&gt;\n",
       "        &lt;gmd:CI_ResponsibleParty&gt;\n",
       "          &lt;gmd:organisationName&gt;\n",
       "            &lt;gco:CharacterString&gt;NSIDC DAAC &amp;gt; NASA National Snow and Ice Data Center Distributed Active Archive Center&lt;/gco:CharacterString&gt;\n",
       "          &lt;/gmd:organisationName&gt;\n",
       "          &lt;gmd:contactInfo&gt;\n",
       "            &lt;gmd:CI_Contact id=&quot;NSIDC_DAAC_CONTACT_ID&quot;&gt;\n",
       "              &lt;gmd:phone&gt;\n",
       "                &lt;gmd:CI_Telephone&gt;\n",
       "                  &lt;gmd:voice&gt;\n",
       "                    &lt;gco:CharacterString&gt;303-492-6199&lt;/gco:CharacterString&gt;\n",
       "                  &lt;/gmd:voice&gt;\n",
       "                  &lt;gmd:facsimile&gt;\n",
       "                    &lt;gco:CharacterString&gt;303-492-2468&lt;/gco:CharacterString&gt;\n",
       "                  &lt;/gmd:facsimile&gt;\n",
       "                &lt;/gmd:CI_Telephone&gt;\n",
       "              &lt;/gmd:phone&gt;\n",
       "              &lt;gmd:address&gt;\n",
       "                &lt;gmd:CI_Address&gt;\n",
       "                  &lt;gmd:deliveryPoint&gt;\n",
       "                    &lt;gco:CharacterString&gt;1540 30th St Campus Box 449&lt;/gco:CharacterString&gt;\n",
       "                  &lt;/gmd:deliveryPoint&gt;\n",
       "                  &lt;gmd:city&gt;\n",
       "                    &lt;gco:CharacterString&gt;Boulder&lt;/gco:CharacterString&gt;\n",
       "                  &lt;/gmd:city&gt;\n",
       "                  &lt;gmd:administrativeArea&gt;\n",
       "                    &lt;gco:CharacterString&gt;Colorado&lt;/gco:CharacterString&gt;\n",
       "                  &lt;/gmd:administrativeArea&gt;\n",
       "                  &lt;gmd:postalCode&gt;\n",
       "                    &lt;gco:CharacterString&gt;80309-0449&lt;/gco:CharacterString&gt;\n",
       "                  &lt;/gmd:postalCode&gt;\n",
       "                  &lt;gmd:country&gt;\n",
       "                    &lt;gco:CharacterString&gt;USA&lt;/gco:CharacterString&gt;\n",
       "                  &lt;/gmd:country&gt;\n",
       "                  &lt;gmd:electronicMailAddress&gt;\n",
       "                    &lt;gco:CharacterString&gt;nsidc@nsidc.org&lt;/gco:CharacterString&gt;\n",
       "                  &lt;/gmd:electronicMailAddress&gt;\n",
       "                &lt;/gmd:CI_Address&gt;\n",
       "              &lt;/gmd:address&gt;\n",
       "              &lt;gmd:onlineResource&gt;\n",
       "                &lt;gmd:CI_OnlineResource&gt;\n",
       "                  &lt;gmd:linkage&gt;\n",
       "                    &lt;gmd:URL&gt;http://nsidc.org/daac/&lt;/gmd:URL&gt;\n",
       "                  &lt;/gmd:linkage&gt;\n",
       "                &lt;/gmd:CI_OnlineResource&gt;\n",
       "              &lt;/gmd:onlineResource&gt;\n",
       "              &lt;gmd:hoursOfService&gt;\n",
       "                &lt;gco:CharacterString&gt;9:00 A.M. to 5:00 P.M., U.S. Mountain Time, Monday through Friday, excluding U.S. holidays.&lt;/gco:CharacterString&gt;\n",
       "              &lt;/gmd:hoursOfService&gt;\n",
       "              &lt;gmd:contactInstructions&gt;\n",
       "                &lt;gco:CharacterString&gt;Contact by e-mail first&lt;/gco:CharacterString&gt;\n",
       "              &lt;/gmd:contactInstructions&gt;\n",
       "            &lt;/gmd:CI_Contact&gt;\n",
       "          &lt;/gmd:contactInfo&gt;\n",
       "          &lt;gmd:role&gt;\n",
       "            &lt;gmd:CI_RoleCode codeList=&quot;http://cdn.earthdata.nasa.gov/iso/resources/Codelist/gmxCodelists.xml#CI_RoleCode&quot; codeListValue=&quot;pointOfContact&quot;&gt;pointOfContact&lt;/gmd:CI_RoleCode&gt;\n",
       "          &lt;/gmd:role&gt;\n",
       "        &lt;/gmd:CI_ResponsibleParty&gt;\n",
       "      &lt;/gmd:contact&gt;\n",
       "      &lt;gmd:dateStamp&gt;\n",
       "        &lt;gco:Date&gt;2015-10-15&lt;/gco:Date&gt;\n",
       "      &lt;/gmd:dateStamp&gt;\n",
       "      &lt;gmd:metadataStandardName&gt;\n",
       "        &lt;gco:CharacterString&gt;ISO 19115-2 Geographic information - Metadata - Part 2: Extensions for imagery and gridded data&lt;/gco:CharacterString&gt;\n",
       "      &lt;/gmd:metadataStandardName&gt;\n",
       "      &lt;gmd:metadataStandardVersion&gt;\n",
       "        &lt;gco:CharacterString&gt;ISO 19115-2:2009(E)&lt;/gco:CharacterString&gt;\n",
       "      &lt;/gmd:metadataStandardVersion&gt;\n",
       "      &lt;gmd:identificationInfo&gt;\n",
       "        &lt;gmd:MD_DataIdentification&gt;\n",
       "          &lt;gmd:citation&gt;\n",
       "            &lt;gmd:CI_Citation&gt;\n",
       "              &lt;!-- ECS extracts the LongName from here --&gt;\n",
       "              &lt;!-- UMM-C expects the ShortName to precede the LongName separated by a &amp;gt; here --&gt;\n",
       "              &lt;gmd:title&gt;\n",
       "                &lt;gco:CharacterString&gt;ATLAS/ICESat-2 L3B Seasonal, Annual, and Biennial Land Ice Height Change&lt;/gco:CharacterString&gt;\n",
       "              &lt;/gmd:title&gt;\n",
       "              &lt;gmd:date&gt;\n",
       "                &lt;gmd:CI_Date&gt;\n",
       "                  &lt;!-- ECS extracts the RevisionDate from here --&gt;\n",
       "                  &lt;gmd:date&gt;\n",
       "                    &lt;gco:Date&gt;2021-06-07&lt;/gco:Date&gt;\n",
       "                  &lt;/gmd:date&gt;\n",
       "                  &lt;gmd:dateType&gt;\n",
       "                    &lt;gmd:CI_DateTypeCode codeList=&quot;http://cdn.earthdata.nasa.gov/iso/resources/Codelist/gmxCodelists.xml#CI_DateTypeCode&quot; codeListValue=&quot;revision&quot;&gt;revision&lt;/gmd:CI_DateTypeCode&gt;\n",
       "                  &lt;/gmd:dateType&gt;\n",
       "                &lt;/gmd:CI_Date&gt;\n",
       "              &lt;/gmd:date&gt;\n",
       "              &lt;!-- VersionID is expected to be here by the Base Reference Metadata Model document --&gt;\n",
       "              &lt;gmd:edition&gt;\n",
       "                &lt;gco:CharacterString&gt;001&lt;/gco:CharacterString&gt;\n",
       "              &lt;/gmd:edition&gt;\n",
       "              &lt;gmd:identifier&gt;\n",
       "                &lt;gmd:MD_Identifier&gt;\n",
       "                  &lt;!-- ECS extracts the ShortName from here --&gt;\n",
       "                  &lt;gmd:code&gt;\n",
       "                    &lt;gco:CharacterString&gt;ATL15&lt;/gco:CharacterString&gt;\n",
       "                  &lt;/gmd:code&gt;\n",
       "                  &lt;gmd:description&gt;\n",
       "                    &lt;gco:CharacterString&gt;The ECS Short Name&lt;/gco:CharacterString&gt;\n",
       "                  &lt;/gmd:description&gt;\n",
       "                &lt;/gmd:MD_Identifier&gt;\n",
       "              &lt;/gmd:identifier&gt;\n",
       "              &lt;gmd:identifier&gt;\n",
       "                &lt;gmd:MD_Identifier&gt;\n",
       "                  &lt;!-- ECS extracts the VersionID from here --&gt;\n",
       "                  &lt;gmd:code&gt;\n",
       "                    &lt;gco:CharacterString&gt;001&lt;/gco:CharacterString&gt;\n",
       "                  &lt;/gmd:code&gt;\n",
       "                  &lt;gmd:description&gt;\n",
       "                    &lt;gco:CharacterString&gt;The ECS Version ID&lt;/gco:CharacterString&gt;\n",
       "                  &lt;/gmd:description&gt;\n",
       "                &lt;/gmd:MD_Identifier&gt;\n",
       "              &lt;/gmd:identifier&gt;\n",
       "              &lt;gmd:identifier&gt;\n",
       "                &lt;gmd:MD_Identifier&gt;\n",
       "                  &lt;!-- This field provides the Digital Object Identifier (DOI). --&gt;\n",
       "                  &lt;gmd:code&gt;\n",
       "                    &lt;gmx:Anchor xlink:actuate=&quot;onRequest&quot; xlink:href=&quot;https://doi.org/10.5067/ATLAS/ATL15.001&quot;&gt;doi:10.5067/ATLAS/ATL15.001&lt;/gmx:Anchor&gt;\n",
       "                  &lt;/gmd:code&gt;\n",
       "                  &lt;gmd:codeSpace&gt;\n",
       "                    &lt;gco:CharacterString&gt;gov.nasa.esdis&lt;/gco:CharacterString&gt;\n",
       "                  &lt;/gmd:codeSpace&gt;\n",
       "                  &lt;gmd:description&gt;\n",
       "                    &lt;gco:CharacterString&gt;A Digital Object Identifier (DOI)&lt;/gco:CharacterString&gt;\n",
       "                  &lt;/gmd:description&gt;\n",
       "                &lt;/gmd:MD_Identifier&gt;\n",
       "              &lt;/gmd:identifier&gt;\n",
       "              &lt;gmd:citedResponsibleParty&gt;\n",
       "                &lt;gmd:CI_ResponsibleParty&gt;\n",
       "                  &lt;gmd:organisationName&gt;\n",
       "                    &lt;gco:CharacterString&gt;National Aeronautics and Space Administration (NASA)&lt;/gco:CharacterString&gt;\n",
       "                  &lt;/gmd:organisationName&gt;\n",
       "                  &lt;gmd:role&gt;\n",
       "                    &lt;gmd:CI_RoleCode codeList=&quot;http://www.isotc211.org/2005/resources/Codelist/gmxCodelists.xml#CI_RoleCode&quot; codeListValue=&quot;resourceProvider&quot;&gt;resourceProvider&lt;/gmd:CI_RoleCode&gt;\n",
       "                  &lt;/gmd:role&gt;\n",
       "                &lt;/gmd:CI_ResponsibleParty&gt;\n",
       "              &lt;/gmd:citedResponsibleParty&gt;\n",
       "              &lt;gmd:citedResponsibleParty&gt;\n",
       "                &lt;gmd:CI_ResponsibleParty&gt;\n",
       "                  &lt;!-- ECS expects ProcessingCenter to be here --&gt;\n",
       "                  &lt;gmd:organisationName&gt;\n",
       "                    &lt;gco:CharacterString&gt;GSFC I-SIPS &amp;gt; ICESat-2 Science Investigator-led Processing System&lt;/gco:CharacterString&gt;\n",
       "                  &lt;/gmd:organisationName&gt;\n",
       "                  &lt;gmd:role&gt;\n",
       "                    &lt;gmd:CI_RoleCode codeList=&quot;http://cdn.earthdata.nasa.gov/iso/resources/Codelist/gmxCodelists.xml#CI_RoleCode&quot; codeListValue=&quot;originator&quot;&gt;originator&lt;/gmd:CI_RoleCode&gt;\n",
       "                  &lt;/gmd:role&gt;\n",
       "                &lt;/gmd:CI_ResponsibleParty&gt;\n",
       "              &lt;/gmd:citedResponsibleParty&gt;\n",
       "              &lt;!-- ECS extracts the VersionDescription from here --&gt;\n",
       "              &lt;gmd:otherCitationDetails&gt;\n",
       "                &lt;gco:CharacterString&gt;Initial version of the processing software&lt;/gco:CharacterString&gt;\n",
       "              &lt;/gmd:otherCitationDetails&gt;\n",
       "            &lt;/gmd:CI_Citation&gt;\n",
       "          &lt;/gmd:citation&gt;\n",
       "          &lt;!-- ECS extracts the CollectionDescription from here --&gt;\n",
       "          &lt;gmd:abstract&gt;\n",
       "            &lt;gco:CharacterString&gt;The ICESat-2 ATL15 standard data product reports a land ice elevation change as comapred to an ice sheet digital elevation model (DEM).&lt;/gco:CharacterString&gt;\n",
       "          &lt;/gmd:abstract&gt;\n",
       "          &lt;gmd:purpose&gt;\n",
       "            &lt;gco:CharacterString&gt;The purpose of ATL15 is to provide an IceSat-2 gridded satellite summary of height changes of land-based ice.&lt;/gco:CharacterString&gt;\n",
       "          &lt;/gmd:purpose&gt;\n",
       "          &lt;gmd:credit&gt;\n",
       "            &lt;gco:CharacterString&gt;The software that generates the ATL15 product was designed and implemented within the ICESat-2 Science Investigator-led Processing System at the NASA Goddard Space Flight Center in Greenbelt, Maryland.&lt;/gco:CharacterString&gt;\n",
       "          &lt;/gmd:credit&gt;\n",
       "          &lt;gmd:status&gt;\n",
       "            &lt;gmd:MD_ProgressCode codeList=&quot;http://www.isotc211.org/2005/resources/Codelist/gmxCodelists.xml#MD_ProgressCode&quot; codeListValue=&quot;onGoing&quot;&gt;onGoing&lt;/gmd:MD_ProgressCode&gt;\n",
       "          &lt;/gmd:status&gt;\n",
       "          &lt;gmd:pointOfContact&gt;\n",
       "            &lt;gmd:CI_ResponsibleParty&gt;\n",
       "              &lt;!-- ECS expects ArchiveCenter to be here --&gt;\n",
       "              &lt;gmd:organisationName&gt;\n",
       "                &lt;gco:CharacterString&gt;NSIDC DAAC &amp;gt; NASA National Snow and Ice Data Center Distributed Active Archive Center&lt;/gco:CharacterString&gt;\n",
       "              &lt;/gmd:organisationName&gt;\n",
       "              &lt;gmd:contactInfo xlink:href=&quot;#NSIDC_DAAC_CONTACT_ID&quot;/&gt;\n",
       "              &lt;gmd:role&gt;\n",
       "                &lt;gmd:CI_RoleCode codeList=&quot;http://cdn.earthdata.nasa.gov/iso/resources/Codelist/gmxCodelists.xml#CI_RoleCode&quot; codeListValue=&quot;distributor&quot;&gt;distributor&lt;/gmd:CI_RoleCode&gt;\n",
       "              &lt;/gmd:role&gt;\n",
       "            &lt;/gmd:CI_ResponsibleParty&gt;\n",
       "          &lt;/gmd:pointOfContact&gt;\n",
       "          &lt;gmd:resourceFormat&gt;\n",
       "            &lt;gmd:MD_Format&gt;\n",
       "              &lt;gmd:name&gt;\n",
       "                &lt;gco:CharacterString&gt;HDF&lt;/gco:CharacterString&gt;\n",
       "              &lt;/gmd:name&gt;\n",
       "              &lt;gmd:version&gt;\n",
       "                &lt;gco:CharacterString&gt;5&lt;/gco:CharacterString&gt;\n",
       "              &lt;/gmd:version&gt;\n",
       "            &lt;/gmd:MD_Format&gt;\n",
       "          &lt;/gmd:resourceFormat&gt;\n",
       "          &lt;gmd:descriptiveKeywords&gt;\n",
       "            &lt;gmd:MD_Keywords&gt;\n",
       "              &lt;gmd:keyword&gt;\n",
       "                &lt;gco:CharacterString&gt;EARTH SCIENCE &amp;gt; CRYOSPHERE &amp;gt; GLACIERS/ICE SHEETS &amp;gt; GLACIER ELEVATION/ICE SHEET ELEVATION &amp;gt; NONE &amp;gt; NONE &amp;gt; NONE&lt;/gco:CharacterString&gt;\n",
       "              &lt;/gmd:keyword&gt;\n",
       "              &lt;gmd:keyword&gt;\n",
       "                &lt;gco:CharacterString&gt;EARTH SCIENCE &amp;gt; TERRESTRIAL HYDROSPHERE &amp;gt; GLACIERS/ICE SHEETS &amp;gt; GLACIER ELEVATION/ICE SHEET ELEVATION &amp;gt; NONE &amp;gt; NONE &amp;gt; NONE&lt;/gco:CharacterString&gt;\n",
       "              &lt;/gmd:keyword&gt;\n",
       "              &lt;gmd:type&gt;\n",
       "                &lt;gmd:MD_KeywordTypeCode codeList=&quot;http://cdn.earthdata.nasa.gov/iso/resources/Codelist/gmxCodelists.xml#MD_KeywordTypeCode&quot; codeListValue=&quot;theme&quot;&gt;theme&lt;/gmd:MD_KeywordTypeCode&gt;\n",
       "              &lt;/gmd:type&gt;\n",
       "              &lt;gmd:thesaurusName&gt;\n",
       "                &lt;gmd:CI_Citation&gt;\n",
       "                  &lt;gmd:title&gt;\n",
       "                    &lt;gco:CharacterString&gt;NASA/GCMD Science Keywords&lt;/gco:CharacterString&gt;\n",
       "                  &lt;/gmd:title&gt;\n",
       "                  &lt;gmd:date gco:nilReason=&quot;unknown&quot;/&gt;\n",
       "                  &lt;gmd:citedResponsibleParty&gt;\n",
       "                    &lt;gmd:CI_ResponsibleParty id=&quot;GCMD_USO_ID&quot;&gt;\n",
       "                      &lt;gmd:organisationName&gt;\n",
       "                        &lt;gco:CharacterString&gt;NASA Global Change Master Directory (GCMD) User Support Office&lt;/gco:CharacterString&gt;\n",
       "                      &lt;/gmd:organisationName&gt;\n",
       "                      &lt;gmd:contactInfo&gt;\n",
       "                        &lt;gmd:CI_Contact&gt;\n",
       "                          &lt;gmd:phone gco:nilReason=&quot;missing&quot;/&gt;\n",
       "                          &lt;gmd:address&gt;\n",
       "                            &lt;gmd:CI_Address&gt;\n",
       "                              &lt;gmd:deliveryPoint&gt;\n",
       "                                &lt;gco:CharacterString&gt;NASA Global Change Master Directory, Goddard Space Flight Center&lt;/gco:CharacterString&gt;\n",
       "                              &lt;/gmd:deliveryPoint&gt;\n",
       "                              &lt;gmd:city&gt;\n",
       "                                &lt;gco:CharacterString&gt;Greenbelt&lt;/gco:CharacterString&gt;\n",
       "                              &lt;/gmd:city&gt;\n",
       "                              &lt;gmd:administrativeArea&gt;\n",
       "                                &lt;gco:CharacterString&gt;MD&lt;/gco:CharacterString&gt;\n",
       "                              &lt;/gmd:administrativeArea&gt;\n",
       "                              &lt;gmd:postalCode&gt;\n",
       "                                &lt;gco:CharacterString&gt;20771&lt;/gco:CharacterString&gt;\n",
       "                              &lt;/gmd:postalCode&gt;\n",
       "                              &lt;gmd:country&gt;\n",
       "                                &lt;gco:CharacterString&gt;USA&lt;/gco:CharacterString&gt;\n",
       "                              &lt;/gmd:country&gt;\n",
       "                              &lt;gmd:electronicMailAddress&gt;\n",
       "                                &lt;gco:CharacterString&gt;gcmduso@gcmd.gsfc.nasa.gov&lt;/gco:CharacterString&gt;\n",
       "                              &lt;/gmd:electronicMailAddress&gt;\n",
       "                            &lt;/gmd:CI_Address&gt;\n",
       "                          &lt;/gmd:address&gt;\n",
       "                          &lt;gmd:onlineResource&gt;\n",
       "                            &lt;gmd:CI_OnlineResource&gt;\n",
       "                              &lt;gmd:linkage&gt;\n",
       "                                &lt;gmd:URL&gt;http://gcmd.nasa.gov/&lt;/gmd:URL&gt;\n",
       "                              &lt;/gmd:linkage&gt;\n",
       "                              &lt;gmd:protocol&gt;\n",
       "                                &lt;gco:CharacterString&gt;http&lt;/gco:CharacterString&gt;\n",
       "                              &lt;/gmd:protocol&gt;\n",
       "                              &lt;gmd:applicationProfile&gt;\n",
       "                                &lt;gco:CharacterString&gt;web browser&lt;/gco:CharacterString&gt;\n",
       "                              &lt;/gmd:applicationProfile&gt;\n",
       "                              &lt;gmd:name&gt;\n",
       "                                &lt;gco:CharacterString&gt;NASA Global Change Master Directory (GCMD)&lt;/gco:CharacterString&gt;\n",
       "                              &lt;/gmd:name&gt;\n",
       "                              &lt;gmd:description&gt;\n",
       "                                &lt;gco:CharacterString&gt;Home Page&lt;/gco:CharacterString&gt;\n",
       "                              &lt;/gmd:description&gt;\n",
       "                              &lt;gmd:function&gt;\n",
       "                                &lt;gmd:CI_OnLineFunctionCode codeList=&quot;http://cdn.earthdata.nasa.gov/iso/resources/Codelist/gmxCodelists.xml#CI_OnLineFunctionCode&quot; codeListValue=&quot;information&quot;&gt;information&lt;/gmd:CI_OnLineFunctionCode&gt;\n",
       "                              &lt;/gmd:function&gt;\n",
       "                            &lt;/gmd:CI_OnlineResource&gt;\n",
       "                          &lt;/gmd:onlineResource&gt;\n",
       "                          &lt;gmd:contactInstructions&gt;\n",
       "                            &lt;gco:CharacterString&gt;http://gcmd.nasa.gov/MailComments/MailComments.jsf?rcpt=gcmduso&lt;/gco:CharacterString&gt;\n",
       "                          &lt;/gmd:contactInstructions&gt;\n",
       "                        &lt;/gmd:CI_Contact&gt;\n",
       "                      &lt;/gmd:contactInfo&gt;\n",
       "                      &lt;gmd:role&gt;\n",
       "                        &lt;gmd:CI_RoleCode codeList=&quot;http://cdn.earthdata.nasa.gov/iso/resources/Codelist/gmxCodelists.xml#CI_RoleCode&quot; codeListValue=&quot;custodian&quot;&gt;custodian&lt;/gmd:CI_RoleCode&gt;\n",
       "                      &lt;/gmd:role&gt;\n",
       "                    &lt;/gmd:CI_ResponsibleParty&gt;\n",
       "                  &lt;/gmd:citedResponsibleParty&gt;\n",
       "                  &lt;gmd:citedResponsibleParty&gt;\n",
       "                    &lt;gmd:CI_ResponsibleParty id=&quot;GCMD_KEYWORDS_ID&quot;&gt;\n",
       "                      &lt;gmd:organisationName&gt;\n",
       "                        &lt;gco:CharacterString&gt;Global Change Master Directory (GCMD)&lt;/gco:CharacterString&gt;\n",
       "                      &lt;/gmd:organisationName&gt;\n",
       "                      &lt;gmd:contactInfo&gt;\n",
       "                        &lt;gmd:CI_Contact&gt;\n",
       "                          &lt;gmd:phone gco:nilReason=&quot;missing&quot;/&gt;\n",
       "                          &lt;gmd:address&gt;\n",
       "                            &lt;gmd:CI_Address&gt;\n",
       "                              &lt;gmd:deliveryPoint&gt;\n",
       "                                &lt;gco:CharacterString&gt;NASA Global Change Master Directory, Goddard Space Flight Center&lt;/gco:CharacterString&gt;\n",
       "                              &lt;/gmd:deliveryPoint&gt;\n",
       "                              &lt;gmd:city&gt;\n",
       "                                &lt;gco:CharacterString&gt;Greenbelt&lt;/gco:CharacterString&gt;\n",
       "                              &lt;/gmd:city&gt;\n",
       "                              &lt;gmd:administrativeArea&gt;\n",
       "                                &lt;gco:CharacterString&gt;MD&lt;/gco:CharacterString&gt;\n",
       "                              &lt;/gmd:administrativeArea&gt;\n",
       "                              &lt;gmd:postalCode&gt;\n",
       "                                &lt;gco:CharacterString&gt;20771&lt;/gco:CharacterString&gt;\n",
       "                              &lt;/gmd:postalCode&gt;\n",
       "                              &lt;gmd:country&gt;\n",
       "                                &lt;gco:CharacterString&gt;USA&lt;/gco:CharacterString&gt;\n",
       "                              &lt;/gmd:country&gt;\n",
       "                              &lt;gmd:electronicMailAddress&gt;\n",
       "                                &lt;gco:CharacterString&gt;gcmduso@gcmd.gsfc.nasa.gov&lt;/gco:CharacterString&gt;\n",
       "                              &lt;/gmd:electronicMailAddress&gt;\n",
       "                            &lt;/gmd:CI_Address&gt;\n",
       "                          &lt;/gmd:address&gt;\n",
       "                          &lt;gmd:onlineResource&gt;\n",
       "                            &lt;gmd:CI_OnlineResource&gt;\n",
       "                              &lt;gmd:linkage&gt;\n",
       "                                &lt;gmd:URL&gt;http://gcmd.nasa.gov/Resources/valids/&lt;/gmd:URL&gt;\n",
       "                              &lt;/gmd:linkage&gt;\n",
       "                              &lt;gmd:protocol&gt;\n",
       "                                &lt;gco:CharacterString&gt;http&lt;/gco:CharacterString&gt;\n",
       "                              &lt;/gmd:protocol&gt;\n",
       "                              &lt;gmd:applicationProfile&gt;\n",
       "                                &lt;gco:CharacterString&gt;web browser&lt;/gco:CharacterString&gt;\n",
       "                              &lt;/gmd:applicationProfile&gt;\n",
       "                              &lt;gmd:name&gt;\n",
       "                                &lt;gco:CharacterString&gt;NASA Global Change Master Directory (GCMD) Keyword Page&lt;/gco:CharacterString&gt;\n",
       "                              &lt;/gmd:name&gt;\n",
       "                              &lt;gmd:description&gt;\n",
       "                                &lt;gco:CharacterString&gt;This page describes the NASA GCMD Keywords, how to reference those keywords and provides download instructions.&lt;/gco:CharacterString&gt;\n",
       "                              &lt;/gmd:description&gt;\n",
       "                              &lt;gmd:function&gt;\n",
       "                                &lt;gmd:CI_OnLineFunctionCode codeList=&quot;http://cdn.earthdata.nasa.gov/iso/resources/Codelist/gmxCodelists.xml#CI_OnLineFunctionCode&quot; codeListValue=&quot;download&quot;&gt;download&lt;/gmd:CI_OnLineFunctionCode&gt;\n",
       "                              &lt;/gmd:function&gt;\n",
       "                            &lt;/gmd:CI_OnlineResource&gt;\n",
       "                          &lt;/gmd:onlineResource&gt;\n",
       "                          &lt;gmd:contactInstructions&gt;\n",
       "                            &lt;gco:CharacterString&gt;http://gcmd.nasa.gov/MailComments/MailComments.jsf?rcpt=gcmduso&lt;/gco:CharacterString&gt;\n",
       "                          &lt;/gmd:contactInstructions&gt;\n",
       "                        &lt;/gmd:CI_Contact&gt;\n",
       "                      &lt;/gmd:contactInfo&gt;\n",
       "                      &lt;gmd:role&gt;\n",
       "                        &lt;gmd:CI_RoleCode codeList=&quot;http://cdn.earthdata.nasa.gov/iso/resources/Codelist/gmxCodelists.xml#CI_RoleCode&quot; codeListValue=&quot;custodian&quot;&gt;custodian&lt;/gmd:CI_RoleCode&gt;\n",
       "                      &lt;/gmd:role&gt;\n",
       "                    &lt;/gmd:CI_ResponsibleParty&gt;\n",
       "                  &lt;/gmd:citedResponsibleParty&gt;\n",
       "                &lt;/gmd:CI_Citation&gt;\n",
       "              &lt;/gmd:thesaurusName&gt;\n",
       "            &lt;/gmd:MD_Keywords&gt;\n",
       "          &lt;/gmd:descriptiveKeywords&gt;\n",
       "          &lt;gmd:descriptiveKeywords&gt;\n",
       "            &lt;gmd:MD_Keywords&gt;\n",
       "              &lt;gmd:keyword&gt;\n",
       "                &lt;gco:CharacterString&gt;GEOGRAPHIC REGION &amp;gt; GLOBAL&lt;/gco:CharacterString&gt;\n",
       "              &lt;/gmd:keyword&gt;\n",
       "              &lt;gmd:type&gt;\n",
       "                &lt;gmd:MD_KeywordTypeCode codeList=&quot;http://cdn.earthdata.nasa.gov/iso/resources/Codelist/gmxCodelists.xml#MD_KeywordTypeCode&quot; codeListValue=&quot;place&quot;&gt;place&lt;/gmd:MD_KeywordTypeCode&gt;\n",
       "              &lt;/gmd:type&gt;\n",
       "              &lt;gmd:thesaurusName&gt;\n",
       "                &lt;gmd:CI_Citation&gt;\n",
       "                  &lt;gmd:title&gt;\n",
       "                    &lt;gco:CharacterString&gt;NASA/GCMD Location Keywords&lt;/gco:CharacterString&gt;\n",
       "                  &lt;/gmd:title&gt;\n",
       "                  &lt;gmd:date gco:nilReason=&quot;unknown&quot;/&gt;\n",
       "                  &lt;gmd:citedResponsibleParty xlink:href=&quot;#GCMD_USO_ID&quot;/&gt;\n",
       "                  &lt;gmd:citedResponsibleParty xlink:href=&quot;#GCMD_KEYWORDS_ID&quot;/&gt;\n",
       "                &lt;/gmd:CI_Citation&gt;\n",
       "              &lt;/gmd:thesaurusName&gt;\n",
       "            &lt;/gmd:MD_Keywords&gt;\n",
       "          &lt;/gmd:descriptiveKeywords&gt;\n",
       "          &lt;gmd:descriptiveKeywords&gt;\n",
       "            &lt;gmd:MD_Keywords&gt;\n",
       "              &lt;gmd:keyword&gt;\n",
       "                &lt;gco:CharacterString&gt;NASA/NSIDC_DAAC &amp;gt; NASA National Snow and Ice Data Center Distributed Active Archive Center&lt;/gco:CharacterString&gt;\n",
       "              &lt;/gmd:keyword&gt;\n",
       "              &lt;gmd:type&gt;\n",
       "                &lt;gmd:MD_KeywordTypeCode codeList=&quot;http://cdn.earthdata.nasa.gov/iso/resources/Codelist/gmxCodelists.xml#MD_KeywordTypeCode&quot; codeListValue=&quot;dataCenter&quot;&gt;dataCenter&lt;/gmd:MD_KeywordTypeCode&gt;\n",
       "              &lt;/gmd:type&gt;\n",
       "              &lt;gmd:thesaurusName&gt;\n",
       "                &lt;gmd:CI_Citation&gt;\n",
       "                  &lt;gmd:title&gt;\n",
       "                    &lt;gco:CharacterString&gt;NASA/GCMD Data Center Keywords&lt;/gco:CharacterString&gt;\n",
       "                  &lt;/gmd:title&gt;\n",
       "                  &lt;gmd:date gco:nilReason=&quot;unknown&quot;/&gt;\n",
       "                  &lt;gmd:citedResponsibleParty xlink:href=&quot;#GCMD_USO_ID&quot;/&gt;\n",
       "                  &lt;gmd:citedResponsibleParty xlink:href=&quot;#GCMD_KEYWORDS_ID&quot;/&gt;\n",
       "                &lt;/gmd:CI_Citation&gt;\n",
       "              &lt;/gmd:thesaurusName&gt;\n",
       "            &lt;/gmd:MD_Keywords&gt;\n",
       "          &lt;/gmd:descriptiveKeywords&gt;\n",
       "          &lt;gmd:descriptiveKeywords&gt;\n",
       "            &lt;gmd:MD_Keywords&gt;\n",
       "              &lt;gmd:keyword&gt;\n",
       "                &lt;gco:CharacterString&gt;Earth Observation Satellites &amp;gt; NASA Decadal Survey &amp;gt; ICESAT-2 &amp;gt; Ice, Cloud, and land Elevation Satellite-2&lt;/gco:CharacterString&gt;\n",
       "              &lt;/gmd:keyword&gt;\n",
       "              &lt;gmd:type&gt;\n",
       "                &lt;gmd:MD_KeywordTypeCode codeList=&quot;http://cdn.earthdata.nasa.gov/iso/resources/Codelist/gmxCodelists.xml#MD_KeywordTypeCode&quot; codeListValue=&quot;platform&quot;&gt;platform&lt;/gmd:MD_KeywordTypeCode&gt;\n",
       "              &lt;/gmd:type&gt;\n",
       "              &lt;gmd:thesaurusName&gt;\n",
       "                &lt;gmd:CI_Citation&gt;\n",
       "                  &lt;gmd:title&gt;\n",
       "                    &lt;gco:CharacterString&gt;NASA/GCMD Platform Keywords&lt;/gco:CharacterString&gt;\n",
       "                  &lt;/gmd:title&gt;\n",
       "                  &lt;gmd:date gco:nilReason=&quot;unknown&quot;/&gt;\n",
       "                  &lt;gmd:citedResponsibleParty xlink:href=&quot;#GCMD_USO_ID&quot;/&gt;\n",
       "                  &lt;gmd:citedResponsibleParty xlink:href=&quot;#GCMD_KEYWORDS_ID&quot;/&gt;\n",
       "                &lt;/gmd:CI_Citation&gt;\n",
       "              &lt;/gmd:thesaurusName&gt;\n",
       "            &lt;/gmd:MD_Keywords&gt;\n",
       "          &lt;/gmd:descriptiveKeywords&gt;\n",
       "          &lt;gmd:descriptiveKeywords&gt;\n",
       "            &lt;gmd:MD_Keywords&gt;\n",
       "              &lt;gmd:keyword&gt;\n",
       "                &lt;gco:CharacterString&gt;Earth Remote Sensing Instruments &amp;gt; Active Remote Sensing &amp;gt; Altimeters &amp;gt; Lidar/Laser Altimeters &amp;gt; ATLAS &amp;gt; Advanced Topographic Laser Altimeter System&lt;/gco:CharacterString&gt;\n",
       "              &lt;/gmd:keyword&gt;\n",
       "              &lt;gmd:type&gt;\n",
       "                &lt;gmd:MD_KeywordTypeCode codeList=&quot;http://cdn.earthdata.nasa.gov/iso/resources/Codelist/gmxCodelists.xml#MD_KeywordTypeCode&quot; codeListValue=&quot;instrument&quot;&gt;instrument&lt;/gmd:MD_KeywordTypeCode&gt;\n",
       "              &lt;/gmd:type&gt;\n",
       "              &lt;gmd:thesaurusName&gt;\n",
       "                &lt;gmd:CI_Citation&gt;\n",
       "                  &lt;gmd:title&gt;\n",
       "                    &lt;gco:CharacterString&gt;NASA/GCMD Instrument Keywords&lt;/gco:CharacterString&gt;\n",
       "                  &lt;/gmd:title&gt;\n",
       "                  &lt;gmd:date gco:nilReason=&quot;unknown&quot;/&gt;\n",
       "                  &lt;gmd:citedResponsibleParty xlink:href=&quot;#GCMD_USO_ID&quot;/&gt;\n",
       "                  &lt;gmd:citedResponsibleParty xlink:href=&quot;#GCMD_KEYWORDS_ID&quot;/&gt;\n",
       "                &lt;/gmd:CI_Citation&gt;\n",
       "              &lt;/gmd:thesaurusName&gt;\n",
       "            &lt;/gmd:MD_Keywords&gt;\n",
       "          &lt;/gmd:descriptiveKeywords&gt;\n",
       "          &lt;gmd:resourceConstraints&gt;\n",
       "            &lt;gmd:MD_Constraints&gt;\n",
       "              &lt;gmd:useLimitation&gt;\n",
       "                &lt;gco:CharacterString&gt;Cite these data in publications as follows: The data used in this study were produced by the ICESat-2 Science Project Office at NASA/GSFC. The data archive site is the NASA National Snow and Ice Data Center Distributed Active Archive Center.&lt;/gco:CharacterString&gt;\n",
       "              &lt;/gmd:useLimitation&gt;\n",
       "            &lt;/gmd:MD_Constraints&gt;\n",
       "          &lt;/gmd:resourceConstraints&gt;\n",
       "          &lt;gmd:language&gt;\n",
       "            &lt;gco:CharacterString&gt;eng&lt;/gco:CharacterString&gt;\n",
       "          &lt;/gmd:language&gt;\n",
       "          &lt;gmd:topicCategory&gt;\n",
       "            &lt;gmd:MD_TopicCategoryCode&gt;geoscientificInformation&lt;/gmd:MD_TopicCategoryCode&gt;\n",
       "          &lt;/gmd:topicCategory&gt;\n",
       "          &lt;gmd:extent&gt;\n",
       "            &lt;gmd:EX_Extent id=&quot;boundingExtent&quot;&gt;\n",
       "              &lt;gmd:description&gt;\n",
       "                &lt;gco:CharacterString&gt;SpatialCoverageType=HORIZONTAL, SpatialGranuleSpatialRepresentation=GEODETIC, TemporalRangeType=Continuous Range, TimeType=UTC, CoordinateSystem=CARTESIAN&lt;/gco:CharacterString&gt;\n",
       "              &lt;/gmd:description&gt;\n",
       "              &lt;gmd:geographicElement&gt;\n",
       "                &lt;gmd:EX_GeographicBoundingBox&gt;\n",
       "                  &lt;!-- ECS extracts WestBoundingCoordinate from here --&gt;\n",
       "                  &lt;gmd:westBoundLongitude&gt;\n",
       "                    &lt;gco:Decimal&gt;-180.0&lt;/gco:Decimal&gt;\n",
       "                  &lt;/gmd:westBoundLongitude&gt;\n",
       "                  &lt;!-- ECS extracts EastBoundingCoordinate from here --&gt;\n",
       "                  &lt;gmd:eastBoundLongitude&gt;\n",
       "                    &lt;gco:Decimal&gt;180.0&lt;/gco:Decimal&gt;\n",
       "                  &lt;/gmd:eastBoundLongitude&gt;\n",
       "                  &lt;!-- ECS extracts SouthBoundingCoordinate from here --&gt;\n",
       "                  &lt;gmd:southBoundLatitude&gt;\n",
       "                    &lt;gco:Decimal&gt;-90.0&lt;/gco:Decimal&gt;\n",
       "                  &lt;/gmd:southBoundLatitude&gt;\n",
       "                  &lt;!-- ECS extracts NorthBoundingCoordinate from here --&gt;\n",
       "                  &lt;gmd:northBoundLatitude&gt;\n",
       "                    &lt;gco:Decimal&gt;90.0&lt;/gco:Decimal&gt;\n",
       "                  &lt;/gmd:northBoundLatitude&gt;\n",
       "                &lt;/gmd:EX_GeographicBoundingBox&gt;\n",
       "              &lt;/gmd:geographicElement&gt;\n",
       "              &lt;gmd:temporalElement&gt;\n",
       "                &lt;gmd:EX_TemporalExtent&gt;\n",
       "                  &lt;gmd:extent&gt;\n",
       "                    &lt;gml:TimePeriod gml:id=&quot;TimePeriod_ID_1&quot;&gt;\n",
       "                      &lt;!-- ECS extracts RangeBeginningDate and RangeBeginningTime from here --&gt;\n",
       "                      &lt;gml:beginPosition&gt;2005-01-01T00:00:00Z&lt;/gml:beginPosition&gt;\n",
       "                      &lt;!-- ECS extracts RangeEndingDate and RangeEndingTime from here --&gt;\n",
       "                      &lt;gml:endPosition&gt;2021-03-24T20:39:52Z&lt;/gml:endPosition&gt;\n",
       "                    &lt;/gml:TimePeriod&gt;\n",
       "                  &lt;/gmd:extent&gt;\n",
       "                &lt;/gmd:EX_TemporalExtent&gt;\n",
       "              &lt;/gmd:temporalElement&gt;\n",
       "            &lt;/gmd:EX_Extent&gt;\n",
       "          &lt;/gmd:extent&gt;\n",
       "          &lt;gmd:processingLevel&gt;\n",
       "            &lt;gmd:MD_Identifier&gt;\n",
       "              &lt;gmd:code&gt;\n",
       "                &lt;gco:CharacterString&gt;3B&lt;/gco:CharacterString&gt;\n",
       "              &lt;/gmd:code&gt;\n",
       "              &lt;gmd:description gco:nilReason=&quot;missing&quot;/&gt;\n",
       "            &lt;/gmd:MD_Identifier&gt;\n",
       "          &lt;/gmd:processingLevel&gt;\n",
       "        &lt;/gmd:MD_DataIdentification&gt;\n",
       "      &lt;/gmd:identificationInfo&gt;\n",
       "      &lt;gmd:contentInfo&gt;\n",
       "        &lt;gmd:MD_ImageDescription&gt;\n",
       "          &lt;gmd:attributeDescription gco:nilReason=&quot;missing&quot;/&gt;\n",
       "          &lt;gmd:contentType gco:nilReason=&quot;missing&quot;/&gt;\n",
       "          &lt;gmd:processingLevelCode&gt;\n",
       "            &lt;gmd:MD_Identifier&gt;\n",
       "              &lt;gmd:code&gt;\n",
       "                &lt;gco:CharacterString&gt;3B&lt;/gco:CharacterString&gt;\n",
       "              &lt;/gmd:code&gt;\n",
       "              &lt;gmd:description gco:nilReason=&quot;missing&quot;/&gt;\n",
       "            &lt;/gmd:MD_Identifier&gt;\n",
       "          &lt;/gmd:processingLevelCode&gt;\n",
       "        &lt;/gmd:MD_ImageDescription&gt;\n",
       "      &lt;/gmd:contentInfo&gt;\n",
       "      &lt;gmd:distributionInfo&gt;\n",
       "        &lt;gmd:MD_Distribution&gt;\n",
       "          &lt;gmd:distributionFormat&gt;\n",
       "            &lt;gmd:MD_Format&gt;\n",
       "              &lt;gmd:name&gt;\n",
       "                &lt;gco:CharacterString&gt;HDF&lt;/gco:CharacterString&gt;\n",
       "              &lt;/gmd:name&gt;\n",
       "              &lt;gmd:version&gt;\n",
       "                &lt;gco:CharacterString&gt;5&lt;/gco:CharacterString&gt;\n",
       "              &lt;/gmd:version&gt;\n",
       "            &lt;/gmd:MD_Format&gt;\n",
       "          &lt;/gmd:distributionFormat&gt;\n",
       "          &lt;gmd:distributor&gt;\n",
       "            &lt;gmd:MD_Distributor&gt;\n",
       "              &lt;gmd:distributorContact&gt;\n",
       "                &lt;gmd:CI_ResponsibleParty&gt;\n",
       "                  &lt;gmd:organisationName&gt;\n",
       "                    &lt;gco:CharacterString&gt;NSIDC DAAC &amp;gt; NASA National Snow and Ice Data Center Distributed Active Archive Center&lt;/gco:CharacterString&gt;\n",
       "                  &lt;/gmd:organisationName&gt;\n",
       "                  &lt;gmd:contactInfo xlink:href=&quot;#NSIDC_DAAC_CONTACT_ID&quot;/&gt;\n",
       "                  &lt;gmd:role&gt;\n",
       "                    &lt;gmd:CI_RoleCode codeList=&quot;http://cdn.earthdata.nasa.gov/iso/resources/Codelist/gmxCodelists.xml#CI_RoleCode&quot; codeListValue=&quot;distributor&quot;&gt;distributor&lt;/gmd:CI_RoleCode&gt;\n",
       "                  &lt;/gmd:role&gt;\n",
       "                &lt;/gmd:CI_ResponsibleParty&gt;\n",
       "              &lt;/gmd:distributorContact&gt;\n",
       "              &lt;gmd:distributorTransferOptions&gt;\n",
       "                &lt;gmd:MD_DigitalTransferOptions&gt;\n",
       "                  &lt;gmd:onLine&gt;\n",
       "                    &lt;gmd:CI_OnlineResource&gt;\n",
       "                      &lt;gmd:linkage&gt;\n",
       "                        &lt;gmd:URL&gt;http://nsidc.org/data/icesat2/data.html&lt;/gmd:URL&gt;\n",
       "                      &lt;/gmd:linkage&gt;\n",
       "                      &lt;gmd:protocol&gt;\n",
       "                        &lt;gco:CharacterString&gt;http&lt;/gco:CharacterString&gt;\n",
       "                      &lt;/gmd:protocol&gt;\n",
       "                      &lt;gmd:description&gt;\n",
       "                        &lt;gco:CharacterString&gt;Data Product Description Page&lt;/gco:CharacterString&gt;\n",
       "                      &lt;/gmd:description&gt;\n",
       "                      &lt;gmd:function&gt;\n",
       "                        &lt;gmd:CI_OnLineFunctionCode codeList=&quot;http://cdn.earthdata.nasa.gov/iso/resources/Codelist/gmxCodelists.xml#CI_OnLineFunctionCode&quot; codeListValue=&quot;information&quot;&gt;information&lt;/gmd:CI_OnLineFunctionCode&gt;\n",
       "                      &lt;/gmd:function&gt;\n",
       "                    &lt;/gmd:CI_OnlineResource&gt;\n",
       "                  &lt;/gmd:onLine&gt;\n",
       "                  &lt;gmd:onLine&gt;\n",
       "                    &lt;gmd:CI_OnlineResource&gt;\n",
       "                      &lt;gmd:linkage&gt;\n",
       "                        &lt;gmd:URL&gt;http://nsidc.org/data/icesat2/order.html&lt;/gmd:URL&gt;\n",
       "                      &lt;/gmd:linkage&gt;\n",
       "                      &lt;gmd:protocol&gt;\n",
       "                        &lt;gco:CharacterString&gt;http&lt;/gco:CharacterString&gt;\n",
       "                      &lt;/gmd:protocol&gt;\n",
       "                      &lt;gmd:description&gt;\n",
       "                        &lt;gco:CharacterString&gt;Data Product Order Page&lt;/gco:CharacterString&gt;\n",
       "                      &lt;/gmd:description&gt;\n",
       "                      &lt;gmd:function&gt;\n",
       "                        &lt;gmd:CI_OnLineFunctionCode codeList=&quot;http://cdn.earthdata.nasa.gov/iso/resources/Codelist/gmxCodelists.xml#CI_OnLineFunctionCode&quot; codeListValue=&quot;order&quot;&gt;order&lt;/gmd:CI_OnLineFunctionCode&gt;\n",
       "                      &lt;/gmd:function&gt;\n",
       "                    &lt;/gmd:CI_OnlineResource&gt;\n",
       "                  &lt;/gmd:onLine&gt;\n",
       "                  &lt;gmd:onLine&gt;\n",
       "                    &lt;gmd:CI_OnlineResource&gt;\n",
       "                      &lt;gmd:linkage&gt;\n",
       "                        &lt;gmd:URL&gt;https://doi.org/10.5067/ATLAS/ATL15.001&lt;/gmd:URL&gt;\n",
       "                      &lt;/gmd:linkage&gt;\n",
       "                      &lt;gmd:protocol&gt;\n",
       "                        &lt;gco:CharacterString&gt;http&lt;/gco:CharacterString&gt;\n",
       "                      &lt;/gmd:protocol&gt;\n",
       "                      &lt;gmd:description&gt;\n",
       "                        &lt;gco:CharacterString&gt;Digital Object Identifier URL&lt;/gco:CharacterString&gt;\n",
       "                      &lt;/gmd:description&gt;\n",
       "                      &lt;gmd:function&gt;\n",
       "                        &lt;gmd:CI_OnLineFunctionCode codeList=&quot;http://cdn.earthdata.nasa.gov/iso/resources/Codelist/gmxCodelists.xml#CI_OnLineFunctionCode&quot; codeListValue=&quot;information&quot;&gt;information&lt;/gmd:CI_OnLineFunctionCode&gt;\n",
       "                      &lt;/gmd:function&gt;\n",
       "                    &lt;/gmd:CI_OnlineResource&gt;\n",
       "                  &lt;/gmd:onLine&gt;\n",
       "                &lt;/gmd:MD_DigitalTransferOptions&gt;\n",
       "              &lt;/gmd:distributorTransferOptions&gt;\n",
       "            &lt;/gmd:MD_Distributor&gt;\n",
       "          &lt;/gmd:distributor&gt;\n",
       "        &lt;/gmd:MD_Distribution&gt;\n",
       "      &lt;/gmd:distributionInfo&gt;\n",
       "      &lt;gmi:acquisitionInformation&gt;\n",
       "        &lt;gmi:MI_AcquisitionInformation&gt;\n",
       "          &lt;gmi:instrument&gt;\n",
       "            &lt;eos:EOS_Instrument id=&quot;ATLAS_INSTRUMENT_ID&quot;&gt;\n",
       "              &lt;gmi:citation&gt;\n",
       "                &lt;gmd:CI_Citation&gt;\n",
       "                  &lt;gmd:title&gt;\n",
       "                    &lt;gco:CharacterString&gt;ATLAS &amp;gt; Advanced Topographic Laser Altimeter System&lt;/gco:CharacterString&gt;\n",
       "                  &lt;/gmd:title&gt;\n",
       "                  &lt;gmd:date gco:nilReason=&quot;unknown&quot;/&gt;\n",
       "                &lt;/gmd:CI_Citation&gt;\n",
       "              &lt;/gmi:citation&gt;\n",
       "              &lt;gmi:identifier&gt;\n",
       "                &lt;gmd:MD_Identifier&gt;\n",
       "                  &lt;gmd:code&gt;\n",
       "                    &lt;gco:CharacterString&gt;ATLAS&lt;/gco:CharacterString&gt;\n",
       "                  &lt;/gmd:code&gt;\n",
       "                  &lt;gmd:description&gt;\n",
       "                    &lt;gco:CharacterString&gt;Advanced Topographic Laser Altimeter System&lt;/gco:CharacterString&gt;\n",
       "                  &lt;/gmd:description&gt;\n",
       "                &lt;/gmd:MD_Identifier&gt;\n",
       "              &lt;/gmi:identifier&gt;\n",
       "              &lt;gmi:type&gt;\n",
       "                &lt;gco:CharacterString&gt;Laser Altimeter&lt;/gco:CharacterString&gt;\n",
       "              &lt;/gmi:type&gt;\n",
       "              &lt;gmi:description&gt;\n",
       "                &lt;gco:CharacterString&gt;ATLAS on ICESat-2 determines the range between the satellite and the Earth&#x27;s surface by measuring the two-way time delay of short pulses of laser light that it transmits in six beams.  It is different from previous operational ice-sheet altimeters in that it is a photon-counting LIDAR.  ATLAS records a set of arrival times for individual photons, which are then analyzed to derive surface, vegetation, and cloud properties.  ATLAS has six beams arranged in three pairs, so that it samples each of three reference pair tracks with a pair of beams; ATLAS transmits pulses at 10 kHz, giving approximately one pulse every 0.7 m along track; ATLAS&#x27;s expected pointing control will be better than 90 m RMS.&lt;/gco:CharacterString&gt;\n",
       "              &lt;/gmi:description&gt;\n",
       "              &lt;gmi:mountedOn xlink:href=&quot;#ICESAT_2_PLATFORM_ID&quot;/&gt;\n",
       "            &lt;/eos:EOS_Instrument&gt;\n",
       "          &lt;/gmi:instrument&gt;\n",
       "          &lt;gmi:operation&gt;\n",
       "            &lt;!-- MI_Operation is expected to be here by the Base Reference Metadata Model document--&gt;\n",
       "            &lt;gmi:MI_Operation&gt;\n",
       "              &lt;gmi:description&gt;\n",
       "                &lt;gco:CharacterString&gt;ICESat-2 &amp;gt; Ice, Cloud, and land Elevation Satellite-2&lt;/gco:CharacterString&gt;\n",
       "              &lt;/gmi:description&gt;\n",
       "              &lt;gmi:citation&gt;\n",
       "                &lt;gmd:CI_Citation&gt;\n",
       "                  &lt;gmd:title&gt;\n",
       "                    &lt;gco:CharacterString&gt;ICESat-2 &amp;gt; Ice, Cloud, and land Elevation Satellite-2&lt;/gco:CharacterString&gt;\n",
       "                  &lt;/gmd:title&gt;\n",
       "                  &lt;gmd:date gco:nilReason=&quot;unknown&quot;/&gt;\n",
       "                &lt;/gmd:CI_Citation&gt;\n",
       "              &lt;/gmi:citation&gt;\n",
       "              &lt;gmi:identifier&gt;\n",
       "                &lt;gmd:MD_Identifier&gt;\n",
       "                  &lt;gmd:code&gt;\n",
       "                    &lt;gco:CharacterString&gt;ICESat-2&lt;/gco:CharacterString&gt;\n",
       "                  &lt;/gmd:code&gt;\n",
       "                  &lt;gmd:description&gt;\n",
       "                    &lt;gco:CharacterString&gt;Ice, Cloud, and land Elevation Satellite-2&lt;/gco:CharacterString&gt;\n",
       "                  &lt;/gmd:description&gt;\n",
       "                &lt;/gmd:MD_Identifier&gt;\n",
       "              &lt;/gmi:identifier&gt;\n",
       "              &lt;gmi:status&gt;\n",
       "                &lt;gmd:MD_ProgressCode codeList=&quot;http://cdn.earthdata.nasa.gov/iso/resources/Codelist/gmxCodelists.xml#MD_ProgressCode&quot; codeListValue=&quot;underDevelopment&quot;&gt;underDevelopment&lt;/gmd:MD_ProgressCode&gt;\n",
       "              &lt;/gmi:status&gt;\n",
       "              &lt;gmi:parentOperation gco:nilReason=&quot;inapplicable&quot;/&gt;\n",
       "              &lt;gmi:platform xlink:href=&quot;#ICESAT_2_PLATFORM_ID&quot;/&gt;\n",
       "            &lt;/gmi:MI_Operation&gt;\n",
       "          &lt;/gmi:operation&gt;\n",
       "          &lt;gmi:platform&gt;\n",
       "            &lt;eos:EOS_Platform id=&quot;ICESAT_2_PLATFORM_ID&quot;&gt;\n",
       "              &lt;gmi:citation&gt;\n",
       "                &lt;gmd:CI_Citation&gt;\n",
       "                  &lt;gmd:title&gt;\n",
       "                    &lt;gco:CharacterString&gt;ICESat-2 &amp;gt; Ice, Cloud, and land Elevation Satellite-2&lt;/gco:CharacterString&gt;\n",
       "                  &lt;/gmd:title&gt;\n",
       "                  &lt;gmd:date gco:nilReason=&quot;unknown&quot;/&gt;\n",
       "                &lt;/gmd:CI_Citation&gt;\n",
       "              &lt;/gmi:citation&gt;\n",
       "              &lt;gmi:identifier&gt;\n",
       "                &lt;gmd:MD_Identifier&gt;\n",
       "                  &lt;gmd:code&gt;\n",
       "                    &lt;gco:CharacterString&gt;ICESat-2&lt;/gco:CharacterString&gt;\n",
       "                  &lt;/gmd:code&gt;\n",
       "                  &lt;gmd:description&gt;\n",
       "                    &lt;gco:CharacterString&gt;Ice, Cloud, and land Elevation Satellite-2&lt;/gco:CharacterString&gt;\n",
       "                  &lt;/gmd:description&gt;\n",
       "                &lt;/gmd:MD_Identifier&gt;\n",
       "              &lt;/gmi:identifier&gt;\n",
       "              &lt;gmi:description&gt;\n",
       "                &lt;gco:CharacterString&gt;Spacecraft&lt;/gco:CharacterString&gt;\n",
       "              &lt;/gmi:description&gt;\n",
       "              &lt;gmi:instrument xlink:href=&quot;#ATLAS_INSTRUMENT_ID&quot;/&gt;\n",
       "            &lt;/eos:EOS_Platform&gt;\n",
       "          &lt;/gmi:platform&gt;\n",
       "        &lt;/gmi:MI_AcquisitionInformation&gt;\n",
       "      &lt;/gmi:acquisitionInformation&gt;\n",
       "    &lt;/gmi:MI_Metadata&gt;\n",
       "  &lt;/gmd:seriesMetadata&gt;\n",
       "&lt;/gmd:DS_Series&gt;\n",
       "</dd><dt><span>processDescription :</span></dt><dd>QA processing is performed by an external utility on each granule produced by SIPS. The utility reads the granule, performs both generic and product-specific quality-assessment calculations, and writes a text-based quality assessment report. The name and creation data of this report are identified within the QADatasetIdentification metadata</dd><dt><span>runTimeParameters :</span></dt><dd>ATL15_AA_0311_01km_001_01.ctl</dd><dt><span>softwareDate :</span></dt><dd>Nov 23 2021</dd><dt><span>softwareTitle :</span></dt><dd>ATL15 QA Utility</dd><dt><span>softwareVersion :</span></dt><dd>Version 1.0</dd><dt><span>stepDateTime :</span></dt><dd>2021-12-03T17:37:31.000000Z</dd><dt><span>ATBDDate :</span></dt><dd>12/04/2019</dd><dt><span>ATBDTitle :</span></dt><dd>Algorithm Theoretical Basis Document (ATBD) For Sea Ice Products</dd><dt><span>ATBDVersion :</span></dt><dd>N/A</dd><dt><span>documentation :</span></dt><dd>ATLAS Science Algorithm Software Design Description (SDD) - Volume 14 (atlas_l3b_is)</dd><dt><span>documentDate :</span></dt><dd>Feb 2020</dd><dt><span>ShortName :</span></dt><dd>ATL15_SDP</dd><dt><span>format :</span></dt><dd>HDF</dd><dt><span>formatVersion :</span></dt><dd>5</dd><dt><span>identifier_product_DOI :</span></dt><dd>doi:10.5067/ATLAS/ATL15.001</dd><dt><span>longName :</span></dt><dd>ATLAS/ICESat-2 L3B Seasonal, Annual, and Biennial Land Ice Height Change</dd><dt><span>maintenanceAndUpdateFrequency :</span></dt><dd>asNeeded</dd><dt><span>maintenanceDate :</span></dt><dd>SET_BY_META</dd><dt><span>mission :</span></dt><dd>ICESat-2 &gt; Ice, Cloud, and land Elevation Satellite-2</dd><dt><span>pointOfContact :</span></dt><dd>NSIDC DAAC &gt; NASA National Snow and Ice Data Center Distributed Active Archive Center</dd><dt><span>resourceProviderOrganizationName :</span></dt><dd>National Aeronautics and Space Administration (NASA)</dd><dt><span>revisionDate :</span></dt><dd>2021-06-07</dd><dt><span>asas_release :</span></dt><dd>SET_BY_PGE</dd><dt><span>citation :</span></dt><dd>Cite these data in publications as follows: The data used in this study were produced by the ICESat-2 Science Project Office at NASA/GSFC. The data archive site is the NASA National Snow and Ice Data Center Distributed Active Archive Center.</dd><dt><span>contributor_name :</span></dt><dd>Benjamin Smith (besmith@uw.edu), Tyler Sutterley (tsutterl@uw.edu), Suzanne Dickinson (sdickins@uw.edu), Benjamin Jelley (benjamin.p.jelley@nasa.gov), Denis Felikson (denis.felikson@nasa.gov), Thomas E Neumann (thomas.neumann@nasa.gov), Helen Fricker (hafricker@ucsd.edu), Alex Gardner (alex.s.gardner@jpl.nasa.gov), Laurence Padman (padman@esr.org), Thorsten Markus (thorsten.markus@nasa.gov), Nathan Kurtz (nathan.t.kurtz@nasa.gov), Suneel Bhardwaj (suneel.bhardwaj@nasa.gov), David W Hancock III (david.w.hancock@nasa.gov), Jeffrey Lee (jeffrey.e.lee@nasa.gov)</dd><dt><span>contributor_role :</span></dt><dd>Investigator, Investigator, Investigator, Investigator, Investigator, Algorithm Developer, Algorithm Developer, Algorithm Developer</dd><dt><span>Conventions :</span></dt><dd>CF-1.7</dd><dt><span>creator_name :</span></dt><dd>GSFC I-SIPS &gt; ICESat-2 Science Investigator-led Processing System</dd><dt><span>date_created :</span></dt><dd>2021-12-02T21:51:02.624829Z</dd><dt><span>date_type :</span></dt><dd>UTC</dd><dt><span>GDAL_AREA_OR_POINT :</span></dt><dd>Area</dd><dt><span>geospatial_lat_max :</span></dt><dd>-57.40598684329443</dd><dt><span>geospatial_lat_min :</span></dt><dd>-90</dd><dt><span>geospatial_lat_units :</span></dt><dd>degrees_north</dd><dt><span>geospatial_lon_max :</span></dt><dd>180</dd><dt><span>geospatial_lon_min :</span></dt><dd>-180</dd><dt><span>geospatial_lon_units :</span></dt><dd>degrees_east</dd><dt><span>granule_type :</span></dt><dd>ATL15</dd><dt><span>hdfversion :</span></dt><dd>SET_BY_PGE</dd><dt><span>history :</span></dt><dd>SET_BY_PGE</dd><dt><span>identifier_product_doi :</span></dt><dd>doi:10.5067/ATLAS/ATL15.001</dd><dt><span>identifier_product_doi_authority :</span></dt><dd>http://dx.doi.org</dd><dt><span>identifier_product_format_version :</span></dt><dd>SET_BY_PGE</dd><dt><span>identifier_product_type :</span></dt><dd>ATL15</dd><dt><span>institution :</span></dt><dd>National Aeronautics and Space Administration (NASA)</dd><dt><span>instrument :</span></dt><dd>ATLAS &gt; Advanced Topographic Laser Altimeter System</dd><dt><span>keywords :</span></dt><dd>EARTH SCIENCE &gt; CRYOSPHERE &gt; GLACIERS/ICE SHEETS &gt; GLACIER ELEVATION/ICE SHEET ELEVATION &gt; NONE &gt; NONE &gt; NONE</dd><dt><span>keywords_vocabulary :</span></dt><dd>NASA/GCMD Science Keywords</dd><dt><span>level :</span></dt><dd>L3B</dd><dt><span>license :</span></dt><dd>Data may not be reproduced or distributed without including the citation for this product included in this metadata. Data may not be distributed in an altered form without the written permission of the ICESat-2 Science Project Office at NASA/GSFC.</dd><dt><span>naming_authority :</span></dt><dd>http://dx.doi.org</dd><dt><span>netcdfversion :</span></dt><dd>4.7.4</dd><dt><span>platform :</span></dt><dd>ICESat-2 &gt; Ice, Cloud, and land Elevation Satellite-2</dd><dt><span>processing_level :</span></dt><dd>3B</dd><dt><span>project :</span></dt><dd>ICESat-2 &gt; Ice, Cloud, and land Elevation Satellite-2</dd><dt><span>publisher_email :</span></dt><dd>nsidc@nsidc.org</dd><dt><span>publisher_name :</span></dt><dd>NSIDC DAAC &gt; NASA National Snow and Ice Data Center Distributed Active Archive Center</dd><dt><span>publisher_url :</span></dt><dd>http://nsidc.org/daac/</dd><dt><span>references :</span></dt><dd>http://nsidc.org/data/icesat2/data.html</dd><dt><span>reference_frame :</span></dt><dd>ITRF2014</dd><dt><span>short_name :</span></dt><dd>ATL15</dd><dt><span>source :</span></dt><dd>Spacecraft</dd><dt><span>spatial_coverage_type :</span></dt><dd>Horizontal</dd><dt><span>standard_name_vocabulary :</span></dt><dd>CF-1.6</dd><dt><span>summary :</span></dt><dd>The purpose of ATL15 is to provide an IceSat-2 gridded satellite summary of height changes of land-based ice.</dd><dt><span>time_coverage_duration :</span></dt><dd>70616089.15128851</dd><dt><span>time_coverage_end :</span></dt><dd>2021-06-23T16:19:43.177120Z</dd><dt><span>time_coverage_start :</span></dt><dd>2019-03-29T08:44:54.025831Z</dd><dt><span>time_type :</span></dt><dd>CCSDS UTC-A</dd><dt><span>vertical_datum :</span></dt><dd>WGS84</dd></dl></div></li></ul></div></div>"
      ],
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:              (y: 4521, x: 5521, band: 1, time: 12)\n",
       "Coordinates:\n",
       "  * y                    (y) float64 2.32e+06 2.319e+06 ... -2.199e+06 -2.2e+06\n",
       "  * x                    (x) float64 -2.72e+06 -2.719e+06 ... 2.799e+06 2.8e+06\n",
       "  * band                 (band) int64 1\n",
       "    Polar_Stereographic  int64 0\n",
       "  * time                 (time) float64 273.9 365.2 ... 1.187e+03 1.278e+03\n",
       "Data variables:\n",
       "    cell_area            (band, y, x) float32 ...\n",
       "    delta_h              (time, y, x) float32 ...\n",
       "    delta_h_sigma        (time, y, x) float32 ...\n",
       "    ice_mask             (band, y, x) float32 ...\n",
       "    data_count           (time, y, x) float32 ...\n",
       "    misfit_rms           (time, y, x) float32 ...\n",
       "    misfit_scaled_rms    (time, y, x) float32 ...\n",
       "Attributes: (12/118)\n",
       "    description:                        This data set (ATL15) contains season...\n",
       "    identifier:                         atl15_qa_util\n",
       "    pulse_rate:                         10000 pps\n",
       "    type:                               Spacecraft\n",
       "    wavelength:                         532 nm\n",
       "    Description:                        Describe the group\n",
       "    ...                                 ...\n",
       "    summary:                            The purpose of ATL15 is to provide an...\n",
       "    time_coverage_duration:             70616089.15128851\n",
       "    time_coverage_end:                  2021-06-23T16:19:43.177120Z\n",
       "    time_coverage_start:                2019-03-29T08:44:54.025831Z\n",
       "    time_type:                          CCSDS UTC-A\n",
       "    vertical_datum:                     WGS84"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import ICESat-2 ATL15 Gridded Antarctic and Arctic Land Ice Height Change data product \n",
    "# https://doi.org/10.5067/ATLAS/ATL15.001\n",
    "file = data_dir + '/altimetry/ICESat-2/ATL15.001-Ant/ATL15_AA_0311_01km_001_01.nc'\n",
    "ATL15_dh = rioxarray.open_rasterio(file, group='delta_h', masked=True)\n",
    "# display xarray data set meta data\n",
    "ATL15_dh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scripps Grounding Line\n",
    "# https://doi.pangaea.de/10.1594/PANGAEA.819147\n",
    "Scripps_gl = gpd.read_file(data_dir + '/boundaries/Depoorter2013-boundaries/scripps_antarctica_polygons_v1.shp' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import subglacial lake outlines \n",
    "outlines = open(script_dir + '/Smith2009_outlines.py')\n",
    "read_file = outlines.read()\n",
    "exec(read_file)\n",
    "\n",
    "outlines = open(script_dir + '/SiegfriedFricker2018_outlines.py')\n",
    "read_file = outlines.read()\n",
    "exec(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>geometry</th>\n",
       "      <th>area (m^2)</th>\n",
       "      <th>perimeter (m)</th>\n",
       "      <th>cite</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Byrd_s1</td>\n",
       "      <td>POLYGON ((485674.120 -925528.902, 487712.653 -...</td>\n",
       "      <td>1.718639e+08</td>\n",
       "      <td>49204.386135</td>\n",
       "      <td>Smith and others, 2009, J. Glac., doi:10.3189/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Byrd_s3</td>\n",
       "      <td>POLYGON ((448649.741 -765043.898, 450532.915 -...</td>\n",
       "      <td>7.293213e+07</td>\n",
       "      <td>30837.269210</td>\n",
       "      <td>Smith and others, 2009, J. Glac., doi:10.3189/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cook_E1</td>\n",
       "      <td>POLYGON ((829182.800 -1794308.733, 830125.592 ...</td>\n",
       "      <td>2.642098e+08</td>\n",
       "      <td>60912.169435</td>\n",
       "      <td>Smith and others, 2009, J. Glac., doi:10.3189/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>David_1</td>\n",
       "      <td>POLYGON ((602372.876 -1478703.451, 603495.338 ...</td>\n",
       "      <td>9.599200e+08</td>\n",
       "      <td>115518.929731</td>\n",
       "      <td>Smith and others, 2009, J. Glac., doi:10.3189/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>David_s1</td>\n",
       "      <td>POLYGON ((660030.476 -1451099.814, 661929.661 ...</td>\n",
       "      <td>1.929171e+08</td>\n",
       "      <td>49712.162343</td>\n",
       "      <td>Smith and others, 2009, J. Glac., doi:10.3189/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Foundation_1</td>\n",
       "      <td>POLYGON ((-558303.980 312113.150, -556309.653 ...</td>\n",
       "      <td>1.961027e+08</td>\n",
       "      <td>54407.011135</td>\n",
       "      <td>Smith and others, 2009, J. Glac., doi:10.3189/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Foundation_2</td>\n",
       "      <td>POLYGON ((-502447.609 323781.186, -500635.007 ...</td>\n",
       "      <td>7.165268e+07</td>\n",
       "      <td>30708.363593</td>\n",
       "      <td>Smith and others, 2009, J. Glac., doi:10.3189/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Foundation_3</td>\n",
       "      <td>POLYGON ((-502644.404 304289.262, -501259.527 ...</td>\n",
       "      <td>2.184164e+07</td>\n",
       "      <td>17522.374490</td>\n",
       "      <td>Smith and others, 2009, J. Glac., doi:10.3189/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Foundation_4</td>\n",
       "      <td>POLYGON ((-470982.992 316376.719, -471176.081 ...</td>\n",
       "      <td>7.930457e+07</td>\n",
       "      <td>31776.545946</td>\n",
       "      <td>Smith and others, 2009, J. Glac., doi:10.3189/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Foundation_5</td>\n",
       "      <td>POLYGON ((-456251.645 337815.286, -454589.088 ...</td>\n",
       "      <td>9.177758e+07</td>\n",
       "      <td>37361.413373</td>\n",
       "      <td>Smith and others, 2009, J. Glac., doi:10.3189/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Institute_E1</td>\n",
       "      <td>POLYGON ((-836825.409 231944.199, -835372.896 ...</td>\n",
       "      <td>4.621437e+08</td>\n",
       "      <td>80257.229278</td>\n",
       "      <td>Smith and others, 2009, J. Glac., doi:10.3189/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Institute_E2</td>\n",
       "      <td>POLYGON ((-794246.620 154826.448, -792417.282 ...</td>\n",
       "      <td>7.667833e+07</td>\n",
       "      <td>33158.171411</td>\n",
       "      <td>Smith and others, 2009, J. Glac., doi:10.3189/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Institute_W1</td>\n",
       "      <td>POLYGON ((-915982.790 205937.854, -915152.147 ...</td>\n",
       "      <td>8.502658e+07</td>\n",
       "      <td>33793.058918</td>\n",
       "      <td>Smith and others, 2009, J. Glac., doi:10.3189/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Institute_W2</td>\n",
       "      <td>POLYGON ((-911253.882 100854.988, -910835.143 ...</td>\n",
       "      <td>6.635862e+07</td>\n",
       "      <td>30494.725858</td>\n",
       "      <td>Smith and others, 2009, J. Glac., doi:10.3189/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Lambert_1</td>\n",
       "      <td>POLYGON ((1609621.308 647722.246, 1609895.046 ...</td>\n",
       "      <td>6.247935e+08</td>\n",
       "      <td>91864.817300</td>\n",
       "      <td>Smith and others, 2009, J. Glac., doi:10.3189/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LennoxKing_1</td>\n",
       "      <td>POLYGON ((217194.716 -522095.759, 219003.302 -...</td>\n",
       "      <td>3.668237e+07</td>\n",
       "      <td>22955.904463</td>\n",
       "      <td>Smith and others, 2009, J. Glac., doi:10.3189/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Nimrod_1</td>\n",
       "      <td>POLYGON ((345840.406 -612619.805, 346660.006 -...</td>\n",
       "      <td>7.748673e+07</td>\n",
       "      <td>32701.865632</td>\n",
       "      <td>Smith and others, 2009, J. Glac., doi:10.3189/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Ninnis_1</td>\n",
       "      <td>POLYGON ((1120237.973 -1921686.742, 1122239.94...</td>\n",
       "      <td>1.887194e+08</td>\n",
       "      <td>50658.748856</td>\n",
       "      <td>Smith and others, 2009, J. Glac., doi:10.3189/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Ninnis_2</td>\n",
       "      <td>POLYGON ((1064316.832 -1800848.484, 1065918.93...</td>\n",
       "      <td>2.268832e+08</td>\n",
       "      <td>54647.138884</td>\n",
       "      <td>Smith and others, 2009, J. Glac., doi:10.3189/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Slessor_1</td>\n",
       "      <td>POLYGON ((-475174.305 982851.137, -473209.917 ...</td>\n",
       "      <td>2.551321e+08</td>\n",
       "      <td>69179.324150</td>\n",
       "      <td>Smith and others, 2009, J. Glac., doi:10.3189/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Whillans_6</td>\n",
       "      <td>POLYGON ((-451544.869 -488823.261, -451209.964...</td>\n",
       "      <td>7.458477e+07</td>\n",
       "      <td>31952.842516</td>\n",
       "      <td>Smith and others, 2009, J. Glac., doi:10.3189/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Whillans_7</td>\n",
       "      <td>POLYGON ((-543163.376 -500759.165, -542800.367...</td>\n",
       "      <td>7.696570e+07</td>\n",
       "      <td>32373.996995</td>\n",
       "      <td>Smith and others, 2009, J. Glac., doi:10.3189/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            name                                           geometry  \\\n",
       "0        Byrd_s1  POLYGON ((485674.120 -925528.902, 487712.653 -...   \n",
       "1        Byrd_s3  POLYGON ((448649.741 -765043.898, 450532.915 -...   \n",
       "2        Cook_E1  POLYGON ((829182.800 -1794308.733, 830125.592 ...   \n",
       "3        David_1  POLYGON ((602372.876 -1478703.451, 603495.338 ...   \n",
       "4       David_s1  POLYGON ((660030.476 -1451099.814, 661929.661 ...   \n",
       "5   Foundation_1  POLYGON ((-558303.980 312113.150, -556309.653 ...   \n",
       "6   Foundation_2  POLYGON ((-502447.609 323781.186, -500635.007 ...   \n",
       "7   Foundation_3  POLYGON ((-502644.404 304289.262, -501259.527 ...   \n",
       "8   Foundation_4  POLYGON ((-470982.992 316376.719, -471176.081 ...   \n",
       "9   Foundation_5  POLYGON ((-456251.645 337815.286, -454589.088 ...   \n",
       "10  Institute_E1  POLYGON ((-836825.409 231944.199, -835372.896 ...   \n",
       "11  Institute_E2  POLYGON ((-794246.620 154826.448, -792417.282 ...   \n",
       "12  Institute_W1  POLYGON ((-915982.790 205937.854, -915152.147 ...   \n",
       "13  Institute_W2  POLYGON ((-911253.882 100854.988, -910835.143 ...   \n",
       "14     Lambert_1  POLYGON ((1609621.308 647722.246, 1609895.046 ...   \n",
       "15  LennoxKing_1  POLYGON ((217194.716 -522095.759, 219003.302 -...   \n",
       "16      Nimrod_1  POLYGON ((345840.406 -612619.805, 346660.006 -...   \n",
       "17      Ninnis_1  POLYGON ((1120237.973 -1921686.742, 1122239.94...   \n",
       "18      Ninnis_2  POLYGON ((1064316.832 -1800848.484, 1065918.93...   \n",
       "19     Slessor_1  POLYGON ((-475174.305 982851.137, -473209.917 ...   \n",
       "20    Whillans_6  POLYGON ((-451544.869 -488823.261, -451209.964...   \n",
       "21    Whillans_7  POLYGON ((-543163.376 -500759.165, -542800.367...   \n",
       "\n",
       "      area (m^2)  perimeter (m)  \\\n",
       "0   1.718639e+08   49204.386135   \n",
       "1   7.293213e+07   30837.269210   \n",
       "2   2.642098e+08   60912.169435   \n",
       "3   9.599200e+08  115518.929731   \n",
       "4   1.929171e+08   49712.162343   \n",
       "5   1.961027e+08   54407.011135   \n",
       "6   7.165268e+07   30708.363593   \n",
       "7   2.184164e+07   17522.374490   \n",
       "8   7.930457e+07   31776.545946   \n",
       "9   9.177758e+07   37361.413373   \n",
       "10  4.621437e+08   80257.229278   \n",
       "11  7.667833e+07   33158.171411   \n",
       "12  8.502658e+07   33793.058918   \n",
       "13  6.635862e+07   30494.725858   \n",
       "14  6.247935e+08   91864.817300   \n",
       "15  3.668237e+07   22955.904463   \n",
       "16  7.748673e+07   32701.865632   \n",
       "17  1.887194e+08   50658.748856   \n",
       "18  2.268832e+08   54647.138884   \n",
       "19  2.551321e+08   69179.324150   \n",
       "20  7.458477e+07   31952.842516   \n",
       "21  7.696570e+07   32373.996995   \n",
       "\n",
       "                                                 cite  \n",
       "0   Smith and others, 2009, J. Glac., doi:10.3189/...  \n",
       "1   Smith and others, 2009, J. Glac., doi:10.3189/...  \n",
       "2   Smith and others, 2009, J. Glac., doi:10.3189/...  \n",
       "3   Smith and others, 2009, J. Glac., doi:10.3189/...  \n",
       "4   Smith and others, 2009, J. Glac., doi:10.3189/...  \n",
       "5   Smith and others, 2009, J. Glac., doi:10.3189/...  \n",
       "6   Smith and others, 2009, J. Glac., doi:10.3189/...  \n",
       "7   Smith and others, 2009, J. Glac., doi:10.3189/...  \n",
       "8   Smith and others, 2009, J. Glac., doi:10.3189/...  \n",
       "9   Smith and others, 2009, J. Glac., doi:10.3189/...  \n",
       "10  Smith and others, 2009, J. Glac., doi:10.3189/...  \n",
       "11  Smith and others, 2009, J. Glac., doi:10.3189/...  \n",
       "12  Smith and others, 2009, J. Glac., doi:10.3189/...  \n",
       "13  Smith and others, 2009, J. Glac., doi:10.3189/...  \n",
       "14  Smith and others, 2009, J. Glac., doi:10.3189/...  \n",
       "15  Smith and others, 2009, J. Glac., doi:10.3189/...  \n",
       "16  Smith and others, 2009, J. Glac., doi:10.3189/...  \n",
       "17  Smith and others, 2009, J. Glac., doi:10.3189/...  \n",
       "18  Smith and others, 2009, J. Glac., doi:10.3189/...  \n",
       "19  Smith and others, 2009, J. Glac., doi:10.3189/...  \n",
       "20  Smith and others, 2009, J. Glac., doi:10.3189/...  \n",
       "21  Smith and others, 2009, J. Glac., doi:10.3189/...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SiegfriedFricker2018_S09outlines_CS2InSAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>geometry</th>\n",
       "      <th>area (m^2)</th>\n",
       "      <th>perimeter (m)</th>\n",
       "      <th>cite</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ConwaySubglacialLake</td>\n",
       "      <td>POLYGON ((-312825.002 -511425.001, -312699.997...</td>\n",
       "      <td>2.669973e+08</td>\n",
       "      <td>93967.290533</td>\n",
       "      <td>Fricker &amp; Scambos, 2009, J. Glac., doi:10.3189...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cook_E2</td>\n",
       "      <td>POLYGON ((765592.392 -1714713.856, 765682.174 ...</td>\n",
       "      <td>2.680933e+08</td>\n",
       "      <td>127109.861123</td>\n",
       "      <td>McMillan and others, 2013, GRL, doi:10.1002/gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EngelhardtSubglacialLake</td>\n",
       "      <td>POLYGON ((-271824.984 -628674.969, -271699.995...</td>\n",
       "      <td>3.577632e+08</td>\n",
       "      <td>122225.431584</td>\n",
       "      <td>Fricker &amp; Scambos, 2009, J. Glac., doi:10.3189...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KT1</td>\n",
       "      <td>POLYGON ((-556189.687 -681400.000, -556000.000...</td>\n",
       "      <td>4.549884e+07</td>\n",
       "      <td>31575.761008</td>\n",
       "      <td>Kim and others, 2016, TC, doi:10.5194/tc-10-29...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KT2</td>\n",
       "      <td>POLYGON ((-441794.803 -712600.000, -441600.000...</td>\n",
       "      <td>3.315274e+07</td>\n",
       "      <td>32351.217554</td>\n",
       "      <td>Kim and others, 2016, TC, doi:10.5194/tc-10-29...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KT3</td>\n",
       "      <td>POLYGON ((-399646.273 -716600.000, -399600.000...</td>\n",
       "      <td>4.055444e+07</td>\n",
       "      <td>33296.288468</td>\n",
       "      <td>Kim and others, 2016, TC, doi:10.5194/tc-10-29...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lake10</td>\n",
       "      <td>POLYGON ((-227949.981 -569549.997, -228075.000...</td>\n",
       "      <td>2.587121e+07</td>\n",
       "      <td>21525.193986</td>\n",
       "      <td>Fricker &amp; Scambos, 2009, J. Glac., doi:10.3189...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Lake12</td>\n",
       "      <td>POLYGON ((-224449.970 -604674.969, -224449.970...</td>\n",
       "      <td>6.689842e+07</td>\n",
       "      <td>31339.673859</td>\n",
       "      <td>Fricker &amp; Scambos, 2009, J. Glac., doi:10.3189...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Lake78</td>\n",
       "      <td>MULTIPOLYGON (((-257325.009 -525800.047, -2571...</td>\n",
       "      <td>2.330027e+08</td>\n",
       "      <td>128470.660267</td>\n",
       "      <td>Carter and others, 2013, J. Glac., doi:10.3189...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Mac1</td>\n",
       "      <td>POLYGON ((-629350.010 -889125.010, -629325.010...</td>\n",
       "      <td>1.563754e+08</td>\n",
       "      <td>64534.427498</td>\n",
       "      <td>Fricker and others, 2010, J. Glac., doi:10.318...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Mac2</td>\n",
       "      <td>POLYGON ((-657250.020 -890550.040, -657249.980...</td>\n",
       "      <td>1.457161e+08</td>\n",
       "      <td>57055.433906</td>\n",
       "      <td>Fricker and others, 2010, J. Glac., doi:10.318...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Mac3</td>\n",
       "      <td>POLYGON ((-642325.010 -883925.000, -642449.980...</td>\n",
       "      <td>1.502500e+08</td>\n",
       "      <td>104150.365454</td>\n",
       "      <td>Fricker and others, 2010, J. Glac., doi:10.318...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Mac4</td>\n",
       "      <td>POLYGON ((-739324.970 -857799.960, -739199.980...</td>\n",
       "      <td>7.520909e+07</td>\n",
       "      <td>38826.874743</td>\n",
       "      <td>Fricker and others, 2010, J. Glac., doi:10.318...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Mac5</td>\n",
       "      <td>POLYGON ((-734575.010 -842800.020, -734449.990...</td>\n",
       "      <td>5.998647e+07</td>\n",
       "      <td>31080.268636</td>\n",
       "      <td>Fricker and others, 2010, J. Glac., doi:10.318...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>MercerSubglacialLake</td>\n",
       "      <td>POLYGON ((-299950.018 -500675.034, -299949.971...</td>\n",
       "      <td>1.432030e+08</td>\n",
       "      <td>61221.448335</td>\n",
       "      <td>Fricker &amp; Scambos, 2009, J. Glac., doi:10.3189...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Rec1</td>\n",
       "      <td>POLYGON ((-448074.984 859324.972, -447949.975 ...</td>\n",
       "      <td>1.046839e+09</td>\n",
       "      <td>200584.510139</td>\n",
       "      <td>Fricker and others, 2014, J. Glac., doi:10.318...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Rec2</td>\n",
       "      <td>POLYGON ((-389950.015 915200.035, -389824.971 ...</td>\n",
       "      <td>7.096422e+08</td>\n",
       "      <td>147292.058299</td>\n",
       "      <td>Fricker and others, 2014, J. Glac., doi:10.318...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Slessor_23</td>\n",
       "      <td>POLYGON ((-408685.484 1046792.659, -408498.695...</td>\n",
       "      <td>2.702501e+08</td>\n",
       "      <td>84962.312011</td>\n",
       "      <td>Siegfried &amp; Fricker, 2018, Ann. Glac., doi:10....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Thw_124</td>\n",
       "      <td>POLYGON ((-1419402.000 -431819.000, -1421479.0...</td>\n",
       "      <td>5.761346e+08</td>\n",
       "      <td>112135.767376</td>\n",
       "      <td>Smith and others, 2017, TC, doi:10.5194/tc-11-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Thw_142</td>\n",
       "      <td>POLYGON ((-1404705.000 -410106.000, -1404692.0...</td>\n",
       "      <td>1.607689e+08</td>\n",
       "      <td>57828.708474</td>\n",
       "      <td>Smith and others, 2017, TC, doi:10.5194/tc-11-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Thw_170</td>\n",
       "      <td>POLYGON ((-1380997.000 -398714.000, -1382313.0...</td>\n",
       "      <td>1.940960e+08</td>\n",
       "      <td>54559.367618</td>\n",
       "      <td>Smith and others, 2017, TC, doi:10.5194/tc-11-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Thw_70</td>\n",
       "      <td>POLYGON ((-1476557.000 -449098.000, -1474606.0...</td>\n",
       "      <td>3.540275e+08</td>\n",
       "      <td>89548.375571</td>\n",
       "      <td>Smith and others, 2017, TC, doi:10.5194/tc-11-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>UpperSubglacialLakeConway</td>\n",
       "      <td>POLYGON ((-370200.008 -533925.036, -370200.008...</td>\n",
       "      <td>1.866440e+08</td>\n",
       "      <td>65462.666719</td>\n",
       "      <td>Fricker &amp; Scambos, 2009, J. Glac., doi:10.3189...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>WhillansSubglacialLake</td>\n",
       "      <td>POLYGON ((-284324.993 -560675.019, -284200.010...</td>\n",
       "      <td>6.196906e+07</td>\n",
       "      <td>35056.905773</td>\n",
       "      <td>Fricker &amp; Scambos, 2009, J. Glac., doi:10.3189...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         name  \\\n",
       "0        ConwaySubglacialLake   \n",
       "1                     Cook_E2   \n",
       "2    EngelhardtSubglacialLake   \n",
       "3                         KT1   \n",
       "4                         KT2   \n",
       "5                         KT3   \n",
       "6                      Lake10   \n",
       "7                      Lake12   \n",
       "8                      Lake78   \n",
       "9                        Mac1   \n",
       "10                       Mac2   \n",
       "11                       Mac3   \n",
       "12                       Mac4   \n",
       "13                       Mac5   \n",
       "14       MercerSubglacialLake   \n",
       "15                       Rec1   \n",
       "16                       Rec2   \n",
       "17                 Slessor_23   \n",
       "18                    Thw_124   \n",
       "19                    Thw_142   \n",
       "20                    Thw_170   \n",
       "21                     Thw_70   \n",
       "22  UpperSubglacialLakeConway   \n",
       "23     WhillansSubglacialLake   \n",
       "\n",
       "                                             geometry    area (m^2)  \\\n",
       "0   POLYGON ((-312825.002 -511425.001, -312699.997...  2.669973e+08   \n",
       "1   POLYGON ((765592.392 -1714713.856, 765682.174 ...  2.680933e+08   \n",
       "2   POLYGON ((-271824.984 -628674.969, -271699.995...  3.577632e+08   \n",
       "3   POLYGON ((-556189.687 -681400.000, -556000.000...  4.549884e+07   \n",
       "4   POLYGON ((-441794.803 -712600.000, -441600.000...  3.315274e+07   \n",
       "5   POLYGON ((-399646.273 -716600.000, -399600.000...  4.055444e+07   \n",
       "6   POLYGON ((-227949.981 -569549.997, -228075.000...  2.587121e+07   \n",
       "7   POLYGON ((-224449.970 -604674.969, -224449.970...  6.689842e+07   \n",
       "8   MULTIPOLYGON (((-257325.009 -525800.047, -2571...  2.330027e+08   \n",
       "9   POLYGON ((-629350.010 -889125.010, -629325.010...  1.563754e+08   \n",
       "10  POLYGON ((-657250.020 -890550.040, -657249.980...  1.457161e+08   \n",
       "11  POLYGON ((-642325.010 -883925.000, -642449.980...  1.502500e+08   \n",
       "12  POLYGON ((-739324.970 -857799.960, -739199.980...  7.520909e+07   \n",
       "13  POLYGON ((-734575.010 -842800.020, -734449.990...  5.998647e+07   \n",
       "14  POLYGON ((-299950.018 -500675.034, -299949.971...  1.432030e+08   \n",
       "15  POLYGON ((-448074.984 859324.972, -447949.975 ...  1.046839e+09   \n",
       "16  POLYGON ((-389950.015 915200.035, -389824.971 ...  7.096422e+08   \n",
       "17  POLYGON ((-408685.484 1046792.659, -408498.695...  2.702501e+08   \n",
       "18  POLYGON ((-1419402.000 -431819.000, -1421479.0...  5.761346e+08   \n",
       "19  POLYGON ((-1404705.000 -410106.000, -1404692.0...  1.607689e+08   \n",
       "20  POLYGON ((-1380997.000 -398714.000, -1382313.0...  1.940960e+08   \n",
       "21  POLYGON ((-1476557.000 -449098.000, -1474606.0...  3.540275e+08   \n",
       "22  POLYGON ((-370200.008 -533925.036, -370200.008...  1.866440e+08   \n",
       "23  POLYGON ((-284324.993 -560675.019, -284200.010...  6.196906e+07   \n",
       "\n",
       "    perimeter (m)                                               cite  \n",
       "0    93967.290533  Fricker & Scambos, 2009, J. Glac., doi:10.3189...  \n",
       "1   127109.861123  McMillan and others, 2013, GRL, doi:10.1002/gr...  \n",
       "2   122225.431584  Fricker & Scambos, 2009, J. Glac., doi:10.3189...  \n",
       "3    31575.761008  Kim and others, 2016, TC, doi:10.5194/tc-10-29...  \n",
       "4    32351.217554  Kim and others, 2016, TC, doi:10.5194/tc-10-29...  \n",
       "5    33296.288468  Kim and others, 2016, TC, doi:10.5194/tc-10-29...  \n",
       "6    21525.193986  Fricker & Scambos, 2009, J. Glac., doi:10.3189...  \n",
       "7    31339.673859  Fricker & Scambos, 2009, J. Glac., doi:10.3189...  \n",
       "8   128470.660267  Carter and others, 2013, J. Glac., doi:10.3189...  \n",
       "9    64534.427498  Fricker and others, 2010, J. Glac., doi:10.318...  \n",
       "10   57055.433906  Fricker and others, 2010, J. Glac., doi:10.318...  \n",
       "11  104150.365454  Fricker and others, 2010, J. Glac., doi:10.318...  \n",
       "12   38826.874743  Fricker and others, 2010, J. Glac., doi:10.318...  \n",
       "13   31080.268636  Fricker and others, 2010, J. Glac., doi:10.318...  \n",
       "14   61221.448335  Fricker & Scambos, 2009, J. Glac., doi:10.3189...  \n",
       "15  200584.510139  Fricker and others, 2014, J. Glac., doi:10.318...  \n",
       "16  147292.058299  Fricker and others, 2014, J. Glac., doi:10.318...  \n",
       "17   84962.312011  Siegfried & Fricker, 2018, Ann. Glac., doi:10....  \n",
       "18  112135.767376  Smith and others, 2017, TC, doi:10.5194/tc-11-...  \n",
       "19   57828.708474  Smith and others, 2017, TC, doi:10.5194/tc-11-...  \n",
       "20   54559.367618  Smith and others, 2017, TC, doi:10.5194/tc-11-...  \n",
       "21   89548.375571  Smith and others, 2017, TC, doi:10.5194/tc-11-...  \n",
       "22   65462.666719  Fricker & Scambos, 2009, J. Glac., doi:10.3189...  \n",
       "23   35056.905773  Fricker & Scambos, 2009, J. Glac., doi:10.3189...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SiegfriedFricker2018_SF18outlines_CS2InSAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>geometry</th>\n",
       "      <th>area (m^2)</th>\n",
       "      <th>perimeter (m)</th>\n",
       "      <th>cite</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bindschadler_1</td>\n",
       "      <td>POLYGON ((-792264.327 -691480.857, -791281.458...</td>\n",
       "      <td>1.943146e+08</td>\n",
       "      <td>51147.562479</td>\n",
       "      <td>Smith and others, 2009, J. Glac., doi:10.3189/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bindschadler_2</td>\n",
       "      <td>POLYGON ((-842788.063 -708464.240, -842354.948...</td>\n",
       "      <td>1.072249e+08</td>\n",
       "      <td>37249.152584</td>\n",
       "      <td>Smith and others, 2009, J. Glac., doi:10.3189/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bindschadler_3</td>\n",
       "      <td>POLYGON ((-874893.221 -654533.044, -876415.673...</td>\n",
       "      <td>1.404559e+08</td>\n",
       "      <td>44183.483257</td>\n",
       "      <td>Smith and others, 2009, J. Glac., doi:10.3189/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bindschadler_4</td>\n",
       "      <td>POLYGON ((-828821.778 -584874.415, -828822.032...</td>\n",
       "      <td>2.816411e+08</td>\n",
       "      <td>62680.016773</td>\n",
       "      <td>Smith and others, 2009, J. Glac., doi:10.3189/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bindschadler_5</td>\n",
       "      <td>POLYGON ((-858067.460 -573467.564, -858714.391...</td>\n",
       "      <td>3.923966e+08</td>\n",
       "      <td>73686.203194</td>\n",
       "      <td>Smith and others, 2009, J. Glac., doi:10.3189/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Totten_2</td>\n",
       "      <td>POLYGON ((1959881.978 -739690.464, 1960402.314...</td>\n",
       "      <td>7.098553e+08</td>\n",
       "      <td>110449.727727</td>\n",
       "      <td>Smith and others, 2009, J. Glac., doi:10.3189/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Vostok_1</td>\n",
       "      <td>POLYGON ((1335211.769 -404847.824, 1335858.932...</td>\n",
       "      <td>6.729400e+07</td>\n",
       "      <td>29793.488369</td>\n",
       "      <td>Smith and others, 2009, J. Glac., doi:10.3189/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Whillans_8</td>\n",
       "      <td>POLYGON ((-654478.748 -281124.560, -653777.327...</td>\n",
       "      <td>1.625714e+08</td>\n",
       "      <td>45873.974279</td>\n",
       "      <td>Smith and others, 2009, J. Glac., doi:10.3189/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Wilkes_1</td>\n",
       "      <td>POLYGON ((2214185.180 -666018.604, 2214317.389...</td>\n",
       "      <td>5.880773e+08</td>\n",
       "      <td>89565.314574</td>\n",
       "      <td>Smith and others, 2009, J. Glac., doi:10.3189/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>Wilkes_2</td>\n",
       "      <td>POLYGON ((1985649.483 -1222665.850, 1986964.16...</td>\n",
       "      <td>1.766583e+08</td>\n",
       "      <td>48307.837257</td>\n",
       "      <td>Smith and others, 2009, J. Glac., doi:10.3189/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              name                                           geometry  \\\n",
       "0   Bindschadler_1  POLYGON ((-792264.327 -691480.857, -791281.458...   \n",
       "1   Bindschadler_2  POLYGON ((-842788.063 -708464.240, -842354.948...   \n",
       "2   Bindschadler_3  POLYGON ((-874893.221 -654533.044, -876415.673...   \n",
       "3   Bindschadler_4  POLYGON ((-828821.778 -584874.415, -828822.032...   \n",
       "4   Bindschadler_5  POLYGON ((-858067.460 -573467.564, -858714.391...   \n",
       "..             ...                                                ...   \n",
       "70        Totten_2  POLYGON ((1959881.978 -739690.464, 1960402.314...   \n",
       "71        Vostok_1  POLYGON ((1335211.769 -404847.824, 1335858.932...   \n",
       "72      Whillans_8  POLYGON ((-654478.748 -281124.560, -653777.327...   \n",
       "73        Wilkes_1  POLYGON ((2214185.180 -666018.604, 2214317.389...   \n",
       "74        Wilkes_2  POLYGON ((1985649.483 -1222665.850, 1986964.16...   \n",
       "\n",
       "      area (m^2)  perimeter (m)  \\\n",
       "0   1.943146e+08   51147.562479   \n",
       "1   1.072249e+08   37249.152584   \n",
       "2   1.404559e+08   44183.483257   \n",
       "3   2.816411e+08   62680.016773   \n",
       "4   3.923966e+08   73686.203194   \n",
       "..           ...            ...   \n",
       "70  7.098553e+08  110449.727727   \n",
       "71  6.729400e+07   29793.488369   \n",
       "72  1.625714e+08   45873.974279   \n",
       "73  5.880773e+08   89565.314574   \n",
       "74  1.766583e+08   48307.837257   \n",
       "\n",
       "                                                 cite  \n",
       "0   Smith and others, 2009, J. Glac., doi:10.3189/...  \n",
       "1   Smith and others, 2009, J. Glac., doi:10.3189/...  \n",
       "2   Smith and others, 2009, J. Glac., doi:10.3189/...  \n",
       "3   Smith and others, 2009, J. Glac., doi:10.3189/...  \n",
       "4   Smith and others, 2009, J. Glac., doi:10.3189/...  \n",
       "..                                                ...  \n",
       "70  Smith and others, 2009, J. Glac., doi:10.3189/...  \n",
       "71  Smith and others, 2009, J. Glac., doi:10.3189/...  \n",
       "72  Smith and others, 2009, J. Glac., doi:10.3189/...  \n",
       "73  Smith and others, 2009, J. Glac., doi:10.3189/...  \n",
       "74  Smith and others, 2009, J. Glac., doi:10.3189/...  \n",
       "\n",
       "[75 rows x 5 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SiegfriedFricker2018_S09outlines_noInSAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>geometry</th>\n",
       "      <th>area (m^2)</th>\n",
       "      <th>perimeter (m)</th>\n",
       "      <th>cite</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mac6</td>\n",
       "      <td>POLYGON ((-907727.770 -830662.200, -905516.600...</td>\n",
       "      <td>1.054051e+08</td>\n",
       "      <td>37174.953805</td>\n",
       "      <td>Fricker and others, 2010, J. Glac., doi:10.318...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mac7</td>\n",
       "      <td>POLYGON ((-792290.820 -691503.980, -793860.830...</td>\n",
       "      <td>1.943272e+08</td>\n",
       "      <td>51149.223275</td>\n",
       "      <td>Fricker and others, 2010, J. Glac., doi:10.318...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mac8</td>\n",
       "      <td>POLYGON ((-842816.190 -708487.890, -842383.070...</td>\n",
       "      <td>1.072318e+08</td>\n",
       "      <td>37250.346833</td>\n",
       "      <td>Fricker and others, 2010, J. Glac., doi:10.318...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rec10</td>\n",
       "      <td>POLYGON ((140924.994 903449.944, 140924.994 90...</td>\n",
       "      <td>2.931863e+08</td>\n",
       "      <td>82668.753599</td>\n",
       "      <td>Fricker and others, 2014, J. Glac., doi:10.318...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rec3</td>\n",
       "      <td>POLYGON ((-323075.001 894450.022, -323075.005 ...</td>\n",
       "      <td>6.251871e+07</td>\n",
       "      <td>32808.673780</td>\n",
       "      <td>Fricker and others, 2014, J. Glac., doi:10.318...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Rec4</td>\n",
       "      <td>POLYGON ((-174200.004 944325.029, -174200.000 ...</td>\n",
       "      <td>2.299425e+08</td>\n",
       "      <td>75112.043315</td>\n",
       "      <td>Fricker and others, 2014, J. Glac., doi:10.318...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Rec5</td>\n",
       "      <td>POLYGON ((-128199.995 941949.982, -128200.002 ...</td>\n",
       "      <td>2.849787e+08</td>\n",
       "      <td>92761.512855</td>\n",
       "      <td>Fricker and others, 2014, J. Glac., doi:10.318...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Rec6</td>\n",
       "      <td>POLYGON ((-90075.003 920949.990, -90075.003 92...</td>\n",
       "      <td>4.107123e+08</td>\n",
       "      <td>92063.631487</td>\n",
       "      <td>Fricker and others, 2014, J. Glac., doi:10.318...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Rec8</td>\n",
       "      <td>POLYGON ((37675.000 782450.023, 37799.998 7824...</td>\n",
       "      <td>2.370994e+08</td>\n",
       "      <td>67402.197270</td>\n",
       "      <td>Fricker and others, 2014, J. Glac., doi:10.318...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Rec9</td>\n",
       "      <td>POLYGON ((75300.001 714325.030, 75424.999 7143...</td>\n",
       "      <td>2.358326e+08</td>\n",
       "      <td>63019.500560</td>\n",
       "      <td>Fricker and others, 2014, J. Glac., doi:10.318...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    name                                           geometry    area (m^2)  \\\n",
       "0   Mac6  POLYGON ((-907727.770 -830662.200, -905516.600...  1.054051e+08   \n",
       "1   Mac7  POLYGON ((-792290.820 -691503.980, -793860.830...  1.943272e+08   \n",
       "2   Mac8  POLYGON ((-842816.190 -708487.890, -842383.070...  1.072318e+08   \n",
       "3  Rec10  POLYGON ((140924.994 903449.944, 140924.994 90...  2.931863e+08   \n",
       "4   Rec3  POLYGON ((-323075.001 894450.022, -323075.005 ...  6.251871e+07   \n",
       "5   Rec4  POLYGON ((-174200.004 944325.029, -174200.000 ...  2.299425e+08   \n",
       "6   Rec5  POLYGON ((-128199.995 941949.982, -128200.002 ...  2.849787e+08   \n",
       "7   Rec6  POLYGON ((-90075.003 920949.990, -90075.003 92...  4.107123e+08   \n",
       "8   Rec8  POLYGON ((37675.000 782450.023, 37799.998 7824...  2.370994e+08   \n",
       "9   Rec9  POLYGON ((75300.001 714325.030, 75424.999 7143...  2.358326e+08   \n",
       "\n",
       "   perimeter (m)                                               cite  \n",
       "0   37174.953805  Fricker and others, 2010, J. Glac., doi:10.318...  \n",
       "1   51149.223275  Fricker and others, 2010, J. Glac., doi:10.318...  \n",
       "2   37250.346833  Fricker and others, 2010, J. Glac., doi:10.318...  \n",
       "3   82668.753599  Fricker and others, 2014, J. Glac., doi:10.318...  \n",
       "4   32808.673780  Fricker and others, 2014, J. Glac., doi:10.318...  \n",
       "5   75112.043315  Fricker and others, 2014, J. Glac., doi:10.318...  \n",
       "6   92761.512855  Fricker and others, 2014, J. Glac., doi:10.318...  \n",
       "7   92063.631487  Fricker and others, 2014, J. Glac., doi:10.318...  \n",
       "8   67402.197270  Fricker and others, 2014, J. Glac., doi:10.318...  \n",
       "9   63019.500560  Fricker and others, 2014, J. Glac., doi:10.318...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SiegfriedFricker2018_SF18outlines_noInSAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>geometry</th>\n",
       "      <th>area (m^2)</th>\n",
       "      <th>perimeter (m)</th>\n",
       "      <th>cite</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bindschadler_1</td>\n",
       "      <td>POLYGON ((-792264.327362 -691480.857142, -7912...</td>\n",
       "      <td>194314586.957024</td>\n",
       "      <td>51147.562479</td>\n",
       "      <td>Smith and others, 2009, J. Glac., doi:10.3189/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bindschadler_2</td>\n",
       "      <td>POLYGON ((-842788.063077 -708464.24025, -84235...</td>\n",
       "      <td>107224893.755605</td>\n",
       "      <td>37249.152584</td>\n",
       "      <td>Smith and others, 2009, J. Glac., doi:10.3189/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bindschadler_3</td>\n",
       "      <td>POLYGON ((-874893.221204 -654533.044355, -8764...</td>\n",
       "      <td>140455869.623503</td>\n",
       "      <td>44183.483257</td>\n",
       "      <td>Smith and others, 2009, J. Glac., doi:10.3189/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bindschadler_4</td>\n",
       "      <td>POLYGON ((-828821.777959 -584874.414823, -8288...</td>\n",
       "      <td>281641064.156404</td>\n",
       "      <td>62680.016773</td>\n",
       "      <td>Smith and others, 2009, J. Glac., doi:10.3189/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bindschadler_5</td>\n",
       "      <td>POLYGON ((-858067.460067 -573467.563734, -8587...</td>\n",
       "      <td>392396583.575188</td>\n",
       "      <td>73686.203194</td>\n",
       "      <td>Smith and others, 2009, J. Glac., doi:10.3189/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>Whillans_7</td>\n",
       "      <td>POLYGON ((-543163.375533 -500759.16526, -54280...</td>\n",
       "      <td>76965701.86622</td>\n",
       "      <td>32373.996995</td>\n",
       "      <td>Smith and others, 2009, J. Glac., doi:10.3189/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>Whillans_8</td>\n",
       "      <td>POLYGON ((-654478.748309 -281124.560477, -6537...</td>\n",
       "      <td>162571436.70252</td>\n",
       "      <td>45873.974279</td>\n",
       "      <td>Smith and others, 2009, J. Glac., doi:10.3189/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>Wilkes_1</td>\n",
       "      <td>POLYGON ((2214185.18045 -666018.604064, 221431...</td>\n",
       "      <td>588077293.262147</td>\n",
       "      <td>89565.314574</td>\n",
       "      <td>Smith and others, 2009, J. Glac., doi:10.3189/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>Wilkes_2</td>\n",
       "      <td>POLYGON ((1985649.48349 -1222665.85001, 198696...</td>\n",
       "      <td>176658323.865219</td>\n",
       "      <td>48307.837257</td>\n",
       "      <td>Smith and others, 2009, J. Glac., doi:10.3189/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>lower_Whillans6</td>\n",
       "      <td>POINT (-450000, -540000)</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>Sauthoff and others, in prep</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>132 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                name                                           geometry  \\\n",
       "0     Bindschadler_1  POLYGON ((-792264.327362 -691480.857142, -7912...   \n",
       "1     Bindschadler_2  POLYGON ((-842788.063077 -708464.24025, -84235...   \n",
       "2     Bindschadler_3  POLYGON ((-874893.221204 -654533.044355, -8764...   \n",
       "3     Bindschadler_4  POLYGON ((-828821.777959 -584874.414823, -8288...   \n",
       "4     Bindschadler_5  POLYGON ((-858067.460067 -573467.563734, -8587...   \n",
       "..               ...                                                ...   \n",
       "127       Whillans_7  POLYGON ((-543163.375533 -500759.16526, -54280...   \n",
       "128       Whillans_8  POLYGON ((-654478.748309 -281124.560477, -6537...   \n",
       "129         Wilkes_1  POLYGON ((2214185.18045 -666018.604064, 221431...   \n",
       "130         Wilkes_2  POLYGON ((1985649.48349 -1222665.85001, 198696...   \n",
       "131  lower_Whillans6                           POINT (-450000, -540000)   \n",
       "\n",
       "           area (m^2) perimeter (m)  \\\n",
       "0    194314586.957024  51147.562479   \n",
       "1    107224893.755605  37249.152584   \n",
       "2    140455869.623503  44183.483257   \n",
       "3    281641064.156404  62680.016773   \n",
       "4    392396583.575188  73686.203194   \n",
       "..                ...           ...   \n",
       "127    76965701.86622  32373.996995   \n",
       "128   162571436.70252  45873.974279   \n",
       "129  588077293.262147  89565.314574   \n",
       "130  176658323.865219  48307.837257   \n",
       "131               nan           nan   \n",
       "\n",
       "                                                  cite  \n",
       "0    Smith and others, 2009, J. Glac., doi:10.3189/...  \n",
       "1    Smith and others, 2009, J. Glac., doi:10.3189/...  \n",
       "2    Smith and others, 2009, J. Glac., doi:10.3189/...  \n",
       "3    Smith and others, 2009, J. Glac., doi:10.3189/...  \n",
       "4    Smith and others, 2009, J. Glac., doi:10.3189/...  \n",
       "..                                                 ...  \n",
       "127  Smith and others, 2009, J. Glac., doi:10.3189/...  \n",
       "128  Smith and others, 2009, J. Glac., doi:10.3189/...  \n",
       "129  Smith and others, 2009, J. Glac., doi:10.3189/...  \n",
       "130  Smith and others, 2009, J. Glac., doi:10.3189/...  \n",
       "131                       Sauthoff and others, in prep  \n",
       "\n",
       "[132 rows x 5 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SiegfriedFricker2018_outlines.loc[len(SiegfriedFricker2018_outlines)] = ['lower_Whillans6', 'POINT (-450000, -540000)', 'nan', 'nan', 'Sauthoff and others, in prep'] \n",
    "\n",
    "SiegfriedFricker2018_outlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130    POLYGON ((1985649.483 -1222665.850, 1986964.16...\n",
       "Name: geometry, dtype: geometry"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SiegfriedFricker2018_outlines[SiegfriedFricker2018_outlines['name']=='Wilkes_2']['geometry']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131    POINT (-450000, -540000)\n",
       "Name: geometry, dtype: object"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SiegfriedFricker2018_outlines[SiegfriedFricker2018_outlines['name']=='lower_Whillans6']['geometry']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of S09 lakes redelineated in SF18\n",
    "S09_SF18_compare_1to1 = [['Cook_E2', 'Cook_E2'],\n",
    "    ['KambTrunk_1', 'KT1'],\n",
    "    ['Macayeal_1', 'Mac1'],\n",
    "    ['Macayeal_2', 'Mac2'],\n",
    "    ['Mercer_1', 'Lake78'],\n",
    "    ['Mercer_2', 'MercerSubglacialLake'],\n",
    "    ['Recovery_3', 'Rec2'],\n",
    "    ['Recovery_4', 'Rec3'],\n",
    "    ['Recovery_5', 'Rec4'], \n",
    "    ['Recovery_6', 'Rec5'],\n",
    "    ['Recovery_7', 'Rec6'],\n",
    "    ['Recovery_9', 'Rec8'],\n",
    "    ['Recovery_10', 'Rec9'],\n",
    "    ['Recovery_11', 'Rec10'],     \n",
    "    ['Whillans_1', 'EngelhardtSubglacialLake'],            \n",
    "    ['Whillans_2a', 'Lake12'],\n",
    "    ['Whillans_2b', 'Lake10'],\n",
    "    ['Whillans_3', 'WhillansSubglacialLake'],\n",
    "    ['Whillans_4', 'ConwaySubglacialLake'],\n",
    "    ['Whillans_5', 'UpperSubglacialLakeConway']]\n",
    "\n",
    "# create list of S09 lakes redelineated in SF18 with CS2 InSAR coverage\n",
    "S09_SF18_compare_1to1_CS2InSAR = [['Cook_E2', 'Cook_E2'],\n",
    "    ['KambTrunk_1', 'KT1'],\n",
    "    ['Macayeal_1', 'Mac1'],\n",
    "    ['Macayeal_2', 'Mac2'],\n",
    "    ['Mercer_1', 'Lake78'],\n",
    "    ['Mercer_2', 'MercerSubglacialLake'],\n",
    "    ['Recovery_3', 'Rec2'],\n",
    "    ['Whillans_1', 'EngelhardtSubglacialLake'],            \n",
    "    ['Whillans_2a', 'Lake12'],\n",
    "    ['Whillans_2b', 'Lake10'],\n",
    "    ['Whillans_3', 'WhillansSubglacialLake'],\n",
    "    ['Whillans_4', 'ConwaySubglacialLake'],\n",
    "    ['Whillans_5', 'UpperSubglacialLakeConway']]\n",
    "\n",
    "# create list of S09 lakes redelineated in SF18 without CS2 InSAR coverage\n",
    "S09_SF18_compare_1to1_noInSAR = [['Recovery_4', 'Rec3'],\n",
    "    ['Recovery_5', 'Rec4'], \n",
    "    ['Recovery_6', 'Rec5'],\n",
    "    ['Recovery_7', 'Rec6'],\n",
    "    ['Recovery_9', 'Rec8'],\n",
    "    ['Recovery_10', 'Rec9'],\n",
    "    ['Recovery_11', 'Rec10']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of two S09 lakes converted to one SF18 lake\n",
    "S09_SF18_compare_2to1 = [['Slessor_2', 'Slessor_3', 'Slessor_23'],\n",
    "    ['Recovery_1', 'Recovery_2', 'Rec1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of one S09 lake converted to two SF18 lakes\n",
    "S09_SF18_compare_1to2 = [['Macayeal_3', 'Mac4', 'Mac5']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to time-variable outline delineation method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S09SF18varoutlines_dhdt_plot_anim_height_thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# incorporating subtracting off-lake secular height change\n",
    "def S09SF18varoutlines_dhdvdt_plot_anim_height_thresholds(lakename_SF18, buffer, thres, dataset): \n",
    "    '''\n",
    "    # adding different arbitrary height thresholds for creating lake outlines\n",
    "    Create planview dh/dt plots of ice surface height changes using geopandas buffer created bounding box around known lakes in \n",
    "    Siegfried and Fricker, 2018 (SF18) inventory.\n",
    "    Create time-variable outlines using skimage contour to plot variable outline alongside published outlines for comparison. \n",
    "    Inputs: \n",
    "        lakename: lake of interest from SiegfriedFricker2018_outlines inventory\n",
    "        buffer: horizontal distance in meters away from SF18 lake outline used to create bounding box that is displayed around lake of interest\n",
    "        thres(hold): vertical distance in meters to delineate ice surface deformation contour\n",
    "        dataset: dataset to be analyzed (CS2_dh or ATL15_dh)\n",
    "    Outputs: \n",
    "        Sequence of planview dh/dt visuals of CryoSat-2 or ICESat-2 ATL15 with variable ice surface deformation contours plotted to delineate time-variable lake boundary.\n",
    "    '''\n",
    "    # isolate individual lake using gpd buffer\n",
    "    #lake_gpd = Smith2009_outlines.loc[Smith2009_outlines['Name'] == lakename]\n",
    "    lake_gpd = SiegfriedFricker2018_outlines.loc[SiegfriedFricker2018_outlines['name'] == lakename_SF18]\n",
    "    lake_buffer = lake_gpd.buffer(buffer)\n",
    "    # define lake bounding box\n",
    "    x_min = lake_buffer.bounds.values[0,0]; x_max = lake_buffer.bounds.values[0,2]\n",
    "    y_min = lake_buffer.bounds.values[0,1]; y_max = lake_buffer.bounds.values[0,3]\n",
    "    # subset ATL15 data set to region of interest\n",
    "    mask_x = (dataset.x >= x_min) & (dataset.x <= x_max)\n",
    "    mask_y = (dataset.y >= y_min) & (dataset.y <= y_max)\n",
    "    ds_sub = dataset.where(mask_x & mask_y, drop=True)\n",
    "    # find magnitude of ice surface deformation in bounding box / find appropriate color map scale\n",
    "    height_anom_pos = []\n",
    "    height_anom_neg = []\n",
    "    for cyc in range(len(ds_sub.time)-1):\n",
    "        pos = np.nanmax(ds_sub.delta_h[cyc+1,:,:]-ds_sub.delta_h[cyc,:,:])\n",
    "        neg = np.nanmin(ds_sub.delta_h[cyc+1,:,:]-ds_sub.delta_h[cyc,:,:])\n",
    "        height_anom_pos += [pos]\n",
    "        height_anom_neg += [neg]\n",
    "    max_height_anom_pos = max(height_anom_pos)\n",
    "    max_height_anom_neg = min(height_anom_neg)\n",
    "    max_height_anom_abs = max(max_height_anom_pos,abs(max_height_anom_neg))\n",
    "    v = np.round(max_height_anom_abs)\n",
    "    # create fig, ax, colorbar\n",
    "    fig, ax = plt.subplots(figsize=(8,8))\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes('right', size='5%', pad=0.2)\n",
    "    # create empty list to store animation im(age)s\n",
    "    ani = animation.PillowWriter(fps=1)\n",
    "    if dataset.fileName == 'mos_2010.5_2021.5.h5':\n",
    "        ani.setup(fig, '/Users/Wilson/Documents/0-code/1-lakeshores/output_dhdvdt-using-variable-outlines/S09SF18varoutlines_dhdt_plot_anim_height_thresholds/anim/S09SF18varoutlines_dhdt_anim-{}-dhdt-{}.gif'.format(lakename_SF18, 'CS2'), dpi=300)\n",
    "    elif dataset.fileName == 'ATL15_AA_0311_01km_001_01.nc':    \n",
    "        ani.setup(fig, '/Users/Wilson/Documents/0-code/1-lakeshores/output_dhdvdt-using-variable-outlines/S09SF18varoutlines_dhdt_plot_anim_height_thresholds/anim/S09SF18varoutlines_dhdt_anim-{}-dhdt-{}.gif'.format(lakename_SF18, 'IS2'), dpi=300)\n",
    "    dates = []\n",
    "    for idx in range(len(ds_sub.time)-1): \n",
    "        dhdt = ds_sub.delta_h[idx+1,:,:]-ds_sub.delta_h[idx,:,:]\n",
    "        # calculate mid-cycle dates for plotting\n",
    "        if dataset.fileName == 'mos_2010.5_2021.5.h5':\n",
    "            newdate = datetime.datetime(int(ds_sub.time.values[idx]), 1, 1) + datetime.timedelta(days = (ds_sub.time.values[idx] % 1) * 365.25)\n",
    "            newdate1 = datetime.datetime(int(ds_sub.time.values[idx+1]), 1, 1) + datetime.timedelta(days = (ds_sub.time.values[idx+1] % 1) * 365.25)\n",
    "            midcycdays = newdate1 - newdate\n",
    "            midcycdate = newdate + midcycdays/2\n",
    "            dates += [midcycdate]\n",
    "        elif dataset.fileName == 'ATL15_AA_0311_01km_001_01.nc':    \n",
    "            date_time_str = '18-01-01'\n",
    "            date_time_obj = datetime.datetime.strptime(date_time_str, '%y-%m-%d')\n",
    "            newdate = date_time_obj + datetime.timedelta(days=ds_sub.time.values[idx])\n",
    "            newdate1 = date_time_obj + datetime.timedelta(days=ds_sub.time.values[idx+1])\n",
    "            midcycdays = newdate1 - newdate\n",
    "            midcycdate = newdate + midcycdays/2\n",
    "            dates += [midcycdate]\n",
    "        # plot figure\n",
    "        dhdt = ds_sub.delta_h[idx+1,:,:]-ds_sub.delta_h[idx,:,:]\n",
    "        img = ax.imshow(dhdt, extent=[x_min, x_max, y_min, y_max], \n",
    "            origin='upper', cmap=cmocean.cm.balance_r, vmin=-v, vmax=v)\n",
    "        # create contours of ice surface elevation height changes to delineate lake outlines\n",
    "        contours_fill = []\n",
    "        contours_drain = []\n",
    "        for thres_i in thres:     \n",
    "            contour = measure.find_contours(dhdt.values, thres_i)\n",
    "            if len(contour) > 0: \n",
    "                contours_fill += [contour]\n",
    "            contour = measure.find_contours(dhdt.values, -thres_i)\n",
    "            if len(contour) > 0: \n",
    "                contours_drain += [contour]\n",
    "        # create mapping conversion factor to map array location to polar stereographic x,y\n",
    "        x_conv = (x_max-x_min)/dhdt.shape[1]\n",
    "        y_conv = (y_max-y_min)/dhdt.shape[0]\n",
    "        # plot variable outlines found in this time slice\n",
    "        for i in range(len(contours_fill)): \n",
    "            for j in range(len(contours_fill[i])):\n",
    "                ax.plot(x_min+contours_fill[i][j][:,1]*x_conv, y_max-contours_fill[i][j][:,0]*y_conv, color='mediumblue', linestyle='dashdot', linewidth=1)\n",
    "        for i in range(len(contours_drain)): \n",
    "            for j in range(len(contours_drain[i])):\n",
    "                ax.plot(x_min+contours_drain[i][j][:,1]*x_conv, y_max-contours_drain[i][j][:,0]*y_conv, color='maroon', linestyle=(0, (3, 1, 1, 1)), linewidth=1)\n",
    "        ax.set(xlim=(x_min, x_max), ylim=(y_min, y_max))\n",
    "        # change polar stereographic m to km\n",
    "        km_scale = 1e3\n",
    "        ticks_x = ticker.FuncFormatter(lambda x, pos: '{0:g}'.format(x/km_scale))\n",
    "        ax.xaxis.set_major_formatter(ticks_x)\n",
    "        ticks_y = ticker.FuncFormatter(lambda x, pos: '{0:g}'.format(x/km_scale))\n",
    "        ax.yaxis.set_major_formatter(ticks_y)  \n",
    "        # adjust ticks\n",
    "        # ax.set_xticks(np.arange(np.round(x_min, decimals = -3),np.round(x_max, decimals = -3),5000))\n",
    "        # ax.set_yticks(np.arange(np.round(y_min, decimals = -3),np.round(y_max, decimals = -3),5000))\n",
    "        # label axes\n",
    "        ax.set_xlabel('x [km]', size=15)\n",
    "        ax.set_ylabel('y [km]', size=15)\n",
    "        # add title and colorbar\n",
    "        ax.set_title(lakename_SF18+' dh + outline comparison \\nh$_{'+newdate1.strftime('%m/%Y')+'}$ - h$_{'+newdate.strftime('%m/%Y')+'}$', pad=7.5, fontsize=17.5)\n",
    "        fig.colorbar(img, cax=cax).set_label('height change (dh) [m]', size=15)\n",
    "        # overlay published outlines for visual comparison \n",
    "        Smith2009_outlines.boundary.plot(ax=ax, color='k', linestyle='--', linewidth=1)\n",
    "        SiegfriedFricker2018_outlines.boundary.plot(ax=ax, color='k', linestyle='-', linewidth=1)\n",
    "        Smith2009 = plt.Line2D((0, 1), (0, 0), color='k', linestyle='--', linewidth=2)\n",
    "        SiegfriedFricker2018 = plt.Line2D((0, 1), (0, 0), color='k', linestyle='-', linewidth=2)\n",
    "        uplift = plt.Line2D((0, 1), (0, 0), color='mediumblue', linestyle='dashdot', linewidth=2)\n",
    "        subsidence = plt.Line2D((0, 1), (0, 0), color='maroon', linestyle=(0, (3, 1, 1, 1)), linewidth=2)\n",
    "        ax.legend([Smith2009,SiegfriedFricker2018,uplift, subsidence],\n",
    "            ['Smith and others, 2009 outline','Siegfried & Fricker, 2018 outline',\n",
    "            ('+'+str(thres)+' m uplift (filling) variable outline'), '–'+str(thres)+' m subsidence (draining) variable outline'], \n",
    "            loc='upper left')\n",
    "        # plot inset map to show location \n",
    "        axIns = ax.inset_axes([0.01, 0.001, 0.25, 0.25])\n",
    "        axIns.patch.set_facecolor('lightskyblue')\n",
    "        axIns.set_aspect('equal')\n",
    "        axIns.scatter(((x_max+x_min)/2), ((y_max+y_min)/2), marker='*', \n",
    "            linewidth=1, edgecolor='k', facecolor='r', s=100, zorder=3)\n",
    "        Scripps_gl.plot(ax=axIns, color='ghostwhite', edgecolor='k', linewidth=0.5, zorder=2)\n",
    "        axIns.axis('off')\n",
    "        # save and close figure\n",
    "        if dataset.fileName == 'mos_2010.5_2021.5.h5':\n",
    "            plt.savefig('/Users/Wilson/Documents/0-code/1-lakeshores/output_dhdvdt-using-variable-outlines/S09SF18varoutlines_dhdt_plot_anim_height_thresholds/plot/S09SF18varoutlines_dhdt_plot-{}-{}-dhdt-{}.png'.format(lakename_SF18,'CS2',midcycdate.strftime('%Y-%m')), dpi=300, bbox_inches = \"tight\")\n",
    "        elif dataset.fileName == 'ATL15_AA_0311_01km_001_01.nc':    \n",
    "            plt.savefig('/Users/Wilson/Documents/0-code/1-lakeshores/output_dhdvdt-using-variable-outlines/S09SF18varoutlines_dhdt_plot_anim_height_thresholds/plot/S09SF18varoutlines_dhdt_plot-{}-{}-dhdt-{}.png'.format(lakename_SF18,'IS2',midcycdate.strftime('%Y-%m')), dpi=300, bbox_inches = \"tight\")      \n",
    "        # append im(age) to ims list\n",
    "        ani.grab_frame()\n",
    "        ax.clear()\n",
    "    # finish animation\n",
    "    ani.finish()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def S09SF18varoutlines_dhdt_plot_anim_height_thresholds(lakename_SF18, buffer, thres, dataset): \n",
    "    '''\n",
    "    # adding different arbitrary height thresholds for creating lake outlines\n",
    "    Create planview dh/dt plots of ice surface height changes using geopandas buffer created bounding box around known lakes in \n",
    "    Siegfried and Fricker, 2018 (SF18) inventory.\n",
    "    Create time-variable outlines using skimage contour to plot variable outline alongside published outlines for comparison. \n",
    "    Inputs: \n",
    "        lakename: lake of interest from SiegfriedFricker2018_outlines inventory\n",
    "        buffer: horizontal distance in meters away from SF18 lake outline used to create bounding box that is displayed around lake of interest\n",
    "        thres(hold): vertical distance in meters to delineate ice surface deformation contour\n",
    "        dataset: dataset to be analyzed (CS2_dh or ATL15_dh)\n",
    "    Outputs: \n",
    "        Sequence of planview dh/dt visuals of CryoSat-2 or ICESat-2 ATL15 with variable ice surface deformation contours plotted to delineate time-variable lake boundary.\n",
    "    '''\n",
    "    # isolate individual lake using gpd buffer\n",
    "    #lake_gpd = Smith2009_outlines.loc[Smith2009_outlines['Name'] == lakename]\n",
    "    lake_gpd = SiegfriedFricker2018_outlines.loc[SiegfriedFricker2018_outlines['name'] == lakename_SF18]\n",
    "    lake_buffer = lake_gpd.buffer(buffer)\n",
    "    # define lake bounding box\n",
    "    x_min = lake_buffer.bounds.values[0,0]; x_max = lake_buffer.bounds.values[0,2]\n",
    "    y_min = lake_buffer.bounds.values[0,1]; y_max = lake_buffer.bounds.values[0,3]\n",
    "    # subset ATL15 data set to region of interest\n",
    "    mask_x = (dataset.x >= x_min) & (dataset.x <= x_max)\n",
    "    mask_y = (dataset.y >= y_min) & (dataset.y <= y_max)\n",
    "    ds_sub = dataset.where(mask_x & mask_y, drop=True)\n",
    "    # find magnitude of ice surface deformation in bounding box / find appropriate color map scale\n",
    "    height_anom_pos = []\n",
    "    height_anom_neg = []\n",
    "    for cyc in range(len(ds_sub.time)-1):\n",
    "        pos = np.nanmax(ds_sub.delta_h[cyc+1,:,:]-ds_sub.delta_h[cyc,:,:])\n",
    "        neg = np.nanmin(ds_sub.delta_h[cyc+1,:,:]-ds_sub.delta_h[cyc,:,:])\n",
    "        height_anom_pos += [pos]\n",
    "        height_anom_neg += [neg]\n",
    "    max_height_anom_pos = max(height_anom_pos)\n",
    "    max_height_anom_neg = min(height_anom_neg)\n",
    "    max_height_anom_abs = max(max_height_anom_pos,abs(max_height_anom_neg))\n",
    "    v = np.round(max_height_anom_abs)\n",
    "    # create fig, ax, colorbar\n",
    "    fig, ax = plt.subplots(figsize=(8,8))\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes('right', size='5%', pad=0.2)\n",
    "    # create empty list to store animation im(age)s\n",
    "    ani = animation.PillowWriter(fps=1)\n",
    "    if dataset.fileName == 'mos_2010.5_2021.5.h5':\n",
    "        ani.setup(fig, '/Users/Wilson/Documents/0-code/1-lakeshores/output_dhdvdt-using-variable-outlines/S09SF18varoutlines_dhdt_plot_anim_height_thresholds/anim/S09SF18varoutlines_dhdt_anim-{}-dhdt-{}.gif'.format(lakename_SF18, 'CS2'), dpi=300)\n",
    "    elif dataset.fileName == 'ATL15_AA_0311_01km_001_01.nc':    \n",
    "        ani.setup(fig, '/Users/Wilson/Documents/0-code/1-lakeshores/output_dhdvdt-using-variable-outlines/S09SF18varoutlines_dhdt_plot_anim_height_thresholds/anim/S09SF18varoutlines_dhdt_anim-{}-dhdt-{}.gif'.format(lakename_SF18, 'IS2'), dpi=300)\n",
    "    dates = []\n",
    "    for idx in range(len(ds_sub.time)-1): \n",
    "        dhdt = ds_sub.delta_h[idx+1,:,:]-ds_sub.delta_h[idx,:,:]\n",
    "        # calculate mid-cycle dates for plotting\n",
    "        if dataset.fileName == 'mos_2010.5_2021.5.h5':\n",
    "            newdate = datetime.datetime(int(ds_sub.time.values[idx]), 1, 1) + datetime.timedelta(days = (ds_sub.time.values[idx] % 1) * 365.25)\n",
    "            newdate1 = datetime.datetime(int(ds_sub.time.values[idx+1]), 1, 1) + datetime.timedelta(days = (ds_sub.time.values[idx+1] % 1) * 365.25)\n",
    "            midcycdays = newdate1 - newdate\n",
    "            midcycdate = newdate + midcycdays/2\n",
    "            dates += [midcycdate]\n",
    "        elif dataset.fileName == 'ATL15_AA_0311_01km_001_01.nc':    \n",
    "            date_time_str = '18-01-01'\n",
    "            date_time_obj = datetime.datetime.strptime(date_time_str, '%y-%m-%d')\n",
    "            newdate = date_time_obj + datetime.timedelta(days=ds_sub.time.values[idx])\n",
    "            newdate1 = date_time_obj + datetime.timedelta(days=ds_sub.time.values[idx+1])\n",
    "            midcycdays = newdate1 - newdate\n",
    "            midcycdate = newdate + midcycdays/2\n",
    "            dates += [midcycdate]\n",
    "        # plot figure\n",
    "        dhdt = ds_sub.delta_h[idx+1,:,:]-ds_sub.delta_h[idx,:,:]\n",
    "        img = ax.imshow(dhdt, extent=[x_min, x_max, y_min, y_max], \n",
    "            origin='upper', cmap=cmocean.cm.balance_r, vmin=-v, vmax=v)\n",
    "        # create contours of ice surface elevation height changes to delineate lake outlines\n",
    "        contours_fill = []\n",
    "        contours_drain = []\n",
    "        for thres_i in thres:     \n",
    "            contour = measure.find_contours(dhdt.values, thres_i)\n",
    "            if len(contour) > 0: \n",
    "                contours_fill += [contour]\n",
    "            contour = measure.find_contours(dhdt.values, -thres_i)\n",
    "            if len(contour) > 0: \n",
    "                contours_drain += [contour]\n",
    "        # create mapping conversion factor to map array location to polar stereographic x,y\n",
    "        x_conv = (x_max-x_min)/dhdt.shape[1]\n",
    "        y_conv = (y_max-y_min)/dhdt.shape[0]\n",
    "        # plot variable outlines found in this time slice\n",
    "        for i in range(len(contours_fill)): \n",
    "            for j in range(len(contours_fill[i])):\n",
    "                ax.plot(x_min+contours_fill[i][j][:,1]*x_conv, y_max-contours_fill[i][j][:,0]*y_conv, color='mediumblue', linestyle='dashdot', linewidth=1)\n",
    "        for i in range(len(contours_drain)): \n",
    "            for j in range(len(contours_drain[i])):\n",
    "                ax.plot(x_min+contours_drain[i][j][:,1]*x_conv, y_max-contours_drain[i][j][:,0]*y_conv, color='maroon', linestyle=(0, (3, 1, 1, 1)), linewidth=1)\n",
    "        ax.set(xlim=(x_min, x_max), ylim=(y_min, y_max))\n",
    "        # change polar stereographic m to km\n",
    "        km_scale = 1e3\n",
    "        ticks_x = ticker.FuncFormatter(lambda x, pos: '{0:g}'.format(x/km_scale))\n",
    "        ax.xaxis.set_major_formatter(ticks_x)\n",
    "        ticks_y = ticker.FuncFormatter(lambda x, pos: '{0:g}'.format(x/km_scale))\n",
    "        ax.yaxis.set_major_formatter(ticks_y)  \n",
    "        # adjust ticks\n",
    "        ax.set_xticks(np.arange(np.round(x_min, decimals = -3),np.round(x_max, decimals = -3),5000))\n",
    "        ax.set_yticks(np.arange(np.round(y_min, decimals = -3),np.round(y_max, decimals = -3),5000))\n",
    "        # label axes\n",
    "        ax.set_xlabel('x [km]', size=15)\n",
    "        ax.set_ylabel('y [km]', size=15)\n",
    "        # add title and colorbar\n",
    "        ax.set_title(lakename_SF18+' dh + outline comparison \\nh$_{'+newdate1.strftime('%m/%Y')+'}$ - h$_{'+newdate.strftime('%m/%Y')+'}$', pad=7.5, fontsize=17.5)\n",
    "        fig.colorbar(img, cax=cax).set_label('height change (dh) [m]', size=15)\n",
    "        # overlay published outlines for visual comparison \n",
    "        Smith2009_outlines.boundary.plot(ax=ax, color='k', linestyle='--', linewidth=1)\n",
    "        SiegfriedFricker2018_outlines.boundary.plot(ax=ax, color='k', linestyle='-', linewidth=1)\n",
    "        Smith2009 = plt.Line2D((0, 1), (0, 0), color='k', linestyle='--', linewidth=2)\n",
    "        SiegfriedFricker2018 = plt.Line2D((0, 1), (0, 0), color='k', linestyle='-', linewidth=2)\n",
    "        uplift = plt.Line2D((0, 1), (0, 0), color='mediumblue', linestyle='dashdot', linewidth=2)\n",
    "        subsidence = plt.Line2D((0, 1), (0, 0), color='maroon', linestyle=(0, (3, 1, 1, 1)), linewidth=2)\n",
    "        ax.legend([Smith2009,SiegfriedFricker2018,uplift, subsidence],\n",
    "            ['Smith and others, 2009 outline','Siegfried & Fricker, 2018 outline',\n",
    "            ('+'+str(thres)+' m uplift (filling) variable outline'), '–'+str(thres)+' m subsidence (draining) variable outline'], \n",
    "            loc='upper left')\n",
    "        # plot inset map to show location \n",
    "        axIns = ax.inset_axes([0.01, 0.001, 0.25, 0.25])\n",
    "        axIns.patch.set_facecolor('lightskyblue')\n",
    "        axIns.set_aspect('equal')\n",
    "        axIns.scatter(((x_max+x_min)/2), ((y_max+y_min)/2), marker='*', \n",
    "            linewidth=1, edgecolor='k', facecolor='r', s=100, zorder=3)\n",
    "        Scripps_gl.plot(ax=axIns, color='ghostwhite', edgecolor='k', linewidth=0.5, zorder=2)\n",
    "        axIns.axis('off')\n",
    "        # save and close figure\n",
    "        if dataset.fileName == 'mos_2010.5_2021.5.h5':\n",
    "            plt.savefig('/Users/Wilson/Documents/0-code/1-lakeshores/output_dhdvdt-using-variable-outlines/S09SF18varoutlines_dhdt_plot_anim_height_thresholds/plot/S09SF18varoutlines_dhdt_plot-{}-{}-dhdt-{}.png'.format(lakename_SF18,'CS2',midcycdate.strftime('%Y-%m')), dpi=300, bbox_inches = \"tight\")\n",
    "        elif dataset.fileName == 'ATL15_AA_0311_01km_001_01.nc':    \n",
    "            plt.savefig('/Users/Wilson/Documents/0-code/1-lakeshores/output_dhdvdt-using-variable-outlines/S09SF18varoutlines_dhdt_plot_anim_height_thresholds/plot/S09SF18varoutlines_dhdt_plot-{}-{}-dhdt-{}.png'.format(lakename_SF18,'IS2',midcycdate.strftime('%Y-%m')), dpi=300, bbox_inches = \"tight\")      \n",
    "        # append im(age) to ims list\n",
    "        ani.grab_frame()\n",
    "        ax.clear()\n",
    "    # finish animation\n",
    "    ani.finish()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test function working using one lake\n",
    "# S09SF18varoutlines_dhdt_plot_anim_height_thresholds('ConwaySubglacialLake', 10000, [0.2, 0.4, 0.6, 0.8], CS2_dh)\n",
    "S09SF18varoutlines_dhdt_plot_anim_height_thresholds('ConwaySubglacialLake', 10000, [0.2, 0.4, 0.6, 0.8], ATL15_dh)\n",
    "# S09SF18varoutlines_dhdt_plot_anim_height_thresholds('Lambert_1', 10000, [0.2, 0.4, 0.6, 0.8], CS2_dh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run func on all lakes from SF18 inventory\n",
    "for idx in range(len(SiegfriedFricker2018_outlines)-1):\n",
    "    lakename = SiegfriedFricker2018_outlines['name'][idx]\n",
    "    S09SF18varoutlines_dhdt_plot_anim_height_thresholds(lakename, 7500, [0.2, 0.4, 0.6, 0.8], CS2_dh)\n",
    "    S09SF18varoutlines_dhdt_plot_anim_height_thresholds(lakename, 7500, [0.2, 0.4, 0.6, 0.8], ATL15_dh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Func S09SF18varoutlines_dhdt_plot_anim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def S09SF18varoutlines_dhdt_plot_anim(lakename_SF18, buffer, thres, dataset): \n",
    "    '''\n",
    "    Create planview dh/dt plots of ice surface height changes using geopandas buffer created bounding box around known lakes in \n",
    "    Siegfried and Fricker, 2018 (SF18) inventory.\n",
    "    Create time-variable outlines using skimage contour to plot variable outline alongside published outlines for comparison. \n",
    "    Inputs: \n",
    "        lakename: lake of interest from SiegfriedFricker2018_outlines inventory\n",
    "        buffer: horizontal distance in meters away from SF18 lake outline used to create bounding box that is displayed around lake of interest\n",
    "        thres(hold): vertical distance in meters to delineate ice surface deformation contour\n",
    "        dataset: dataset to be analyzed (CS2_dh or ATL15_dh)\n",
    "    Outputs: \n",
    "        Sequence of planview dh/dt visuals of CryoSat-2 or ICESat-2 ATL15 with variable ice surface deformation contours plotted to delineate time-variable lake boundary.\n",
    "    '''\n",
    "    # isolate individual lake using gpd buffer\n",
    "    #lake_gpd = Smith2009_outlines.loc[Smith2009_outlines['Name'] == lakename]\n",
    "    lake_gpd = SiegfriedFricker2018_outlines.loc[SiegfriedFricker2018_outlines['name'] == lakename_SF18]\n",
    "    lake_buffer = lake_gpd.buffer(buffer)\n",
    "    # define lake bounding box\n",
    "    x_min = lake_buffer.bounds.values[0,0]; x_max = lake_buffer.bounds.values[0,2]\n",
    "    y_min = lake_buffer.bounds.values[0,1]; y_max = lake_buffer.bounds.values[0,3]\n",
    "    # subset ATL15 data set to region of interest\n",
    "    mask_x = (dataset.x >= x_min) & (dataset.x <= x_max)\n",
    "    mask_y = (dataset.y >= y_min) & (dataset.y <= y_max)\n",
    "    ds_sub = dataset.where(mask_x & mask_y, drop=True)\n",
    "    # find magnitude of ice surface deformation in bounding box / find appropriate color map scale\n",
    "    height_anom_pos = []\n",
    "    height_anom_neg = []\n",
    "    for cyc in range(len(ds_sub.time)-1):\n",
    "        pos = np.nanmax(ds_sub.delta_h[cyc+1,:,:]-ds_sub.delta_h[cyc,:,:])\n",
    "        neg = np.nanmin(ds_sub.delta_h[cyc+1,:,:]-ds_sub.delta_h[cyc,:,:])\n",
    "        height_anom_pos += [pos]\n",
    "        height_anom_neg += [neg]\n",
    "    max_height_anom_pos = max(height_anom_pos)\n",
    "    max_height_anom_neg = min(height_anom_neg)\n",
    "    max_height_anom_abs = max(max_height_anom_pos,abs(max_height_anom_neg))\n",
    "    v = np.round(max_height_anom_abs)\n",
    "    # create fig, ax, colorbar\n",
    "    fig, ax = plt.subplots(figsize=(8,8))\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes('right', size='5%', pad=0.2)\n",
    "    # create empty list to store animation im(age)s\n",
    "    ani = animation.PillowWriter(fps=2)\n",
    "    if dataset.fileName == 'mos_2010.5_2021.5.h5':\n",
    "        ani.setup(fig, '/Users/Wilson/Documents/0-code/1-lakeshores/output_dhdvdt-using-variable-outlines/S09SF18varoutlines_dhdt_plot_anim/anim/S09SF18varoutlines_dhdt_anim-{}-dhdt-{}.gif'.format(lakename_SF18, 'CS2'), dpi=300)\n",
    "    elif dataset.fileName == 'ATL15_AA_0311_01km_001_01.nc':    \n",
    "        ani.setup(fig, '/Users/Wilson/Documents/0-code/1-lakeshores/output_dhdvdt-using-variable-outlines/S09SF18varoutlines_dhdt_plot_anim/anim/S09SF18varoutlines_dhdt_anim-{}-dhdt-{}.gif'.format(lakename_SF18, 'IS2'), dpi=300)\n",
    "    dates = []\n",
    "    for idx in range(len(ds_sub.time)-1): \n",
    "        dhdt = ds_sub.delta_h[idx+1,:,:]-ds_sub.delta_h[idx,:,:]\n",
    "        # calculate mid-cycle dates for plotting\n",
    "        if dataset.fileName == 'mos_2010.5_2021.5.h5':\n",
    "            newdate = datetime.datetime(int(ds_sub.time.values[idx]), 1, 1) + datetime.timedelta(days = (ds_sub.time.values[idx] % 1) * 365.25)\n",
    "            newdate1 = datetime.datetime(int(ds_sub.time.values[idx+1]), 1, 1) + datetime.timedelta(days = (ds_sub.time.values[idx+1] % 1) * 365.25)\n",
    "            midcycdays = newdate1 - newdate\n",
    "            midcycdate = newdate + midcycdays/2\n",
    "            dates += [midcycdate]\n",
    "        elif dataset.fileName == 'ATL15_AA_0311_01km_001_01.nc':    \n",
    "            date_time_str = '18-01-01'\n",
    "            date_time_obj = datetime.datetime.strptime(date_time_str, '%y-%m-%d')\n",
    "            newdate = date_time_obj + datetime.timedelta(days=ds_sub.time.values[idx])\n",
    "            newdate1 = date_time_obj + datetime.timedelta(days=ds_sub.time.values[idx+1])\n",
    "            midcycdays = newdate1 - newdate\n",
    "            midcycdate = newdate + midcycdays/2\n",
    "            dates += [midcycdate]\n",
    "        # plot figure\n",
    "        dhdt = ds_sub.delta_h[idx+1,:,:]-ds_sub.delta_h[idx,:,:]\n",
    "        img = ax.imshow(dhdt, extent=[x_min, x_max, y_min, y_max], \n",
    "            origin='upper', cmap=cmocean.cm.balance_r, vmin=-v, vmax=v)\n",
    "        # create contours of ice surface elevation height changes to delineate lake outlines\n",
    "        contours_fill = []\n",
    "        contours_drain = []\n",
    "        contour = measure.find_contours(dhdt.values, thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_fill += [contour]\n",
    "        contour = measure.find_contours(dhdt.values, -thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_drain += [contour]\n",
    "        # create mapping conversion factor to map array location to polar stereographic x,y\n",
    "        x_conv = (x_max-x_min)/dhdt.shape[1]\n",
    "        y_conv = (y_max-y_min)/dhdt.shape[0]\n",
    "        # plot variable outlines found in this time slice\n",
    "        for i in range(len(contours_fill)): \n",
    "            for j in range(len(contours_fill[i])):\n",
    "                ax.plot(x_min+contours_fill[i][j][:, 1]*x_conv, y_max-contours_fill[i][j][:, 0]*y_conv, color='mediumblue', linestyle='dashdot', linewidth=2)\n",
    "        for i in range(len(contours_drain)): \n",
    "            for j in range(len(contours_drain[i])):\n",
    "                ax.plot(x_min+contours_drain[i][j][:, 1]*x_conv, y_max-contours_drain[i][j][:, 0]*y_conv, color='maroon', linestyle=(0, (3, 1, 1, 1)), linewidth=2)\n",
    "        ax.set(xlim=(x_min, x_max), ylim=(y_min, y_max))\n",
    "        # change polar stereographic m to km\n",
    "        km_scale = 1e3\n",
    "        ticks_x = ticker.FuncFormatter(lambda x, pos: '{0:g}'.format(x/km_scale))\n",
    "        ax.xaxis.set_major_formatter(ticks_x)\n",
    "        ticks_y = ticker.FuncFormatter(lambda x, pos: '{0:g}'.format(x/km_scale))\n",
    "        ax.yaxis.set_major_formatter(ticks_y)  \n",
    "        # adjust ticks\n",
    "        ax.set_xticks(np.arange(np.round(x_min, decimals = -3),np.round(x_max, decimals = -3),5000))\n",
    "        ax.set_yticks(np.arange(np.round(y_min, decimals = -3),np.round(y_max, decimals = -3),5000))\n",
    "        # label axes\n",
    "        ax.set_xlabel('x [km]', size=15)\n",
    "        ax.set_ylabel('y [km]', size=15)\n",
    "        # add plot title and colorbar\n",
    "        ax.set_title(lakename_SF18+' dh/dt + outline comparison \\n$h_{'+newdate1.strftime('%m/%Y')+'} - h_{'+newdate.strftime('%m/%Y')+'}$', pad=7.5, fontsize=17.5)\n",
    "        fig.colorbar(img, cax=cax).set_label('Height (h) change [m]', size=15)\n",
    "        # overlay published outlines for visual comparison \n",
    "        Smith2009_outlines.boundary.plot(ax=ax, color='k', linestyle='--', linewidth=1)\n",
    "        SiegfriedFricker2018_outlines.boundary.plot(ax=ax, color='k', linestyle='-', linewidth=1)\n",
    "        Smith2009 = plt.Line2D((0, 1), (0, 0), color='k', linestyle='--', linewidth=2)\n",
    "        SiegfriedFricker2018 = plt.Line2D((0, 1), (0, 0), color='k', linestyle='-', linewidth=2)\n",
    "        uplift = plt.Line2D((0, 1), (0, 0), color='mediumblue', linestyle='dashdot', linewidth=2)\n",
    "        subsidence = plt.Line2D((0, 1), (0, 0), color='maroon', linestyle=(0, (3, 1, 1, 1)), linewidth=2)\n",
    "        ax.legend([Smith2009,SiegfriedFricker2018,uplift, subsidence],\n",
    "            ['Smith and others, 2009 outline','Siegfried & Fricker, 2018 outline',\n",
    "            ('+'+str(thres)+' m uplift (filling) variable outline'), '–'+str(thres)+' m subsidence (draining) variable outline'], \n",
    "            loc='best')\n",
    "        # plot inset map to show location \n",
    "        axIns = ax.inset_axes([0.05, 0.001, 0.25, 0.25])\n",
    "        axIns.patch.set_facecolor('lightskyblue')\n",
    "        axIns.set_aspect('equal')\n",
    "        axIns.scatter(((x_max+x_min)/2), ((y_max+y_min)/2), marker='*', \n",
    "            linewidth=1, edgecolor='k', facecolor='r', s=100, zorder=3)\n",
    "        Scripps_gl.plot(ax=axIns, color='ghostwhite', edgecolor='k', linewidth=0.5, zorder=2)\n",
    "        axIns.axis('off')\n",
    "        # save and close figure\n",
    "        if dataset.fileName == 'mos_2010.5_2021.5.h5':\n",
    "            plt.savefig('/Users/Wilson/Documents/0-code/1-lakeshores/output_dhdvdt-using-variable-outlines/S09SF18varoutlines_dhdt_plot_anim/plot/S09SF18varoutlines_dhdt_plot-{}-{}-dhdt-{}.png'.format(lakename_SF18,'CS2',midcycdate.strftime('%Y-%m')), dpi=300, bbox_inches = \"tight\")\n",
    "        elif dataset.fileName == 'ATL15_AA_0311_01km_001_01.nc':    \n",
    "            plt.savefig('/Users/Wilson/Documents/0-code/1-lakeshores/output_dhdvdt-using-variable-outlines/S09SF18varoutlines_dhdt_plot_anim/plot/S09SF18varoutlines_dhdt_plot-{}-{}-dhdt-{}.png'.format(lakename_SF18,'IS2',midcycdate.strftime('%Y-%m')), dpi=300, bbox_inches = 'tight')      \n",
    "        # append im(age) to ims list\n",
    "        ani.grab_frame()\n",
    "        ax.clear()\n",
    "    # finish animation\n",
    "    ani.finish()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test function working using one lake\n",
    "S09SF18varoutlines_dhdt_plot_anim('EngelhardtSubglacialLake', 10000, 0.5, CS2_dh)\n",
    "# S09SF18varoutlines_dhdt_plot_anim('ConwaySubglacialLake', 10000, 0.5, ATL15_dh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run func on all lakes from SF18 inventory\n",
    "for idx in range(len(SiegfriedFricker2018_outlines)-1):\n",
    "    lakename = SiegfriedFricker2018_outlines['name'][idx]\n",
    "    S09SF18varoutlines_dhdt_plot_anim_height_thresholds(lakename, 7500, [0.25, 0.75], CS2_dh)\n",
    "    S09SF18varoutlines_dhdt_plot_anim_height_thresholds(lakename, 7500, [0.25, 0.75], ATL15_dh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explicit bbox\n",
    "def S09SF18varoutlines_dhdt_plot_anim_height_thresholds(x_min, x_max, y_min, y_max, lakename_SF18, buffer, thres, dataset): \n",
    "    '''\n",
    "    Create planview dh/dt plots of ice surface height changes using geopandas buffer created bounding box around known lakes in \n",
    "    Siegfried and Fricker, 2018 (SF18) inventory.\n",
    "    Create time-variable outlines using skimage contour to plot variable outline alongside published outlines for comparison. \n",
    "    Inputs: \n",
    "        lakename: lake of interest from SiegfriedFricker2018_outlines inventory\n",
    "        buffer: horizontal distance in meters away from SF18 lake outline used to create bounding box that is displayed around lake of interest\n",
    "        thres(hold): vertical distance in meters to delineate ice surface deformation contour\n",
    "        dataset: dataset to be analyzed (CS2_dh or ATL15_dh)\n",
    "    Outputs: \n",
    "        Sequence of planview dh/dt visuals of CryoSat-2 or ICESat-2 ATL15 with variable ice surface deformation contours plotted to delineate time-variable lake boundary.\n",
    "    '''\n",
    "    # isolate individual lake using gpd buffer\n",
    "    #lake_gpd = Smith2009_outlines.loc[Smith2009_outlines['Name'] == lakename]\n",
    "    lake_gpd = SiegfriedFricker2018_outlines.loc[SiegfriedFricker2018_outlines['name'] == lakename_SF18]\n",
    "    lake_buffer = lake_gpd.buffer(buffer)\n",
    "    # define lake bounding box\n",
    "    # x_min = lake_buffer.bounds.values[0,0]; x_max = lake_buffer.bounds.values[0,2]\n",
    "    # y_min = lake_buffer.bounds.values[0,1]; y_max = lake_buffer.bounds.values[0,3]\n",
    "    # subset ATL15 data set to region of interest\n",
    "    mask_x = (dataset.x >= x_min) & (dataset.x <= x_max)\n",
    "    mask_y = (dataset.y >= y_min) & (dataset.y <= y_max)\n",
    "    ds_sub = dataset.where(mask_x & mask_y, drop=True)\n",
    "    # find magnitude of ice surface deformation in bounding box / find appropriate color map scale\n",
    "    height_anom_pos = []\n",
    "    height_anom_neg = []\n",
    "    for cyc in range(len(ds_sub.time)-1):\n",
    "        pos = np.nanmax(ds_sub.delta_h[cyc+1,:,:]-ds_sub.delta_h[cyc,:,:])\n",
    "        neg = np.nanmin(ds_sub.delta_h[cyc+1,:,:]-ds_sub.delta_h[cyc,:,:])\n",
    "        height_anom_pos += [pos]\n",
    "        height_anom_neg += [neg]\n",
    "    max_height_anom_pos = max(height_anom_pos)\n",
    "    max_height_anom_neg = min(height_anom_neg)\n",
    "    max_height_anom_abs = max(max_height_anom_pos,abs(max_height_anom_neg))\n",
    "    v = np.round(max_height_anom_abs)\n",
    "    # create fig, ax, colorbar\n",
    "    fig, ax = plt.subplots(figsize=(8,8))\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes('right', size='5%', pad=0.2)\n",
    "    # create empty list to store animation im(age)s\n",
    "    ani = animation.PillowWriter(fps=1)\n",
    "    if dataset.fileName == 'mos_2010.5_2021.5.h5':\n",
    "        ani.setup(fig, '/Users/Wilson/Documents/0-code/1-lakeshores/output_dhdvdt-using-variable-outlines/S09SF18varoutlines_dhdt_plot_anim_height_thresholds/anim/S09SF18varoutlines_dhdt_anim-{}-dhdt-{}.gif'.format(lakename_SF18, 'CS2'), dpi=300)\n",
    "    elif dataset.fileName == 'ATL15_AA_0311_01km_001_01.nc':    \n",
    "        ani.setup(fig, '/Users/Wilson/Documents/0-code/1-lakeshores/output_dhdvdt-using-variable-outlines/S09SF18varoutlines_dhdt_plot_anim_height_thresholds/anim/S09SF18varoutlines_dhdt_anim-{}-dhdt-{}.gif'.format(lakename_SF18, 'IS2'), dpi=300)\n",
    "    dates = []\n",
    "    for idx in range(len(ds_sub.time)-1): \n",
    "        dhdt = ds_sub.delta_h[idx+1,:,:]-ds_sub.delta_h[idx,:,:]\n",
    "        # calculate mid-cycle dates for plotting\n",
    "        if dataset.fileName == 'mos_2010.5_2021.5.h5':\n",
    "            newdate = datetime.datetime(int(ds_sub.time.values[idx]), 1, 1) + datetime.timedelta(days = (ds_sub.time.values[idx] % 1) * 365.25)\n",
    "            newdate1 = datetime.datetime(int(ds_sub.time.values[idx+1]), 1, 1) + datetime.timedelta(days = (ds_sub.time.values[idx+1] % 1) * 365.25)\n",
    "            midcycdays = newdate1 - newdate\n",
    "            midcycdate = newdate + midcycdays/2\n",
    "            dates += [midcycdate]\n",
    "        elif dataset.fileName == 'ATL15_AA_0311_01km_001_01.nc':    \n",
    "            date_time_str = '18-01-01'\n",
    "            date_time_obj = datetime.datetime.strptime(date_time_str, '%y-%m-%d')\n",
    "            newdate = date_time_obj + datetime.timedelta(days=ds_sub.time.values[idx])\n",
    "            newdate1 = date_time_obj + datetime.timedelta(days=ds_sub.time.values[idx+1])\n",
    "            midcycdays = newdate1 - newdate\n",
    "            midcycdate = newdate + midcycdays/2\n",
    "            dates += [midcycdate]\n",
    "        # plot figure\n",
    "        dhdt = ds_sub.delta_h[idx+1,:,:]-ds_sub.delta_h[idx,:,:]\n",
    "        img = ax.imshow(dhdt, extent=[x_min, x_max, y_min, y_max], \n",
    "            origin='upper', cmap=cmocean.cm.balance_r, vmin=-v, vmax=v)\n",
    "        # create contours of ice surface elevation height changes to delineate lake outlines\n",
    "        contours_fill = []\n",
    "        contours_drain = []\n",
    "        for thres_i in thres:     \n",
    "            contour = measure.find_contours(dhdt.values, thres_i)\n",
    "            if len(contour) > 0: \n",
    "                contours_fill += [contour]\n",
    "            contour = measure.find_contours(dhdt.values, -thres_i)\n",
    "            if len(contour) > 0: \n",
    "                contours_drain += [contour]\n",
    "        # create mapping conversion factor to map array location to polar stereographic x,y\n",
    "        x_conv = (x_max-x_min)/dhdt.shape[1]\n",
    "        y_conv = (y_max-y_min)/dhdt.shape[0]\n",
    "        # plot variable outlines found in this time slice\n",
    "        for i in range(len(contours_fill)): \n",
    "            for j in range(len(contours_fill[i])):\n",
    "                ax.plot(x_min+contours_fill[i][j][:,1]*x_conv, y_max-contours_fill[i][j][:,0]*y_conv, color='mediumblue', linestyle='dashdot', linewidth=1)\n",
    "        for i in range(len(contours_drain)): \n",
    "            for j in range(len(contours_drain[i])):\n",
    "                ax.plot(x_min+contours_drain[i][j][:,1]*x_conv, y_max-contours_drain[i][j][:,0]*y_conv, color='maroon', linestyle=(0, (3, 1, 1, 1)), linewidth=1)\n",
    "        ax.set(xlim=(x_min, x_max), ylim=(y_min, y_max))\n",
    "        # Change polar stereographic m to km\n",
    "        km_scale = 1e3\n",
    "        ticks_x = ticker.FuncFormatter(lambda x, pos: '{0:g}'.format(x/km_scale))\n",
    "        ax.xaxis.set_major_formatter(ticks_x)\n",
    "        ticks_y = ticker.FuncFormatter(lambda x, pos: '{0:g}'.format(x/km_scale))\n",
    "        ax.yaxis.set_major_formatter(ticks_y)  \n",
    "        # adjust ticks\n",
    "        ax.set_xticks(np.arange(x_min,x_max,5000))\n",
    "        ax.set_yticks(np.arange(y_min,y_max,5000))\n",
    "        # label axes\n",
    "        ax.set_xlabel('x [km]', size=15)\n",
    "        ax.set_ylabel('y [km]', size=15)\n",
    "        ax.set_title(lakename_SF18+' dh + outline comparison \\nh$_{'+newdate1.strftime('%m/%Y')+'}$ - h$_{'+newdate.strftime('%m/%Y')+'}$', pad=7.5, fontsize=17.5)\n",
    "        fig.colorbar(img, cax=cax).set_label('height change (dh) [m]', size=15)\n",
    "        # overlay published outlines for visual comparison \n",
    "        Smith2009_outlines.boundary.plot(ax=ax, color='k', linestyle='--', linewidth=1)\n",
    "        SiegfriedFricker2018_outlines.boundary.plot(ax=ax, color='k', linestyle='-', linewidth=1)\n",
    "        Smith2009 = plt.Line2D((0, 1), (0, 0), color='k', linestyle='--', linewidth=2)\n",
    "        SiegfriedFricker2018 = plt.Line2D((0, 1), (0, 0), color='k', linestyle='-', linewidth=2)\n",
    "        uplift = plt.Line2D((0, 1), (0, 0), color='mediumblue', linestyle='dashdot', linewidth=2)\n",
    "        subsidence = plt.Line2D((0, 1), (0, 0), color='maroon', linestyle=(0, (3, 1, 1, 1)), linewidth=2)\n",
    "        ax.legend([Smith2009,SiegfriedFricker2018,uplift, subsidence],\n",
    "            ['Smith and others, 2009 outline','Siegfried & Fricker, 2018 outline',\n",
    "            ('+'+str(thres)+' m uplift (filling) variable outline'), '–'+str(thres)+' m subsidence (draining) variable outline'], \n",
    "            loc='upper left')\n",
    "        # plot inset map to show location \n",
    "        axIns = ax.inset_axes([0.01, 0.001, 0.25, 0.25])\n",
    "        axIns.patch.set_facecolor('lightskyblue')\n",
    "        axIns.set_aspect('equal')\n",
    "        axIns.scatter(((x_max+x_min)/2), ((y_max+y_min)/2), marker='*', \n",
    "            linewidth=1, edgecolor='k', facecolor='r', s=100, zorder=3)\n",
    "        Scripps_gl.plot(ax=axIns, color='ghostwhite', edgecolor='k', linewidth=0.5, zorder=2)\n",
    "        axIns.axis('off')\n",
    "        # save and close figure\n",
    "        if dataset.fileName == 'mos_2010.5_2021.5.h5':\n",
    "            plt.savefig('/Users/Wilson/Documents/0-code/1-lakeshores/output_dhdvdt-using-variable-outlines/S09SF18varoutlines_dhdt_plot_anim_height_thresholds/plot/S09SF18varoutlines_dhdt_plot-{}-{}-dhdt-{}.png'.format(lakename_SF18,'CS2',midcycdate.strftime('%Y-%m')), dpi=300, bbox_inches = \"tight\")\n",
    "        elif dataset.fileName == 'ATL15_AA_0311_01km_001_01.nc':    \n",
    "            plt.savefig('/Users/Wilson/Documents/0-code/1-lakeshores/output_dhdvdt-using-variable-outlines/S09SF18varoutlines_dhdt_plot_anim_height_thresholds/plot/S09SF18varoutlines_dhdt_plot-{}-{}-dhdt-{}.png'.format(lakename_SF18,'IS2',midcycdate.strftime('%Y-%m')), dpi=300, bbox_inches = \"tight\")      \n",
    "        # append im(age) to ims list\n",
    "        ani.grab_frame()\n",
    "        ax.clear()\n",
    "    # finish animation\n",
    "    ani.finish()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test function working using one lake\n",
    "x_min = -3.4e5\n",
    "x_max = -2.9e5\n",
    "y_min = -5.4e5\n",
    "y_max = -5.0e5\n",
    "\n",
    "# test function working using one lake\n",
    "# S09SF18varoutlines_dhdt_plot_anim_height_thresholds('ConwaySubglacialLake', 10000, [0.25, 0.5, 0.75], CS2_dh)\n",
    "S09SF18varoutlines_dhdt_plot_anim_height_thresholds(x_min, x_max, y_min, y_max, 'ConwaySubglacialLake', 10000, [0.2, 0.4, 0.6, 0.8], ATL15_dh)\n",
    "# S09SF18varoutlines_dhdt_plot_anim_height_thresholds('Lambert_1', 10000, [0.25, 0.5, 0.75], CS2_dh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run func on all lakes from SF18 inventory\n",
    "for idx in range(len(SiegfriedFricker2018_outlines)-1):\n",
    "    lakename = SiegfriedFricker2018_outlines['name'][idx]\n",
    "    S09SF18varoutlines_dhdt_plot_anim_height_thresholds(lakename, 7500, [0.25, 0.75], CS2_dh)\n",
    "    S09SF18varoutlines_dhdt_plot_anim_height_thresholds(lakename, 7500, [0.25, 0.75], ATL15_dh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run func on all lakes from SF18 inventory\n",
    "for idx in range(len(SiegfriedFricker2018_outlines)-1):\n",
    "    lakename = SiegfriedFricker2018_outlines['name'][idx]\n",
    "    S09SF18varoutlines_dhdt_plot_anim_height_thresholds(lakename, 7500, [0.25, 0.75], CS2_dh)\n",
    "    S09SF18varoutlines_dhdt_plot_anim_height_thresholds(lakename, 7500, [0.25, 0.75], ATL15_dh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# added explicit bounding box for more precision in plotting fig (from original func)\n",
    "def S09SF18varoutlines_dhdt_plot_anim(x_min, x_max, y_min, y_max, lakename_SF18, buffer, thres, dataset): \n",
    "    '''\n",
    "    Create planview dh/dt plots of ice surface height changes using geopandas buffer created bounding box around known lakes in \n",
    "    Siegfried and Fricker, 2018 (SF18) inventory.\n",
    "    Create time-variable outlines using skimage contour to plot variable outline alongside published outlines for comparison. \n",
    "    Inputs: \n",
    "        lakename: lake of interest from SiegfriedFricker2018_outlines inventory\n",
    "        buffer: horizontal distance in meters away from SF18 lake outline used to create bounding box that is displayed around lake of interest\n",
    "        thres(hold): vertical distance in meters to delineate ice surface deformation contour\n",
    "        dataset: dataset to be analyzed (CS2_dh or ATL15_dh)\n",
    "    Outputs: \n",
    "        Sequence of planview dh/dt visuals of CryoSat-2 or ICESat-2 ATL15 with variable ice surface deformation contours plotted to delineate time-variable lake boundary.\n",
    "    '''\n",
    "    # isolate individual lake using gpd buffer\n",
    "    #lake_gpd = Smith2009_outlines.loc[Smith2009_outlines['Name'] == lakename]\n",
    "    lake_gpd = SiegfriedFricker2018_outlines.loc[SiegfriedFricker2018_outlines['name'] == lakename_SF18]\n",
    "    lake_buffer = lake_gpd.buffer(buffer)\n",
    "    # define lake bounding box\n",
    "    # x_min = lake_buffer.bounds.values[0,0]; x_max = lake_buffer.bounds.values[0,2]\n",
    "    # y_min = lake_buffer.bounds.values[0,1]; y_max = lake_buffer.bounds.values[0,3]\n",
    "    # subset ATL15 data set to region of interest\n",
    "    mask_x = (dataset.x >= x_min) & (dataset.x <= x_max)\n",
    "    mask_y = (dataset.y >= y_min) & (dataset.y <= y_max)\n",
    "    ds_sub = dataset.where(mask_x & mask_y, drop=True)\n",
    "    # find magnitude of ice surface deformation in bounding box / find appropriate color map scale\n",
    "    height_anom_pos = []\n",
    "    height_anom_neg = []\n",
    "    for cyc in range(len(ds_sub.time)-1):\n",
    "        pos = np.nanmax(ds_sub.delta_h[cyc+1,:,:]-ds_sub.delta_h[cyc,:,:])\n",
    "        neg = np.nanmin(ds_sub.delta_h[cyc+1,:,:]-ds_sub.delta_h[cyc,:,:])\n",
    "        height_anom_pos += [pos]\n",
    "        height_anom_neg += [neg]\n",
    "    max_height_anom_pos = max(height_anom_pos)\n",
    "    max_height_anom_neg = min(height_anom_neg)\n",
    "    max_height_anom_abs = max(max_height_anom_pos,abs(max_height_anom_neg))\n",
    "    v = np.round(max_height_anom_abs)\n",
    "    # create fig, ax, colorbar\n",
    "    fig, ax = plt.subplots(figsize=(8,8))\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes('right', size='5%', pad=0.2)\n",
    "    # create empty list to store animation im(age)s\n",
    "    ani = animation.PillowWriter(fps=2)\n",
    "    if dataset.fileName == 'mos_2010.5_2021.5.h5':\n",
    "        ani.setup(fig, '/Users/Wilson/Documents/0-code/1-lakeshores/output_dhdvdt-using-variable-outlines/S09SF18varoutlines_dhdt_plot_anim/anim/S09SF18varoutlines_dhdt_anim-{}-dhdt-{}.gif'.format(lakename_SF18, 'CS2'), dpi=300)\n",
    "    elif dataset.fileName == 'ATL15_AA_0311_01km_001_01.nc':    \n",
    "        ani.setup(fig, '/Users/Wilson/Documents/0-code/1-lakeshores/output_dhdvdt-using-variable-outlines/S09SF18varoutlines_dhdt_plot_anim/anim/S09SF18varoutlines_dhdt_anim-{}-dhdt-{}.gif'.format(lakename_SF18, 'IS2'), dpi=300)\n",
    "    dates = []\n",
    "    for idx in range(len(ds_sub.time)-1): \n",
    "        dhdt = ds_sub.delta_h[idx+1,:,:]-ds_sub.delta_h[idx,:,:]\n",
    "        # calculate mid-cycle dates for plotting\n",
    "        if dataset.fileName == 'mos_2010.5_2021.5.h5':\n",
    "            newdate = datetime.datetime(int(ds_sub.time.values[idx]), 1, 1) + datetime.timedelta(days = (ds_sub.time.values[idx] % 1) * 365.25)\n",
    "            newdate1 = datetime.datetime(int(ds_sub.time.values[idx+1]), 1, 1) + datetime.timedelta(days = (ds_sub.time.values[idx+1] % 1) * 365.25)\n",
    "            midcycdays = newdate1 - newdate\n",
    "            midcycdate = newdate + midcycdays/2\n",
    "            dates += [midcycdate]\n",
    "        elif dataset.fileName == 'ATL15_AA_0311_01km_001_01.nc':    \n",
    "            date_time_str = '18-01-01'\n",
    "            date_time_obj = datetime.datetime.strptime(date_time_str, '%y-%m-%d')\n",
    "            newdate = date_time_obj + datetime.timedelta(days=ds_sub.time.values[idx])\n",
    "            newdate1 = date_time_obj + datetime.timedelta(days=ds_sub.time.values[idx+1])\n",
    "            midcycdays = newdate1 - newdate\n",
    "            midcycdate = newdate + midcycdays/2\n",
    "            dates += [midcycdate]\n",
    "        # plot figure\n",
    "        dhdt = ds_sub.delta_h[idx+1,:,:]-ds_sub.delta_h[idx,:,:]\n",
    "        img = ax.imshow(dhdt, extent=[x_min, x_max, y_min, y_max], \n",
    "            origin='upper', cmap=cmocean.cm.balance_r, vmin=-v, vmax=v)\n",
    "        # create contours of ice surface elevation height changes to delineate lake outlines\n",
    "        contours_fill = []\n",
    "        contours_drain = []\n",
    "        contour = measure.find_contours(dhdt.values, thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_fill += [contour]\n",
    "        contour = measure.find_contours(dhdt.values, -thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_drain += [contour]\n",
    "        # create mapping conversion factor to map array location to polar stereographic x,y\n",
    "        x_conv = (x_max-x_min)/dhdt.shape[1]\n",
    "        y_conv = (y_max-y_min)/dhdt.shape[0]\n",
    "        # plot variable outlines found in this time slice\n",
    "        for i in range(len(contours_fill)): \n",
    "            for j in range(len(contours_fill[i])):\n",
    "                ax.plot(x_min+contours_fill[i][j][:, 1]*x_conv, y_max-contours_fill[i][j][:, 0]*y_conv, color='mediumblue', linestyle='dashdot', linewidth=2)\n",
    "        for i in range(len(contours_drain)): \n",
    "            for j in range(len(contours_drain[i])):\n",
    "                ax.plot(x_min+contours_drain[i][j][:, 1]*x_conv, y_max-contours_drain[i][j][:, 0]*y_conv, color='maroon', linestyle=(0, (3, 1, 1, 1)), linewidth=2)\n",
    "        ax.set(xlim=(x_min, x_max), ylim=(y_min, y_max))\n",
    "        ax.set_xlabel('polar stereographic x [m]', size=15)\n",
    "        ax.set_ylabel('polar stereographic y [m]', size=15)\n",
    "        ax.ticklabel_format(axis='both',scilimits=(0,0))\n",
    "        # ax.set_title(lakename_SF18+' dh/dt and outline comparison \\n$h_{'+newdate1.strftime('%m/%Y')+'} - h_{'+newdate.strftime('%m/%Y')+'}$', pad=7.5, fontsize=17.5)\n",
    "        ax.set_title('Slessor$_{23}$ dh/dt and outline comparison \\n$h_{'+newdate1.strftime('%m/%Y')+'} - h_{'+newdate.strftime('%m/%Y')+'}$', pad=7.5, fontsize=17.5)\n",
    "        fig.colorbar(img, cax=cax).set_label('Height (h) change [m]', size=15)\n",
    "        # overlay published outlines for visual comparison \n",
    "        Smith2009_outlines.boundary.plot(ax=ax, color='k', linestyle='--', linewidth=1)\n",
    "        SiegfriedFricker2018_outlines.boundary.plot(ax=ax, color='k', linestyle='-', linewidth=1)\n",
    "        Smith2009 = plt.Line2D((0, 1), (0, 0), color='k', linestyle='--', linewidth=2)\n",
    "        SiegfriedFricker2018 = plt.Line2D((0, 1), (0, 0), color='k', linestyle='-', linewidth=2)\n",
    "        uplift = plt.Line2D((0, 1), (0, 0), color='mediumblue', linestyle='dashdot', linewidth=2)\n",
    "        subsidence = plt.Line2D((0, 1), (0, 0), color='maroon', linestyle=(0, (3, 1, 1, 1)), linewidth=2)\n",
    "        ax.legend([Smith2009,SiegfriedFricker2018,uplift, subsidence],\n",
    "            ['Smith and others, 2009 outline','Siegfried & Fricker, 2018 outline',\n",
    "            ('+'+str(thres)+' m uplift (filling) variable outline'), '–'+str(thres)+' m subsidence (draining) variable outline'], \n",
    "            loc='best')\n",
    "        # plot inset map to show location \n",
    "        axIns = ax.inset_axes([0.05, 0.75, 0.25, 0.25])\n",
    "        axIns.patch.set_facecolor('lightskyblue')\n",
    "        axIns.set_aspect('equal')\n",
    "        axIns.scatter(((x_max+x_min)/2), ((y_max+y_min)/2), marker='*', \n",
    "            linewidth=1, edgecolor='k', facecolor='r', s=100, zorder=3)\n",
    "        Scripps_gl.plot(ax=axIns, color='ghostwhite', edgecolor='k', linewidth=0.5, zorder=2)\n",
    "        # SiegfriedFricker2018_outlines.boundary.plot(ax=axIns, color='k', linestyle='-', linewidth=1)\n",
    "        axIns.axis('off')\n",
    "        # save and close figure\n",
    "        if dataset.fileName == 'mos_2010.5_2021.5.h5':\n",
    "            plt.savefig('/Users/Wilson/Documents/0-code/1-lakeshores/output_dhdvdt-using-variable-outlines/S09SF18varoutlines_dhdt_plot_anim/plot/S09SF18varoutlines_dhdt_plot-{}-{}-dhdt-{}.png'.format(lakename_SF18,'CS2',midcycdate.strftime('%Y-%m')), dpi=300, bbox_inches = \"tight\")\n",
    "        elif dataset.fileName == 'ATL15_AA_0311_01km_001_01.nc':    \n",
    "            plt.savefig('/Users/Wilson/Documents/0-code/1-lakeshores/output_dhdvdt-using-variable-outlines/S09SF18varoutlines_dhdt_plot_anim/plot/S09SF18varoutlines_dhdt_plot-{}-{}-dhdt-{}.png'.format(lakename_SF18,'IS2',midcycdate.strftime('%Y-%m')), dpi=300, bbox_inches = \"tight\")      \n",
    "        # append im(age) to ims list\n",
    "        ani.grab_frame()\n",
    "        ax.clear()\n",
    "    # finish animation\n",
    "    ani.finish()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changed to make bounding box explicit\n",
    "# adding polygon creation to plot moving centroid\n",
    "def S09SF18varoutlines_dhdt_plot_anim(x_min, x_max, y_min, y_max, lakename_SF18, buffer, thres, dataset): \n",
    "    '''\n",
    "    Create planview dh/dt plots of ice surface height changes using geopandas buffer created bounding box around known lakes in \n",
    "    Siegfried and Fricker, 2018 (SF18) inventory.\n",
    "    Create time-variable outlines using skimage contour to plot variable outline alongside published outlines for comparison. \n",
    "    Inputs: \n",
    "        lakename: lake of interest from SiegfriedFricker2018_outlines inventory\n",
    "        buffer: horizontal distance in meters away from SF18 lake outline used to create bounding box that is displayed around lake of interest\n",
    "        thres(hold): vertical distance in meters to delineate ice surface deformation contour\n",
    "        dataset: dataset to be analyzed (CS2_dh or ATL15_dh)\n",
    "    Outputs: \n",
    "        Sequence of planview dh/dt visuals of CryoSat-2 or ICESat-2 ATL15 with variable ice surface deformation contours plotted to delineate time-variable lake boundary.\n",
    "    '''\n",
    "    # isolate individual lake using gpd buffer\n",
    "    #lake_gpd = Smith2009_outlines.loc[Smith2009_outlines['Name'] == lakename]\n",
    "    lake_gpd = SiegfriedFricker2018_outlines.loc[SiegfriedFricker2018_outlines['name'] == lakename_SF18]\n",
    "    lake_buffer = lake_gpd.buffer(buffer)\n",
    "    # define lake bounding box\n",
    "    # x_min = lake_buffer.bounds.values[0,0]; x_max = lake_buffer.bounds.values[0,2]\n",
    "    # y_min = lake_buffer.bounds.values[0,1]; y_max = lake_buffer.bounds.values[0,3]\n",
    "    # subset ATL15 data set to region of interest\n",
    "    mask_x = (dataset.x >= x_min) & (dataset.x <= x_max)\n",
    "    mask_y = (dataset.y >= y_min) & (dataset.y <= y_max)\n",
    "    ds_sub = dataset.where(mask_x & mask_y, drop=True)\n",
    "    # find magnitude of ice surface deformation in bounding box / find appropriate color map scale\n",
    "    height_anom_pos = []\n",
    "    height_anom_neg = []\n",
    "    for cyc in range(len(ds_sub.time)-1):\n",
    "        pos = np.nanmax(ds_sub.delta_h[cyc+1,:,:]-ds_sub.delta_h[cyc,:,:])\n",
    "        neg = np.nanmin(ds_sub.delta_h[cyc+1,:,:]-ds_sub.delta_h[cyc,:,:])\n",
    "        height_anom_pos += [pos]\n",
    "        height_anom_neg += [neg]\n",
    "    max_height_anom_pos = max(height_anom_pos)\n",
    "    max_height_anom_neg = min(height_anom_neg)\n",
    "    max_height_anom_abs = max(max_height_anom_pos,abs(max_height_anom_neg))\n",
    "    v = np.round(max_height_anom_abs)\n",
    "    # create fig, ax, colorbar\n",
    "    fig, ax = plt.subplots(figsize=(8,8))\n",
    "    cmap = plt.get_cmap('CMRmap')\n",
    "    norm = plt.Normalize(ds_sub.time.values[0],ds_sub.time.values[-1])    \n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes('right', size='5%', pad=0.2)\n",
    "    # create empty list to store animation im(age)s\n",
    "    ani = animation.PillowWriter(fps=2)\n",
    "    if dataset.fileName == 'mos_2010.5_2021.5.h5':\n",
    "        ani.setup(fig, '/Users/Wilson/Documents/0-code/1-lakeshores/output_dhdvdt-using-variable-outlines/S09SF18varoutlines_dhdt_plot_anim/anim/S09SF18varoutlines_dhdt_anim-{}-dhdt-{}.gif'.format(lakename_SF18, 'CS2'), dpi=300)\n",
    "    elif dataset.fileName == 'ATL15_AA_0311_01km_001_01.nc':    \n",
    "        ani.setup(fig, '/Users/Wilson/Documents/0-code/1-lakeshores/output_dhdvdt-using-variable-outlines/S09SF18varoutlines_dhdt_plot_anim/anim/S09SF18varoutlines_dhdt_anim-{}-dhdt-{}.gif'.format(lakename_SF18, 'IS2'), dpi=300)\n",
    "    dates = []\n",
    "    for idx in range(len(ds_sub.time)-1): \n",
    "        dhdt = ds_sub.delta_h[idx+1,:,:]-ds_sub.delta_h[idx,:,:]\n",
    "        # calculate mid-cycle dates for plotting\n",
    "        if dataset.fileName == 'mos_2010.5_2021.5.h5':\n",
    "            newdate = datetime.datetime(int(ds_sub.time.values[idx]), 1, 1) + datetime.timedelta(days = (ds_sub.time.values[idx] % 1) * 365.25)\n",
    "            newdate1 = datetime.datetime(int(ds_sub.time.values[idx+1]), 1, 1) + datetime.timedelta(days = (ds_sub.time.values[idx+1] % 1) * 365.25)\n",
    "            midcycdays = newdate1 - newdate\n",
    "            midcycdate = newdate + midcycdays/2\n",
    "            dates += [midcycdate]\n",
    "        elif dataset.fileName == 'ATL15_AA_0311_01km_001_01.nc':    \n",
    "            date_time_str = '18-01-01'\n",
    "            date_time_obj = datetime.datetime.strptime(date_time_str, '%y-%m-%d')\n",
    "            newdate = date_time_obj + datetime.timedelta(days=ds_sub.time.values[idx])\n",
    "            newdate1 = date_time_obj + datetime.timedelta(days=ds_sub.time.values[idx+1])\n",
    "            midcycdays = newdate1 - newdate\n",
    "            midcycdate = newdate + midcycdays/2\n",
    "            dates += [midcycdate]\n",
    "        # plot figure\n",
    "        dhdt = ds_sub.delta_h[idx+1,:,:]-ds_sub.delta_h[idx,:,:]\n",
    "        img = ax.imshow(dhdt, extent=[x_min, x_max, y_min, y_max], \n",
    "            origin='upper', cmap=cmocean.cm.balance_r, vmin=-v, vmax=v)\n",
    "        # create contours of ice surface elevation height changes to delineate lake outlines\n",
    "        contours_fill = []\n",
    "        contours_drain = []\n",
    "        polys = []\n",
    "        contour = measure.find_contours(dhdt.values, thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_fill += [contour]\n",
    "        contour = measure.find_contours(dhdt.values, -thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_drain += [contour]\n",
    "        # create mapping conversion factor to map array location to polar stereographic x,y\n",
    "        x_conv = (x_max-x_min)/dhdt.shape[1]\n",
    "        y_conv = (y_max-y_min)/dhdt.shape[0]\n",
    "        # plot variable outlines found in this time slice\n",
    "        # make polygons from variable outlines\n",
    "        for i in range(len(contours_fill)): \n",
    "            for j in range(len(contours_fill[i])):\n",
    "                ax.plot(x_min+contours_fill[i][j][:, 1]*x_conv, y_max-contours_fill[i][j][:, 0]*y_conv, \n",
    "                color='mediumblue', linestyle='dashdot', linewidth=1)\n",
    "                if len(contours_fill[i][j][:, 1]) > 2: \n",
    "                    poly = Polygon(list(zip(contours_fill[i][j][:, 1]*x_conv+x_min, y_max-contours_fill[i][j][:, 0]*y_conv))) \n",
    "                    ax.plot(poly.centroid.coords[0][0], poly.centroid.coords[0][1], marker='+', color='mediumblue', markersize=10)\n",
    "                    polys += [poly]\n",
    "        for i in range(len(contours_drain)): \n",
    "            for j in range(len(contours_drain[i])):\n",
    "                ax.plot(x_min+contours_drain[i][j][:, 1]*x_conv, y_max-contours_drain[i][j][:, 0]*y_conv, color='maroon', linestyle=(0, (3, 1, 1, 1)), linewidth=1)\n",
    "                if len(contours_drain[i][j][:, 1]) > 2: \n",
    "                    poly = Polygon(list(zip(contours_drain[i][j][:, 1]*x_conv+x_min, y_max-contours_drain[i][j][:, 0]*y_conv))) \n",
    "                    ax.plot(poly.centroid.coords[0][0], poly.centroid.coords[0][1], marker='+', color='maroon', markersize=10)\n",
    "                    polys += [poly]\n",
    "        ax.set(xlim=(x_min, x_max), ylim=(y_min, y_max))\n",
    "        # change polar stereographic m to km for cleaner-looking axes labels\n",
    "        km_scale = 1e3\n",
    "        ticks_x = ticker.FuncFormatter(lambda x, pos: '{0:g}'.format(x/km_scale))\n",
    "        ax.xaxis.set_major_formatter(ticks_x)\n",
    "        ticks_y = ticker.FuncFormatter(lambda x, pos: '{0:g}'.format(x/km_scale))\n",
    "        ax.yaxis.set_major_formatter(ticks_y)  \n",
    "        ax.set_xlabel('x [km]', size=15)\n",
    "        ax.set_ylabel('y [km]', size=15)\n",
    "        ax.set_title(lakename_SF18+' dh/dt and outline comparison \\n$h_{'+newdate1.strftime('%m/%Y')+'} - h_{'+newdate.strftime('%m/%Y')+'}$', pad=7.5, fontsize=17.5)\n",
    "        # ax.set_title('Slessor$_{23}$ dh and outline comparison \\n$h_{'+newdate1.strftime('%m/%Y')+'} - h_{'+newdate.strftime('%m/%Y')+'}$', pad=7.5, fontsize=17.5)\n",
    "        fig.colorbar(img, cax=cax).set_label('Height (h) change [m]', size=15)\n",
    "        # overlay published outlines for visual comparison \n",
    "        Smith2009_outlines.boundary.plot(ax=ax, color='k', linestyle='--', linewidth=1)\n",
    "        SiegfriedFricker2018_outlines.boundary.plot(ax=ax, color='k', linestyle='-', linewidth=1)\n",
    "        Smith2009 = plt.Line2D((0, 1), (0, 0), color='k', linestyle='--', linewidth=2)\n",
    "        SiegfriedFricker2018 = plt.Line2D((0, 1), (0, 0), color='k', linestyle='-', linewidth=2)\n",
    "        uplift = plt.Line2D((0, 1), (0, 0), color='mediumblue', linestyle='dashdot', linewidth=2)\n",
    "        subsidence = plt.Line2D((0, 1), (0, 0), color='maroon', linestyle=(0, (3, 1, 1, 1)), linewidth=2)\n",
    "        ax.legend([Smith2009,SiegfriedFricker2018,uplift, subsidence],\n",
    "            ['Smith and others, 2009 outline','Siegfried & Fricker, 2018 outline',\n",
    "            ('+'+str(thres)+' m uplift (filling) variable outline'), '–'+str(thres)+' m subsidence (draining) variable outline'], \n",
    "            loc='best')\n",
    "        # plot inset map to show location \n",
    "        axIns = ax.inset_axes([0.05, 0.75, 0.25, 0.25])\n",
    "        axIns.patch.set_facecolor('lightskyblue')\n",
    "        axIns.set_aspect('equal')\n",
    "        axIns.scatter(((x_max+x_min)/2), ((y_max+y_min)/2), marker='*', \n",
    "            linewidth=1, edgecolor='k', facecolor='r', s=100, zorder=3)\n",
    "        Scripps_gl.plot(ax=axIns, color='ghostwhite', edgecolor='k', linewidth=0.5, zorder=2)\n",
    "        # SiegfriedFricker2018_outlines.boundary.plot(ax=axIns, color='k', linestyle='-', linewidth=1)\n",
    "        axIns.axis('off')\n",
    "        # save and close figure\n",
    "        if dataset.fileName == 'mos_2010.5_2021.5.h5':\n",
    "            plt.savefig('/Users/Wilson/Documents/0-code/1-lakeshores/output_dhdvdt-using-variable-outlines/S09SF18varoutlines_dhdt_plot_anim/plot/S09SF18varoutlines_dhdt_plot-{}-{}-dhdt-{}.png'.format(lakename_SF18,'CS2',midcycdate.strftime('%Y-%m')), dpi=300, bbox_inches = \"tight\")\n",
    "        elif dataset.fileName == 'ATL15_AA_0311_01km_001_01.nc':    \n",
    "            plt.savefig('/Users/Wilson/Documents/0-code/1-lakeshores/output_dhdvdt-using-variable-outlines/S09SF18varoutlines_dhdt_plot_anim/plot/S09SF18varoutlines_dhdt_plot-{}-{}-dhdt-{}.png'.format(lakename_SF18,'IS2',midcycdate.strftime('%Y-%m')), dpi=300, bbox_inches = \"tight\")      \n",
    "        # append im(age) to ims list\n",
    "        ani.grab_frame()\n",
    "        ax.clear()\n",
    "    # finish animation\n",
    "    ani.finish()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test function working using one lake\n",
    "x_min = -4.25e5\n",
    "x_max = -3.9e5\n",
    "y_min = 1.015e6\n",
    "y_max = 1.05e6\n",
    "S09SF18varoutlines_dhdt_plot_anim(x_min, x_max, y_min, y_max, 'Slessor_23', 10000, 0.5, CS2_dh)\n",
    "# S09SF18varoutlines_dhdt_plot_anim('Slessor_23', 10000, 0.5, ATL15_dh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test function working using one lake\n",
    "# S09SF18varoutlines_dhdt_plot_anim('Whillans_7', 10000, 0.75, CS2_dh)\n",
    "S09SF18varoutlines_dhdt_plot_anim('Whillans_7', 10000, 0.75, ATL15_dh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run func on all lakes from SF18 inventory\n",
    "for idx in range(len(SiegfriedFricker2018_outlines)-1):\n",
    "    lakename = SiegfriedFricker2018_outlines['name'][idx]\n",
    "    S09SF18varoutlines_dhdt_plot_anim(lakename, 7500, 0.75, CS2_dh)\n",
    "    S09SF18varoutlines_dhdt_plot_anim(lakename, 7500, 0.75, ATL15_dh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Func S09SF18varoutlines_agg_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def S09SF18varoutlines_agg_plot(lakename_SF18, buffer, thres, dataset): \n",
    "    '''\n",
    "    Create planview plot of an aggregated times series of variable outlines compared to known lakes. Uses geopandas buffer created bounding box \n",
    "    around known lakes in Siegfried and Fricker, 2018 (SF18) inventory.\n",
    "    Create time-variable outlines using skimage contour to plot variable outline alongside published outlines for comparison. \n",
    "    Inputs: \n",
    "        lakename_SF18: lake of interest from SiegfriedFricker2018_outlines inventory\n",
    "        buffer: horizontal distance in meters away from SF18 lake outline used to create bounding box that is displayed around lake of interest\n",
    "        thres(hold): vertical distance in meters to delineate ice surface deformation contour\n",
    "        dataset: dataset to be analyzed (CS2_dh or ATL15_dh)\n",
    "    Outputs: \n",
    "        Aggregated time-variable lake outlines in regions of known lakes using CryoSat-2 or ICESat-2 ATL15 dh/dt data.\n",
    "    '''\n",
    "    # isolate individual lake using gpd buffer\n",
    "    #lake_gpd = Smith2009_outlines.loc[Smith2009_outlines['Name'] == lakename_SF18]\n",
    "    lake_gpd = SiegfriedFricker2018_outlines.loc[SiegfriedFricker2018_outlines['name'] == lakename_SF18]\n",
    "    lake_buffer = lake_gpd.buffer(buffer)\n",
    "    # define lake bounding box\n",
    "    x_min = lake_buffer.bounds.values[0,0]; x_max = lake_buffer.bounds.values[0,2]\n",
    "    y_min = lake_buffer.bounds.values[0,1]; y_max = lake_buffer.bounds.values[0,3]\n",
    "    # subset ATL15 data set to region of interest\n",
    "    mask_x = (dataset.x >= x_min) & (dataset.x <= x_max)\n",
    "    mask_y = (dataset.y >= y_min) & (dataset.y <= y_max)\n",
    "    ds_sub = dataset.where(mask_x & mask_y, drop=True)\n",
    "    # find magnitude of ice surface deformation in bounding box / find appropriate color map scale\n",
    "    height_anom_pos = []\n",
    "    height_anom_neg = []\n",
    "    for cyc in range(len(ds_sub.time)-1):\n",
    "        pos = np.nanmax(ds_sub.delta_h[cyc+1,:,:]-ds_sub.delta_h[cyc,:,:])\n",
    "        neg = np.nanmin(ds_sub.delta_h[cyc+1,:,:]-ds_sub.delta_h[cyc,:,:])\n",
    "        height_anom_pos += [pos]\n",
    "        height_anom_neg += [neg]\n",
    "    max_height_anom_pos = max(height_anom_pos)\n",
    "    max_height_anom_neg = min(height_anom_neg)\n",
    "    max_height_anom_abs = max(max_height_anom_pos,abs(max_height_anom_neg))\n",
    "    v = np.round(max_height_anom_abs)\n",
    "    # create empty list to store dates\n",
    "    dates = []\n",
    "    # plot figure\n",
    "    fig, ax = plt.subplots(figsize=(10,10))\n",
    "    cmap = plt.get_cmap('CMRmap')\n",
    "    norm = plt.Normalize(ds_sub.time.values[0],ds_sub.time.values[-1])    \n",
    "    for idx in range(len(ds_sub.time)-1): \n",
    "        # subset data to dhdt diff between orbital cycles of delta_h\n",
    "        dhdt = ds_sub.delta_h[idx+1,:,:]-ds_sub.delta_h[idx,:,:]\n",
    "        # calculate mid-cycle dates for plotting\n",
    "        if dataset.fileName == 'mos_2010.5_2021.5.h5':\n",
    "            newdate = datetime.datetime(int(ds_sub.time.values[idx]), 1, 1) + datetime.timedelta(days = (ds_sub.time.values[idx] % 1) * 365.25)\n",
    "            newdate1 = datetime.datetime(int(ds_sub.time.values[idx+1]), 1, 1) + datetime.timedelta(days = (ds_sub.time.values[idx+1] % 1) * 365.25)\n",
    "            midcycdays = newdate1 - newdate\n",
    "            midcycdate = newdate + midcycdays/2\n",
    "            dates += [midcycdate]\n",
    "        elif dataset.fileName == 'ATL15_AA_0311_01km_001_01.nc':    \n",
    "            date_time_str = '18-01-01'\n",
    "            date_time_obj = datetime.datetime.strptime(date_time_str, '%y-%m-%d')\n",
    "            newdate = date_time_obj + datetime.timedelta(days=ds_sub.time.values[idx])\n",
    "            newdate1 = date_time_obj + datetime.timedelta(days=ds_sub.time.values[idx+1])\n",
    "            midcycdays = newdate1 - newdate\n",
    "            midcycdate = newdate + midcycdays/2\n",
    "            dates += [midcycdate]\n",
    "        # create contours of ice surface elevation height changes to delineate variable lake outlines       \n",
    "        contours_fill = []\n",
    "        contours_drain = []\n",
    "        contour = measure.find_contours(dhdt.values, thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_fill += [contour]\n",
    "        contour = measure.find_contours(dhdt.values, -thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_drain += [contour]\n",
    "        # create mapping conversion factor to map array location to polar stereographic x,y\n",
    "        x_conv = (x_max-x_min)/dhdt.shape[1]\n",
    "        y_conv = (y_max-y_min)/dhdt.shape[0]\n",
    "        # plot variable outlines found in this time slice\n",
    "        for i in range(len(contours_fill)): \n",
    "            for j in range(len(contours_fill[i])):\n",
    "                ax.plot(x_min+contours_fill[i][j][:, 1]*x_conv, y_max-contours_fill[i][j][:, 0]*y_conv, \n",
    "                color=cmap(norm(ds_sub.time.values[idx])), linestyle=(0, (3, 1, 1, 1)), linewidth=1) \n",
    "        for i in range(len(contours_drain)): \n",
    "            for j in range(len(contours_drain[i])):\n",
    "                ax.plot(x_min+contours_drain[i][j][:, 1]*x_conv, y_max-contours_drain[i][j][:, 0]*y_conv, \n",
    "                color=cmap(norm(ds_sub.time.values[idx])), linestyle=(0, (5, 1)), linewidth=1)\n",
    "    ax.set(xlim=(x_min, x_max), ylim=(y_min, y_max))\n",
    "    # change polar stereographic m to km for cleaner-looking axes labels\n",
    "    km_scale = 1e3\n",
    "    ticks_x = ticker.FuncFormatter(lambda x, pos: '{0:g}'.format(x/km_scale))\n",
    "    ax.xaxis.set_major_formatter(ticks_x)\n",
    "    ticks_y = ticker.FuncFormatter(lambda x, pos: '{0:g}'.format(x/km_scale))\n",
    "    ax.yaxis.set_major_formatter(ticks_y)  \n",
    "    ax.set_xlabel('x [km]', size=15)\n",
    "    ax.set_ylabel('y [km]', size=15)\n",
    "    ax.set_title(lakename_SF18+ '\\noutline comparison', pad=7.5, fontsize=17.5)\n",
    "    m = plt.cm.ScalarMappable(cmap=cmap)\n",
    "    m.set_array(np.array([datetime2fracyear(date) for date in dates[0:-1]]))\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes('right', size='5%', pad=0.2)\n",
    "    if dataset.fileName == 'mos_2010.5_2021.5.h5': \n",
    "        fig.colorbar(m, cax=cax).set_label('Year', size=15)\n",
    "    if dataset.fileName == 'ATL15_AA_0311_01km_001_01.nc':    \n",
    "        clb = fig.colorbar(m, ticks=np.array([2019,2020,2021]),  cax=cax)\n",
    "    # overlay published outlines for visual comparison \n",
    "    Smith2009_outlines.boundary.plot(ax=ax, color='k', linestyle=(0, (1, 5)), linewidth=1)\n",
    "    SiegfriedFricker2018_outlines.boundary.plot(ax=ax, color='k', linestyle=(0, (1, 1)), linewidth=1)\n",
    "    Smith2009 = plt.Line2D((0, 1), (0, 0), color='k', linestyle=(0, (1, 5)), linewidth=2)\n",
    "    SiegfriedFricker2018 = plt.Line2D((0, 1), (0, 0), color='k', linestyle=(0, (1, 1)), linewidth=2)\n",
    "    uplift = plt.Line2D((0, 1), (0, 0), color='k', linestyle=(0, (3, 1, 1, 1)), linewidth=2)\n",
    "    subsidence = plt.Line2D((0, 1), (0, 0), color='k', linestyle=(0, (5, 1)), linewidth=1)\n",
    "    ax.legend([Smith2009,SiegfriedFricker2018,uplift, subsidence],\n",
    "        ['Smith and others, 2009 outline','Siegfried & Fricker, 2018 outline',\n",
    "        ('+'+str(thres)+' m uplift (filling) variable outline'), '–'+str(thres)+' m subsidence (draining) variable outline'], \n",
    "        loc='best')\n",
    "    # plot inset map to show location \n",
    "    axIns = ax.inset_axes([0.05, 0.001, 0.25, 0.25])\n",
    "    axIns.patch.set_facecolor('lightskyblue')\n",
    "    axIns.set_aspect('equal')\n",
    "    axIns.scatter(((x_max+x_min)/2), ((y_max+y_min)/2), marker='*', \n",
    "        linewidth=1, edgecolor='k', facecolor='r', s=100, zorder=3)\n",
    "    Scripps_gl.plot(ax=axIns, color='ghostwhite', edgecolor='k', linewidth=0.5, zorder=2)\n",
    "    axIns.axis('off')\n",
    "    # save and close figure\n",
    "    if dataset.fileName == 'mos_2010.5_2021.5.h5':\n",
    "        plt.savefig('/Users/Wilson/Documents/0-code/1-lakeshores/output_dhdvdt-using-variable-outlines/S09SF18varoutlines_agg_plot/S09SF18varoutlines_agg-{}-{}.png'.format(lakename_SF18,'CS2'), dpi=300, bbox_inches = \"tight\")\n",
    "    elif dataset.fileName == 'ATL15_AA_0311_01km_001_01.nc':    \n",
    "        plt.savefig('/Users/Wilson/Documents/0-code/1-lakeshores/output_dhdvdt-using-variable-outlines/S09SF18varoutlines_agg_plot/S09SF18varoutlines_agg-{}-{}.png'.format(lakename_SF18,'IS2'), dpi=300, bbox_inches = \"tight\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test function working using one lake\n",
    "S09SF18varoutlines_agg_plot('Mac1', 10000, 0.5, CS2_dh)\n",
    "S09SF18varoutlines_agg_plot('Mac1', 10000, 0.5, ATL15_dh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run func on all lakes from SF18 inventory\n",
    "for idx in range(len(SiegfriedFricker2018_outlines)-1):\n",
    "    lakename = SiegfriedFricker2018_outlines['name'][idx]\n",
    "    S09SF18varoutlines_agg_plot(lakename, 7500, 0.75, CS2_dh)\n",
    "    S09SF18varoutlines_agg_plot(lakename, 7500, 0.75, ATL15_dh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S09SF18varoutlines_agg_plot('KT1', 7500, 0.5, CS2_dh)\n",
    "S09SF18varoutlines_agg_plot('KT1', 7500, 0.5, ATL15_dh)\n",
    "S09SF18varoutlines_agg_plot('KT2', 7500, 0.5, CS2_dh)\n",
    "S09SF18varoutlines_agg_plot('KT2', 7500, 0.5, ATL15_dh)\n",
    "S09SF18varoutlines_agg_plot('KT3', 7500, 0.5, CS2_dh)\n",
    "S09SF18varoutlines_agg_plot('KT3', 7500, 0.5, ATL15_dh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding explicit coords\n",
    "def S09SF18varoutlines_agg_plot(x_min, x_max, y_min, y_max,lakename_SF18, buffer, thres, dataset): \n",
    "    '''\n",
    "    Create planview plot of an aggregated times series of variable outlines compared to known lakes. Uses geopandas buffer created bounding box \n",
    "    around known lakes in Siegfried and Fricker, 2018 (SF18) inventory.\n",
    "    Create time-variable outlines using skimage contour to plot variable outline alongside published outlines for comparison. \n",
    "    Inputs: \n",
    "        lakename_SF18: lake of interest from SiegfriedFricker2018_outlines inventory\n",
    "        buffer: horizontal distance in meters away from SF18 lake outline used to create bounding box that is displayed around lake of interest\n",
    "        thres(hold): vertical distance in meters to delineate ice surface deformation contour\n",
    "        dataset: dataset to be analyzed (CS2_dh or ATL15_dh)\n",
    "    Outputs: \n",
    "        Aggregated time-variable lake outlines in regions of known lakes using CryoSat-2 or ICESat-2 ATL15 dh/dt data.\n",
    "    '''\n",
    "    # isolate individual lake using gpd buffer\n",
    "    #lake_gpd = Smith2009_outlines.loc[Smith2009_outlines['Name'] == lakename_SF18]\n",
    "    lake_gpd = SiegfriedFricker2018_outlines.loc[SiegfriedFricker2018_outlines['name'] == lakename_SF18]\n",
    "    lake_buffer = lake_gpd.buffer(buffer)\n",
    "    # define lake bounding box\n",
    "    # x_min = lake_buffer.bounds.values[0,0]; x_max = lake_buffer.bounds.values[0,2]\n",
    "    # y_min = lake_buffer.bounds.values[0,1]; y_max = lake_buffer.bounds.values[0,3]\n",
    "    # subset ATL15 data set to region of interest\n",
    "    mask_x = (dataset.x >= x_min) & (dataset.x <= x_max)\n",
    "    mask_y = (dataset.y >= y_min) & (dataset.y <= y_max)\n",
    "    ds_sub = dataset.where(mask_x & mask_y, drop=True)\n",
    "    # find magnitude of ice surface deformation in bounding box / find appropriate color map scale\n",
    "    height_anom_pos = []\n",
    "    height_anom_neg = []\n",
    "    for cyc in range(len(ds_sub.time)-1):\n",
    "        pos = np.nanmax(ds_sub.delta_h[cyc+1,:,:]-ds_sub.delta_h[cyc,:,:])\n",
    "        neg = np.nanmin(ds_sub.delta_h[cyc+1,:,:]-ds_sub.delta_h[cyc,:,:])\n",
    "        height_anom_pos += [pos]\n",
    "        height_anom_neg += [neg]\n",
    "    max_height_anom_pos = max(height_anom_pos)\n",
    "    max_height_anom_neg = min(height_anom_neg)\n",
    "    max_height_anom_abs = max(max_height_anom_pos,abs(max_height_anom_neg))\n",
    "    v = np.round(max_height_anom_abs)\n",
    "    # create empty list to store dates\n",
    "    dates = []\n",
    "    # plot figure\n",
    "    fig, ax = plt.subplots(figsize=(10,10))\n",
    "    cmap = plt.get_cmap('CMRmap')\n",
    "    norm = plt.Normalize(ds_sub.time.values[0],ds_sub.time.values[-1])    \n",
    "    for idx in range(len(ds_sub.time)-1): \n",
    "        # calculate dhdt diff between orbital cycles of delta_h\n",
    "        dhdt = ds_sub.delta_h[idx+1,:,:]-ds_sub.delta_h[idx,:,:]\n",
    "        # calculate mid-cycle dates for plotting\n",
    "        if dataset.fileName == 'mos_2010.5_2021.5.h5':\n",
    "            newdate = datetime.datetime(int(ds_sub.time.values[idx]), 1, 1) + datetime.timedelta(days = (ds_sub.time.values[idx] % 1) * 365.25)\n",
    "            newdate1 = datetime.datetime(int(ds_sub.time.values[idx+1]), 1, 1) + datetime.timedelta(days = (ds_sub.time.values[idx+1] % 1) * 365.25)\n",
    "            midcycdays = newdate1 - newdate\n",
    "            midcycdate = newdate + midcycdays/2\n",
    "            dates += [midcycdate]\n",
    "        elif dataset.fileName == 'ATL15_AA_0311_01km_001_01.nc':    \n",
    "            date_time_str = '18-01-01'\n",
    "            date_time_obj = datetime.datetime.strptime(date_time_str, '%y-%m-%d')\n",
    "            newdate = date_time_obj + datetime.timedelta(days=ds_sub.time.values[idx])\n",
    "            newdate1 = date_time_obj + datetime.timedelta(days=ds_sub.time.values[idx+1])\n",
    "            midcycdays = newdate1 - newdate\n",
    "            midcycdate = newdate + midcycdays/2\n",
    "            dates += [midcycdate]\n",
    "        # create empty lists to store contour data    \n",
    "        contours_fill = []\n",
    "        contours_drain = []\n",
    "        # create contours of ice surface elevation height changes to delineate variable lake outlines   \n",
    "        contour = measure.find_contours(dhdt.values, thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_fill += [contour]\n",
    "        contour = measure.find_contours(dhdt.values, -thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_drain += [contour]\n",
    "        # create mapping conversion factor to map array location to polar stereographic x,y\n",
    "        x_conv = (x_max-x_min)/dhdt.shape[1]\n",
    "        y_conv = (y_max-y_min)/dhdt.shape[0]\n",
    "        # plot variable outlines found in this time slice\n",
    "        for i in range(len(contours_fill)): \n",
    "            for j in range(len(contours_fill[i])):\n",
    "                ax.plot(x_min+contours_fill[i][j][:, 1]*x_conv, y_max-contours_fill[i][j][:, 0]*y_conv, \n",
    "                color=cmap(norm(ds_sub.time.values[idx])), linestyle=(0, (3, 1, 1, 1)), linewidth=1) \n",
    "        for i in range(len(contours_drain)): \n",
    "            for j in range(len(contours_drain[i])):\n",
    "                ax.plot(x_min+contours_drain[i][j][:, 1]*x_conv, y_max-contours_drain[i][j][:, 0]*y_conv, \n",
    "                color=cmap(norm(ds_sub.time.values[idx])), linestyle=(0, (5, 1)), linewidth=1)\n",
    "    ax.set(xlim=(x_min, x_max), ylim=(y_min, y_max))\n",
    "    # change polar stereographic m to km for cleaner-looking axes labels\n",
    "    km_scale = 1e3\n",
    "    ticks_x = ticker.FuncFormatter(lambda x, pos: '{0:g}'.format(x/km_scale))\n",
    "    ax.xaxis.set_major_formatter(ticks_x)\n",
    "    ticks_y = ticker.FuncFormatter(lambda x, pos: '{0:g}'.format(x/km_scale))\n",
    "    ax.yaxis.set_major_formatter(ticks_y)  \n",
    "    ax.set_xlabel('x [km]', size=15)\n",
    "    ax.set_ylabel('y [km]', size=15)\n",
    "    ax.set_title(lakename_SF18+ '\\noutline comparison', pad=7.5, fontsize=17.5)\n",
    "    m = plt.cm.ScalarMappable(cmap=cmap)\n",
    "    m.set_array(np.array([datetime2fracyear(date) for date in dates[0:-1]]))\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes('right', size='5%', pad=0.2)\n",
    "    if dataset.fileName == 'mos_2010.5_2021.5.h5': \n",
    "        fig.colorbar(m, cax=cax).set_label('Year', size=15)\n",
    "    if dataset.fileName == 'ATL15_AA_0311_01km_001_01.nc':    \n",
    "        clb = fig.colorbar(m, ticks=np.array([2019,2020,2021]),  cax=cax)\n",
    "    # overlay published outlines for visual comparison \n",
    "    Smith2009_outlines.boundary.plot(ax=ax, color='k', linestyle=(0, (1, 5)), linewidth=1)\n",
    "    SiegfriedFricker2018_SF18outlines.boundary.plot(ax=ax, color='k', linestyle=(0, (1, 1)), linewidth=1)\n",
    "    Smith2009 = plt.Line2D((0, 1), (0, 0), color='k', linestyle=(0, (1, 5)), linewidth=2)\n",
    "    SiegfriedFricker2018 = plt.Line2D((0, 1), (0, 0), color='k', linestyle=(0, (1, 1)), linewidth=2)\n",
    "    uplift = plt.Line2D((0, 1), (0, 0), color='k', linestyle=(0, (3, 1, 1, 1)), linewidth=2)\n",
    "    subsidence = plt.Line2D((0, 1), (0, 0), color='k', linestyle=(0, (5, 1)), linewidth=1)\n",
    "    ax.legend([Smith2009,SiegfriedFricker2018,uplift, subsidence],\n",
    "        ['Smith and others, 2009 static outline', 'Siegfried & Fricker, 2018 static outline',\n",
    "        ('+'+str(thres)+' m uplift (filling) variable outline'), '–'+str(thres)+' m subsidence (draining) variable outline'], \n",
    "        loc='best')\n",
    "    # plot inset map to show location \n",
    "    axIns = ax.inset_axes([0.05, 0.001, 0.25, 0.25])\n",
    "    axIns.patch.set_facecolor('lightskyblue')\n",
    "    axIns.set_aspect('equal')\n",
    "    axIns.scatter(((x_max+x_min)/2), ((y_max+y_min)/2), marker='*', \n",
    "        linewidth=1, edgecolor='k', facecolor='r', s=100, zorder=3)\n",
    "    Scripps_gl.plot(ax=axIns, color='ghostwhite', edgecolor='k', linewidth=0.5, zorder=2)\n",
    "    axIns.axis('off')\n",
    "    # save and close figure\n",
    "    if dataset.fileName == 'mos_2010.5_2021.5.h5':\n",
    "        plt.savefig('/Users/Wilson/Documents/0-code/1-lakeshores/output_dhdvdt-using-variable-outlines/S09SF18varoutlines_agg_plot/S09SF18varoutlines_agg-{}-{}.png'.format(lakename_SF18,'CS2'), dpi=300, bbox_inches = \"tight\")\n",
    "    elif dataset.fileName == 'ATL15_AA_0311_01km_001_01.nc':    \n",
    "        plt.savefig('/Users/Wilson/Documents/0-code/1-lakeshores/output_dhdvdt-using-variable-outlines/S09SF18varoutlines_agg_plot/S09SF18varoutlines_agg-{}-{}.png'.format(lakename_SF18,'IS2'), dpi=300, bbox_inches = \"tight\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# test function working using one lake\n",
    "x_min = -5.6e5\n",
    "x_max = -5.3e5\n",
    "y_min = -5.15e5\n",
    "y_max = -4.9e5\n",
    "# test function working using one lake\n",
    "# S09SF18varoutlines_agg_plot(x_min, x_max, y_min, y_max, 'Whillans_7', 10000, 0.5, CS2_dh)\n",
    "S09SF18varoutlines_agg_plot(x_min, x_max, y_min, y_max, 'Whillans_7', 10000, 0.5, ATL15_dh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run func on all lakes from SF18 inventory\n",
    "for idx in range(len(SiegfriedFricker2018_outlines)-1):\n",
    "    lakename = SiegfriedFricker2018_outlines['name'][idx]\n",
    "    S09SF18varoutlines_agg_plot(lakename, 7500, 0.75, CS2_dh)\n",
    "    S09SF18varoutlines_agg_plot(lakename, 7500, 0.75, ATL15_dh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S09SF18varoutlines_agg_plot('KT1', 7500, 0.5, CS2_dh)\n",
    "S09SF18varoutlines_agg_plot('KT1', 7500, 0.5, ATL15_dh)\n",
    "S09SF18varoutlines_agg_plot('KT2', 7500, 0.5, CS2_dh)\n",
    "S09SF18varoutlines_agg_plot('KT2', 7500, 0.5, ATL15_dh)\n",
    "S09SF18varoutlines_agg_plot('KT3', 7500, 0.5, CS2_dh)\n",
    "S09SF18varoutlines_agg_plot('KT3', 7500, 0.5, ATL15_dh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S09SF18varoutlines_agg_plot_centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making 1x2 plot to show migrating lake centroid; fall 2022 IS2 sci team meeting\n",
    "def S09SF18varoutlines_agg_plot_centroid(lakename_SF18, buffer, thres, dataset): \n",
    "    '''\n",
    "    Create planview plot of an aggregated times series of variable outlines compared to known lakes. Uses geopandas buffer created bounding box \n",
    "    around known lakes in Siegfried and Fricker, 2018 (SF18) inventory.\n",
    "    Create time-variable outlines using skimage contour to plot variable outline alongside published outlines for comparison. \n",
    "    Inputs: \n",
    "        lakename_SF18: lake of interest from SiegfriedFricker2018_outlines inventory\n",
    "        buffer: horizontal distance in meters away from SF18 lake outline used to create bounding box that is displayed around lake of interest\n",
    "        thres(hold): vertical distance in meters to delineate ice surface deformation contour\n",
    "        dataset: dataset to be analyzed (CS2_dh or ATL15_dh)\n",
    "    Outputs: \n",
    "        Aggregated time-variable lake outlines in regions of known lakes using CryoSat-2 or ICESat-2 ATL15 dh/dt data.\n",
    "    '''\n",
    "    # isolate individual lake using gpd buffer\n",
    "    #lake_gpd = Smith2009_outlines.loc[Smith2009_outlines['Name'] == lakename_SF18]\n",
    "    lake_gpd = SiegfriedFricker2018_outlines.loc[SiegfriedFricker2018_outlines['name'] == lakename_SF18]\n",
    "    lake_buffer = lake_gpd.buffer(buffer)\n",
    "    # define lake bounding box\n",
    "    x_min = lake_buffer.bounds.values[0,0]; x_max = lake_buffer.bounds.values[0,2]\n",
    "    y_min = lake_buffer.bounds.values[0,1]; y_max = lake_buffer.bounds.values[0,3]\n",
    "    # subset ATL15 data set to region of interest\n",
    "    mask_x = (dataset.x >= x_min) & (dataset.x <= x_max)\n",
    "    mask_y = (dataset.y >= y_min) & (dataset.y <= y_max)\n",
    "    ds_sub = dataset.where(mask_x & mask_y, drop=True)\n",
    "    # find magnitude of ice surface deformation in bounding box / find appropriate color map scale\n",
    "    height_anom_pos = []\n",
    "    height_anom_neg = []\n",
    "    for cyc in range(len(ds_sub.time)-1):\n",
    "        pos = np.nanmax(ds_sub.delta_h[cyc+1,:,:]-ds_sub.delta_h[cyc,:,:])\n",
    "        neg = np.nanmin(ds_sub.delta_h[cyc+1,:,:]-ds_sub.delta_h[cyc,:,:])\n",
    "        height_anom_pos += [pos]\n",
    "        height_anom_neg += [neg]\n",
    "    max_height_anom_pos = max(height_anom_pos)\n",
    "    max_height_anom_neg = min(height_anom_neg)\n",
    "    max_height_anom_abs = max(max_height_anom_pos,abs(max_height_anom_neg))\n",
    "    v = np.round(max_height_anom_abs)\n",
    "    # create contours of ice surface elevation height changes to delineate lake outlines\n",
    "    dates = []\n",
    "    # plot figure\n",
    "    fig, axes = plt.subplots(1,2, sharey=True, figsize=(15,10))\n",
    "    cmap = plt.get_cmap('CMRmap')\n",
    "    norm = plt.Normalize(ds_sub.time.values[0],ds_sub.time.values[-1])    \n",
    "    for idx in range(len(ds_sub.time)-1): \n",
    "        # subset data to dhdt diff between orbital cycles of delta_h\n",
    "        dhdt = ds_sub.delta_h[idx+1,:,:]-ds_sub.delta_h[idx,:,:]\n",
    "        # calculate mid-cycle dates for plotting\n",
    "        if dataset.fileName == 'mos_2010.5_2021.5.h5':\n",
    "            newdate = datetime.datetime(int(ds_sub.time.values[idx]), 1, 1) + datetime.timedelta(days = (ds_sub.time.values[idx] % 1) * 365.25)\n",
    "            newdate1 = datetime.datetime(int(ds_sub.time.values[idx+1]), 1, 1) + datetime.timedelta(days = (ds_sub.time.values[idx+1] % 1) * 365.25)\n",
    "            midcycdays = newdate1 - newdate\n",
    "            midcycdate = newdate + midcycdays/2\n",
    "            dates += [midcycdate]\n",
    "        elif dataset.fileName == 'ATL15_AA_0311_01km_001_01.nc':    \n",
    "            date_time_str = '18-01-01'\n",
    "            date_time_obj = datetime.datetime.strptime(date_time_str, '%y-%m-%d')\n",
    "            newdate = date_time_obj + datetime.timedelta(days=ds_sub.time.values[idx])\n",
    "            newdate1 = date_time_obj + datetime.timedelta(days=ds_sub.time.values[idx+1])\n",
    "            midcycdays = newdate1 - newdate\n",
    "            midcycdate = newdate + midcycdays/2\n",
    "            dates += [midcycdate]\n",
    "        # create contours of ice surface elevation height changes to delineate variable lake outlines       \n",
    "        contours_fill = []\n",
    "        contours_drain = []\n",
    "        polys = []\n",
    "        contour = measure.find_contours(dhdt.values, thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_fill += [contour]\n",
    "        contour = measure.find_contours(dhdt.values, -thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_drain += [contour]\n",
    "        # create mapping conversion factor to map array location to polar stereographic x,y\n",
    "        x_conv = (x_max-x_min)/dhdt.shape[1]\n",
    "        y_conv = (y_max-y_min)/dhdt.shape[0]\n",
    "        # plot variable outlines found in this time slice\n",
    "        for i in range(len(contours_fill)): \n",
    "            for j in range(len(contours_fill[i])):\n",
    "                axes[0].plot(x_min+contours_fill[i][j][:, 1]*x_conv, y_max-contours_fill[i][j][:, 0]*y_conv, \n",
    "                color=cmap(norm(ds_sub.time.values[idx])), linestyle=(0, (3, 1, 1, 1)), linewidth=1)\n",
    "                if len(contours_fill[i][j][:, 1]) > 2: \n",
    "                    poly = Polygon(list(zip(contours_fill[i][j][:, 1]*x_conv+x_min, y_max-contours_fill[i][j][:, 0]*y_conv))) \n",
    "                    axes[1].plot(poly.centroid.coords[0][0], poly.centroid.coords[0][1], marker='+', color=cmap(norm(ds_sub.time.values[idx])), markersize=10)\n",
    "                    polys += [poly]\n",
    "        for i in range(len(contours_drain)): \n",
    "            for j in range(len(contours_drain[i])):\n",
    "                axes[0].plot(x_min+contours_drain[i][j][:, 1]*x_conv, y_max-contours_drain[i][j][:, 0]*y_conv, \n",
    "                color=cmap(norm(ds_sub.time.values[idx])), linestyle=(0, (5, 1)), linewidth=1)\n",
    "                if len(contours_drain[i][j][:, 1]) > 2: \n",
    "                    poly = Polygon(list(zip(contours_drain[i][j][:, 1]*x_conv+x_min, y_max-contours_drain[i][j][:, 0]*y_conv))) \n",
    "                    axes[1].plot(poly.centroid.coords[0][0], poly.centroid.coords[0][1], marker='+', color=cmap(norm(ds_sub.time.values[idx])), markersize=10)\n",
    "                    polys += [poly]\n",
    "    # Change polar stereographic m to km\n",
    "    km_scale = 1e3\n",
    "    ticks_x = ticker.FuncFormatter(lambda x, pos: '{0:g}'.format(x/km_scale))\n",
    "    axes[0].xaxis.set_major_formatter(ticks_x)\n",
    "    axes[1].xaxis.set_major_formatter(ticks_x)\n",
    "    ticks_y = ticker.FuncFormatter(lambda x, pos: '{0:g}'.format(x/km_scale))\n",
    "    axes[0].yaxis.set_major_formatter(ticks_y)  \n",
    "    axes[0].set(xlim=(x_min, x_max), ylim=(y_min, y_max))\n",
    "    axes[1].set(xlim=(x_min, x_max), ylim=(y_min, y_max))\n",
    "    axes[0].set_xlabel('x [km]', size=15)\n",
    "    axes[1].set_xlabel('x [km]', size=15)\n",
    "    axes[0].set_ylabel('y [km]', size=15)\n",
    "    # axes[0].ticklabel_format(axis='both',scilimits=(0,0))\n",
    "    axes[0].set_title(lakename_SF18+ '\\nvariable outline time series', pad=7.5, fontsize=17.5)\n",
    "    axes[1].set_title(lakename_SF18+ '\\ncentroid migration time series', pad=7.5, fontsize=17.5)\n",
    "    m = plt.cm.ScalarMappable(cmap=cmap)\n",
    "    m.set_array(np.array([datetime2fracyear(date) for date in dates[0:-1]]))\n",
    "    divider = make_axes_locatable(axes[1])\n",
    "    fig.colorbar(m, cax=cax).set_label('Year', size=15) # arg for whole number years later: format=\"%d\", must find way to control no. ticks so that same year is not repeated multiple ticks\n",
    "    # overlay published outlines for visual comparison \n",
    "    Smith2009_outlines.boundary.plot(ax=axes[0], color='k', linestyle=(0, (1, 5)), linewidth=1)\n",
    "    SiegfriedFricker2018_outlines.boundary.plot(ax=axes[0], color='k', linestyle=(0, (1, 1)), linewidth=1)\n",
    "    Smith2009_outlines.boundary.plot(ax=axes[1], color='k', linestyle=(0, (1, 5)), linewidth=1)\n",
    "    SiegfriedFricker2018_outlines.boundary.plot(ax=axes[1], color='k', linestyle=(0, (1, 1)), linewidth=1)\n",
    "    Smith2009 = plt.Line2D((0, 1), (0, 0), color='k', linestyle=(0, (1, 5)), linewidth=2)\n",
    "    SiegfriedFricker2018 = plt.Line2D((0, 1), (0, 0), color='k', linestyle=(0, (1, 1)), linewidth=2)\n",
    "    uplift = plt.Line2D((0, 1), (0, 0), color='k', linestyle=(0, (3, 1, 1, 1)), linewidth=2)\n",
    "    subsidence = plt.Line2D((0, 1), (0, 0), color='k', linestyle=(0, (5, 1)), linewidth=1)\n",
    "    axes[0].legend([Smith2009,SiegfriedFricker2018,uplift, subsidence],\n",
    "        ['Smith and others, 2009 outline','Siegfried & Fricker, 2018 outline',\n",
    "        ('+'+str(thres)+' m uplift (filling) variable outline'), '–'+str(thres)+' m subsidence (draining) variable outline'], \n",
    "        loc='best')\n",
    "    # plot inset map to show location \n",
    "    axIns = axes[0].inset_axes([0.001, 0.68, 0.3, 0.3])\n",
    "    axIns.patch.set_facecolor('lightskyblue')\n",
    "    axIns.set_aspect('equal')\n",
    "    axIns.scatter(((x_max+x_min)/2), ((y_max+y_min)/2), marker='*', \n",
    "        linewidth=1, edgecolor='k', facecolor='r', s=100, zorder=3)\n",
    "    Scripps_gl.plot(ax=axIns, color='ghostwhite', edgecolor='k', linewidth=0.5, zorder=2)\n",
    "    axIns.axis('off')\n",
    "    # save and close figure\n",
    "    if dataset.fileName == 'mos_2010.5_2021.5.h5':\n",
    "        plt.savefig('/Users/Wilson/Documents/0-code/1-lakeshores/output_dhdvdt-using-variable-outlines/S09SF18varoutlines_agg_plot_centroid/S09SF18varoutlines_agg_centroid-{}-{}.png'.format(lakename_SF18,'CS2'), dpi=300, bbox_inches = \"tight\")\n",
    "    elif dataset.fileName == 'ATL15_AA_0311_01km_001_01.nc':    \n",
    "        plt.savefig('/Users/Wilson/Documents/0-code/1-lakeshores/output_dhdvdt-using-variable-outlines/S09SF18varoutlines_agg_plot_centroid/S09SF18varoutlines_agg_centroid-{}-{}.png'.format(lakename_SF18,'IS2'), dpi=300, bbox_inches = \"tight\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run func on all lakes from SF18 inventory\n",
    "for idx in range(len(SiegfriedFricker2018_outlines)-1):\n",
    "    lakename = SiegfriedFricker2018_outlines['name'][idx]\n",
    "    S09SF18varoutlines_agg_plot_centroid(lakename, 7500, 0.75, CS2_dh)\n",
    "    S09SF18varoutlines_agg_plot_centroid(lakename, 7500, 0.75, ATL15_dh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explicit bounding box around lake\n",
    "def S09SF18varoutlines_agg_plot_centroid(x_min, x_max, y_min, y_max, lakename_SF18, buffer, thres, dataset): \n",
    "    '''\n",
    "    Create planview plot of an aggregated times series of variable outlines compared to known lakes. Uses geopandas buffer created bounding box \n",
    "    around known lakes in Siegfried and Fricker, 2018 (SF18) inventory.\n",
    "    Create time-variable outlines using skimage contour to plot variable outline alongside published outlines for comparison. \n",
    "    Inputs: \n",
    "        lakename_SF18: lake of interest from SiegfriedFricker2018_outlines inventory\n",
    "        buffer: horizontal distance in meters away from SF18 lake outline used to create bounding box that is displayed around lake of interest\n",
    "        thres(hold): vertical distance in meters to delineate ice surface deformation contour\n",
    "        dataset: dataset to be analyzed (CS2_dh or ATL15_dh)\n",
    "    Outputs: \n",
    "        Aggregated time-variable lake outlines in regions of known lakes using CryoSat-2 or ICESat-2 ATL15 dh/dt data.\n",
    "    '''\n",
    "    # isolate individual lake using gpd buffer\n",
    "    #lake_gpd = Smith2009_outlines.loc[Smith2009_outlines['Name'] == lakename_SF18]\n",
    "    lake_gpd = SiegfriedFricker2018_outlines.loc[SiegfriedFricker2018_outlines['name'] == lakename_SF18]\n",
    "    lake_buffer = lake_gpd.buffer(buffer)\n",
    "    # define lake bounding box\n",
    "    # x_min = lake_buffer.bounds.values[0,0]; x_max = lake_buffer.bounds.values[0,2]\n",
    "    # y_min = lake_buffer.bounds.values[0,1]; y_max = lake_buffer.bounds.values[0,3]\n",
    "    # subset ATL15 data set to region of interest\n",
    "    mask_x = (dataset.x >= x_min) & (dataset.x <= x_max)\n",
    "    mask_y = (dataset.y >= y_min) & (dataset.y <= y_max)\n",
    "    ds_sub = dataset.where(mask_x & mask_y, drop=True)\n",
    "    # find magnitude of ice surface deformation in bounding box / find appropriate color map scale\n",
    "    height_anom_pos = []\n",
    "    height_anom_neg = []\n",
    "    for cyc in range(len(ds_sub.time)-1):\n",
    "        pos = np.nanmax(ds_sub.delta_h[cyc+1,:,:]-ds_sub.delta_h[cyc,:,:])\n",
    "        neg = np.nanmin(ds_sub.delta_h[cyc+1,:,:]-ds_sub.delta_h[cyc,:,:])\n",
    "        height_anom_pos += [pos]\n",
    "        height_anom_neg += [neg]\n",
    "    max_height_anom_pos = max(height_anom_pos)\n",
    "    max_height_anom_neg = min(height_anom_neg)\n",
    "    max_height_anom_abs = max(max_height_anom_pos,abs(max_height_anom_neg))\n",
    "    v = np.round(max_height_anom_abs)\n",
    "    # create contours of ice surface elevation height changes to delineate lake outlines\n",
    "    dates = []\n",
    "    # plot figure \n",
    "    fig, axes = plt.subplots(1,2, sharey=True, figsize=(15,10))\n",
    "    cmap = plt.get_cmap('CMRmap')\n",
    "    norm = plt.Normalize(ds_sub.time.values[0],ds_sub.time.values[-1])    \n",
    "    for idx in range(len(ds_sub.time)-1): \n",
    "        # subset data to dhdt diff between orbital cycles of delta_h\n",
    "        dhdt = ds_sub.delta_h[idx+1,:,:]-ds_sub.delta_h[idx,:,:]\n",
    "        # calculate mid-cycle dates for plotting\n",
    "        if dataset.fileName == 'mos_2010.5_2021.5.h5':\n",
    "            newdate = datetime.datetime(int(ds_sub.time.values[idx]), 1, 1) + datetime.timedelta(days = (ds_sub.time.values[idx] % 1) * 365.25)\n",
    "            newdate1 = datetime.datetime(int(ds_sub.time.values[idx+1]), 1, 1) + datetime.timedelta(days = (ds_sub.time.values[idx+1] % 1) * 365.25)\n",
    "            midcycdays = newdate1 - newdate\n",
    "            midcycdate = newdate + midcycdays/2\n",
    "            dates += [midcycdate]\n",
    "        elif dataset.fileName == 'ATL15_AA_0311_01km_001_01.nc':    \n",
    "            date_time_str = '18-01-01'\n",
    "            date_time_obj = datetime.datetime.strptime(date_time_str, '%y-%m-%d')\n",
    "            newdate = date_time_obj + datetime.timedelta(days=ds_sub.time.values[idx])\n",
    "            newdate1 = date_time_obj + datetime.timedelta(days=ds_sub.time.values[idx+1])\n",
    "            midcycdays = newdate1 - newdate\n",
    "            midcycdate = newdate + midcycdays/2\n",
    "            dates += [midcycdate]\n",
    "        # create contours of ice surface elevation height changes to delineate variable lake outlines       \n",
    "        contours_fill = []\n",
    "        contours_drain = []\n",
    "        polys = []\n",
    "        contour = measure.find_contours(dhdt.values, thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_fill += [contour]\n",
    "        contour = measure.find_contours(dhdt.values, -thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_drain += [contour]\n",
    "        # create mapping conversion factor to map array location to polar stereographic x,y\n",
    "        x_conv = (x_max-x_min)/dhdt.shape[1]\n",
    "        y_conv = (y_max-y_min)/dhdt.shape[0]\n",
    "        # plot variable outlines found in this time slice\n",
    "        for i in range(len(contours_fill)): \n",
    "            for j in range(len(contours_fill[i])):\n",
    "                axes[0].plot(x_min+contours_fill[i][j][:, 1]*x_conv, y_max-contours_fill[i][j][:, 0]*y_conv, \n",
    "                color=cmap(norm(ds_sub.time.values[idx])), linestyle=(0, (3, 1, 1, 1)), linewidth=1)\n",
    "                if len(contours_fill[i][j][:, 1]) > 2: \n",
    "                    poly = Polygon(list(zip(contours_fill[i][j][:, 1]*x_conv+x_min, y_max-contours_fill[i][j][:, 0]*y_conv))) \n",
    "                    axes[1].plot(poly.centroid.coords[0][0], poly.centroid.coords[0][1], marker='+', color=cmap(norm(ds_sub.time.values[idx])), markersize=10)\n",
    "                    polys += [poly]\n",
    "        for i in range(len(contours_drain)): \n",
    "            for j in range(len(contours_drain[i])):\n",
    "                axes[0].plot(x_min+contours_drain[i][j][:, 1]*x_conv, y_max-contours_drain[i][j][:, 0]*y_conv, \n",
    "                color=cmap(norm(ds_sub.time.values[idx])), linestyle=(0, (5, 1)), linewidth=1)\n",
    "                if len(contours_drain[i][j][:, 1]) > 2: \n",
    "                    poly = Polygon(list(zip(contours_drain[i][j][:, 1]*x_conv+x_min, y_max-contours_drain[i][j][:, 0]*y_conv))) \n",
    "                    axes[1].plot(poly.centroid.coords[0][0], poly.centroid.coords[0][1], marker='+', color=cmap(norm(ds_sub.time.values[idx])), markersize=10)\n",
    "                    polys += [poly]\n",
    "    # Change polar stereographic m to km\n",
    "    km_scale = 1e3\n",
    "    ticks_x = ticker.FuncFormatter(lambda x, pos: '{0:g}'.format(x/km_scale))\n",
    "    axes[0].xaxis.set_major_formatter(ticks_x)\n",
    "    axes[1].xaxis.set_major_formatter(ticks_x)\n",
    "    ticks_y = ticker.FuncFormatter(lambda x, pos: '{0:g}'.format(x/km_scale))\n",
    "    axes[0].yaxis.set_major_formatter(ticks_y)  \n",
    "    axes[0].set(xlim=(x_min, x_max), ylim=(y_min, y_max))\n",
    "    axes[1].set(xlim=(x_min, x_max), ylim=(y_min, y_max))\n",
    "    axes[0].set_xlabel('x [km]', size=15)\n",
    "    axes[1].set_xlabel('x [km]', size=15)\n",
    "    axes[0].set_ylabel('y [km]', size=15)\n",
    "    # axes[0].ticklabel_format(axis='both',scilimits=(0,0))\n",
    "    axes[0].set_title(lakename_SF18+ '\\nvariable outline time series', pad=7.5, fontsize=17.5)\n",
    "    axes[1].set_title(lakename_SF18+ '\\ncentroid migration time series', pad=7.5, fontsize=17.5)\n",
    "    m = plt.cm.ScalarMappable(cmap=cmap)\n",
    "    m.set_array(np.array([datetime2fracyear(date) for date in dates[0:-1]]))\n",
    "    divider = make_axes_locatable(axes[1])\n",
    "    cax = divider.append_axes('right', size='5%', pad=0.2)\n",
    "    fig.colorbar(m, cax=cax).set_label('Year', size=15) # arg for whole number years later: format=\"%d\", must find way to control no. ticks so that same year is not repeated multiple ticks\n",
    "    # overlay published outlines for visual comparison \n",
    "    Smith2009_outlines.boundary.plot(ax=axes[0], color='k', linestyle=(0, (1, 5)), linewidth=1)\n",
    "    SiegfriedFricker2018_outlines.boundary.plot(ax=axes[0], color='k', linestyle=(0, (1, 1)), linewidth=1)\n",
    "    Smith2009_outlines.boundary.plot(ax=axes[1], color='k', linestyle=(0, (1, 5)), linewidth=1)\n",
    "    SiegfriedFricker2018_outlines.boundary.plot(ax=axes[1], color='k', linestyle=(0, (1, 1)), linewidth=1)\n",
    "    Smith2009 = plt.Line2D((0, 1), (0, 0), color='k', linestyle=(0, (1, 5)), linewidth=2)\n",
    "    SiegfriedFricker2018 = plt.Line2D((0, 1), (0, 0), color='k', linestyle=(0, (1, 1)), linewidth=2)\n",
    "    uplift = plt.Line2D((0, 1), (0, 0), color='k', linestyle=(0, (3, 1, 1, 1)), linewidth=2)\n",
    "    subsidence = plt.Line2D((0, 1), (0, 0), color='k', linestyle=(0, (5, 1)), linewidth=1)\n",
    "    axes[0].legend([Smith2009,SiegfriedFricker2018,uplift, subsidence],\n",
    "        ['Smith and others, 2009 outline','Siegfried & Fricker, 2018 outline',\n",
    "        ('+'+str(thres)+' m uplift (filling) variable outline'), '–'+str(thres)+' m subsidence (draining) variable outline'], \n",
    "        loc='best')\n",
    "    # plot inset map to show location \n",
    "    axIns = axes[0].inset_axes([0.001, 0.68, 0.3, 0.3])\n",
    "    axIns.patch.set_facecolor('lightskyblue')\n",
    "    axIns.set_aspect('equal')\n",
    "    axIns.scatter(((x_max+x_min)/2), ((y_max+y_min)/2), marker='*', \n",
    "        linewidth=1, edgecolor='k', facecolor='r', s=100, zorder=3)\n",
    "    Scripps_gl.plot(ax=axIns, color='ghostwhite', edgecolor='k', linewidth=0.5, zorder=2)\n",
    "    axIns.axis('off')\n",
    "    # save and close figure\n",
    "    if dataset.fileName == 'mos_2010.5_2021.5.h5':\n",
    "        plt.savefig('/Users/Wilson/Documents/0-code/1-lakeshores/output_dhdvdt-using-variable-outlines/S09SF18varoutlines_agg_plot_centroid/S09SF18varoutlines_agg-{}-{}.png'.format(lakename_SF18,'CS2'), dpi=300, bbox_inches = \"tight\")\n",
    "    elif dataset.fileName == 'ATL15_AA_0311_01km_001_01.nc':    \n",
    "        plt.savefig('/Users/Wilson/Documents/0-code/1-lakeshores/output_dhdvdt-using-variable-outlines/S09SF18varoutlines_agg_plot_centroid/S09SF18varoutlines_agg-{}-{}.png'.format(lakename_SF18,'IS2'), dpi=300, bbox_inches = \"tight\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test function working using one lake\n",
    "x_min = -4.25e5\n",
    "x_max = -3.9e5\n",
    "y_min = 1.015e6\n",
    "y_max = 1.05e6\n",
    "S09SF18varoutlines_agg_plot_centroid(x_min, x_max, y_min, y_max, 'Slessor_23', 10000, 0.5, CS2_dh)\n",
    "# S09SF18varoutlines_dhdt_plot_anim('Slessor_23', 10000, 0.5, ATL15_dh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test function working using one lake\n",
    "S09SF18varoutlines_agg_plot_centroid('Whillans_7', 10000, 0.75, CS2_dh)\n",
    "S09SF18varoutlines_agg_plot_centroid('Whillans_7', 10000, 0.75, ATL15_dh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run func on all lakes from SF18 inventory\n",
    "for idx in range(len(SiegfriedFricker2018_outlines)-1):\n",
    "    lakename = SiegfriedFricker2018_outlines['name'][idx]\n",
    "    S09SF18varoutlines_agg_plot_centroid(lakename, 7500, 0.75, CS2_dh)\n",
    "    S09SF18varoutlines_agg_plot_centroid(lakename, 7500, 0.75, ATL15_dh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# redo a few plots that need larger buffer\n",
    "S09SF18varoutlines_agg_plot_centroid('UpperSubglacialLakeConway', 8500, 0.75, CS2_dh)\n",
    "\n",
    "S09SF18varoutlines_agg_plot_centroid('MercerSubglacialLake', 5500, 0.75, CS2_dh)\n",
    "S09SF18varoutlines_agg_plot_centroid('MercerSubglacialLake', 5500, 0.75, ATL15_dh)\n",
    "\n",
    "S09SF18varoutlines_agg_plot_centroid('Slessor_23', 8500, 0.75, CS2_dh)\n",
    "S09SF18varoutlines_agg_plot_centroid('Slessor_23', 8500, 0.75, ATL15_dh)\n",
    "\n",
    "S09SF18varoutlines_agg_plot_centroid('Lambert_1', 9000, 0.75, CS2_dh)\n",
    "S09SF18varoutlines_agg_plot_centroid('Lambert_1', 9000, 0.75, ATL15_dh)\n",
    "\n",
    "S09SF18varoutlines_agg_plot_centroid('Whillans_7', 9000, 0.75, ATL15_dh)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Func S09SF18varoutlines_agg_dvdt_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original\n",
    "def S09SF18varoutlines_agg_dvdt_plot(lakename_SF18, buffer, thres, dataset): \n",
    "    '''\n",
    "    Create 2x2 plot incl planview aggregated times series of variable outlines compared to known lakes alongside dv time series for CS2 and IS2 eras. \n",
    "    * uses geopandas buffer created bounding box around known lakes in Siegfried and Fricker, 2018 (SF18) inventory. \n",
    "    * creates time-variable outlines using skimage contour to plot variable outline alongside published outlines for comparison. \n",
    "    * creates dv time series by clipping dh data to either static outline or variable outline for each time slice.\n",
    "    Inputs: \n",
    "        lakename_SF18: lake of interest from SiegfriedFricker2018_outlines inventory\n",
    "        buffer: horizontal distance in meters away from SF18 lake outline used to create bounding box that is displayed around lake of interest\n",
    "        thres(hold): vertical distance in meters to delineate ice surface deformation contour\n",
    "        dataset: dataset to be analyzed (CS2_dh or ATL15_dh)\n",
    "    Outputs: \n",
    "        Aggregated time-variable lake outlines in regions of known lakes using CryoSat-2 or ICESat-2 ATL15 dh/dt data alongside dv/dt time series.\n",
    "    '''\n",
    "    # isolate individual lake using gpd buffer\n",
    "    #lake_gpd = Smith2009_outlines.loc[Smith2009_outlines['Name'] == lakename_SF18]\n",
    "    lake_gpd = SiegfriedFricker2018_outlines.loc[SiegfriedFricker2018_outlines['name'] == lakename_SF18]\n",
    "    lake_buffer = lake_gpd.buffer(buffer)\n",
    "    # define lake bounding box\n",
    "    x_min = lake_buffer.bounds.values[0,0]; x_max = lake_buffer.bounds.values[0,2]\n",
    "    y_min = lake_buffer.bounds.values[0,1]; y_max = lake_buffer.bounds.values[0,3]\n",
    "    # subset ATL15 data set to region of interest\n",
    "    mask_x = (dataset.x >= x_min) & (dataset.x <= x_max)\n",
    "    mask_y = (dataset.y >= y_min) & (dataset.y <= y_max)\n",
    "    ds_sub = dataset.where(mask_x & mask_y, drop=True)\n",
    "    # find magnitude of ice surface deformation in bounding box / find appropriate color map scale\n",
    "    height_anom_pos = []\n",
    "    height_anom_neg = []\n",
    "    for cyc in range(len(ds_sub.time)-1):\n",
    "        pos = np.nanmax(ds_sub.delta_h[cyc+1,:,:]-ds_sub.delta_h[cyc,:,:])\n",
    "        neg = np.nanmin(ds_sub.delta_h[cyc+1,:,:]-ds_sub.delta_h[cyc,:,:])\n",
    "        height_anom_pos += [pos]\n",
    "        height_anom_neg += [neg]\n",
    "    max_height_anom_pos = max(height_anom_pos)\n",
    "    max_height_anom_neg = min(height_anom_neg)\n",
    "    max_height_anom_abs = max(max_height_anom_pos,abs(max_height_anom_neg))\n",
    "    v = np.round(max_height_anom_abs)\n",
    "    # create empty lists to store data\n",
    "    dates = []\n",
    "    lkavgdhdt_SF18 = []\n",
    "    lkavgdhdt_var = []\n",
    "    vols_SF18 = []\n",
    "    vols_var = []\n",
    "    # plot figure\n",
    "    fig, axes = plt.subplots(1,2, figsize=(20,10))\n",
    "    plt.subplots_adjust(wspace=0.15)\n",
    "    cmap = plt.get_cmap('CMRmap')\n",
    "    norm = plt.Normalize(ds_sub.time.values[0],ds_sub.time.values[-1])    \n",
    "    for idx in range(len(ds_sub.time)-1): \n",
    "        dhdt = ds_sub.delta_h[idx+1,:,:]-ds_sub.delta_h[idx,:,:]\n",
    "        # calculate mid-cycle dates for plotting\n",
    "        if dataset.fileName == 'mos_2010.5_2021.5.h5':\n",
    "            newdate = datetime.datetime(int(ds_sub.time.values[idx]), 1, 1) + datetime.timedelta(days = (ds_sub.time.values[idx] % 1) * 365.25)\n",
    "            newdate1 = datetime.datetime(int(ds_sub.time.values[idx+1]), 1, 1) + datetime.timedelta(days = (ds_sub.time.values[idx+1] % 1) * 365.25)\n",
    "            midcycdays = newdate1 - newdate\n",
    "            midcycdate = newdate + midcycdays/2\n",
    "            dates += [midcycdate]\n",
    "        elif dataset.fileName == 'ATL15_AA_0311_01km_001_01.nc':    \n",
    "            date_time_str = '18-01-01'\n",
    "            date_time_obj = datetime.datetime.strptime(date_time_str, '%y-%m-%d')\n",
    "            newdate = date_time_obj + datetime.timedelta(days=ds_sub.time.values[idx])\n",
    "            newdate1 = date_time_obj + datetime.timedelta(days=ds_sub.time.values[idx+1])\n",
    "            midcycdays = newdate1 - newdate\n",
    "            midcycdate = newdate + midcycdays/2\n",
    "            dates += [midcycdate]\n",
    "        # subset data to dhdt diff between orbital cycles of delta_h\n",
    "        dhdt = ds_sub.delta_h[idx+1,:,:]-ds_sub.delta_h[idx,:,:]\n",
    "        # clip ATL15 data to just show (first set crs)\n",
    "        dhdt.rio.write_crs(3031, inplace=True)\n",
    "        dhdt_clip_SF18 = dhdt.rio.clip(lake_gpd.geometry.values, lake_gpd.crs, drop=False, invert=False)\n",
    "        # calculate lake avg. dh/dt and dv/dt time series using published stationary outlines\n",
    "        avg_lk_dhdt_SF18 = np.nanmean(dhdt_clip_SF18)\n",
    "        lkavgdhdt_SF18 += [avg_lk_dhdt_SF18]\n",
    "        vol_SF18 = avg_lk_dhdt_SF18*SiegfriedFricker2018_outlines[SiegfriedFricker2018_outlines['name'] == lakename_SF18]['area (m^2)']\n",
    "        vols_SF18 += [vol_SF18.values[0]]\n",
    "        # create contours of ice surface elevation height changes to delineate variable lake outlines\n",
    "        contours_fill = []\n",
    "        contours_drain = []   \n",
    "        polys = []\n",
    "        contour = measure.find_contours(dhdt.values, thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_fill += [contour]\n",
    "        contour = measure.find_contours(dhdt.values, -thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_drain += [contour]\n",
    "        # create mapping conversion factor to map array location to polar stereographic x,y\n",
    "        x_conv = (x_max-x_min)/dhdt.shape[1]\n",
    "        y_conv = (y_max-y_min)/dhdt.shape[0]\n",
    "        # plot variable outlines found in this time slice\n",
    "        # make polygons from variable outlines\n",
    "        for i in range(len(contours_fill)): \n",
    "            for j in range(len(contours_fill[i])):\n",
    "                axes[0].plot(x_min+contours_fill[i][j][:, 1]*x_conv, y_max-contours_fill[i][j][:, 0]*y_conv, \n",
    "                color=cmap(norm(ds_sub.time.values[idx])), linestyle=(0, (3, 1, 1, 1)), linewidth=1)\n",
    "                if len(contours_fill[i][j][:, 1]) > 2: \n",
    "                    poly = Polygon(list(zip(contours_fill[i][j][:, 1]*x_conv+x_min, y_max-contours_fill[i][j][:, 0]*y_conv))) \n",
    "                    polys += [poly]\n",
    "        for i in range(len(contours_drain)): \n",
    "            for j in range(len(contours_drain[i])):\n",
    "                axes[0].plot(x_min+contours_drain[i][j][:, 1]*x_conv, y_max-contours_drain[i][j][:, 0]*y_conv, color=cmap(norm(ds_sub.time.values[idx])), linestyle=(0, (5, 1)), linewidth=1)\n",
    "                if len(contours_drain[i][j][:, 1]) > 2: \n",
    "                    poly = Polygon(list(zip(contours_drain[i][j][:, 1]*x_conv+x_min, y_max-contours_drain[i][j][:, 0]*y_conv))) \n",
    "                    polys += [poly]\n",
    "        # set area to zero each time step\n",
    "        variable_area = 0\n",
    "        # if polygons are present at time step, \n",
    "        if len(polys) > 0: \n",
    "            # clip data to polygons\n",
    "            dhdt_clip = dhdt.rio.clip(polys, drop=False, invert=False)\n",
    "            # then calculate on-lake averages of dh/dt\n",
    "            avg_lk_dhdt = np.nanmean(dhdt_clip)\n",
    "            # occasionally small polygons will completely clip data resulting in nan's for lake avg. dh/dt\n",
    "            # replace with zeros\n",
    "            if math.isnan(avg_lk_dhdt): \n",
    "                avg_lk_dhdt = 0\n",
    "                lkavgdhdt_var += [avg_lk_dhdt]\n",
    "            else:\n",
    "                lkavgdhdt_var += [avg_lk_dhdt]\n",
    "                # and dv/dt\n",
    "            for i in range(len(polys)):\n",
    "                variable_area = variable_area + polys[i].area\n",
    "            vol_var = avg_lk_dhdt*variable_area\n",
    "            vols_var += [vol_var]\n",
    "        else: \n",
    "            variable_area = 0\n",
    "            avg_lk_dhdt = 0\n",
    "            lkavgdhdt_var += [avg_lk_dhdt]\n",
    "            vol_var = avg_lk_dhdt*variable_area\n",
    "            vols_var += [vol_var]\n",
    "    axes[0].set(xlim=(x_min, x_max), ylim=(y_min, y_max))\n",
    "    # change polar stereographic m to km\n",
    "    km_scale = 1e3\n",
    "    ticks_x = ticker.FuncFormatter(lambda x, pos: '{0:g}'.format(x/km_scale))\n",
    "    axes[0].xaxis.set_major_formatter(ticks_x)\n",
    "    ticks_y = ticker.FuncFormatter(lambda x, pos: '{0:g}'.format(x/km_scale))\n",
    "    axes[0].yaxis.set_major_formatter(ticks_y)  \n",
    "    # adjust ticks\n",
    "    axes[0].set_xticks(np.arange(np.round(x_min, decimals = -3),np.round(x_max, decimals = -3),5000))\n",
    "    axes[0].set_yticks(np.arange(np.round(y_min, decimals = -3),np.round(y_max, decimals = -3),5000))\n",
    "    # label axes\n",
    "    axes[0].set_xlabel('x [km]', size=15)\n",
    "    axes[0].set_ylabel('y [km]', size=15)\n",
    "    # add title and colorbar\n",
    "    axes[0].set_title(lakename_SF18+ ' outline comparison', pad=7.5, fontsize=17.5)\n",
    "    m = plt.cm.ScalarMappable(cmap=cmap)\n",
    "    m.set_array(np.array([datetime2fracyear(date) for date in dates[0:-1]]))\n",
    "    divider = make_axes_locatable(axes[0])\n",
    "    cax = divider.append_axes('right', size='5%', pad=0.2)\n",
    "    if dataset.fileName == 'mos_2010.5_2021.5.h5': \n",
    "        fig.colorbar(m, cax=cax).set_label('Year', size=15)\n",
    "    if dataset.fileName == 'ATL15_AA_0311_01km_001_01.nc':    \n",
    "        clb = fig.colorbar(m, ticks=np.array([2019,2020,2021]),  cax=cax).set_label('Year', size=15)\n",
    "    # overlay published outlines for visual comparison \n",
    "    Smith2009_outlines.boundary.plot(ax=axes[0], color='k', linestyle=(0, (1, 5)), linewidth=1)\n",
    "    SiegfriedFricker2018_outlines.boundary.plot(ax=axes[0], color='k', linestyle=(0, (1, 1)), linewidth=1)\n",
    "    Smith2009 = plt.Line2D((0, 1), (0, 0), color='k', linestyle=(0, (1, 5)), linewidth=2)\n",
    "    SiegfriedFricker2018 = plt.Line2D((0, 1), (0, 0), color='k', linestyle=(0, (1, 1)), linewidth=2)\n",
    "    uplift = plt.Line2D((0, 1), (0, 0), color='k', linestyle=(0, (3, 1, 1, 1)), linewidth=2)\n",
    "    subsidence = plt.Line2D((0, 1), (0, 0), color='k', linestyle=(0, (5, 1)), linewidth=1)\n",
    "    variable_outlines = plt.Line2D((0, 1), (0, 0), color='darkturquoise', linestyle='dashdot', linewidth=2)\n",
    "    axes[0].legend([Smith2009,SiegfriedFricker2018,uplift, subsidence],\n",
    "        ['Smith and others, 2009 static outline','Siegfried & Fricker, 2018 static outline',\n",
    "        ('+'+str(thres)+' m uplift (filling) variable outline'), '–'+str(thres)+' m subsidence (draining) variable outline'], \n",
    "        loc='upper right')\n",
    "    # plot inset map to show location \n",
    "    axIns = axes[0].inset_axes([0.05, 0.001, 0.25, 0.25])\n",
    "    axIns.patch.set_facecolor('lightskyblue')\n",
    "    axIns.set_aspect('equal')\n",
    "    axIns.scatter(((x_max+x_min)/2), ((y_max+y_min)/2), marker='*', \n",
    "        linewidth=1, edgecolor='k', facecolor='r', s=100, zorder=3)\n",
    "    Scripps_gl.plot(ax=axIns, color='ghostwhite', edgecolor='k', linewidth=0.5, zorder=2)\n",
    "    axIns.axis('off')\n",
    "    # plot dvdt subplot\n",
    "    axes[1].plot(dates, np.divide(np.cumsum(vols_SF18), 1e+9), color='k', linestyle='dashed')\n",
    "    axes[1].plot(dates, np.divide(np.cumsum(vols_var), 1e+9), color='darkturquoise', linestyle='dashdot')\n",
    "    locator = mdates.AutoDateLocator(minticks=1, maxticks=7)\n",
    "    formatter = mdates.ConciseDateFormatter(locator)\n",
    "    axes[1].xaxis.set_major_locator(locator)\n",
    "    axes[1].xaxis.set_major_formatter(formatter)\n",
    "    # axes[1].set_title('{} volume change time series'.format(lakename_SF18), fontsize=17.5)\n",
    "    axes[1].set_xlabel('Year', size=15)\n",
    "    axes[1].set_ylabel('Volume change [km$^3$]', size=15)\n",
    "    axes[1].yaxis.tick_right()\n",
    "    axes[1].yaxis.set_label_position(\"right\")\n",
    "    axes[1].legend([SiegfriedFricker2018,variable_outlines],\n",
    "        ['Siegfried & Fricker, 2018',\n",
    "        '±{} m variable outlines'.format(thres)], \n",
    "        loc='best')  \n",
    "    # save and close figure\n",
    "    if dataset.fileName == 'mos_2010.5_2021.5.h5':\n",
    "        plt.savefig('/Users/Wilson/Documents/0-code/1-lakeshores/output_dhdvdt-using-variable-outlines/S09SF18varoutlines_agg_dvdt_plot/S09SF18varoutlines_agg_dvdt_plot-{}-{}.png'\\\n",
    "            .format(lakename_SF18, 'CS2'), dpi=300, bbox_inches = \"tight\")\n",
    "    elif dataset.fileName == 'ATL15_AA_0311_01km_001_01.nc':    \n",
    "        plt.savefig('/Users/Wilson/Documents/0-code/1-lakeshores/output_dhdvdt-using-variable-outlines/S09SF18varoutlines_agg_dvdt_plot/S09SF18varoutlines_agg_dvdt_plot-{}-{}.png'\\\n",
    "            .format(lakename_SF18, 'IS2'), dpi=300, bbox_inches = \"tight\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test function working using one lake\n",
    "S09SF18varoutlines_agg_dvdt_plot('Whillans_7', 13000, 0.5, ATL15_dh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run func on all lakes from SF18 inventory\n",
    "for idx in range(len(SiegfriedFricker2018_outlines)-1):\n",
    "    lakename = SiegfriedFricker2018_outlines['name'][idx]\n",
    "    S09SF18varoutlines_agg_dvdt_plot(lakename, 7500, 0.5, CS2_dh)\n",
    "    S09SF18varoutlines_agg_dvdt_plot(lakename, 7500, 0.5, ATL15_dh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying use of explicit bounding box coords vs. based on boundary\n",
    "def S09SF18varoutlines_agg_dvdt_plot_coords(x_min, x_max, y_min, y_max, lakename_SF18, buffer, thres, dataset): \n",
    "    '''\n",
    "    Create planview plot of an aggregated times series of variable outlines compared to known lakes alongside dv/dt time series. Uses geopandas buffer created bounding box around known lakes in Siegfried and Fricker, 2018 (SF18) inventory. Creates time-variable outlines using skimage contour to plot variable outline alongside published outlines for comparison. \n",
    "    Inputs: \n",
    "        lakename_SF18: lake of interest from SiegfriedFricker2018_outlines inventory\n",
    "        buffer: horizontal distance in meters away from SF18 lake outline used to create bounding box that is displayed around lake of interest\n",
    "        thres(hold): vertical distance in meters to delineate ice surface deformation contour\n",
    "        dataset: dataset to be analyzed (CS2_dh or ATL15_dh)\n",
    "    Outputs: \n",
    "        Aggregated time-variable lake outlines in regions of known lakes using CryoSat-2 or ICESat-2 ATL15 dh/dt data alongside dVol time series.\n",
    "    '''\n",
    "    # isolate individual lake using gpd buffer\n",
    "    #lake_gpd = Smith2009_outlines.loc[Smith2009_outlines['Name'] == lakename_SF18]\n",
    "    lake_gpd = SiegfriedFricker2018_outlines.loc[SiegfriedFricker2018_outlines['name'] == lakename_SF18]\n",
    "    lake_buffer = lake_gpd.buffer(buffer)\n",
    "    # define lake bounding box\n",
    "    # x_min = lake_buffer.bounds.values[0,0]; x_max = lake_buffer.bounds.values[0,2]\n",
    "    # y_min = lake_buffer.bounds.values[0,1]; y_max = lake_buffer.bounds.values[0,3]\n",
    "    # subset ATL15 data set to region of interest\n",
    "    mask_x = (dataset.x >= x_min) & (dataset.x <= x_max)\n",
    "    mask_y = (dataset.y >= y_min) & (dataset.y <= y_max)\n",
    "    ds_sub = dataset.where(mask_x & mask_y, drop=True)\n",
    "    # find magnitude of ice surface deformation in bounding box / find appropriate color map scale\n",
    "    height_anom_pos = []\n",
    "    height_anom_neg = []\n",
    "    for cyc in range(len(ds_sub.time)-1):\n",
    "        pos = np.nanmax(ds_sub.delta_h[cyc+1,:,:]-ds_sub.delta_h[cyc,:,:])\n",
    "        neg = np.nanmin(ds_sub.delta_h[cyc+1,:,:]-ds_sub.delta_h[cyc,:,:])\n",
    "        height_anom_pos += [pos]\n",
    "        height_anom_neg += [neg]\n",
    "    max_height_anom_pos = max(height_anom_pos)\n",
    "    max_height_anom_neg = min(height_anom_neg)\n",
    "    max_height_anom_abs = max(max_height_anom_pos,abs(max_height_anom_neg))\n",
    "    v = np.round(max_height_anom_abs)\n",
    "    dates = []\n",
    "    lkavgdhdt_SF18 = []\n",
    "    lkavgdhdt_var = []\n",
    "    vols_SF18 = []\n",
    "    vols_var = []\n",
    "    # plot figure\n",
    "    fig, axes = plt.subplots(1,2, figsize=(21,7))\n",
    "    # fig.suptitle('{} outline and dVol comparison'.format(lakename_SF18), fontsize=24)\n",
    "    fig.suptitle('Whillans$_7$ outline and $\\Delta$volume comparison', fontsize=30)\n",
    "    plt.subplots_adjust(wspace=0.15)\n",
    "    cmap = plt.get_cmap('CMRmap')\n",
    "    norm = plt.Normalize(ds_sub.time.values[0],ds_sub.time.values[-1])    \n",
    "    for idx in range(len(ds_sub.time)-1): \n",
    "        dhdt = ds_sub.delta_h[idx+1,:,:]-ds_sub.delta_h[idx,:,:]\n",
    "        # calculate mid-cycle dates for plotting\n",
    "        if dataset.fileName == 'mos_2010.5_2021.5.h5':\n",
    "            newdate = datetime.datetime(int(ds_sub.time.values[idx]), 1, 1) + datetime.timedelta(days = (ds_sub.time.values[idx] % 1) * 365.25)\n",
    "            newdate1 = datetime.datetime(int(ds_sub.time.values[idx+1]), 1, 1) + datetime.timedelta(days = (ds_sub.time.values[idx+1] % 1) * 365.25)\n",
    "            midcycdays = newdate1 - newdate\n",
    "            midcycdate = newdate + midcycdays/2\n",
    "            dates += [midcycdate]\n",
    "        elif dataset.fileName == 'ATL15_AA_0311_01km_001_01.nc':    \n",
    "            date_time_str = '18-01-01'\n",
    "            date_time_obj = datetime.datetime.strptime(date_time_str, '%y-%m-%d')\n",
    "            newdate = date_time_obj + datetime.timedelta(days=ds_sub.time.values[idx])\n",
    "            newdate1 = date_time_obj + datetime.timedelta(days=ds_sub.time.values[idx+1])\n",
    "            midcycdays = newdate1 - newdate\n",
    "            midcycdate = newdate + midcycdays/2\n",
    "            dates += [midcycdate]\n",
    "        # subset data to dhdt diff between orbital cycles of delta_h\n",
    "        dhdt = ds_sub.delta_h[idx+1,:,:]-ds_sub.delta_h[idx,:,:]\n",
    "        # clip ATL15 data to just show (first set crs)\n",
    "        dhdt.rio.write_crs(3031, inplace=True)\n",
    "        dhdt_clip_SF18 = dhdt.rio.clip(lake_gpd.geometry.values, lake_gpd.crs, drop=False, invert=False)\n",
    "        # calculate lake avg. dh/dt and dv/dt time series using published stationary outlines\n",
    "        avg_lk_dhdt_SF18 = np.nanmean(dhdt_clip_SF18)\n",
    "        lkavgdhdt_SF18 += [avg_lk_dhdt_SF18]\n",
    "        vol_SF18 = avg_lk_dhdt_SF18*SiegfriedFricker2018_outlines[SiegfriedFricker2018_outlines['name'] == lakename_SF18]['area (m^2)']\n",
    "        vols_SF18 += [vol_SF18.values[0]]\n",
    "        # create contours of ice surface elevation height changes to delineate variable lake outlines\n",
    "        contours_fill = []\n",
    "        contours_drain = []   \n",
    "        polys = []\n",
    "        contour = measure.find_contours(dhdt.values, thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_fill += [contour]\n",
    "        contour = measure.find_contours(dhdt.values, -thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_drain += [contour]\n",
    "        # create mapping conversion factor to map array location to polar stereographic x,y\n",
    "        x_conv = (x_max-x_min)/dhdt.shape[1]\n",
    "        y_conv = (y_max-y_min)/dhdt.shape[0]\n",
    "        # plot variable outlines found in this time slice\n",
    "        # make polygons from variable outlines\n",
    "        for i in range(len(contours_fill)): \n",
    "            for j in range(len(contours_fill[i])):\n",
    "                axes[0].plot(x_min+contours_fill[i][j][:, 1]*x_conv, y_max-contours_fill[i][j][:, 0]*y_conv, \n",
    "                color=cmap(norm(ds_sub.time.values[idx])), linestyle=(0, (3, 1, 1, 1)), linewidth=1)\n",
    "                if len(contours_fill[i][j][:, 1]) > 2: \n",
    "                    poly = Polygon(list(zip(contours_fill[i][j][:, 1]*x_conv+x_min, y_max-contours_fill[i][j][:, 0]*y_conv))) \n",
    "                    polys += [poly]\n",
    "        for i in range(len(contours_drain)): \n",
    "            for j in range(len(contours_drain[i])):\n",
    "                axes[0].plot(x_min+contours_drain[i][j][:, 1]*x_conv, y_max-contours_drain[i][j][:, 0]*y_conv, color=cmap(norm(ds_sub.time.values[idx])), linestyle=(0, (5, 1)), linewidth=1)\n",
    "                if len(contours_drain[i][j][:, 1]) > 2: \n",
    "                    poly = Polygon(list(zip(contours_drain[i][j][:, 1]*x_conv+x_min, y_max-contours_drain[i][j][:, 0]*y_conv))) \n",
    "                    polys += [poly]\n",
    "        # set area to zero each time step\n",
    "        variable_area = 0\n",
    "        # if polygons are present at time step, \n",
    "        if len(polys) > 0: \n",
    "            # clip data to polygons\n",
    "            dhdt_clip = dhdt.rio.clip(polys, drop=False, invert=False)\n",
    "            # then calculate on-lake averages of dh/dt\n",
    "            avg_lk_dhdt = np.nanmean(dhdt_clip)\n",
    "            # occasionally small polygons will completely clip data resulting in nan's for lake avg. dh/dt\n",
    "            # replace with zeros\n",
    "            if math.isnan(avg_lk_dhdt): \n",
    "                avg_lk_dhdt = 0\n",
    "                lkavgdhdt_var += [avg_lk_dhdt]\n",
    "            else:\n",
    "                lkavgdhdt_var += [avg_lk_dhdt]\n",
    "                # and dv/dt\n",
    "            for i in range(len(polys)):\n",
    "                variable_area = variable_area + polys[i].area\n",
    "            vol_var = avg_lk_dhdt*variable_area\n",
    "            vols_var += [vol_var]\n",
    "        else: \n",
    "            variable_area = 0\n",
    "            avg_lk_dhdt = 0\n",
    "            lkavgdhdt_var += [avg_lk_dhdt]\n",
    "            vol_var = avg_lk_dhdt*variable_area\n",
    "            vols_var += [vol_var]\n",
    "    axes[0].set(xlim=(x_min, x_max), ylim=(y_min, y_max))\n",
    "    axes[0].set_xlabel('polar stereographic x [m]', size=15)\n",
    "    axes[0].set_ylabel('polar stereographic y [m]', size=15)\n",
    "    axes[0].ticklabel_format(axis='both',scilimits=(0,0))\n",
    "    # axes[0].set_title('outline comparison', pad=7.5, fontsize=17.5)\n",
    "    m = plt.cm.ScalarMappable(cmap=cmap)\n",
    "    m.set_array(np.array([datetime2fracyear(date) for date in dates[0:-1]]))\n",
    "    divider = make_axes_locatable(axes[0])\n",
    "    cax = divider.append_axes('right', size='5%', pad=0.2)\n",
    "    clb = fig.colorbar(m, cax=cax)\n",
    "    clb.ax.set_title('Year')\n",
    "    # overlay published outlines for visual comparison \n",
    "    Smith2009_outlines.boundary.plot(ax=axes[0], color='k', linestyle=(0, (1, 5)), linewidth=1)\n",
    "    SiegfriedFricker2018_outlines.boundary.plot(ax=axes[0], color='k', linestyle=(0, (1, 1)), linewidth=1)\n",
    "    Smith2009 = plt.Line2D((0, 1), (0, 0), color='k', linestyle=(0, (1, 5)), linewidth=2)\n",
    "    SiegfriedFricker2018 = plt.Line2D((0, 1), (0, 0), color='k', linestyle=(0, (1, 1)), linewidth=2)\n",
    "    uplift = plt.Line2D((0, 1), (0, 0), color='k', linestyle=(0, (3, 1, 1, 1)), linewidth=2)\n",
    "    subsidence = plt.Line2D((0, 1), (0, 0), color='k', linestyle=(0, (5, 1)), linewidth=1)\n",
    "    variable_outlines = plt.Line2D((0, 1), (0, 0), color='darkturquoise', linestyle='dashdot', linewidth=2)\n",
    "    axes[0].legend([Smith2009,\n",
    "    #SiegfriedFricker2018,\n",
    "    uplift, subsidence],\n",
    "        ['Smith and others, 2009 static outline',\n",
    "        #'Siegfried & Fricker, 2018 outline',\n",
    "        ('+'+str(thres)+' m uplift (filling) variable outline'), '–'+str(thres)+' m subsidence (draining) variable outline'], \n",
    "        loc='upper right')\n",
    "    # plot inset map to show location \n",
    "    axIns = axes[0].inset_axes([0.001, 0.68, 0.3, 0.3])\n",
    "    axIns.patch.set_facecolor('lightskyblue')\n",
    "    axIns.set_aspect('equal')\n",
    "    axIns.scatter(((x_max+x_min)/2), ((y_max+y_min)/2), marker='*', \n",
    "        linewidth=1, edgecolor='k', facecolor='r', s=100, zorder=3)\n",
    "    Scripps_gl.plot(ax=axIns, color='ghostwhite', edgecolor='k', linewidth=0.5, zorder=2)\n",
    "    SiegfriedFricker2018_outlines.boundary.plot(ax=axIns, color='k', linestyle=(0, (1, 1)), linewidth=1)\n",
    "    axIns.axis('off')\n",
    "    # plot dvdt subplot\n",
    "    axes[1].plot(dates, np.divide(np.cumsum(vols_SF18), 1e+9), color='k', linestyle='dashed')\n",
    "    axes[1].plot(dates, np.divide(np.cumsum(vols_var), 1e+9), color='darkturquoise', linestyle='dashdot')\n",
    "    locator = mdates.AutoDateLocator(minticks=1, maxticks=7)\n",
    "    formatter = mdates.ConciseDateFormatter(locator)\n",
    "    axes[1].xaxis.set_major_locator(locator)\n",
    "    axes[1].xaxis.set_major_formatter(formatter)\n",
    "    #axes[1].set_title('dVol', fontsize=17.5)\n",
    "    axes[1].set_xlabel('Year', size=15)\n",
    "    axes[1].set_ylabel('Volume change [km$^3$]', size=15)\n",
    "    axes[1].yaxis.tick_right()\n",
    "    axes[1].yaxis.set_label_position(\"right\")\n",
    "    axes[1].legend([Smith2009,variable_outlines],\n",
    "        ['Smith and others, 2009 static outline',\n",
    "        '±{} m variable outlines'.format(thres)], \n",
    "        loc='best')  \n",
    "    # save and close figure\n",
    "    if dataset.fileName == 'mos_2010.5_2021.5.h5':\n",
    "        plt.savefig('/Users/Wilson/Documents/0-code/1-lakeshores/output_dhdvdt-using-variable-outlines/S09SF18varoutlines_agg_dvdt_plot/S09SF18varoutlines_agg_dvdt_plot-{}-{}.png'\\\n",
    "            .format(lakename_SF18, 'CS2'), dpi=300, bbox_inches = \"tight\")\n",
    "    elif dataset.fileName == 'ATL15_AA_0311_01km_001_01.nc':    \n",
    "        plt.savefig('/Users/Wilson/Documents/0-code/1-lakeshores/output_dhdvdt-using-variable-outlines/S09SF18varoutlines_agg_dvdt_plot/S09SF18varoutlines_agg_dvdt_plot-{}-{}.png'\\\n",
    "            .format(lakename_SF18, 'IS2'), dpi=300, bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test function working using one lake\n",
    "# S09SF18varoutlines_agg_dvdt_plot_coords(-5.65e5,-5.3e5,-5.1e5,-4.95e5, 'Whillans_7', 10000, 0.5, CS2_dh)\n",
    "S09SF18varoutlines_agg_dvdt_plot_coords(-5.57e5,-5.3e5,-5.1e5,-4.9e5, 'Whillans_7', 10000, 0.5, ATL15_dh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run func on all lakes from SF18 inventory\n",
    "for idx in range(len(SiegfriedFricker2018_outlines)-1):\n",
    "    lakename = SiegfriedFricker2018_outlines['name'][idx]\n",
    "    S09SF18varoutlines_agg_dvdt_plot(lakename, 7500, 0.5, CS2_dh)\n",
    "    S09SF18varoutlines_agg_dvdt_plot(lakename, 7500, 0.5, ATL15_dh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modified 2x2 to plot CS2 and IS2 on same plot\n",
    "# for SiegfriedFricker2018_SF18outlines_CS2InSAR\n",
    "def S09SF18varoutlines_agg_dvdt_plot(lakename_SF18, buffer, thres, dataset1, dataset2): \n",
    "    '''\n",
    "    Create planview plot of an aggregated times series of variable outlines compared to known lakes alongside dv/dt time series. Uses geopandas buffer created bounding box around known lakes in Siegfried and Fricker, 2018 (SF18) inventory. Creates time-variable outlines using skimage contour to plot variable outline alongside published outlines for comparison. \n",
    "    Inputs: \n",
    "        lakename_SF18: lake of interest from SiegfriedFricker2018_outlines inventory\n",
    "        buffer: horizontal distance in meters away from SF18 lake outline used to create bounding box that is displayed around lake of interest\n",
    "        thres(hold): vertical distance in meters to delineate ice surface deformation contour\n",
    "        dataset: dataset to be analyzed (CS2_dh or ATL15_dh)\n",
    "    Outputs: \n",
    "        Aggregated time-variable lake outlines in regions of known lakes using CryoSat-2 or ICESat-2 ATL15 dh/dt data alongside dVol time series.\n",
    "    '''\n",
    "    # isolate individual lake using gpd buffer\n",
    "    lake_SF18 = SiegfriedFricker2018_outlines.loc[SiegfriedFricker2018_outlines['name'] == lakename_SF18]\n",
    "    lake_buffer = lake_SF18.buffer(buffer)\n",
    "    # define lake bounding box\n",
    "    x_min = lake_buffer.bounds.values[0,0]; x_max = lake_buffer.bounds.values[0,2]\n",
    "    y_min = lake_buffer.bounds.values[0,1]; y_max = lake_buffer.bounds.values[0,3]\n",
    "    # subset ATL15 data set to region of interest\n",
    "    mask_x = (dataset1.x >= x_min) & (dataset1.x <= x_max)\n",
    "    mask_y = (dataset1.y >= y_min) & (dataset1.y <= y_max)\n",
    "    ds_sub = dataset1.where(mask_x & mask_y, drop=True)\n",
    "    # find magnitude of ice surface deformation in bounding box / find appropriate color map scale\n",
    "    height_anom_pos = []\n",
    "    height_anom_neg = []\n",
    "    for cyc in range(len(ds_sub.time)-1):\n",
    "        pos = np.nanmax(ds_sub.delta_h[cyc+1,:,:]-ds_sub.delta_h[cyc,:,:])\n",
    "        neg = np.nanmin(ds_sub.delta_h[cyc+1,:,:]-ds_sub.delta_h[cyc,:,:])\n",
    "        height_anom_pos += [pos]\n",
    "        height_anom_neg += [neg]\n",
    "    max_height_anom_pos = max(height_anom_pos)\n",
    "    max_height_anom_neg = min(height_anom_neg)\n",
    "    max_height_anom_abs = max(max_height_anom_pos,abs(max_height_anom_neg))\n",
    "    v = np.round(max_height_anom_abs)\n",
    "    # create empty lists to store data\n",
    "    dates = []\n",
    "    lkavgdhdt_SF18 = []\n",
    "    lkavgdhdt_var = []\n",
    "    vols_SF18 = []\n",
    "    vols_var = []\n",
    "    # plot figure\n",
    "    fig, axes = plt.subplots(2,2, figsize=(20,20))\n",
    "    # plt.subplots_adjust(wspace=0.15, hspace = 0.1)\n",
    "    cmap = plt.get_cmap('CMRmap')\n",
    "    norm = plt.Normalize(ds_sub.time.values[0],ds_sub.time.values[-1])    \n",
    "    for idx in range(len(ds_sub.time)-1): \n",
    "        dhdt = ds_sub.delta_h[idx+1,:,:]-ds_sub.delta_h[idx,:,:]\n",
    "        # calculate mid-cycle dates for plotting\n",
    "        if dataset1.fileName == 'mos_2010.5_2021.5.h5':\n",
    "            newdate = datetime.datetime(int(ds_sub.time.values[idx]), 1, 1) + datetime.timedelta(days = (ds_sub.time.values[idx] % 1) * 365.25)\n",
    "            newdate1 = datetime.datetime(int(ds_sub.time.values[idx+1]), 1, 1) + datetime.timedelta(days = (ds_sub.time.values[idx+1] % 1) * 365.25)\n",
    "            midcycdays = newdate1 - newdate\n",
    "            midcycdate = newdate + midcycdays/2\n",
    "            dates += [midcycdate]\n",
    "        elif dataset1.fileName == 'ATL15_AA_0311_01km_001_01.nc':    \n",
    "            date_time_str = '18-01-01'\n",
    "            date_time_obj = datetime.datetime.strptime(date_time_str, '%y-%m-%d')\n",
    "            newdate = date_time_obj + datetime.timedelta(days=ds_sub.time.values[idx])\n",
    "            newdate1 = date_time_obj + datetime.timedelta(days=ds_sub.time.values[idx+1])\n",
    "            midcycdays = newdate1 - newdate\n",
    "            midcycdate = newdate + midcycdays/2\n",
    "            dates += [midcycdate]\n",
    "        # subset data to dhdt diff between orbital cycles of delta_h\n",
    "        dhdt = ds_sub.delta_h[idx+1,:,:]-ds_sub.delta_h[idx,:,:]\n",
    "        # clip ATL15 data to just show (first set crs)\n",
    "        dhdt.rio.write_crs(3031, inplace=True)\n",
    "        dhdt_clip_SF18 = dhdt.rio.clip(lake_SF18.geometry.values, lake_SF18.crs, drop=False, invert=False)\n",
    "        # calculate lake avg. dh/dt and dv/dt time series using published static outlines\n",
    "        avg_lk_dhdt_SF18 = np.nanmean(dhdt_clip_SF18)\n",
    "        lkavgdhdt_SF18 += [avg_lk_dhdt_SF18]\n",
    "        vol_SF18 = avg_lk_dhdt_SF18*SiegfriedFricker2018_outlines[SiegfriedFricker2018_outlines['name'] == lakename_SF18]['area (m^2)']\n",
    "        vols_SF18 += [vol_SF18.values[0]]\n",
    "        # create contours of ice surface elevation height changes to delineate variable lake outlines\n",
    "        contours_fill = []\n",
    "        contours_drain = []   \n",
    "        polys = []\n",
    "        contour = measure.find_contours(dhdt.values, thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_fill += [contour]\n",
    "        contour = measure.find_contours(dhdt.values, -thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_drain += [contour]\n",
    "        # create mapping conversion factor to map array location to polar stereographic x,y\n",
    "        x_conv = (x_max-x_min)/dhdt.shape[1]\n",
    "        y_conv = (y_max-y_min)/dhdt.shape[0]\n",
    "        # plot variable outlines found in this time slice\n",
    "        # make polygons from variable outlines\n",
    "        for i in range(len(contours_fill)): \n",
    "            for j in range(len(contours_fill[i])):\n",
    "                axes[0,0].plot(x_min+contours_fill[i][j][:, 1]*x_conv, y_max-contours_fill[i][j][:, 0]*y_conv, \n",
    "                color=cmap(norm(ds_sub.time.values[idx])), linestyle=(0, (3, 1, 1, 1)), linewidth=1)\n",
    "                if len(contours_fill[i][j][:, 1]) > 2: \n",
    "                    poly = Polygon(list(zip(contours_fill[i][j][:, 1]*x_conv+x_min, y_max-contours_fill[i][j][:, 0]*y_conv))) \n",
    "                    polys += [poly]\n",
    "        for i in range(len(contours_drain)): \n",
    "            for j in range(len(contours_drain[i])):\n",
    "                axes[0,0].plot(x_min+contours_drain[i][j][:, 1]*x_conv, y_max-contours_drain[i][j][:, 0]*y_conv, color=cmap(norm(ds_sub.time.values[idx])), linestyle=(0, (5, 1)), linewidth=1)\n",
    "                if len(contours_drain[i][j][:, 1]) > 2: \n",
    "                    poly = Polygon(list(zip(contours_drain[i][j][:, 1]*x_conv+x_min, y_max-contours_drain[i][j][:, 0]*y_conv))) \n",
    "                    polys += [poly]\n",
    "        # set area to zero each time step\n",
    "        variable_area = 0\n",
    "        # if polygons are present at time step, \n",
    "        if len(polys) > 0: \n",
    "            # clip data to polygons\n",
    "            dhdt_clip = dhdt.rio.clip(polys, drop=False, invert=False)\n",
    "            # then calculate on-lake averages of dh/dt\n",
    "            avg_lk_dhdt = np.nanmean(dhdt_clip)\n",
    "            # occasionally small polygons will completely clip data resulting in nan's for lake avg. dh/dt\n",
    "            # replace with zeros\n",
    "            if math.isnan(avg_lk_dhdt): \n",
    "                avg_lk_dhdt = 0\n",
    "                lkavgdhdt_var += [avg_lk_dhdt]\n",
    "            else:\n",
    "                lkavgdhdt_var += [avg_lk_dhdt]\n",
    "                # and dv/dt\n",
    "            for i in range(len(polys)):\n",
    "                variable_area = variable_area + polys[i].area\n",
    "            vol_var = avg_lk_dhdt*variable_area\n",
    "            vols_var += [vol_var]\n",
    "        else: \n",
    "            variable_area = 0\n",
    "            avg_lk_dhdt = 0\n",
    "            lkavgdhdt_var += [avg_lk_dhdt]\n",
    "            vol_var = avg_lk_dhdt*variable_area\n",
    "            vols_var += [vol_var]\n",
    "    axes[0,0].set(xlim=(x_min, x_max), ylim=(y_min, y_max))\n",
    "    # change polar stereographic m to km\n",
    "    km_scale = 1e3\n",
    "    ticks_x = ticker.FuncFormatter(lambda x, pos: '{0:g}'.format(x/km_scale))\n",
    "    axes[0,0].xaxis.set_major_formatter(ticks_x)\n",
    "    ticks_y = ticker.FuncFormatter(lambda x, pos: '{0:g}'.format(x/km_scale))\n",
    "    axes[0,0].yaxis.set_major_formatter(ticks_y)  \n",
    "    # adjust ticks\n",
    "    # axes[0,0].set_xticks(np.arange(np.round(x_min, decimals = -3),np.round(x_max, decimals = -3),5000))\n",
    "    # axes[0,0].set_yticks(np.arange(np.round(y_min, decimals = -3),np.round(y_max, decimals = -3),5000))\n",
    "    # label axes\n",
    "    axes[0,0].set_xlabel('x [km]', size=15)\n",
    "    axes[0,0].set_ylabel('y [km]', size=15)\n",
    "    # add title and colorbar\n",
    "    # axes[0].set_title('outline comparison', pad=7.5, fontsize=17.5)\n",
    "    m = plt.cm.ScalarMappable(cmap=cmap)\n",
    "    m.set_array(np.array([datetime2fracyear(date_idx) for date_idx in dates[0:-1]]))\n",
    "    divider = make_axes_locatable(axes[0,0])\n",
    "    cax = divider.append_axes('bottom', size='2.5%', pad=0.7)\n",
    "    clb = fig.colorbar(m, cax=cax, orientation='horizontal').set_label('Year', size=15)\n",
    "    # display MOA visual imagery\n",
    "    # axes[0,0].imshow(mpimg.imread('Whillans_7.png'), extent=[x_min1,x_max1,y_min1,y_max1], alpha=1)\n",
    "    # overlay published outlines for visual comparison \n",
    "    Smith2009_outlines.boundary.plot(ax=axes[0,0], color='darkturquoise', linestyle=(0, (1, 5)), linewidth=1)\n",
    "    SiegfriedFricker2018_SF18outlines.boundary.plot(ax=axes[0,0], color='darkturquoise', linestyle=(0, (1, 1)), linewidth=1)\n",
    "    # create lines for legends\n",
    "    Smith2009 = plt.Line2D((0, 1), (0, 0), color='darkturquoise', linestyle=(0, (1, 5)), linewidth=2)\n",
    "    SiegfriedFricker2018 = plt.Line2D((0, 1), (0, 0), color='darkturquoise', linestyle=(0, (1, 1)), linewidth=2)\n",
    "    uplift = plt.Line2D((0, 1), (0, 0), color='k', linestyle=(0, (3, 1, 1, 1)), linewidth=2)\n",
    "    subsidence = plt.Line2D((0, 1), (0, 0), color='k', linestyle=(0, (5, 1)), linewidth=1)\n",
    "    variable_outlines = plt.Line2D((0, 1), (0, 0), color='k', linestyle='dashdot', linewidth=2)\n",
    "    axes[0,0].legend([#Smith2009,\n",
    "        SiegfriedFricker2018,\n",
    "        uplift, subsidence],\n",
    "        [#'Smith and others, 2009 static outline',\n",
    "        'Siegfried & Fricker, 2018 static outline',\n",
    "        ('+'+str(thres)+' m uplift (filling) variable outline'), '–'+str(thres)+' m subsidence (draining) variable outline'], \n",
    "        loc='upper right')\n",
    "    # plot inset map to show location \n",
    "    axIns = axes[0,0].inset_axes([0.005, -0.03, 0.3, 0.3])\n",
    "    axIns.patch.set_facecolor('lightskyblue')\n",
    "    axIns.set_aspect('equal')\n",
    "    axIns.scatter(((x_max+x_min)/2), ((y_max+y_min)/2), marker='*', \n",
    "        linewidth=1, edgecolor='k', facecolor='r', s=100, zorder=3)\n",
    "    Scripps_gl.plot(ax=axIns, color='ghostwhite', edgecolor='k', linewidth=0.5, zorder=2)\n",
    "    axIns.axis('off')\n",
    "    # plot dv subplot\n",
    "    axes[0,1].plot(dates[:idx+1], np.divide(np.cumsum(vols_SF18[:idx+1]), 1e+9), color='darkturquoise', linestyle=(0, (1, 1)))\n",
    "    axes[0,1].plot(dates[:idx+1], np.divide(np.cumsum(vols_var[:idx+1]), 1e+9), color='k', linestyle='dashdot')\n",
    "    locator = mdates.AutoDateLocator(minticks=1, maxticks=7)\n",
    "    formatter = mdates.ConciseDateFormatter(locator)\n",
    "    axes[0,1].xaxis.set_major_locator(locator)\n",
    "    axes[0,1].xaxis.set_major_formatter(formatter)\n",
    "    axes[0,1].set_xlabel('Year', size=15)\n",
    "    axes[0,1].set_ylabel('Volume change [km$^3$]', size=15)\n",
    "    axes[0,1].yaxis.tick_right()\n",
    "    axes[0,1].yaxis.set_label_position(\"right\")\n",
    "    axes[0,1].legend([#Smith2009,\n",
    "        SiegfriedFricker2018,variable_outlines],\n",
    "                    [#'Smith and others, 2009 static outline',\n",
    "        'Siegfried & Fricker, 2018 static outline',\n",
    "        '±{} m variable outlines'.format(thres)], \n",
    "                    loc='upper right')\n",
    "\n",
    "    # subset ATL15 data set to region of interest\n",
    "    mask_x = (dataset2.x >= x_min) & (dataset2.x <= x_max)\n",
    "    mask_y = (dataset2.y >= y_min) & (dataset2.y <= y_max)\n",
    "    ds_sub = dataset2.where(mask_x & mask_y, drop=True)\n",
    "    # find magnitude of ice surface deformation in bounding box / find appropriate color map scale\n",
    "    height_anom_pos = []\n",
    "    height_anom_neg = []\n",
    "    for cyc in range(len(ds_sub.time)-1):\n",
    "        pos = np.nanmax(ds_sub.delta_h[cyc+1,:,:]-ds_sub.delta_h[cyc,:,:])\n",
    "        neg = np.nanmin(ds_sub.delta_h[cyc+1,:,:]-ds_sub.delta_h[cyc,:,:])\n",
    "        height_anom_pos += [pos]\n",
    "        height_anom_neg += [neg]\n",
    "    max_height_anom_pos = max(height_anom_pos)\n",
    "    max_height_anom_neg = min(height_anom_neg)\n",
    "    max_height_anom_abs = max(max_height_anom_pos,abs(max_height_anom_neg))\n",
    "    v = np.round(max_height_anom_abs)\n",
    "    # create empty lists to store data\n",
    "    dates = []\n",
    "    lkavgdhdt_SF18 = []\n",
    "    lkavgdhdt_var = []\n",
    "    vols_SF18 = []\n",
    "    vols_var = []\n",
    "    # plot figure\n",
    "    norm = plt.Normalize(ds_sub.time.values[0],ds_sub.time.values[-1])    \n",
    "    for idx in range(len(ds_sub.time)-1): \n",
    "        dhdt = ds_sub.delta_h[idx+1,:,:]-ds_sub.delta_h[idx,:,:]\n",
    "        # calculate mid-cycle dates for plotting\n",
    "        if dataset2.fileName == 'mos_2010.5_2021.5.h5':\n",
    "            newdate = datetime.datetime(int(ds_sub.time.values[idx]), 1, 1) + datetime.timedelta(days = (ds_sub.time.values[idx] % 1) * 365.25)\n",
    "            newdate1 = datetime.datetime(int(ds_sub.time.values[idx+1]), 1, 1) + datetime.timedelta(days = (ds_sub.time.values[idx+1] % 1) * 365.25)\n",
    "            midcycdays = newdate1 - newdate\n",
    "            midcycdate = newdate + midcycdays/2\n",
    "            dates += [midcycdate]\n",
    "        elif dataset2.fileName == 'ATL15_AA_0311_01km_001_01.nc':    \n",
    "            date_time_str = '18-01-01'\n",
    "            date_time_obj = datetime.datetime.strptime(date_time_str, '%y-%m-%d')\n",
    "            newdate = date_time_obj + datetime.timedelta(days=ds_sub.time.values[idx])\n",
    "            newdate1 = date_time_obj + datetime.timedelta(days=ds_sub.time.values[idx+1])\n",
    "            midcycdays = newdate1 - newdate\n",
    "            midcycdate = newdate + midcycdays/2\n",
    "            dates += [midcycdate]\n",
    "        # subset data to dhdt diff between orbital cycles of delta_h\n",
    "        dhdt = ds_sub.delta_h[idx+1,:,:]-ds_sub.delta_h[idx,:,:]\n",
    "        # clip data to lake area (first set crs)\n",
    "        dhdt.rio.write_crs(3031, inplace=True)\n",
    "        dhdt_clip_SF18 = dhdt.rio.clip(lake_SF18.geometry.values, lake_SF18.crs, drop=False, invert=False)\n",
    "        # calculate lake avg. dh/dt and dv/dt time series using published static outlines\n",
    "        avg_lk_dhdt_SF18 = np.nanmean(dhdt_clip_SF18)\n",
    "        lkavgdhdt_SF18 += [avg_lk_dhdt_SF18]\n",
    "        vol_SF18 = avg_lk_dhdt_SF18*SiegfriedFricker2018_outlines[SiegfriedFricker2018_outlines['name'] == lakename_SF18]['area (m^2)']\n",
    "        vols_SF18 += [vol_SF18.values[0]]\n",
    "        # create contours of ice surface elevation height changes to delineate variable lake outlines\n",
    "        contours_fill = []\n",
    "        contours_drain = []   \n",
    "        polys = []\n",
    "        contour = measure.find_contours(dhdt.values, thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_fill += [contour]\n",
    "        contour = measure.find_contours(dhdt.values, -thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_drain += [contour]\n",
    "        # create mapping conversion factor to map array location to polar stereographic x,y\n",
    "        x_conv = (x_max-x_min)/dhdt.shape[1]\n",
    "        y_conv = (y_max-y_min)/dhdt.shape[0]\n",
    "        # plot variable outlines found in this time slice\n",
    "        # make polygons from variable outlines\n",
    "        for i in range(len(contours_fill)): \n",
    "            for j in range(len(contours_fill[i])):\n",
    "                axes[1,0].plot(x_min+contours_fill[i][j][:, 1]*x_conv, y_max-contours_fill[i][j][:, 0]*y_conv, \n",
    "                color=cmap(norm(ds_sub.time.values[idx])), linestyle=(0, (3, 1, 1, 1)), linewidth=1)\n",
    "                if len(contours_fill[i][j][:, 1]) > 2: \n",
    "                    poly = Polygon(list(zip(contours_fill[i][j][:, 1]*x_conv+x_min, y_max-contours_fill[i][j][:, 0]*y_conv))) \n",
    "                    polys += [poly]\n",
    "        for i in range(len(contours_drain)): \n",
    "            for j in range(len(contours_drain[i])):\n",
    "                axes[1,0].plot(x_min+contours_drain[i][j][:, 1]*x_conv, y_max-contours_drain[i][j][:, 0]*y_conv, color=cmap(norm(ds_sub.time.values[idx])), linestyle=(0, (5, 1)), linewidth=1)\n",
    "                if len(contours_drain[i][j][:, 1]) > 2: \n",
    "                    poly = Polygon(list(zip(contours_drain[i][j][:, 1]*x_conv+x_min, y_max-contours_drain[i][j][:, 0]*y_conv))) \n",
    "                    polys += [poly]\n",
    "        # set area to zero each time step\n",
    "        variable_area = 0\n",
    "        # if polygons are present at time step, \n",
    "        if len(polys) > 0: \n",
    "            # clip data to polygons\n",
    "            dhdt_clip = dhdt.rio.clip(polys, drop=False, invert=False)\n",
    "            # then calculate on-lake averages of dh/dt\n",
    "            avg_lk_dhdt = np.nanmean(dhdt_clip)\n",
    "            # occasionally small polygons will completely clip data resulting in nan's for lake avg. dh/dt\n",
    "            # replace with zeros\n",
    "            if math.isnan(avg_lk_dhdt): \n",
    "                avg_lk_dhdt = 0\n",
    "                lkavgdhdt_var += [avg_lk_dhdt]\n",
    "            else:\n",
    "                lkavgdhdt_var += [avg_lk_dhdt]\n",
    "                # and dv/dt\n",
    "            for i in range(len(polys)):\n",
    "                variable_area = variable_area + polys[i].area\n",
    "            vol_var = avg_lk_dhdt*variable_area\n",
    "            vols_var += [vol_var]\n",
    "        else: \n",
    "            variable_area = 0\n",
    "            avg_lk_dhdt = 0\n",
    "            lkavgdhdt_var += [avg_lk_dhdt]\n",
    "            vol_var = avg_lk_dhdt*variable_area\n",
    "            vols_var += [vol_var]\n",
    "    axes[1,0].set(xlim=(x_min, x_max), ylim=(y_min, y_max))\n",
    "    # change polar stereographic m to km\n",
    "    km_scale = 1e3\n",
    "    ticks_x = ticker.FuncFormatter(lambda x, pos: '{0:g}'.format(x/km_scale))\n",
    "    axes[1,0].xaxis.set_major_formatter(ticks_x)\n",
    "    ticks_y = ticker.FuncFormatter(lambda x, pos: '{0:g}'.format(x/km_scale))\n",
    "    axes[1,0].yaxis.set_major_formatter(ticks_y)  \n",
    "    # adjust ticks\n",
    "    # axes[1,0].set_xticks(np.arange(np.round(x_min, decimals = -3),np.round(x_max, decimals = -3),5000))\n",
    "    # axes[1,0].set_yticks(np.arange(np.round(y_min, decimals = -3),np.round(y_max, decimals = -3),5000))\n",
    "    # label axes\n",
    "    axes[1,0].set_xlabel('x [km]', size=15)\n",
    "    axes[1,0].set_ylabel('y [km]', size=15)\n",
    "    # add colorbar\n",
    "    m = plt.cm.ScalarMappable(cmap=cmap)\n",
    "    m.set_array(np.array([datetime2fracyear(date_idx) for date_idx in dates[0:-1]]))\n",
    "    divider = make_axes_locatable(axes[1,0])\n",
    "    cax = divider.append_axes('bottom', size='2.5%', pad=0.7)\n",
    "    clb = fig.colorbar(m,  cax=cax, orientation='horizontal', ticks=np.array([2019,2020,2021])).set_label('Year', size=15)\n",
    "    # overlay published outlines for visual comparison \n",
    "    Smith2009_outlines.boundary.plot(ax=axes[1,0], color='darkturquoise', linestyle=(0, (1, 5)), linewidth=1)\n",
    "    SiegfriedFricker2018_SF18outlines.boundary.plot(ax=axes[1,0], color='darkturquoise', linestyle=(0, (1, 1)), linewidth=1)\n",
    "    axes[1,0].legend([#Smith2009, \n",
    "        SiegfriedFricker2018, uplift, subsidence],\n",
    "        [#'Smith and others, 2009 static outline',\n",
    "        'Siegfried & Fricker, 2018 static outline',\n",
    "        ('+'+str(thres)+' m uplift (filling) variable outline'), '–'+str(thres)+' m subsidence (draining) variable outline'], \n",
    "        loc='upper right')\n",
    "    # plot inset map to show location \n",
    "    axIns = axes[1,0].inset_axes([0.005, -0.03, 0.3, 0.3])\n",
    "    axIns.patch.set_facecolor('lightskyblue')\n",
    "    axIns.set_aspect('equal')\n",
    "    axIns.scatter(((x_max+x_min)/2), ((y_max+y_min)/2), marker='*', \n",
    "        linewidth=1, edgecolor='k', facecolor='r', s=100, zorder=3)\n",
    "    Scripps_gl.plot(ax=axIns, color='ghostwhite', edgecolor='k', linewidth=0.5, zorder=2)\n",
    "    axIns.axis('off')\n",
    "    # plot dvdt subplot\n",
    "    axes[1,1].plot(dates[:idx+1], np.divide(np.cumsum(vols_SF18[:idx+1]), 1e+9), color='darkturquoise', linestyle=(0, (1, 1)))\n",
    "    axes[1,1].plot(dates[:idx+1], np.divide(np.cumsum(vols_var[:idx+1]), 1e+9), color='k', linestyle='dashdot')\n",
    "    locator = mdates.AutoDateLocator(minticks=1, maxticks=7)\n",
    "    formatter = mdates.ConciseDateFormatter(locator)\n",
    "    axes[1,1].xaxis.set_major_locator(locator)\n",
    "    axes[1,1].xaxis.set_major_formatter(formatter)\n",
    "    min_vol = min(np.divide(min(np.cumsum(vols_SF18)), 1e+9), \n",
    "                    np.divide(min(np.cumsum(vols_var)), 1e+9))\n",
    "    max_vol = max(np.divide(max(np.cumsum(vols_SF18)), 1e+9), \n",
    "                    np.divide(max(np.cumsum(vols_var)), 1e+9))\n",
    "    if dataset2.fileName == 'mos_2010.5_2021.5.h5':\n",
    "        axes[1,1].set(xlim=(datetime.datetime(int(ds_sub.time.values[0]), 1, 1) + datetime.timedelta(days = (ds_sub.time.values[0] % 1) * 365.25), \n",
    "                            datetime.datetime(int(ds_sub.time.values[-1]), 1, 1) + datetime.timedelta(days = (ds_sub.time.values[-1] % 1) * 365.25)), \n",
    "                    ylim=((min_vol - (max_vol - min_vol)*0.05),\n",
    "                            (max_vol + (max_vol - min_vol)*0.05)))\n",
    "    elif dataset2.fileName == 'ATL15_AA_0311_01km_001_01.nc':    \n",
    "        axes[1,1].set(xlim=(date_time_obj + datetime.timedelta(days=ds_sub.time.values[1]),\n",
    "                            date_time_obj + datetime.timedelta(days=ds_sub.time.values[-1])), \n",
    "                    ylim=((min_vol - (max_vol - min_vol)*0.05), \n",
    "                            (max_vol + (max_vol - min_vol)*0.05)))\n",
    "    axes[1,1].set_xlabel('Year', size=15)\n",
    "    axes[1,1].set_ylabel('Volume change [km$^3$]', size=15)\n",
    "    axes[1,1].yaxis.tick_right()\n",
    "    axes[1,1].yaxis.set_label_position(\"right\")\n",
    "    axes[1,1].legend([#Smith2009,\n",
    "        SiegfriedFricker2018,variable_outlines],\n",
    "                    [#'Smith and others, 2009 static outline',\n",
    "        'Siegfried & Fricker, 2018 static outline',\n",
    "        '±{} m variable outlines'.format(thres)], \n",
    "                    loc='upper right')\n",
    "    # save and close figure\n",
    "    plt.savefig('/Users/Wilson/Documents/0-code/1-lakeshores/output_dhdvdt-using-variable-outlines/S09SF18varoutlines_agg_dvdt_plot/S09SF18varoutlines_agg_dvdt_plot-{}.png'\\\n",
    "        .format(lakename_SF18), dpi=300, bbox_inches = \"tight\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tn/2b7yqbx51jxb820_x39chyc80000gn/T/ipykernel_10453/4228700830.py:108: RuntimeWarning: Mean of empty slice\n",
      "  avg_lk_dhdt = np.nanmean(dhdt_clip)\n",
      "/var/folders/tn/2b7yqbx51jxb820_x39chyc80000gn/T/ipykernel_10453/4228700830.py:108: RuntimeWarning: Mean of empty slice\n",
      "  avg_lk_dhdt = np.nanmean(dhdt_clip)\n",
      "/var/folders/tn/2b7yqbx51jxb820_x39chyc80000gn/T/ipykernel_10453/4228700830.py:278: RuntimeWarning: Mean of empty slice\n",
      "  avg_lk_dhdt = np.nanmean(dhdt_clip)\n"
     ]
    }
   ],
   "source": [
    "# test on one lake to ensure working\n",
    "S09SF18varoutlines_agg_dvdt_plot('Mac1', 10000, 0.5, CS2_dh, ATL15_dh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tn/2b7yqbx51jxb820_x39chyc80000gn/T/ipykernel_10453/4228700830.py:108: RuntimeWarning: Mean of empty slice\n",
      "  avg_lk_dhdt = np.nanmean(dhdt_clip)\n",
      "/var/folders/tn/2b7yqbx51jxb820_x39chyc80000gn/T/ipykernel_10453/4228700830.py:108: RuntimeWarning: Mean of empty slice\n",
      "  avg_lk_dhdt = np.nanmean(dhdt_clip)\n",
      "/var/folders/tn/2b7yqbx51jxb820_x39chyc80000gn/T/ipykernel_10453/4228700830.py:278: RuntimeWarning: Mean of empty slice\n",
      "  avg_lk_dhdt = np.nanmean(dhdt_clip)\n",
      "/var/folders/tn/2b7yqbx51jxb820_x39chyc80000gn/T/ipykernel_10453/4228700830.py:108: RuntimeWarning: Mean of empty slice\n",
      "  avg_lk_dhdt = np.nanmean(dhdt_clip)\n",
      "/var/folders/tn/2b7yqbx51jxb820_x39chyc80000gn/T/ipykernel_10453/4228700830.py:108: RuntimeWarning: Mean of empty slice\n",
      "  avg_lk_dhdt = np.nanmean(dhdt_clip)\n",
      "/var/folders/tn/2b7yqbx51jxb820_x39chyc80000gn/T/ipykernel_10453/4228700830.py:108: RuntimeWarning: Mean of empty slice\n",
      "  avg_lk_dhdt = np.nanmean(dhdt_clip)\n",
      "/var/folders/tn/2b7yqbx51jxb820_x39chyc80000gn/T/ipykernel_10453/4228700830.py:108: RuntimeWarning: Mean of empty slice\n",
      "  avg_lk_dhdt = np.nanmean(dhdt_clip)\n",
      "/var/folders/tn/2b7yqbx51jxb820_x39chyc80000gn/T/ipykernel_10453/4228700830.py:108: RuntimeWarning: Mean of empty slice\n",
      "  avg_lk_dhdt = np.nanmean(dhdt_clip)\n",
      "/var/folders/tn/2b7yqbx51jxb820_x39chyc80000gn/T/ipykernel_10453/4228700830.py:108: RuntimeWarning: Mean of empty slice\n",
      "  avg_lk_dhdt = np.nanmean(dhdt_clip)\n",
      "/var/folders/tn/2b7yqbx51jxb820_x39chyc80000gn/T/ipykernel_10453/4228700830.py:108: RuntimeWarning: Mean of empty slice\n",
      "  avg_lk_dhdt = np.nanmean(dhdt_clip)\n",
      "/var/folders/tn/2b7yqbx51jxb820_x39chyc80000gn/T/ipykernel_10453/4228700830.py:278: RuntimeWarning: Mean of empty slice\n",
      "  avg_lk_dhdt = np.nanmean(dhdt_clip)\n",
      "/var/folders/tn/2b7yqbx51jxb820_x39chyc80000gn/T/ipykernel_10453/4228700830.py:108: RuntimeWarning: Mean of empty slice\n",
      "  avg_lk_dhdt = np.nanmean(dhdt_clip)\n",
      "/var/folders/tn/2b7yqbx51jxb820_x39chyc80000gn/T/ipykernel_10453/4228700830.py:108: RuntimeWarning: Mean of empty slice\n",
      "  avg_lk_dhdt = np.nanmean(dhdt_clip)\n",
      "/var/folders/tn/2b7yqbx51jxb820_x39chyc80000gn/T/ipykernel_10453/4228700830.py:108: RuntimeWarning: Mean of empty slice\n",
      "  avg_lk_dhdt = np.nanmean(dhdt_clip)\n",
      "/var/folders/tn/2b7yqbx51jxb820_x39chyc80000gn/T/ipykernel_10453/4228700830.py:108: RuntimeWarning: Mean of empty slice\n",
      "  avg_lk_dhdt = np.nanmean(dhdt_clip)\n",
      "/var/folders/tn/2b7yqbx51jxb820_x39chyc80000gn/T/ipykernel_10453/4228700830.py:278: RuntimeWarning: Mean of empty slice\n",
      "  avg_lk_dhdt = np.nanmean(dhdt_clip)\n",
      "/var/folders/tn/2b7yqbx51jxb820_x39chyc80000gn/T/ipykernel_10453/4228700830.py:278: RuntimeWarning: Mean of empty slice\n",
      "  avg_lk_dhdt = np.nanmean(dhdt_clip)\n",
      "/var/folders/tn/2b7yqbx51jxb820_x39chyc80000gn/T/ipykernel_10453/4228700830.py:69: RuntimeWarning: Mean of empty slice\n",
      "  avg_lk_dhdt_SF18 = np.nanmean(dhdt_clip_SF18)\n",
      "/var/folders/tn/2b7yqbx51jxb820_x39chyc80000gn/T/ipykernel_10453/4228700830.py:69: RuntimeWarning: Mean of empty slice\n",
      "  avg_lk_dhdt_SF18 = np.nanmean(dhdt_clip_SF18)\n",
      "/var/folders/tn/2b7yqbx51jxb820_x39chyc80000gn/T/ipykernel_10453/4228700830.py:69: RuntimeWarning: Mean of empty slice\n",
      "  avg_lk_dhdt_SF18 = np.nanmean(dhdt_clip_SF18)\n",
      "/var/folders/tn/2b7yqbx51jxb820_x39chyc80000gn/T/ipykernel_10453/4228700830.py:69: RuntimeWarning: Mean of empty slice\n",
      "  avg_lk_dhdt_SF18 = np.nanmean(dhdt_clip_SF18)\n",
      "/var/folders/tn/2b7yqbx51jxb820_x39chyc80000gn/T/ipykernel_10453/4228700830.py:69: RuntimeWarning: Mean of empty slice\n",
      "  avg_lk_dhdt_SF18 = np.nanmean(dhdt_clip_SF18)\n",
      "/var/folders/tn/2b7yqbx51jxb820_x39chyc80000gn/T/ipykernel_10453/4228700830.py:69: RuntimeWarning: Mean of empty slice\n",
      "  avg_lk_dhdt_SF18 = np.nanmean(dhdt_clip_SF18)\n",
      "/var/folders/tn/2b7yqbx51jxb820_x39chyc80000gn/T/ipykernel_10453/4228700830.py:69: RuntimeWarning: Mean of empty slice\n",
      "  avg_lk_dhdt_SF18 = np.nanmean(dhdt_clip_SF18)\n",
      "/var/folders/tn/2b7yqbx51jxb820_x39chyc80000gn/T/ipykernel_10453/4228700830.py:69: RuntimeWarning: Mean of empty slice\n",
      "  avg_lk_dhdt_SF18 = np.nanmean(dhdt_clip_SF18)\n",
      "/var/folders/tn/2b7yqbx51jxb820_x39chyc80000gn/T/ipykernel_10453/4228700830.py:69: RuntimeWarning: Mean of empty slice\n",
      "  avg_lk_dhdt_SF18 = np.nanmean(dhdt_clip_SF18)\n",
      "/var/folders/tn/2b7yqbx51jxb820_x39chyc80000gn/T/ipykernel_10453/4228700830.py:69: RuntimeWarning: Mean of empty slice\n",
      "  avg_lk_dhdt_SF18 = np.nanmean(dhdt_clip_SF18)\n",
      "/var/folders/tn/2b7yqbx51jxb820_x39chyc80000gn/T/ipykernel_10453/4228700830.py:69: RuntimeWarning: Mean of empty slice\n",
      "  avg_lk_dhdt_SF18 = np.nanmean(dhdt_clip_SF18)\n",
      "/var/folders/tn/2b7yqbx51jxb820_x39chyc80000gn/T/ipykernel_10453/4228700830.py:69: RuntimeWarning: Mean of empty slice\n",
      "  avg_lk_dhdt_SF18 = np.nanmean(dhdt_clip_SF18)\n",
      "/var/folders/tn/2b7yqbx51jxb820_x39chyc80000gn/T/ipykernel_10453/4228700830.py:69: RuntimeWarning: Mean of empty slice\n",
      "  avg_lk_dhdt_SF18 = np.nanmean(dhdt_clip_SF18)\n",
      "/var/folders/tn/2b7yqbx51jxb820_x39chyc80000gn/T/ipykernel_10453/4228700830.py:69: RuntimeWarning: Mean of empty slice\n",
      "  avg_lk_dhdt_SF18 = np.nanmean(dhdt_clip_SF18)\n",
      "/var/folders/tn/2b7yqbx51jxb820_x39chyc80000gn/T/ipykernel_10453/4228700830.py:69: RuntimeWarning: Mean of empty slice\n",
      "  avg_lk_dhdt_SF18 = np.nanmean(dhdt_clip_SF18)\n",
      "/var/folders/tn/2b7yqbx51jxb820_x39chyc80000gn/T/ipykernel_10453/4228700830.py:69: RuntimeWarning: Mean of empty slice\n",
      "  avg_lk_dhdt_SF18 = np.nanmean(dhdt_clip_SF18)\n",
      "/var/folders/tn/2b7yqbx51jxb820_x39chyc80000gn/T/ipykernel_10453/4228700830.py:69: RuntimeWarning: Mean of empty slice\n",
      "  avg_lk_dhdt_SF18 = np.nanmean(dhdt_clip_SF18)\n",
      "/var/folders/tn/2b7yqbx51jxb820_x39chyc80000gn/T/ipykernel_10453/4228700830.py:69: RuntimeWarning: Mean of empty slice\n",
      "  avg_lk_dhdt_SF18 = np.nanmean(dhdt_clip_SF18)\n",
      "/var/folders/tn/2b7yqbx51jxb820_x39chyc80000gn/T/ipykernel_10453/4228700830.py:69: RuntimeWarning: Mean of empty slice\n",
      "  avg_lk_dhdt_SF18 = np.nanmean(dhdt_clip_SF18)\n",
      "/var/folders/tn/2b7yqbx51jxb820_x39chyc80000gn/T/ipykernel_10453/4228700830.py:69: RuntimeWarning: Mean of empty slice\n",
      "  avg_lk_dhdt_SF18 = np.nanmean(dhdt_clip_SF18)\n",
      "/var/folders/tn/2b7yqbx51jxb820_x39chyc80000gn/T/ipykernel_10453/4228700830.py:69: RuntimeWarning: Mean of empty slice\n",
      "  avg_lk_dhdt_SF18 = np.nanmean(dhdt_clip_SF18)\n",
      "/var/folders/tn/2b7yqbx51jxb820_x39chyc80000gn/T/ipykernel_10453/4228700830.py:69: RuntimeWarning: Mean of empty slice\n",
      "  avg_lk_dhdt_SF18 = np.nanmean(dhdt_clip_SF18)\n",
      "/var/folders/tn/2b7yqbx51jxb820_x39chyc80000gn/T/ipykernel_10453/4228700830.py:69: RuntimeWarning: Mean of empty slice\n",
      "  avg_lk_dhdt_SF18 = np.nanmean(dhdt_clip_SF18)\n",
      "/var/folders/tn/2b7yqbx51jxb820_x39chyc80000gn/T/ipykernel_10453/4228700830.py:69: RuntimeWarning: Mean of empty slice\n",
      "  avg_lk_dhdt_SF18 = np.nanmean(dhdt_clip_SF18)\n",
      "/var/folders/tn/2b7yqbx51jxb820_x39chyc80000gn/T/ipykernel_10453/4228700830.py:69: RuntimeWarning: Mean of empty slice\n",
      "  avg_lk_dhdt_SF18 = np.nanmean(dhdt_clip_SF18)\n",
      "/var/folders/tn/2b7yqbx51jxb820_x39chyc80000gn/T/ipykernel_10453/4228700830.py:69: RuntimeWarning: Mean of empty slice\n",
      "  avg_lk_dhdt_SF18 = np.nanmean(dhdt_clip_SF18)\n",
      "/var/folders/tn/2b7yqbx51jxb820_x39chyc80000gn/T/ipykernel_10453/4228700830.py:69: RuntimeWarning: Mean of empty slice\n",
      "  avg_lk_dhdt_SF18 = np.nanmean(dhdt_clip_SF18)\n",
      "/var/folders/tn/2b7yqbx51jxb820_x39chyc80000gn/T/ipykernel_10453/4228700830.py:69: RuntimeWarning: Mean of empty slice\n",
      "  avg_lk_dhdt_SF18 = np.nanmean(dhdt_clip_SF18)\n",
      "/var/folders/tn/2b7yqbx51jxb820_x39chyc80000gn/T/ipykernel_10453/4228700830.py:69: RuntimeWarning: Mean of empty slice\n",
      "  avg_lk_dhdt_SF18 = np.nanmean(dhdt_clip_SF18)\n",
      "/var/folders/tn/2b7yqbx51jxb820_x39chyc80000gn/T/ipykernel_10453/4228700830.py:69: RuntimeWarning: Mean of empty slice\n",
      "  avg_lk_dhdt_SF18 = np.nanmean(dhdt_clip_SF18)\n",
      "/var/folders/tn/2b7yqbx51jxb820_x39chyc80000gn/T/ipykernel_10453/4228700830.py:69: RuntimeWarning: Mean of empty slice\n",
      "  avg_lk_dhdt_SF18 = np.nanmean(dhdt_clip_SF18)\n",
      "/var/folders/tn/2b7yqbx51jxb820_x39chyc80000gn/T/ipykernel_10453/4228700830.py:69: RuntimeWarning: Mean of empty slice\n",
      "  avg_lk_dhdt_SF18 = np.nanmean(dhdt_clip_SF18)\n",
      "/var/folders/tn/2b7yqbx51jxb820_x39chyc80000gn/T/ipykernel_10453/4228700830.py:69: RuntimeWarning: Mean of empty slice\n",
      "  avg_lk_dhdt_SF18 = np.nanmean(dhdt_clip_SF18)\n",
      "/var/folders/tn/2b7yqbx51jxb820_x39chyc80000gn/T/ipykernel_10453/4228700830.py:69: RuntimeWarning: Mean of empty slice\n",
      "  avg_lk_dhdt_SF18 = np.nanmean(dhdt_clip_SF18)\n",
      "/var/folders/tn/2b7yqbx51jxb820_x39chyc80000gn/T/ipykernel_10453/4228700830.py:69: RuntimeWarning: Mean of empty slice\n",
      "  avg_lk_dhdt_SF18 = np.nanmean(dhdt_clip_SF18)\n",
      "/var/folders/tn/2b7yqbx51jxb820_x39chyc80000gn/T/ipykernel_10453/4228700830.py:69: RuntimeWarning: Mean of empty slice\n",
      "  avg_lk_dhdt_SF18 = np.nanmean(dhdt_clip_SF18)\n",
      "/var/folders/tn/2b7yqbx51jxb820_x39chyc80000gn/T/ipykernel_10453/4228700830.py:69: RuntimeWarning: Mean of empty slice\n",
      "  avg_lk_dhdt_SF18 = np.nanmean(dhdt_clip_SF18)\n",
      "/var/folders/tn/2b7yqbx51jxb820_x39chyc80000gn/T/ipykernel_10453/4228700830.py:69: RuntimeWarning: Mean of empty slice\n",
      "  avg_lk_dhdt_SF18 = np.nanmean(dhdt_clip_SF18)\n",
      "/var/folders/tn/2b7yqbx51jxb820_x39chyc80000gn/T/ipykernel_10453/4228700830.py:69: RuntimeWarning: Mean of empty slice\n",
      "  avg_lk_dhdt_SF18 = np.nanmean(dhdt_clip_SF18)\n",
      "/var/folders/tn/2b7yqbx51jxb820_x39chyc80000gn/T/ipykernel_10453/4228700830.py:69: RuntimeWarning: Mean of empty slice\n",
      "  avg_lk_dhdt_SF18 = np.nanmean(dhdt_clip_SF18)\n",
      "/var/folders/tn/2b7yqbx51jxb820_x39chyc80000gn/T/ipykernel_10453/4228700830.py:69: RuntimeWarning: Mean of empty slice\n",
      "  avg_lk_dhdt_SF18 = np.nanmean(dhdt_clip_SF18)\n",
      "/var/folders/tn/2b7yqbx51jxb820_x39chyc80000gn/T/ipykernel_10453/4228700830.py:69: RuntimeWarning: Mean of empty slice\n",
      "  avg_lk_dhdt_SF18 = np.nanmean(dhdt_clip_SF18)\n",
      "/var/folders/tn/2b7yqbx51jxb820_x39chyc80000gn/T/ipykernel_10453/4228700830.py:69: RuntimeWarning: Mean of empty slice\n",
      "  avg_lk_dhdt_SF18 = np.nanmean(dhdt_clip_SF18)\n",
      "/var/folders/tn/2b7yqbx51jxb820_x39chyc80000gn/T/ipykernel_10453/4228700830.py:69: RuntimeWarning: Mean of empty slice\n",
      "  avg_lk_dhdt_SF18 = np.nanmean(dhdt_clip_SF18)\n",
      "/var/folders/tn/2b7yqbx51jxb820_x39chyc80000gn/T/ipykernel_10453/4228700830.py:278: RuntimeWarning: Mean of empty slice\n",
      "  avg_lk_dhdt = np.nanmean(dhdt_clip)\n",
      "/var/folders/tn/2b7yqbx51jxb820_x39chyc80000gn/T/ipykernel_10453/4228700830.py:108: RuntimeWarning: Mean of empty slice\n",
      "  avg_lk_dhdt = np.nanmean(dhdt_clip)\n",
      "/var/folders/tn/2b7yqbx51jxb820_x39chyc80000gn/T/ipykernel_10453/4228700830.py:108: RuntimeWarning: Mean of empty slice\n",
      "  avg_lk_dhdt = np.nanmean(dhdt_clip)\n",
      "/var/folders/tn/2b7yqbx51jxb820_x39chyc80000gn/T/ipykernel_10453/4228700830.py:108: RuntimeWarning: Mean of empty slice\n",
      "  avg_lk_dhdt = np.nanmean(dhdt_clip)\n",
      "/var/folders/tn/2b7yqbx51jxb820_x39chyc80000gn/T/ipykernel_10453/4228700830.py:278: RuntimeWarning: Mean of empty slice\n",
      "  avg_lk_dhdt = np.nanmean(dhdt_clip)\n",
      "/var/folders/tn/2b7yqbx51jxb820_x39chyc80000gn/T/ipykernel_10453/4228700830.py:278: RuntimeWarning: Mean of empty slice\n",
      "  avg_lk_dhdt = np.nanmean(dhdt_clip)\n"
     ]
    }
   ],
   "source": [
    "# run func on all lakes from SF18 inventory with CS2 InSAR coverage\n",
    "for idx in range(len(SiegfriedFricker2018_SF18outlines_CS2InSAR)):\n",
    "    lakename = SiegfriedFricker2018_SF18outlines_CS2InSAR['name'][idx]\n",
    "    S09SF18varoutlines_agg_dvdt_plot(lakename, 10000, 0.5, CS2_dh, ATL15_dh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modified 2x2 to plot CS2 and IS2 on same plot; for S09 defined lakes\n",
    "# use on SiegfriedFricker2018_S09outlines_CS2InSAR\n",
    "def S09SF18varoutlines_agg_dvdt_plot(lakename_S09, buffer, thres, dataset1, dataset2): \n",
    "    '''\n",
    "    Create planview plot of an aggregated times series of variable outlines compared to known lakes alongside dv/dt time series. Uses geopandas buffer created bounding box around known lakes in Siegfried and Fricker, 2018 (SF18) inventory. Creates time-variable outlines using skimage contour to plot variable outline alongside published outlines for comparison. \n",
    "    Inputs: \n",
    "        lakename_SF18: lake of interest from SiegfriedFricker2018_outlines inventory\n",
    "        buffer: horizontal distance in meters away from SF18 lake outline used to create bounding box that is displayed around lake of interest\n",
    "        thres(hold): vertical distance in meters to delineate ice surface deformation contour\n",
    "        dataset: dataset to be analyzed (CS2_dh or ATL15_dh)\n",
    "    Outputs: \n",
    "        Aggregated time-variable lake outlines in regions of known lakes using CryoSat-2 or ICESat-2 ATL15 dh/dt data alongside dVol time series.\n",
    "    '''\n",
    "    # isolate individual lake using gpd buffer\n",
    "    lake_S09 = SiegfriedFricker2018_S09outlines_CS2InSAR.loc[SiegfriedFricker2018_S09outlines_CS2InSAR['name'] == lakename_S09]\n",
    "    lake_buffer = lake_S09.buffer(buffer)\n",
    "    # define lake bounding box\n",
    "    x_min = lake_buffer.bounds.values[0,0]; x_max = lake_buffer.bounds.values[0,2]\n",
    "    y_min = lake_buffer.bounds.values[0,1]; y_max = lake_buffer.bounds.values[0,3]\n",
    "    # subset ATL15 data set to region of interest\n",
    "    mask_x = (dataset1.x >= x_min) & (dataset1.x <= x_max)\n",
    "    mask_y = (dataset1.y >= y_min) & (dataset1.y <= y_max)\n",
    "    ds_sub = dataset1.where(mask_x & mask_y, drop=True)\n",
    "    # find magnitude of ice surface deformation in bounding box / find appropriate color map scale\n",
    "    height_anom_pos = []\n",
    "    height_anom_neg = []\n",
    "    for cyc in range(len(ds_sub.time)-1):\n",
    "        pos = np.nanmax(ds_sub.delta_h[cyc+1,:,:]-ds_sub.delta_h[cyc,:,:])\n",
    "        neg = np.nanmin(ds_sub.delta_h[cyc+1,:,:]-ds_sub.delta_h[cyc,:,:])\n",
    "        height_anom_pos += [pos]\n",
    "        height_anom_neg += [neg]\n",
    "    max_height_anom_pos = max(height_anom_pos)\n",
    "    max_height_anom_neg = min(height_anom_neg)\n",
    "    max_height_anom_abs = max(max_height_anom_pos,abs(max_height_anom_neg))\n",
    "    v = np.round(max_height_anom_abs)\n",
    "    # create empty lists to store data\n",
    "    dates = []\n",
    "    lkavgdhdt_SF18 = []\n",
    "    lkavgdhdt_var = []\n",
    "    vols_S09 = []\n",
    "    vols_var = []\n",
    "    # plot figure\n",
    "    fig, axes = plt.subplots(2,2, figsize=(20,20))\n",
    "    # plt.subplots_adjust(wspace=0.15, hspace = 0.1)\n",
    "    cmap = plt.get_cmap('CMRmap')\n",
    "    norm = plt.Normalize(ds_sub.time.values[0],ds_sub.time.values[-1])    \n",
    "    for idx in range(len(ds_sub.time)-1): \n",
    "        dhdt = ds_sub.delta_h[idx+1,:,:]-ds_sub.delta_h[idx,:,:]\n",
    "        # calculate mid-cycle dates for plotting\n",
    "        if dataset1.fileName == 'mos_2010.5_2021.5.h5':\n",
    "            newdate = datetime.datetime(int(ds_sub.time.values[idx]), 1, 1) + datetime.timedelta(days = (ds_sub.time.values[idx] % 1) * 365.25)\n",
    "            newdate1 = datetime.datetime(int(ds_sub.time.values[idx+1]), 1, 1) + datetime.timedelta(days = (ds_sub.time.values[idx+1] % 1) * 365.25)\n",
    "            midcycdays = newdate1 - newdate\n",
    "            midcycdate = newdate + midcycdays/2\n",
    "            dates += [midcycdate]\n",
    "        elif dataset1.fileName == 'ATL15_AA_0311_01km_001_01.nc':    \n",
    "            date_time_str = '18-01-01'\n",
    "            date_time_obj = datetime.datetime.strptime(date_time_str, '%y-%m-%d')\n",
    "            newdate = date_time_obj + datetime.timedelta(days=ds_sub.time.values[idx])\n",
    "            newdate1 = date_time_obj + datetime.timedelta(days=ds_sub.time.values[idx+1])\n",
    "            midcycdays = newdate1 - newdate\n",
    "            midcycdate = newdate + midcycdays/2\n",
    "            dates += [midcycdate]\n",
    "        # subset data to dhdt diff between orbital cycles of delta_h\n",
    "        dhdt = ds_sub.delta_h[idx+1,:,:]-ds_sub.delta_h[idx,:,:]\n",
    "        # clip ATL15 data to just show (first set crs)\n",
    "        dhdt.rio.write_crs(3031, inplace=True)\n",
    "        dhdt_clip_S09 = dhdt.rio.clip(lake_S09.geometry.values, lake_S09.crs, drop=False, invert=False)\n",
    "        # calculate lake avg. dh/dt and dv/dt time series using published static outlines\n",
    "        avg_lk_dhdt_S09 = np.nanmean(dhdt_clip_S09)\n",
    "        lkavgdhdt_SF18 += [avg_lk_dhdt_S09]\n",
    "        vol_S09 = avg_lk_dhdt_S09*SiegfriedFricker2018_S09outlines_CS2InSAR[SiegfriedFricker2018_S09outlines_CS2InSAR['name'] == lakename_S09]['area (m^2)']\n",
    "        vols_S09 += [vol_S09.values[0]]\n",
    "        # create contours of ice surface elevation height changes to delineate variable lake outlines\n",
    "        contours_fill = []\n",
    "        contours_drain = []   \n",
    "        polys = []\n",
    "        contour = measure.find_contours(dhdt.values, thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_fill += [contour]\n",
    "        contour = measure.find_contours(dhdt.values, -thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_drain += [contour]\n",
    "        # create mapping conversion factor to map array location to polar stereographic x,y\n",
    "        x_conv = (x_max-x_min)/dhdt.shape[1]\n",
    "        y_conv = (y_max-y_min)/dhdt.shape[0]\n",
    "        # plot variable outlines found in this time slice\n",
    "        # make polygons from variable outlines\n",
    "        for i in range(len(contours_fill)): \n",
    "            for j in range(len(contours_fill[i])):\n",
    "                axes[0,0].plot(x_min+contours_fill[i][j][:, 1]*x_conv, y_max-contours_fill[i][j][:, 0]*y_conv, \n",
    "                color=cmap(norm(ds_sub.time.values[idx])), linestyle=(0, (3, 1, 1, 1)), linewidth=1)\n",
    "                if len(contours_fill[i][j][:, 1]) > 2: \n",
    "                    poly = Polygon(list(zip(contours_fill[i][j][:, 1]*x_conv+x_min, y_max-contours_fill[i][j][:, 0]*y_conv))) \n",
    "                    polys += [poly]\n",
    "        for i in range(len(contours_drain)): \n",
    "            for j in range(len(contours_drain[i])):\n",
    "                axes[0,0].plot(x_min+contours_drain[i][j][:, 1]*x_conv, y_max-contours_drain[i][j][:, 0]*y_conv, color=cmap(norm(ds_sub.time.values[idx])), linestyle=(0, (5, 1)), linewidth=1)\n",
    "                if len(contours_drain[i][j][:, 1]) > 2: \n",
    "                    poly = Polygon(list(zip(contours_drain[i][j][:, 1]*x_conv+x_min, y_max-contours_drain[i][j][:, 0]*y_conv))) \n",
    "                    polys += [poly]\n",
    "        # set area to zero each time step\n",
    "        variable_area = 0\n",
    "        # if polygons are present at time step, \n",
    "        if len(polys) > 0: \n",
    "            # clip data to polygons\n",
    "            dhdt_clip = dhdt.rio.clip(polys, drop=False, invert=False)\n",
    "            # then calculate on-lake averages of dh/dt\n",
    "            avg_lk_dhdt = np.nanmean(dhdt_clip)\n",
    "            # occasionally small polygons will completely clip data resulting in nan's for lake avg. dh/dt\n",
    "            # replace with zeros\n",
    "            if math.isnan(avg_lk_dhdt): \n",
    "                avg_lk_dhdt = 0\n",
    "                lkavgdhdt_var += [avg_lk_dhdt]\n",
    "            else:\n",
    "                lkavgdhdt_var += [avg_lk_dhdt]\n",
    "                # and dv/dt\n",
    "            for i in range(len(polys)):\n",
    "                variable_area = variable_area + polys[i].area\n",
    "            vol_var = avg_lk_dhdt*variable_area\n",
    "            vols_var += [vol_var]\n",
    "        else: \n",
    "            variable_area = 0\n",
    "            avg_lk_dhdt = 0\n",
    "            lkavgdhdt_var += [avg_lk_dhdt]\n",
    "            vol_var = avg_lk_dhdt*variable_area\n",
    "            vols_var += [vol_var]\n",
    "    axes[0,0].set(xlim=(x_min, x_max), ylim=(y_min, y_max))\n",
    "    # change polar stereographic m to km\n",
    "    km_scale = 1e3\n",
    "    ticks_x = ticker.FuncFormatter(lambda x, pos: '{0:g}'.format(x/km_scale))\n",
    "    axes[0,0].xaxis.set_major_formatter(ticks_x)\n",
    "    ticks_y = ticker.FuncFormatter(lambda x, pos: '{0:g}'.format(x/km_scale))\n",
    "    axes[0,0].yaxis.set_major_formatter(ticks_y)\n",
    "    # label axes\n",
    "    axes[0,0].set_xlabel('x [km]', size=15)\n",
    "    axes[0,0].set_ylabel('y [km]', size=15)\n",
    "    # add title and colorbar\n",
    "    # axes[0].set_title('outline comparison', pad=7.5, fontsize=17.5)\n",
    "    m = plt.cm.ScalarMappable(cmap=cmap)\n",
    "    m.set_array(np.array([datetime2fracyear(date_idx) for date_idx in dates[0:-1]]))\n",
    "    divider = make_axes_locatable(axes[0,0])\n",
    "    cax = divider.append_axes('bottom', size='2.5%', pad=0.7)\n",
    "    clb = fig.colorbar(m, cax=cax, orientation='horizontal').set_label('Year', size=15)\n",
    "    # overlay published outlines for visual comparison \n",
    "    Smith2009_outlines.boundary.plot(ax=axes[0,0], color='darkturquoise', linestyle=(0, (1, 5)), linewidth=1)\n",
    "    SiegfriedFricker2018_SF18outlines.boundary.plot(ax=axes[0,0], color='darkturquoise', linestyle=(0, (1, 1)), linewidth=1)\n",
    "    # create lines for legends\n",
    "    Smith2009 = plt.Line2D((0, 1), (0, 0), color='darkturquoise', linestyle=(0, (1, 5)), linewidth=2)\n",
    "    SiegfriedFricker2018 = plt.Line2D((0, 1), (0, 0), color='darkturquoise', linestyle=(0, (1, 1)), linewidth=2)\n",
    "    uplift = plt.Line2D((0, 1), (0, 0), color='k', linestyle=(0, (3, 1, 1, 1)), linewidth=2)\n",
    "    subsidence = plt.Line2D((0, 1), (0, 0), color='k', linestyle=(0, (5, 1)), linewidth=1)\n",
    "    variable_outlines = plt.Line2D((0, 1), (0, 0), color='k', linestyle='dashdot', linewidth=2)\n",
    "    axes[0,0].legend([Smith2009,\n",
    "        #SiegfriedFricker2018,\n",
    "        uplift, subsidence],\n",
    "        ['Smith and others, 2009 static outline',\n",
    "        #'Siegfried & Fricker, 2018 static outline',\n",
    "        ('+'+str(thres)+' m uplift (filling) variable outline'), '–'+str(thres)+' m subsidence (draining) variable outline'], \n",
    "        loc='upper right')\n",
    "    # plot inset map to show location \n",
    "    axIns = axes[0,0].inset_axes([0.005, -0.03, 0.3, 0.3])\n",
    "    axIns.patch.set_facecolor('lightskyblue')\n",
    "    axIns.set_aspect('equal')\n",
    "    axIns.scatter(((x_max+x_min)/2), ((y_max+y_min)/2), marker='*', \n",
    "        linewidth=1, edgecolor='k', facecolor='r', s=100, zorder=3)\n",
    "    Scripps_gl.plot(ax=axIns, color='ghostwhite', edgecolor='k', linewidth=0.5, zorder=2)\n",
    "    axIns.axis('off')\n",
    "    # plot dv subplot\n",
    "    axes[0,1].plot(dates[:idx+1], np.divide(np.cumsum(vols_S09[:idx+1]), 1e+9), color='darkturquoise', linestyle=(0, (1, 5)))\n",
    "    axes[0,1].plot(dates[:idx+1], np.divide(np.cumsum(vols_var[:idx+1]), 1e+9), color='k', linestyle='dashdot')\n",
    "    locator = mdates.AutoDateLocator(minticks=1, maxticks=7)\n",
    "    formatter = mdates.ConciseDateFormatter(locator)\n",
    "    axes[0,1].xaxis.set_major_locator(locator)\n",
    "    axes[0,1].xaxis.set_major_formatter(formatter)\n",
    "    axes[0,1].set_xlabel('Year', size=15)\n",
    "    axes[0,1].set_ylabel('Volume change [km$^3$]', size=15)\n",
    "    axes[0,1].yaxis.tick_right()\n",
    "    axes[0,1].yaxis.set_label_position(\"right\")\n",
    "    axes[0,1].legend([Smith2009,\n",
    "        #SiegfriedFricker2018,\n",
    "        variable_outlines],\n",
    "        ['Smith and others, 2009 static outline',\n",
    "        #'Siegfried & Fricker, 2018 static outline',\n",
    "        '±{} m variable outlines'.format(thres)], \n",
    "                    loc='upper right')\n",
    "\n",
    "    # subset ATL15 data set to region of interest\n",
    "    mask_x = (dataset2.x >= x_min) & (dataset2.x <= x_max)\n",
    "    mask_y = (dataset2.y >= y_min) & (dataset2.y <= y_max)\n",
    "    ds_sub = dataset2.where(mask_x & mask_y, drop=True)\n",
    "    # find magnitude of ice surface deformation in bounding box / find appropriate color map scale\n",
    "    height_anom_pos = []\n",
    "    height_anom_neg = []\n",
    "    for cyc in range(len(ds_sub.time)-1):\n",
    "        pos = np.nanmax(ds_sub.delta_h[cyc+1,:,:]-ds_sub.delta_h[cyc,:,:])\n",
    "        neg = np.nanmin(ds_sub.delta_h[cyc+1,:,:]-ds_sub.delta_h[cyc,:,:])\n",
    "        height_anom_pos += [pos]\n",
    "        height_anom_neg += [neg]\n",
    "    max_height_anom_pos = max(height_anom_pos)\n",
    "    max_height_anom_neg = min(height_anom_neg)\n",
    "    max_height_anom_abs = max(max_height_anom_pos,abs(max_height_anom_neg))\n",
    "    v = np.round(max_height_anom_abs)\n",
    "    # create empty lists to store data\n",
    "    dates = []\n",
    "    lkavgdhdt_S09 = []\n",
    "    lkavgdhdt_var = []\n",
    "    vols_S09 = []\n",
    "    vols_var = []\n",
    "    # plot figure\n",
    "    norm = plt.Normalize(ds_sub.time.values[0],ds_sub.time.values[-1])    \n",
    "    for idx in range(len(ds_sub.time)-1): \n",
    "        dhdt = ds_sub.delta_h[idx+1,:,:]-ds_sub.delta_h[idx,:,:]\n",
    "        # calculate mid-cycle dates for plotting\n",
    "        if dataset2.fileName == 'mos_2010.5_2021.5.h5':\n",
    "            newdate = datetime.datetime(int(ds_sub.time.values[idx]), 1, 1) + datetime.timedelta(days = (ds_sub.time.values[idx] % 1) * 365.25)\n",
    "            newdate1 = datetime.datetime(int(ds_sub.time.values[idx+1]), 1, 1) + datetime.timedelta(days = (ds_sub.time.values[idx+1] % 1) * 365.25)\n",
    "            midcycdays = newdate1 - newdate\n",
    "            midcycdate = newdate + midcycdays/2\n",
    "            dates += [midcycdate]\n",
    "        elif dataset2.fileName == 'ATL15_AA_0311_01km_001_01.nc':    \n",
    "            date_time_str = '18-01-01'\n",
    "            date_time_obj = datetime.datetime.strptime(date_time_str, '%y-%m-%d')\n",
    "            newdate = date_time_obj + datetime.timedelta(days=ds_sub.time.values[idx])\n",
    "            newdate1 = date_time_obj + datetime.timedelta(days=ds_sub.time.values[idx+1])\n",
    "            midcycdays = newdate1 - newdate\n",
    "            midcycdate = newdate + midcycdays/2\n",
    "            dates += [midcycdate]\n",
    "        # subset data to dhdt diff between orbital cycles of delta_h\n",
    "        dhdt = ds_sub.delta_h[idx+1,:,:]-ds_sub.delta_h[idx,:,:]\n",
    "        # clip data to lake area (first set crs)\n",
    "        dhdt.rio.write_crs(3031, inplace=True)\n",
    "        dhdt_clip_S09 = dhdt.rio.clip(lake_S09.geometry.values, lake_S09.crs, drop=False, invert=False)\n",
    "        # calculate lake avg. dh/dt and dv/dt time series using published static outlines\n",
    "        avg_lk_dhdt_S09 = np.nanmean(dhdt_clip_S09)\n",
    "        lkavgdhdt_S09 += [avg_lk_dhdt_S09]\n",
    "        vol_S09 = avg_lk_dhdt_S09*SiegfriedFricker2018_S09outlines_CS2InSAR[SiegfriedFricker2018_S09outlines_CS2InSAR['name'] == lakename_S09]['area (m^2)']\n",
    "        vols_S09 += [vol_S09.values[0]]\n",
    "        # create contours of ice surface elevation height changes to delineate variable lake outlines\n",
    "        contours_fill = []\n",
    "        contours_drain = []   \n",
    "        polys = []\n",
    "        contour = measure.find_contours(dhdt.values, thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_fill += [contour]\n",
    "        contour = measure.find_contours(dhdt.values, -thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_drain += [contour]\n",
    "        # create mapping conversion factor to map array location to polar stereographic x,y\n",
    "        x_conv = (x_max-x_min)/dhdt.shape[1]\n",
    "        y_conv = (y_max-y_min)/dhdt.shape[0]\n",
    "        # plot variable outlines found in this time slice\n",
    "        # make polygons from variable outlines\n",
    "        for i in range(len(contours_fill)): \n",
    "            for j in range(len(contours_fill[i])):\n",
    "                axes[1,0].plot(x_min+contours_fill[i][j][:, 1]*x_conv, y_max-contours_fill[i][j][:, 0]*y_conv, \n",
    "                color=cmap(norm(ds_sub.time.values[idx])), linestyle=(0, (3, 1, 1, 1)), linewidth=1)\n",
    "                if len(contours_fill[i][j][:, 1]) > 2: \n",
    "                    poly = Polygon(list(zip(contours_fill[i][j][:, 1]*x_conv+x_min, y_max-contours_fill[i][j][:, 0]*y_conv))) \n",
    "                    polys += [poly]\n",
    "        for i in range(len(contours_drain)): \n",
    "            for j in range(len(contours_drain[i])):\n",
    "                axes[1,0].plot(x_min+contours_drain[i][j][:, 1]*x_conv, y_max-contours_drain[i][j][:, 0]*y_conv, color=cmap(norm(ds_sub.time.values[idx])), linestyle=(0, (5, 1)), linewidth=1)\n",
    "                if len(contours_drain[i][j][:, 1]) > 2: \n",
    "                    poly = Polygon(list(zip(contours_drain[i][j][:, 1]*x_conv+x_min, y_max-contours_drain[i][j][:, 0]*y_conv))) \n",
    "                    polys += [poly]\n",
    "        # set area to zero each time step\n",
    "        variable_area = 0\n",
    "        # if polygons are present at time step, \n",
    "        if len(polys) > 0: \n",
    "            # clip data to polygons\n",
    "            dhdt_clip = dhdt.rio.clip(polys, drop=False, invert=False)\n",
    "            # then calculate on-lake averages of dh/dt\n",
    "            avg_lk_dhdt = np.nanmean(dhdt_clip)\n",
    "            # occasionally small polygons will completely clip data resulting in nan's for lake avg. dh/dt\n",
    "            # replace with zeros\n",
    "            if math.isnan(avg_lk_dhdt): \n",
    "                avg_lk_dhdt = 0\n",
    "                lkavgdhdt_var += [avg_lk_dhdt]\n",
    "            else:\n",
    "                lkavgdhdt_var += [avg_lk_dhdt]\n",
    "                # and dv/dt\n",
    "            for i in range(len(polys)):\n",
    "                variable_area = variable_area + polys[i].area\n",
    "            vol_var = avg_lk_dhdt*variable_area\n",
    "            vols_var += [vol_var]\n",
    "        else: \n",
    "            variable_area = 0\n",
    "            avg_lk_dhdt = 0\n",
    "            lkavgdhdt_var += [avg_lk_dhdt]\n",
    "            vol_var = avg_lk_dhdt*variable_area\n",
    "            vols_var += [vol_var]\n",
    "    axes[1,0].set(xlim=(x_min, x_max), ylim=(y_min, y_max))\n",
    "    # change polar stereographic m to km\n",
    "    km_scale = 1e3\n",
    "    ticks_x = ticker.FuncFormatter(lambda x, pos: '{0:g}'.format(x/km_scale))\n",
    "    axes[1,0].xaxis.set_major_formatter(ticks_x)\n",
    "    ticks_y = ticker.FuncFormatter(lambda x, pos: '{0:g}'.format(x/km_scale))\n",
    "    axes[1,0].yaxis.set_major_formatter(ticks_y)  \n",
    "    # label axes\n",
    "    axes[1,0].set_xlabel('x [km]', size=15)\n",
    "    axes[1,0].set_ylabel('y [km]', size=15)\n",
    "    # add colorbar\n",
    "    m = plt.cm.ScalarMappable(cmap=cmap)\n",
    "    m.set_array(np.array([datetime2fracyear(date_idx) for date_idx in dates[0:-1]]))\n",
    "    divider = make_axes_locatable(axes[1,0])\n",
    "    cax = divider.append_axes('bottom', size='2.5%', pad=0.7)\n",
    "    clb = fig.colorbar(m,  cax=cax, orientation='horizontal', ticks=np.array([2019,2020,2021])).set_label('Year', size=15)\n",
    "    # overlay published outlines for visual comparison \n",
    "    Smith2009_outlines.boundary.plot(ax=axes[1,0], color='darkturquoise', linestyle=(0, (1, 5)), linewidth=1)\n",
    "    SiegfriedFricker2018_SF18outlines.boundary.plot(ax=axes[1,0], color='darkturquoise', linestyle=(0, (1, 1)), linewidth=1)\n",
    "    axes[1,0].legend([Smith2009, \n",
    "        # SiegfriedFricker2018, \n",
    "        uplift, subsidence],\n",
    "        ['Smith and others, 2009 static outline',\n",
    "        # 'Siegfried & Fricker, 2018 static outline',\n",
    "        ('+'+str(thres)+' m uplift (filling) variable outline'), '–'+str(thres)+' m subsidence (draining) variable outline'], \n",
    "        loc='upper right')\n",
    "    # plot inset map to show location \n",
    "    axIns = axes[1,0].inset_axes([0.005, -0.03, 0.3, 0.3])\n",
    "    axIns.patch.set_facecolor('lightskyblue')\n",
    "    axIns.set_aspect('equal')\n",
    "    axIns.scatter(((x_max+x_min)/2), ((y_max+y_min)/2), marker='*', \n",
    "        linewidth=1, edgecolor='k', facecolor='r', s=100, zorder=3)\n",
    "    Scripps_gl.plot(ax=axIns, color='ghostwhite', edgecolor='k', linewidth=0.5, zorder=2)\n",
    "    axIns.axis('off')\n",
    "    # plot dvdt subplot\n",
    "    axes[1,1].plot(dates[:idx+1], np.divide(np.cumsum(vols_S09[:idx+1]), 1e+9), color='darkturquoise', linestyle=(0, (1, 5)))\n",
    "    axes[1,1].plot(dates[:idx+1], np.divide(np.cumsum(vols_var[:idx+1]), 1e+9), color='k', linestyle='dashdot')\n",
    "    locator = mdates.AutoDateLocator(minticks=1, maxticks=7)\n",
    "    formatter = mdates.ConciseDateFormatter(locator)\n",
    "    axes[1,1].xaxis.set_major_locator(locator)\n",
    "    axes[1,1].xaxis.set_major_formatter(formatter)\n",
    "    min_vol = min(np.divide(min(np.cumsum(vols_S09)), 1e+9), \n",
    "                    np.divide(min(np.cumsum(vols_var)), 1e+9))\n",
    "    max_vol = max(np.divide(max(np.cumsum(vols_S09)), 1e+9), \n",
    "                    np.divide(max(np.cumsum(vols_var)), 1e+9))\n",
    "    if dataset2.fileName == 'mos_2010.5_2021.5.h5':\n",
    "        axes[1,1].set(xlim=(datetime.datetime(int(ds_sub.time.values[0]), 1, 1) + datetime.timedelta(days = (ds_sub.time.values[0] % 1) * 365.25), \n",
    "                            datetime.datetime(int(ds_sub.time.values[-1]), 1, 1) + datetime.timedelta(days = (ds_sub.time.values[-1] % 1) * 365.25)), \n",
    "                    ylim=((min_vol - (max_vol - min_vol)*0.05),\n",
    "                            (max_vol + (max_vol - min_vol)*0.05)))\n",
    "    elif dataset2.fileName == 'ATL15_AA_0311_01km_001_01.nc':    \n",
    "        axes[1,1].set(xlim=(date_time_obj + datetime.timedelta(days=ds_sub.time.values[1]),\n",
    "                            date_time_obj + datetime.timedelta(days=ds_sub.time.values[-1])), \n",
    "                    ylim=((min_vol - (max_vol - min_vol)*0.05), \n",
    "                            (max_vol + (max_vol - min_vol)*0.05)))\n",
    "    axes[1,1].set_xlabel('Year', size=15)\n",
    "    axes[1,1].set_ylabel('Volume change [km$^3$]', size=15)\n",
    "    axes[1,1].yaxis.tick_right()\n",
    "    axes[1,1].yaxis.set_label_position(\"right\")\n",
    "    axes[1,1].legend([Smith2009,\n",
    "        # SiegfriedFricker2018,\n",
    "        variable_outlines],\n",
    "                    ['Smith and others, 2009 static outline',\n",
    "        # 'Siegfried & Fricker, 2018 static outline',\n",
    "        '±{} m variable outlines'.format(thres)], \n",
    "                    loc='upper right')\n",
    "    # save and close figure\n",
    "    plt.savefig('/Users/Wilson/Documents/0-code/1-lakeshores/output_dhdvdt-using-variable-outlines/S09SF18varoutlines_agg_dvdt_plot/S09SF18varoutlines_agg_dvdt_plot-{}.png'\\\n",
    "        .format(lakename_S09), dpi=300, bbox_inches = \"tight\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experimenting for lakes that are defined by a centroid\n",
    "# modified 2x2 to plot CS2 and IS2 on same plot; for S09 defined lakes\n",
    "# use on SiegfriedFricker2018_S09outlines_CS2InSAR\n",
    "def S09SF18varoutlines_agg_dvdt_plot(lakename, buffer, thres, dataset1, dataset2): \n",
    "    '''\n",
    "    Create planview plot of an aggregated times series of variable outlines compared to known lakes alongside dv/dt time series. Uses geopandas buffer created bounding box around known lakes in Siegfried and Fricker, 2018 (SF18) inventory. Creates time-variable outlines using skimage contour to plot variable outline alongside published outlines for comparison. \n",
    "    Inputs: \n",
    "        lakename_SF18: lake of interest from SiegfriedFricker2018_outlines inventory\n",
    "        buffer: horizontal distance in meters away from SF18 lake outline used to create bounding box that is displayed around lake of interest\n",
    "        thres(hold): vertical distance in meters to delineate ice surface deformation contour\n",
    "        dataset: dataset to be analyzed (CS2_dh or ATL15_dh)\n",
    "    Outputs: \n",
    "        Aggregated time-variable lake outlines in regions of known lakes using CryoSat-2 or ICESat-2 ATL15 dh/dt data alongside dVol time series.\n",
    "    '''\n",
    "    # isolate individual lake using gpd buffer\n",
    "    lake = SiegfriedFricker2018_outlines.loc[SiegfriedFricker2018_outlines['name'] == lakename]\n",
    "    lake_buffer = lake.buffer(buffer)\n",
    "    # define lake bounding box\n",
    "    x_min = lake_buffer.bounds.values[0,0]; x_max = lake_buffer.bounds.values[0,2]\n",
    "    y_min = lake_buffer.bounds.values[0,1]; y_max = lake_buffer.bounds.values[0,3]\n",
    "    # subset ATL15 data set to region of interest\n",
    "    mask_x = (dataset1.x >= x_min) & (dataset1.x <= x_max)\n",
    "    mask_y = (dataset1.y >= y_min) & (dataset1.y <= y_max)\n",
    "    ds_sub = dataset1.where(mask_x & mask_y, drop=True)\n",
    "    # find magnitude of ice surface deformation in bounding box / find appropriate color map scale\n",
    "    height_anom_pos = []\n",
    "    height_anom_neg = []\n",
    "    for cyc in range(len(ds_sub.time)-1):\n",
    "        pos = np.nanmax(ds_sub.delta_h[cyc+1,:,:]-ds_sub.delta_h[cyc,:,:])\n",
    "        neg = np.nanmin(ds_sub.delta_h[cyc+1,:,:]-ds_sub.delta_h[cyc,:,:])\n",
    "        height_anom_pos += [pos]\n",
    "        height_anom_neg += [neg]\n",
    "    max_height_anom_pos = max(height_anom_pos)\n",
    "    max_height_anom_neg = min(height_anom_neg)\n",
    "    max_height_anom_abs = max(max_height_anom_pos,abs(max_height_anom_neg))\n",
    "    v = np.round(max_height_anom_abs)\n",
    "    # create empty lists to store data\n",
    "    dates = []\n",
    "    lkavgdhdt_SF18 = []\n",
    "    lkavgdhdt_var = []\n",
    "    vols_S09 = []\n",
    "    vols_var = []\n",
    "    # plot figure\n",
    "    fig, axes = plt.subplots(2,2, figsize=(20,20))\n",
    "    # plt.subplots_adjust(wspace=0.15, hspace = 0.1)\n",
    "    cmap = plt.get_cmap('CMRmap')\n",
    "    norm = plt.Normalize(ds_sub.time.values[0],ds_sub.time.values[-1])    \n",
    "    for idx in range(len(ds_sub.time)-1): \n",
    "        dhdt = ds_sub.delta_h[idx+1,:,:]-ds_sub.delta_h[idx,:,:]\n",
    "        # calculate mid-cycle dates for plotting\n",
    "        if dataset1.fileName == 'mos_2010.5_2021.5.h5':\n",
    "            newdate = datetime.datetime(int(ds_sub.time.values[idx]), 1, 1) + datetime.timedelta(days = (ds_sub.time.values[idx] % 1) * 365.25)\n",
    "            newdate1 = datetime.datetime(int(ds_sub.time.values[idx+1]), 1, 1) + datetime.timedelta(days = (ds_sub.time.values[idx+1] % 1) * 365.25)\n",
    "            midcycdays = newdate1 - newdate\n",
    "            midcycdate = newdate + midcycdays/2\n",
    "            dates += [midcycdate]\n",
    "        elif dataset1.fileName == 'ATL15_AA_0311_01km_001_01.nc':    \n",
    "            date_time_str = '18-01-01'\n",
    "            date_time_obj = datetime.datetime.strptime(date_time_str, '%y-%m-%d')\n",
    "            newdate = date_time_obj + datetime.timedelta(days=ds_sub.time.values[idx])\n",
    "            newdate1 = date_time_obj + datetime.timedelta(days=ds_sub.time.values[idx+1])\n",
    "            midcycdays = newdate1 - newdate\n",
    "            midcycdate = newdate + midcycdays/2\n",
    "            dates += [midcycdate]\n",
    "        # subset data to dhdt diff between orbital cycles of delta_h\n",
    "        dhdt = ds_sub.delta_h[idx+1,:,:]-ds_sub.delta_h[idx,:,:]\n",
    "        # clip ATL15 data to just show (first set crs)\n",
    "        dhdt.rio.write_crs(3031, inplace=True)\n",
    "        dhdt_clip_S09 = dhdt.rio.clip(lake_S09.geometry.values, lake_S09.crs, drop=False, invert=False)\n",
    "        # calculate lake avg. dh/dt and dv/dt time series using published static outlines\n",
    "        avg_lk_dhdt_S09 = np.nanmean(dhdt_clip_S09)\n",
    "        lkavgdhdt_SF18 += [avg_lk_dhdt_S09]\n",
    "        vol_S09 = avg_lk_dhdt_S09*SiegfriedFricker2018_S09outlines_CS2InSAR[SiegfriedFricker2018_S09outlines_CS2InSAR['name'] == lakename_S09]['area (m^2)']\n",
    "        vols_S09 += [vol_S09.values[0]]\n",
    "        # create contours of ice surface elevation height changes to delineate variable lake outlines\n",
    "        contours_fill = []\n",
    "        contours_drain = []   \n",
    "        polys = []\n",
    "        contour = measure.find_contours(dhdt.values, thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_fill += [contour]\n",
    "        contour = measure.find_contours(dhdt.values, -thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_drain += [contour]\n",
    "        # create mapping conversion factor to map array location to polar stereographic x,y\n",
    "        x_conv = (x_max-x_min)/dhdt.shape[1]\n",
    "        y_conv = (y_max-y_min)/dhdt.shape[0]\n",
    "        # plot variable outlines found in this time slice\n",
    "        # make polygons from variable outlines\n",
    "        for i in range(len(contours_fill)): \n",
    "            for j in range(len(contours_fill[i])):\n",
    "                axes[0,0].plot(x_min+contours_fill[i][j][:, 1]*x_conv, y_max-contours_fill[i][j][:, 0]*y_conv, \n",
    "                color=cmap(norm(ds_sub.time.values[idx])), linestyle=(0, (3, 1, 1, 1)), linewidth=1)\n",
    "                if len(contours_fill[i][j][:, 1]) > 2: \n",
    "                    poly = Polygon(list(zip(contours_fill[i][j][:, 1]*x_conv+x_min, y_max-contours_fill[i][j][:, 0]*y_conv))) \n",
    "                    polys += [poly]\n",
    "        for i in range(len(contours_drain)): \n",
    "            for j in range(len(contours_drain[i])):\n",
    "                axes[0,0].plot(x_min+contours_drain[i][j][:, 1]*x_conv, y_max-contours_drain[i][j][:, 0]*y_conv, color=cmap(norm(ds_sub.time.values[idx])), linestyle=(0, (5, 1)), linewidth=1)\n",
    "                if len(contours_drain[i][j][:, 1]) > 2: \n",
    "                    poly = Polygon(list(zip(contours_drain[i][j][:, 1]*x_conv+x_min, y_max-contours_drain[i][j][:, 0]*y_conv))) \n",
    "                    polys += [poly]\n",
    "        # set area to zero each time step\n",
    "        variable_area = 0\n",
    "        # if polygons are present at time step, \n",
    "        if len(polys) > 0: \n",
    "            # clip data to polygons\n",
    "            dhdt_clip = dhdt.rio.clip(polys, drop=False, invert=False)\n",
    "            # then calculate on-lake averages of dh/dt\n",
    "            avg_lk_dhdt = np.nanmean(dhdt_clip)\n",
    "            # occasionally small polygons will completely clip data resulting in nan's for lake avg. dh/dt\n",
    "            # replace with zeros\n",
    "            if math.isnan(avg_lk_dhdt): \n",
    "                avg_lk_dhdt = 0\n",
    "                lkavgdhdt_var += [avg_lk_dhdt]\n",
    "            else:\n",
    "                lkavgdhdt_var += [avg_lk_dhdt]\n",
    "                # and dv/dt\n",
    "            for i in range(len(polys)):\n",
    "                variable_area = variable_area + polys[i].area\n",
    "            vol_var = avg_lk_dhdt*variable_area\n",
    "            vols_var += [vol_var]\n",
    "        else: \n",
    "            variable_area = 0\n",
    "            avg_lk_dhdt = 0\n",
    "            lkavgdhdt_var += [avg_lk_dhdt]\n",
    "            vol_var = avg_lk_dhdt*variable_area\n",
    "            vols_var += [vol_var]\n",
    "    axes[0,0].set(xlim=(x_min, x_max), ylim=(y_min, y_max))\n",
    "    # change polar stereographic m to km\n",
    "    km_scale = 1e3\n",
    "    ticks_x = ticker.FuncFormatter(lambda x, pos: '{0:g}'.format(x/km_scale))\n",
    "    axes[0,0].xaxis.set_major_formatter(ticks_x)\n",
    "    ticks_y = ticker.FuncFormatter(lambda x, pos: '{0:g}'.format(x/km_scale))\n",
    "    axes[0,0].yaxis.set_major_formatter(ticks_y)\n",
    "    # label axes\n",
    "    axes[0,0].set_xlabel('x [km]', size=15)\n",
    "    axes[0,0].set_ylabel('y [km]', size=15)\n",
    "    # add title and colorbar\n",
    "    # axes[0].set_title('outline comparison', pad=7.5, fontsize=17.5)\n",
    "    m = plt.cm.ScalarMappable(cmap=cmap)\n",
    "    m.set_array(np.array([datetime2fracyear(date_idx) for date_idx in dates[0:-1]]))\n",
    "    divider = make_axes_locatable(axes[0,0])\n",
    "    cax = divider.append_axes('bottom', size='2.5%', pad=0.7)\n",
    "    clb = fig.colorbar(m, cax=cax, orientation='horizontal').set_label('Year', size=15)\n",
    "    # overlay published outlines for visual comparison \n",
    "    Smith2009_outlines.boundary.plot(ax=axes[0,0], color='darkturquoise', linestyle=(0, (1, 5)), linewidth=1)\n",
    "    SiegfriedFricker2018_SF18outlines.boundary.plot(ax=axes[0,0], color='darkturquoise', linestyle=(0, (1, 1)), linewidth=1)\n",
    "    # create lines for legends\n",
    "    Smith2009 = plt.Line2D((0, 1), (0, 0), color='darkturquoise', linestyle=(0, (1, 5)), linewidth=2)\n",
    "    SiegfriedFricker2018 = plt.Line2D((0, 1), (0, 0), color='darkturquoise', linestyle=(0, (1, 1)), linewidth=2)\n",
    "    uplift = plt.Line2D((0, 1), (0, 0), color='k', linestyle=(0, (3, 1, 1, 1)), linewidth=2)\n",
    "    subsidence = plt.Line2D((0, 1), (0, 0), color='k', linestyle=(0, (5, 1)), linewidth=1)\n",
    "    variable_outlines = plt.Line2D((0, 1), (0, 0), color='k', linestyle='dashdot', linewidth=2)\n",
    "    axes[0,0].legend([Smith2009,\n",
    "        #SiegfriedFricker2018,\n",
    "        uplift, subsidence],\n",
    "        ['Smith and others, 2009 static outline',\n",
    "        #'Siegfried & Fricker, 2018 static outline',\n",
    "        ('+'+str(thres)+' m uplift (filling) variable outline'), '–'+str(thres)+' m subsidence (draining) variable outline'], \n",
    "        loc='upper right')\n",
    "    # plot inset map to show location \n",
    "    axIns = axes[0,0].inset_axes([0.005, -0.03, 0.3, 0.3])\n",
    "    axIns.patch.set_facecolor('lightskyblue')\n",
    "    axIns.set_aspect('equal')\n",
    "    axIns.scatter(((x_max+x_min)/2), ((y_max+y_min)/2), marker='*', \n",
    "        linewidth=1, edgecolor='k', facecolor='r', s=100, zorder=3)\n",
    "    Scripps_gl.plot(ax=axIns, color='ghostwhite', edgecolor='k', linewidth=0.5, zorder=2)\n",
    "    axIns.axis('off')\n",
    "    # plot dv subplot\n",
    "    axes[0,1].plot(dates[:idx+1], np.divide(np.cumsum(vols_S09[:idx+1]), 1e+9), color='darkturquoise', linestyle=(0, (1, 5)))\n",
    "    axes[0,1].plot(dates[:idx+1], np.divide(np.cumsum(vols_var[:idx+1]), 1e+9), color='k', linestyle='dashdot')\n",
    "    locator = mdates.AutoDateLocator(minticks=1, maxticks=7)\n",
    "    formatter = mdates.ConciseDateFormatter(locator)\n",
    "    axes[0,1].xaxis.set_major_locator(locator)\n",
    "    axes[0,1].xaxis.set_major_formatter(formatter)\n",
    "    axes[0,1].set_xlabel('Year', size=15)\n",
    "    axes[0,1].set_ylabel('Volume change [km$^3$]', size=15)\n",
    "    axes[0,1].yaxis.tick_right()\n",
    "    axes[0,1].yaxis.set_label_position(\"right\")\n",
    "    axes[0,1].legend([Smith2009,\n",
    "        #SiegfriedFricker2018,\n",
    "        variable_outlines],\n",
    "        ['Smith and others, 2009 static outline',\n",
    "        #'Siegfried & Fricker, 2018 static outline',\n",
    "        '±{} m variable outlines'.format(thres)], \n",
    "                    loc='upper right')\n",
    "\n",
    "    # subset ATL15 data set to region of interest\n",
    "    mask_x = (dataset2.x >= x_min) & (dataset2.x <= x_max)\n",
    "    mask_y = (dataset2.y >= y_min) & (dataset2.y <= y_max)\n",
    "    ds_sub = dataset2.where(mask_x & mask_y, drop=True)\n",
    "    # find magnitude of ice surface deformation in bounding box / find appropriate color map scale\n",
    "    height_anom_pos = []\n",
    "    height_anom_neg = []\n",
    "    for cyc in range(len(ds_sub.time)-1):\n",
    "        pos = np.nanmax(ds_sub.delta_h[cyc+1,:,:]-ds_sub.delta_h[cyc,:,:])\n",
    "        neg = np.nanmin(ds_sub.delta_h[cyc+1,:,:]-ds_sub.delta_h[cyc,:,:])\n",
    "        height_anom_pos += [pos]\n",
    "        height_anom_neg += [neg]\n",
    "    max_height_anom_pos = max(height_anom_pos)\n",
    "    max_height_anom_neg = min(height_anom_neg)\n",
    "    max_height_anom_abs = max(max_height_anom_pos,abs(max_height_anom_neg))\n",
    "    v = np.round(max_height_anom_abs)\n",
    "    # create empty lists to store data\n",
    "    dates = []\n",
    "    lkavgdhdt_S09 = []\n",
    "    lkavgdhdt_var = []\n",
    "    vols_S09 = []\n",
    "    vols_var = []\n",
    "    # plot figure\n",
    "    norm = plt.Normalize(ds_sub.time.values[0],ds_sub.time.values[-1])    \n",
    "    for idx in range(len(ds_sub.time)-1): \n",
    "        dhdt = ds_sub.delta_h[idx+1,:,:]-ds_sub.delta_h[idx,:,:]\n",
    "        # calculate mid-cycle dates for plotting\n",
    "        if dataset2.fileName == 'mos_2010.5_2021.5.h5':\n",
    "            newdate = datetime.datetime(int(ds_sub.time.values[idx]), 1, 1) + datetime.timedelta(days = (ds_sub.time.values[idx] % 1) * 365.25)\n",
    "            newdate1 = datetime.datetime(int(ds_sub.time.values[idx+1]), 1, 1) + datetime.timedelta(days = (ds_sub.time.values[idx+1] % 1) * 365.25)\n",
    "            midcycdays = newdate1 - newdate\n",
    "            midcycdate = newdate + midcycdays/2\n",
    "            dates += [midcycdate]\n",
    "        elif dataset2.fileName == 'ATL15_AA_0311_01km_001_01.nc':    \n",
    "            date_time_str = '18-01-01'\n",
    "            date_time_obj = datetime.datetime.strptime(date_time_str, '%y-%m-%d')\n",
    "            newdate = date_time_obj + datetime.timedelta(days=ds_sub.time.values[idx])\n",
    "            newdate1 = date_time_obj + datetime.timedelta(days=ds_sub.time.values[idx+1])\n",
    "            midcycdays = newdate1 - newdate\n",
    "            midcycdate = newdate + midcycdays/2\n",
    "            dates += [midcycdate]\n",
    "        # subset data to dhdt diff between orbital cycles of delta_h\n",
    "        dhdt = ds_sub.delta_h[idx+1,:,:]-ds_sub.delta_h[idx,:,:]\n",
    "        # clip data to lake area (first set crs)\n",
    "        dhdt.rio.write_crs(3031, inplace=True)\n",
    "        dhdt_clip_S09 = dhdt.rio.clip(lake_S09.geometry.values, lake_S09.crs, drop=False, invert=False)\n",
    "        # calculate lake avg. dh/dt and dv/dt time series using published static outlines\n",
    "        avg_lk_dhdt_S09 = np.nanmean(dhdt_clip_S09)\n",
    "        lkavgdhdt_S09 += [avg_lk_dhdt_S09]\n",
    "        vol_S09 = avg_lk_dhdt_S09*SiegfriedFricker2018_S09outlines_CS2InSAR[SiegfriedFricker2018_S09outlines_CS2InSAR['name'] == lakename_S09]['area (m^2)']\n",
    "        vols_S09 += [vol_S09.values[0]]\n",
    "        # create contours of ice surface elevation height changes to delineate variable lake outlines\n",
    "        contours_fill = []\n",
    "        contours_drain = []   \n",
    "        polys = []\n",
    "        contour = measure.find_contours(dhdt.values, thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_fill += [contour]\n",
    "        contour = measure.find_contours(dhdt.values, -thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_drain += [contour]\n",
    "        # create mapping conversion factor to map array location to polar stereographic x,y\n",
    "        x_conv = (x_max-x_min)/dhdt.shape[1]\n",
    "        y_conv = (y_max-y_min)/dhdt.shape[0]\n",
    "        # plot variable outlines found in this time slice\n",
    "        # make polygons from variable outlines\n",
    "        for i in range(len(contours_fill)): \n",
    "            for j in range(len(contours_fill[i])):\n",
    "                axes[1,0].plot(x_min+contours_fill[i][j][:, 1]*x_conv, y_max-contours_fill[i][j][:, 0]*y_conv, \n",
    "                color=cmap(norm(ds_sub.time.values[idx])), linestyle=(0, (3, 1, 1, 1)), linewidth=1)\n",
    "                if len(contours_fill[i][j][:, 1]) > 2: \n",
    "                    poly = Polygon(list(zip(contours_fill[i][j][:, 1]*x_conv+x_min, y_max-contours_fill[i][j][:, 0]*y_conv))) \n",
    "                    polys += [poly]\n",
    "        for i in range(len(contours_drain)): \n",
    "            for j in range(len(contours_drain[i])):\n",
    "                axes[1,0].plot(x_min+contours_drain[i][j][:, 1]*x_conv, y_max-contours_drain[i][j][:, 0]*y_conv, color=cmap(norm(ds_sub.time.values[idx])), linestyle=(0, (5, 1)), linewidth=1)\n",
    "                if len(contours_drain[i][j][:, 1]) > 2: \n",
    "                    poly = Polygon(list(zip(contours_drain[i][j][:, 1]*x_conv+x_min, y_max-contours_drain[i][j][:, 0]*y_conv))) \n",
    "                    polys += [poly]\n",
    "        # set area to zero each time step\n",
    "        variable_area = 0\n",
    "        # if polygons are present at time step, \n",
    "        if len(polys) > 0: \n",
    "            # clip data to polygons\n",
    "            dhdt_clip = dhdt.rio.clip(polys, drop=False, invert=False)\n",
    "            # then calculate on-lake averages of dh/dt\n",
    "            avg_lk_dhdt = np.nanmean(dhdt_clip)\n",
    "            # occasionally small polygons will completely clip data resulting in nan's for lake avg. dh/dt\n",
    "            # replace with zeros\n",
    "            if math.isnan(avg_lk_dhdt): \n",
    "                avg_lk_dhdt = 0\n",
    "                lkavgdhdt_var += [avg_lk_dhdt]\n",
    "            else:\n",
    "                lkavgdhdt_var += [avg_lk_dhdt]\n",
    "                # and dv/dt\n",
    "            for i in range(len(polys)):\n",
    "                variable_area = variable_area + polys[i].area\n",
    "            vol_var = avg_lk_dhdt*variable_area\n",
    "            vols_var += [vol_var]\n",
    "        else: \n",
    "            variable_area = 0\n",
    "            avg_lk_dhdt = 0\n",
    "            lkavgdhdt_var += [avg_lk_dhdt]\n",
    "            vol_var = avg_lk_dhdt*variable_area\n",
    "            vols_var += [vol_var]\n",
    "    axes[1,0].set(xlim=(x_min, x_max), ylim=(y_min, y_max))\n",
    "    # change polar stereographic m to km\n",
    "    km_scale = 1e3\n",
    "    ticks_x = ticker.FuncFormatter(lambda x, pos: '{0:g}'.format(x/km_scale))\n",
    "    axes[1,0].xaxis.set_major_formatter(ticks_x)\n",
    "    ticks_y = ticker.FuncFormatter(lambda x, pos: '{0:g}'.format(x/km_scale))\n",
    "    axes[1,0].yaxis.set_major_formatter(ticks_y)  \n",
    "    # label axes\n",
    "    axes[1,0].set_xlabel('x [km]', size=15)\n",
    "    axes[1,0].set_ylabel('y [km]', size=15)\n",
    "    # add colorbar\n",
    "    m = plt.cm.ScalarMappable(cmap=cmap)\n",
    "    m.set_array(np.array([datetime2fracyear(date_idx) for date_idx in dates[0:-1]]))\n",
    "    divider = make_axes_locatable(axes[1,0])\n",
    "    cax = divider.append_axes('bottom', size='2.5%', pad=0.7)\n",
    "    clb = fig.colorbar(m,  cax=cax, orientation='horizontal', ticks=np.array([2019,2020,2021])).set_label('Year', size=15)\n",
    "    # overlay published outlines for visual comparison \n",
    "    Smith2009_outlines.boundary.plot(ax=axes[1,0], color='darkturquoise', linestyle=(0, (1, 5)), linewidth=1)\n",
    "    SiegfriedFricker2018_SF18outlines.boundary.plot(ax=axes[1,0], color='darkturquoise', linestyle=(0, (1, 1)), linewidth=1)\n",
    "    axes[1,0].legend([Smith2009, \n",
    "        # SiegfriedFricker2018, \n",
    "        uplift, subsidence],\n",
    "        ['Smith and others, 2009 static outline',\n",
    "        # 'Siegfried & Fricker, 2018 static outline',\n",
    "        ('+'+str(thres)+' m uplift (filling) variable outline'), '–'+str(thres)+' m subsidence (draining) variable outline'], \n",
    "        loc='upper right')\n",
    "    # plot inset map to show location \n",
    "    axIns = axes[1,0].inset_axes([0.005, -0.03, 0.3, 0.3])\n",
    "    axIns.patch.set_facecolor('lightskyblue')\n",
    "    axIns.set_aspect('equal')\n",
    "    axIns.scatter(((x_max+x_min)/2), ((y_max+y_min)/2), marker='*', \n",
    "        linewidth=1, edgecolor='k', facecolor='r', s=100, zorder=3)\n",
    "    Scripps_gl.plot(ax=axIns, color='ghostwhite', edgecolor='k', linewidth=0.5, zorder=2)\n",
    "    axIns.axis('off')\n",
    "    # plot dvdt subplot\n",
    "    axes[1,1].plot(dates[:idx+1], np.divide(np.cumsum(vols_S09[:idx+1]), 1e+9), color='darkturquoise', linestyle=(0, (1, 5)))\n",
    "    axes[1,1].plot(dates[:idx+1], np.divide(np.cumsum(vols_var[:idx+1]), 1e+9), color='k', linestyle='dashdot')\n",
    "    locator = mdates.AutoDateLocator(minticks=1, maxticks=7)\n",
    "    formatter = mdates.ConciseDateFormatter(locator)\n",
    "    axes[1,1].xaxis.set_major_locator(locator)\n",
    "    axes[1,1].xaxis.set_major_formatter(formatter)\n",
    "    min_vol = min(np.divide(min(np.cumsum(vols_S09)), 1e+9), \n",
    "                    np.divide(min(np.cumsum(vols_var)), 1e+9))\n",
    "    max_vol = max(np.divide(max(np.cumsum(vols_S09)), 1e+9), \n",
    "                    np.divide(max(np.cumsum(vols_var)), 1e+9))\n",
    "    if dataset2.fileName == 'mos_2010.5_2021.5.h5':\n",
    "        axes[1,1].set(xlim=(datetime.datetime(int(ds_sub.time.values[0]), 1, 1) + datetime.timedelta(days = (ds_sub.time.values[0] % 1) * 365.25), \n",
    "                            datetime.datetime(int(ds_sub.time.values[-1]), 1, 1) + datetime.timedelta(days = (ds_sub.time.values[-1] % 1) * 365.25)), \n",
    "                    ylim=((min_vol - (max_vol - min_vol)*0.05),\n",
    "                            (max_vol + (max_vol - min_vol)*0.05)))\n",
    "    elif dataset2.fileName == 'ATL15_AA_0311_01km_001_01.nc':    \n",
    "        axes[1,1].set(xlim=(date_time_obj + datetime.timedelta(days=ds_sub.time.values[1]),\n",
    "                            date_time_obj + datetime.timedelta(days=ds_sub.time.values[-1])), \n",
    "                    ylim=((min_vol - (max_vol - min_vol)*0.05), \n",
    "                            (max_vol + (max_vol - min_vol)*0.05)))\n",
    "    axes[1,1].set_xlabel('Year', size=15)\n",
    "    axes[1,1].set_ylabel('Volume change [km$^3$]', size=15)\n",
    "    axes[1,1].yaxis.tick_right()\n",
    "    axes[1,1].yaxis.set_label_position(\"right\")\n",
    "    axes[1,1].legend([Smith2009,\n",
    "        # SiegfriedFricker2018,\n",
    "        variable_outlines],\n",
    "                    ['Smith and others, 2009 static outline',\n",
    "        # 'Siegfried & Fricker, 2018 static outline',\n",
    "        '±{} m variable outlines'.format(thres)], \n",
    "                    loc='upper right')\n",
    "    # save and close figure\n",
    "    plt.savefig('/Users/Wilson/Documents/0-code/1-lakeshores/output_dhdvdt-using-variable-outlines/S09SF18varoutlines_agg_dvdt_plot/S09SF18varoutlines_agg_dvdt_plot-{}.png'\\\n",
    "        .format(lakename_S09), dpi=300, bbox_inches = \"tight\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'buffer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/Wilson/Documents/0-code/0-contributing/Sauthoff-2023-J.Glaciol./dhdvdt-using-variable-outlines.ipynb Cell 66\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/Wilson/Documents/0-code/0-contributing/Sauthoff-2023-J.Glaciol./dhdvdt-using-variable-outlines.ipynb#Y115sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# test on one lake to ensure working\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/Wilson/Documents/0-code/0-contributing/Sauthoff-2023-J.Glaciol./dhdvdt-using-variable-outlines.ipynb#Y115sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m S09SF18varoutlines_agg_dvdt_plot(\u001b[39m'\u001b[39;49m\u001b[39mlower_Whillans6\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m10000\u001b[39;49m, \u001b[39m0.5\u001b[39;49m, CS2_dh, ATL15_dh)\n",
      "\u001b[1;32m/Users/Wilson/Documents/0-code/0-contributing/Sauthoff-2023-J.Glaciol./dhdvdt-using-variable-outlines.ipynb Cell 66\u001b[0m in \u001b[0;36mS09SF18varoutlines_agg_dvdt_plot\u001b[0;34m(lakename, buffer, thres, dataset1, dataset2)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Wilson/Documents/0-code/0-contributing/Sauthoff-2023-J.Glaciol./dhdvdt-using-variable-outlines.ipynb#Y115sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39m# isolate individual lake using gpd buffer\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Wilson/Documents/0-code/0-contributing/Sauthoff-2023-J.Glaciol./dhdvdt-using-variable-outlines.ipynb#Y115sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m lake \u001b[39m=\u001b[39m SiegfriedFricker2018_outlines\u001b[39m.\u001b[39mloc[SiegfriedFricker2018_outlines[\u001b[39m'\u001b[39m\u001b[39mname\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m lakename]\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/Wilson/Documents/0-code/0-contributing/Sauthoff-2023-J.Glaciol./dhdvdt-using-variable-outlines.ipynb#Y115sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m lake_buffer \u001b[39m=\u001b[39m lake\u001b[39m.\u001b[39;49mbuffer(buffer)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Wilson/Documents/0-code/0-contributing/Sauthoff-2023-J.Glaciol./dhdvdt-using-variable-outlines.ipynb#Y115sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39m# define lake bounding box\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Wilson/Documents/0-code/0-contributing/Sauthoff-2023-J.Glaciol./dhdvdt-using-variable-outlines.ipynb#Y115sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m x_min \u001b[39m=\u001b[39m lake_buffer\u001b[39m.\u001b[39mbounds\u001b[39m.\u001b[39mvalues[\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m]; x_max \u001b[39m=\u001b[39m lake_buffer\u001b[39m.\u001b[39mbounds\u001b[39m.\u001b[39mvalues[\u001b[39m0\u001b[39m,\u001b[39m2\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/lakeshores/lib/python3.10/site-packages/geopandas/base.py:2723\u001b[0m, in \u001b[0;36mGeoPandasBase.buffer\u001b[0;34m(self, distance, resolution, **kwargs)\u001b[0m\n\u001b[1;32m   2717\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   2718\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mIndex values of distance sequence does \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2719\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mnot match index values of the GeoSeries\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2720\u001b[0m         )\n\u001b[1;32m   2721\u001b[0m     distance \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(distance)\n\u001b[0;32m-> 2723\u001b[0m \u001b[39mreturn\u001b[39;00m _delegate_geo_method(\n\u001b[1;32m   2724\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mbuffer\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mself\u001b[39;49m, distance, resolution\u001b[39m=\u001b[39;49mresolution, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m   2725\u001b[0m )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/lakeshores/lib/python3.10/site-packages/geopandas/base.py:81\u001b[0m, in \u001b[0;36m_delegate_geo_method\u001b[0;34m(op, this, *args, **kwargs)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mgeoseries\u001b[39;00m \u001b[39mimport\u001b[39;00m GeoSeries\n\u001b[1;32m     80\u001b[0m a_this \u001b[39m=\u001b[39m GeometryArray(this\u001b[39m.\u001b[39mgeometry\u001b[39m.\u001b[39mvalues)\n\u001b[0;32m---> 81\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39;49m(a_this, op)(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\u001b[39m.\u001b[39mdata\n\u001b[1;32m     82\u001b[0m \u001b[39mreturn\u001b[39;00m GeoSeries(data, index\u001b[39m=\u001b[39mthis\u001b[39m.\u001b[39mindex, crs\u001b[39m=\u001b[39mthis\u001b[39m.\u001b[39mcrs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/lakeshores/lib/python3.10/site-packages/geopandas/array.py:616\u001b[0m, in \u001b[0;36mGeometryArray.buffer\u001b[0;34m(self, distance, resolution, **kwargs)\u001b[0m\n\u001b[1;32m    613\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39misinstance\u001b[39m(distance, (\u001b[39mint\u001b[39m, \u001b[39mfloat\u001b[39m)) \u001b[39mand\u001b[39;00m distance \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m):\n\u001b[1;32m    614\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_geographic_crs(stacklevel\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m)\n\u001b[1;32m    615\u001b[0m \u001b[39mreturn\u001b[39;00m GeometryArray(\n\u001b[0;32m--> 616\u001b[0m     vectorized\u001b[39m.\u001b[39;49mbuffer(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata, distance, resolution\u001b[39m=\u001b[39;49mresolution, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs),\n\u001b[1;32m    617\u001b[0m     crs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcrs,\n\u001b[1;32m    618\u001b[0m )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/lakeshores/lib/python3.10/site-packages/geopandas/_vectorized.py:793\u001b[0m, in \u001b[0;36mbuffer\u001b[0;34m(data, distance, resolution, **kwargs)\u001b[0m\n\u001b[1;32m    790\u001b[0m     \u001b[39mreturn\u001b[39;00m out\n\u001b[1;32m    792\u001b[0m \u001b[39mwith\u001b[39;00m compat\u001b[39m.\u001b[39mignore_shapely2_warnings():\n\u001b[0;32m--> 793\u001b[0m     out[:] \u001b[39m=\u001b[39m [\n\u001b[1;32m    794\u001b[0m         geom\u001b[39m.\u001b[39mbuffer(distance, resolution, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    795\u001b[0m         \u001b[39mif\u001b[39;00m geom \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    796\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    797\u001b[0m         \u001b[39mfor\u001b[39;00m geom \u001b[39min\u001b[39;00m data\n\u001b[1;32m    798\u001b[0m     ]\n\u001b[1;32m    799\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/lakeshores/lib/python3.10/site-packages/geopandas/_vectorized.py:794\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    790\u001b[0m     \u001b[39mreturn\u001b[39;00m out\n\u001b[1;32m    792\u001b[0m \u001b[39mwith\u001b[39;00m compat\u001b[39m.\u001b[39mignore_shapely2_warnings():\n\u001b[1;32m    793\u001b[0m     out[:] \u001b[39m=\u001b[39m [\n\u001b[0;32m--> 794\u001b[0m         geom\u001b[39m.\u001b[39;49mbuffer(distance, resolution, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    795\u001b[0m         \u001b[39mif\u001b[39;00m geom \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    796\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    797\u001b[0m         \u001b[39mfor\u001b[39;00m geom \u001b[39min\u001b[39;00m data\n\u001b[1;32m    798\u001b[0m     ]\n\u001b[1;32m    799\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'buffer'"
     ]
    }
   ],
   "source": [
    "# test on one lake to ensure working\n",
    "S09SF18varoutlines_agg_dvdt_plot('lower_Whillans6', 10000, 0.5, CS2_dh, ATL15_dh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run func on all lakes from S09 inventory with CS2 InSAR coverage\n",
    "for idx in range(len(SiegfriedFricker2018_S09outlines_CS2InSAR)):\n",
    "    lakename = SiegfriedFricker2018_S09outlines_CS2InSAR['name'][idx]\n",
    "    S09SF18varoutlines_agg_dvdt_plot(lakename, 10000, 0.5, CS2_dh, ATL15_dh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modified from 2x2 to plot CS2 and IS2 on same plot to just plot IS2 for lakes where no InSAR available\n",
    "# for SiegfriedFricker2018_S09outlines_noInSAR\n",
    "def S09SF18varoutlines_agg_dvdt_plot(lakename_S09, buffer, thres, dataset1): \n",
    "    '''\n",
    "    Create planview plot of an aggregated times series of variable outlines compared to known lakes alongside dv/dt time series. Uses geopandas buffer created bounding box around known lakes in Siegfried and Fricker, 2018 (SF18) inventory. Creates time-variable outlines using skimage contour to plot variable outline alongside published outlines for comparison. \n",
    "    Inputs: \n",
    "        lakename_SF18: lake of interest from SiegfriedFricker2018_outlines inventory\n",
    "        buffer: horizontal distance in meters away from SF18 lake outline used to create bounding box that is displayed around lake of interest\n",
    "        thres(hold): vertical distance in meters to delineate ice surface deformation contour\n",
    "        dataset: dataset to be analyzed (CS2_dh or ATL15_dh)\n",
    "    Outputs: \n",
    "        Aggregated time-variable lake outlines in regions of known lakes using CryoSat-2 or ICESat-2 ATL15 dh/dt data alongside dVol time series.\n",
    "    '''\n",
    "    # isolate individual lake using gpd buffer\n",
    "    lake_S09 = SiegfriedFricker2018_S09outlines_noInSAR.loc[SiegfriedFricker2018_S09outlines_noInSAR['name'] == lakename_S09]\n",
    "    lake_buffer = lake_S09.buffer(buffer)\n",
    "    # define lake bounding box\n",
    "    x_min = lake_buffer.bounds.values[0,0]; x_max = lake_buffer.bounds.values[0,2]\n",
    "    y_min = lake_buffer.bounds.values[0,1]; y_max = lake_buffer.bounds.values[0,3]\n",
    "    # subset ATL15 data set to region of interest\n",
    "    mask_x = (dataset1.x >= x_min) & (dataset1.x <= x_max)\n",
    "    mask_y = (dataset1.y >= y_min) & (dataset1.y <= y_max)\n",
    "    ds_sub = dataset1.where(mask_x & mask_y, drop=True)\n",
    "    # find magnitude of ice surface deformation in bounding box / find appropriate color map scale\n",
    "    height_anom_pos = []\n",
    "    height_anom_neg = []\n",
    "    for cyc in range(len(ds_sub.time)-1):\n",
    "        pos = np.nanmax(ds_sub.delta_h[cyc+1,:,:]-ds_sub.delta_h[cyc,:,:])\n",
    "        neg = np.nanmin(ds_sub.delta_h[cyc+1,:,:]-ds_sub.delta_h[cyc,:,:])\n",
    "        height_anom_pos += [pos]\n",
    "        height_anom_neg += [neg]\n",
    "    max_height_anom_pos = max(height_anom_pos)\n",
    "    max_height_anom_neg = min(height_anom_neg)\n",
    "    max_height_anom_abs = max(max_height_anom_pos,abs(max_height_anom_neg))\n",
    "    v = np.round(max_height_anom_abs)\n",
    "    # create empty lists to store data\n",
    "    dates = []\n",
    "    lkavgdhdt_S09 = []\n",
    "    lkavgdhdt_var = []\n",
    "    vols_S09 = []\n",
    "    vols_var = []\n",
    "    # plot figure\n",
    "    fig, axes = plt.subplots(1,2, figsize=(20,10))\n",
    "    # plt.subplots_adjust(wspace=0.15, hspace = 0.1)\n",
    "    cmap = plt.get_cmap('CMRmap')\n",
    "    norm = plt.Normalize(ds_sub.time.values[0],ds_sub.time.values[-1])    \n",
    "    for idx in range(len(ds_sub.time)-1): \n",
    "        dhdt = ds_sub.delta_h[idx+1,:,:]-ds_sub.delta_h[idx,:,:]\n",
    "        # calculate mid-cycle dates for plotting\n",
    "        if dataset1.fileName == 'mos_2010.5_2021.5.h5':\n",
    "            newdate = datetime.datetime(int(ds_sub.time.values[idx]), 1, 1) + datetime.timedelta(days = (ds_sub.time.values[idx] % 1) * 365.25)\n",
    "            newdate1 = datetime.datetime(int(ds_sub.time.values[idx+1]), 1, 1) + datetime.timedelta(days = (ds_sub.time.values[idx+1] % 1) * 365.25)\n",
    "            midcycdays = newdate1 - newdate\n",
    "            midcycdate = newdate + midcycdays/2\n",
    "            dates += [midcycdate]\n",
    "        elif dataset1.fileName == 'ATL15_AA_0311_01km_001_01.nc':    \n",
    "            date_time_str = '18-01-01'\n",
    "            date_time_obj = datetime.datetime.strptime(date_time_str, '%y-%m-%d')\n",
    "            newdate = date_time_obj + datetime.timedelta(days=ds_sub.time.values[idx])\n",
    "            newdate1 = date_time_obj + datetime.timedelta(days=ds_sub.time.values[idx+1])\n",
    "            midcycdays = newdate1 - newdate\n",
    "            midcycdate = newdate + midcycdays/2\n",
    "            dates += [midcycdate]\n",
    "        # subset data to dhdt diff between orbital cycles of delta_h\n",
    "        dhdt = ds_sub.delta_h[idx+1,:,:]-ds_sub.delta_h[idx,:,:]\n",
    "        # clip ATL15 data to just show (first set crs)\n",
    "        dhdt.rio.write_crs(3031, inplace=True)\n",
    "        dhdt_clip_S09 = dhdt.rio.clip(lake_S09.geometry.values, lake_S09.crs, drop=False, invert=False)\n",
    "        # calculate lake avg. dh/dt and dv/dt time series using published static outlines\n",
    "        avg_lk_dhdt_S09 = np.nanmean(dhdt_clip_S09)\n",
    "        lkavgdhdt_S09 += [avg_lk_dhdt_S09]\n",
    "        vol_S09 = avg_lk_dhdt_S09*SiegfriedFricker2018_S09outlines_noInSAR[SiegfriedFricker2018_S09outlines_noInSAR['name'] == lakename_S09]['area (m^2)']\n",
    "        vols_S09 += [vol_S09.values[0]]\n",
    "        # create contours of ice surface elevation height changes to delineate variable lake outlines\n",
    "        contours_fill = []\n",
    "        contours_drain = []   \n",
    "        polys = []\n",
    "        contour = measure.find_contours(dhdt.values, thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_fill += [contour]\n",
    "        contour = measure.find_contours(dhdt.values, -thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_drain += [contour]\n",
    "        # create mapping conversion factor to map array location to polar stereographic x,y\n",
    "        x_conv = (x_max-x_min)/dhdt.shape[1]\n",
    "        y_conv = (y_max-y_min)/dhdt.shape[0]\n",
    "        # plot variable outlines found in this time slice\n",
    "        # make polygons from variable outlines\n",
    "        for i in range(len(contours_fill)): \n",
    "            for j in range(len(contours_fill[i])):\n",
    "                axes[0].plot(x_min+contours_fill[i][j][:, 1]*x_conv, y_max-contours_fill[i][j][:, 0]*y_conv, \n",
    "                color=cmap(norm(ds_sub.time.values[idx])), linestyle=(0, (3, 1, 1, 1)), linewidth=1)\n",
    "                if len(contours_fill[i][j][:, 1]) > 2: \n",
    "                    poly = Polygon(list(zip(contours_fill[i][j][:, 1]*x_conv+x_min, y_max-contours_fill[i][j][:, 0]*y_conv))) \n",
    "                    polys += [poly]\n",
    "        for i in range(len(contours_drain)): \n",
    "            for j in range(len(contours_drain[i])):\n",
    "                axes[0].plot(x_min+contours_drain[i][j][:, 1]*x_conv, y_max-contours_drain[i][j][:, 0]*y_conv, color=cmap(norm(ds_sub.time.values[idx])), linestyle=(0, (5, 1)), linewidth=1)\n",
    "                if len(contours_drain[i][j][:, 1]) > 2: \n",
    "                    poly = Polygon(list(zip(contours_drain[i][j][:, 1]*x_conv+x_min, y_max-contours_drain[i][j][:, 0]*y_conv))) \n",
    "                    polys += [poly]\n",
    "        # set area to zero each time step\n",
    "        variable_area = 0\n",
    "        # if polygons are present at time step, \n",
    "        if len(polys) > 0: \n",
    "            # clip data to polygons\n",
    "            dhdt_clip = dhdt.rio.clip(polys, drop=False, invert=False)\n",
    "            # then calculate on-lake averages of dh/dt\n",
    "            avg_lk_dhdt = np.nanmean(dhdt_clip)\n",
    "            # occasionally small polygons will completely clip data resulting in nan's for lake avg. dh/dt\n",
    "            # replace with zeros\n",
    "            if math.isnan(avg_lk_dhdt): \n",
    "                avg_lk_dhdt = 0\n",
    "                lkavgdhdt_var += [avg_lk_dhdt]\n",
    "            else:\n",
    "                lkavgdhdt_var += [avg_lk_dhdt]\n",
    "                # and dv/dt\n",
    "            for i in range(len(polys)):\n",
    "                variable_area = variable_area + polys[i].area\n",
    "            vol_var = avg_lk_dhdt*variable_area\n",
    "            vols_var += [vol_var]\n",
    "        else: \n",
    "            variable_area = 0\n",
    "            avg_lk_dhdt = 0\n",
    "            lkavgdhdt_var += [avg_lk_dhdt]\n",
    "            vol_var = avg_lk_dhdt*variable_area\n",
    "            vols_var += [vol_var]\n",
    "    axes[0].set(xlim=(x_min, x_max), ylim=(y_min, y_max))\n",
    "    # change polar stereographic m to km\n",
    "    km_scale = 1e3\n",
    "    ticks_x = ticker.FuncFormatter(lambda x, pos: '{0:g}'.format(x/km_scale))\n",
    "    axes[0].xaxis.set_major_formatter(ticks_x)\n",
    "    ticks_y = ticker.FuncFormatter(lambda x, pos: '{0:g}'.format(x/km_scale))\n",
    "    axes[0].yaxis.set_major_formatter(ticks_y)  \n",
    "    # label axes\n",
    "    axes[0].set_xlabel('x [km]', size=15)\n",
    "    axes[0].set_ylabel('y [km]', size=15)\n",
    "    # add colorbar\n",
    "    m = plt.cm.ScalarMappable(cmap=cmap)\n",
    "    m.set_array(np.array([datetime2fracyear(date_idx) for date_idx in dates[0:-1]]))\n",
    "    divider = make_axes_locatable(axes[0])\n",
    "    cax = divider.append_axes('bottom', size='2.5%', pad=0.7)\n",
    "    clb = fig.colorbar(m, cax=cax, orientation='horizontal', ticks=np.array([2019,2020,2021])).set_label('Year', size=15)\n",
    "    # overlay published outlines for visual comparison \n",
    "    Smith2009_outlines.boundary.plot(ax=axes[0], color='darkturquoise', linestyle=(0, (1, 5)), linewidth=1)\n",
    "    SiegfriedFricker2018_SF18outlines.boundary.plot(ax=axes[0], color='darkturquoise', linestyle=(0, (1, 1)), linewidth=1)\n",
    "    # create lines for legends\n",
    "    Smith2009 = plt.Line2D((0, 1), (0, 0), color='darkturquoise', linestyle=(0, (1, 5)), linewidth=2)\n",
    "    SiegfriedFricker2018 = plt.Line2D((0, 1), (0, 0), color='darkturquoise', linestyle=(0, (1, 1)), linewidth=2)\n",
    "    uplift = plt.Line2D((0, 1), (0, 0), color='k', linestyle=(0, (3, 1, 1, 1)), linewidth=2)\n",
    "    subsidence = plt.Line2D((0, 1), (0, 0), color='k', linestyle=(0, (5, 1)), linewidth=1)\n",
    "    variable_outlines = plt.Line2D((0, 1), (0, 0), color='k', linestyle='dashdot', linewidth=2)\n",
    "    axes[0].legend([Smith2009,\n",
    "        #SiegfriedFricker2018,\n",
    "        uplift, subsidence],\n",
    "        ['Smith and others, 2009 static outline',\n",
    "        #'Siegfried & Fricker, 2018 static outline',\n",
    "        ('+'+str(thres)+' m uplift (filling) variable outline'), '–'+str(thres)+' m subsidence (draining) variable outline'], \n",
    "        loc='upper right')\n",
    "    # plot inset map to show location \n",
    "    axIns = axes[0].inset_axes([0.005, -0.03, 0.3, 0.3])\n",
    "    axIns.patch.set_facecolor('lightskyblue')\n",
    "    axIns.set_aspect('equal')\n",
    "    axIns.scatter(((x_max+x_min)/2), ((y_max+y_min)/2), marker='*', \n",
    "        linewidth=1, edgecolor='k', facecolor='r', s=100, zorder=3)\n",
    "    Scripps_gl.plot(ax=axIns, color='ghostwhite', edgecolor='k', linewidth=0.5, zorder=2)\n",
    "    axIns.axis('off')\n",
    "    # plot dv subplot\n",
    "    axes[1].plot(dates[:idx+1], np.divide(np.cumsum(vols_S09[:idx+1]), 1e+9), color='darkturquoise', linestyle=(0, (1, 1)))\n",
    "    axes[1].plot(dates[:idx+1], np.divide(np.cumsum(vols_var[:idx+1]), 1e+9), color='k', linestyle='dashdot')\n",
    "    locator = mdates.AutoDateLocator(minticks=1, maxticks=7)\n",
    "    formatter = mdates.ConciseDateFormatter(locator)\n",
    "    axes[1].xaxis.set_major_locator(locator)\n",
    "    axes[1].xaxis.set_major_formatter(formatter)\n",
    "    axes[1].set_xlabel('Year', size=15)\n",
    "    axes[1].set_ylabel('Volume change [km$^3$]', size=15)\n",
    "    axes[1].yaxis.tick_right()\n",
    "    axes[1].yaxis.set_label_position(\"right\")\n",
    "    axes[1].legend([Smith2009,\n",
    "        #SiegfriedFricker2018,\n",
    "        variable_outlines],\n",
    "        ['Smith and others, 2009 static outline',\n",
    "        #'Siegfried & Fricker, 2018 static outline',\n",
    "        '±{} m variable outlines'.format(thres)], \n",
    "                    loc='upper right')\n",
    "    # save and close figure\n",
    "    plt.savefig('/Users/Wilson/Documents/0-code/1-lakeshores/output_dhdvdt-using-variable-outlines/S09SF18varoutlines_agg_dvdt_plot/S09SF18varoutlines_agg_dvdt_plot-{}.png'\\\n",
    "        .format(lakename_S09), dpi=300, bbox_inches = \"tight\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test on one lake to ensure working\n",
    "S09SF18varoutlines_agg_dvdt_plot('Bindschadler_1', 10000, 0.5, ATL15_dh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run func on all lakes from SF18 inventory with CS2 InSAR coverage\n",
    "for idx in range(1,8):#len(SiegfriedFricker2018_S09outlines_noInSAR)):\n",
    "    lakename = SiegfriedFricker2018_S09outlines_noInSAR['name'][idx]\n",
    "    S09SF18varoutlines_agg_dvdt_plot(lakename, 10000, 0.5, ATL15_dh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modified from 2x2 to plot CS2 and IS2 on same plot to just plot IS2 for lakes where no InSAR available\n",
    "# for SiegfriedFricker2018_SF18outlines_noInSAR\n",
    "def S09SF18varoutlines_agg_dvdt_plot(lakename_SF18, buffer, thres, dataset1): \n",
    "    '''\n",
    "    Create planview plot of an aggregated times series of variable outlines compared to known lakes alongside dv/dt time series. Uses geopandas buffer created bounding box around known lakes in Siegfried and Fricker, 2018 (SF18) inventory. Creates time-variable outlines using skimage contour to plot variable outline alongside published outlines for comparison. \n",
    "    Inputs: \n",
    "        lakename_SF18: lake of interest from SiegfriedFricker2018_outlines inventory\n",
    "        buffer: horizontal distance in meters away from SF18 lake outline used to create bounding box that is displayed around lake of interest\n",
    "        thres(hold): vertical distance in meters to delineate ice surface deformation contour\n",
    "        dataset: dataset to be analyzed (CS2_dh or ATL15_dh)\n",
    "    Outputs: \n",
    "        Aggregated time-variable lake outlines in regions of known lakes using CryoSat-2 or ICESat-2 ATL15 dh/dt data alongside dVol time series.\n",
    "    '''\n",
    "    # isolate individual lake using gpd buffer\n",
    "    lake_SF18 = SiegfriedFricker2018_outlines.loc[SiegfriedFricker2018_outlines['name'] == lakename_SF18]\n",
    "    lake_buffer = lake_SF18.buffer(buffer)\n",
    "    # define lake bounding box\n",
    "    x_min = lake_buffer.bounds.values[0,0]; x_max = lake_buffer.bounds.values[0,2]\n",
    "    y_min = lake_buffer.bounds.values[0,1]; y_max = lake_buffer.bounds.values[0,3]\n",
    "    # subset ATL15 data set to region of interest\n",
    "    mask_x = (dataset1.x >= x_min) & (dataset1.x <= x_max)\n",
    "    mask_y = (dataset1.y >= y_min) & (dataset1.y <= y_max)\n",
    "    ds_sub = dataset1.where(mask_x & mask_y, drop=True)\n",
    "    # find magnitude of ice surface deformation in bounding box / find appropriate color map scale\n",
    "    height_anom_pos = []\n",
    "    height_anom_neg = []\n",
    "    for cyc in range(len(ds_sub.time)-1):\n",
    "        pos = np.nanmax(ds_sub.delta_h[cyc+1,:,:]-ds_sub.delta_h[cyc,:,:])\n",
    "        neg = np.nanmin(ds_sub.delta_h[cyc+1,:,:]-ds_sub.delta_h[cyc,:,:])\n",
    "        height_anom_pos += [pos]\n",
    "        height_anom_neg += [neg]\n",
    "    max_height_anom_pos = max(height_anom_pos)\n",
    "    max_height_anom_neg = min(height_anom_neg)\n",
    "    max_height_anom_abs = max(max_height_anom_pos,abs(max_height_anom_neg))\n",
    "    v = np.round(max_height_anom_abs)\n",
    "    # create empty lists to store data\n",
    "    dates = []\n",
    "    lkavgdhdt_SF18 = []\n",
    "    lkavgdhdt_var = []\n",
    "    vols_SF18 = []\n",
    "    vols_var = []\n",
    "    # plot figure\n",
    "    fig, axes = plt.subplots(1,2, figsize=(20,10))\n",
    "    # plt.subplots_adjust(wspace=0.15, hspace = 0.1)\n",
    "    cmap = plt.get_cmap('CMRmap')\n",
    "    norm = plt.Normalize(ds_sub.time.values[0],ds_sub.time.values[-1])    \n",
    "    for idx in range(len(ds_sub.time)-1): \n",
    "        dhdt = ds_sub.delta_h[idx+1,:,:]-ds_sub.delta_h[idx,:,:]\n",
    "        # calculate mid-cycle dates for plotting\n",
    "        if dataset1.fileName == 'mos_2010.5_2021.5.h5':\n",
    "            newdate = datetime.datetime(int(ds_sub.time.values[idx]), 1, 1) + datetime.timedelta(days = (ds_sub.time.values[idx] % 1) * 365.25)\n",
    "            newdate1 = datetime.datetime(int(ds_sub.time.values[idx+1]), 1, 1) + datetime.timedelta(days = (ds_sub.time.values[idx+1] % 1) * 365.25)\n",
    "            midcycdays = newdate1 - newdate\n",
    "            midcycdate = newdate + midcycdays/2\n",
    "            dates += [midcycdate]\n",
    "        elif dataset1.fileName == 'ATL15_AA_0311_01km_001_01.nc':    \n",
    "            date_time_str = '18-01-01'\n",
    "            date_time_obj = datetime.datetime.strptime(date_time_str, '%y-%m-%d')\n",
    "            newdate = date_time_obj + datetime.timedelta(days=ds_sub.time.values[idx])\n",
    "            newdate1 = date_time_obj + datetime.timedelta(days=ds_sub.time.values[idx+1])\n",
    "            midcycdays = newdate1 - newdate\n",
    "            midcycdate = newdate + midcycdays/2\n",
    "            dates += [midcycdate]\n",
    "        # subset data to dhdt diff between orbital cycles of delta_h\n",
    "        dhdt = ds_sub.delta_h[idx+1,:,:]-ds_sub.delta_h[idx,:,:]\n",
    "        # clip ATL15 data to just show (first set crs)\n",
    "        dhdt.rio.write_crs(3031, inplace=True)\n",
    "        dhdt_clip_SF18 = dhdt.rio.clip(lake_SF18.geometry.values, lake_SF18.crs, drop=False, invert=False)\n",
    "        # calculate lake avg. dh/dt and dv/dt time series using published static outlines\n",
    "        avg_lk_dhdt_SF18 = np.nanmean(dhdt_clip_SF18)\n",
    "        lkavgdhdt_SF18 += [avg_lk_dhdt_SF18]\n",
    "        vol_SF18 = avg_lk_dhdt_SF18*SiegfriedFricker2018_outlines[SiegfriedFricker2018_outlines['name'] == lakename_SF18]['area (m^2)']\n",
    "        vols_SF18 += [vol_SF18.values[0]]\n",
    "        # create contours of ice surface elevation height changes to delineate variable lake outlines\n",
    "        contours_fill = []\n",
    "        contours_drain = []   \n",
    "        polys = []\n",
    "        contour = measure.find_contours(dhdt.values, thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_fill += [contour]\n",
    "        contour = measure.find_contours(dhdt.values, -thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_drain += [contour]\n",
    "        # create mapping conversion factor to map array location to polar stereographic x,y\n",
    "        x_conv = (x_max-x_min)/dhdt.shape[1]\n",
    "        y_conv = (y_max-y_min)/dhdt.shape[0]\n",
    "        # plot variable outlines found in this time slice\n",
    "        # make polygons from variable outlines\n",
    "        for i in range(len(contours_fill)): \n",
    "            for j in range(len(contours_fill[i])):\n",
    "                axes[0].plot(x_min+contours_fill[i][j][:, 1]*x_conv, y_max-contours_fill[i][j][:, 0]*y_conv, \n",
    "                color=cmap(norm(ds_sub.time.values[idx])), linestyle=(0, (3, 1, 1, 1)), linewidth=1)\n",
    "                if len(contours_fill[i][j][:, 1]) > 2: \n",
    "                    poly = Polygon(list(zip(contours_fill[i][j][:, 1]*x_conv+x_min, y_max-contours_fill[i][j][:, 0]*y_conv))) \n",
    "                    polys += [poly]\n",
    "        for i in range(len(contours_drain)): \n",
    "            for j in range(len(contours_drain[i])):\n",
    "                axes[0].plot(x_min+contours_drain[i][j][:, 1]*x_conv, y_max-contours_drain[i][j][:, 0]*y_conv, color=cmap(norm(ds_sub.time.values[idx])), linestyle=(0, (5, 1)), linewidth=1)\n",
    "                if len(contours_drain[i][j][:, 1]) > 2: \n",
    "                    poly = Polygon(list(zip(contours_drain[i][j][:, 1]*x_conv+x_min, y_max-contours_drain[i][j][:, 0]*y_conv))) \n",
    "                    polys += [poly]\n",
    "        # set area to zero each time step\n",
    "        variable_area = 0\n",
    "        # if polygons are present at time step, \n",
    "        if len(polys) > 0: \n",
    "            # clip data to polygons\n",
    "            dhdt_clip = dhdt.rio.clip(polys, drop=False, invert=False)\n",
    "            # then calculate on-lake averages of dh/dt\n",
    "            avg_lk_dhdt = np.nanmean(dhdt_clip)\n",
    "            # occasionally small polygons will completely clip data resulting in nan's for lake avg. dh/dt\n",
    "            # replace with zeros\n",
    "            if math.isnan(avg_lk_dhdt): \n",
    "                avg_lk_dhdt = 0\n",
    "                lkavgdhdt_var += [avg_lk_dhdt]\n",
    "            else:\n",
    "                lkavgdhdt_var += [avg_lk_dhdt]\n",
    "                # and dv/dt\n",
    "            for i in range(len(polys)):\n",
    "                variable_area = variable_area + polys[i].area\n",
    "            vol_var = avg_lk_dhdt*variable_area\n",
    "            vols_var += [vol_var]\n",
    "        else: \n",
    "            variable_area = 0\n",
    "            avg_lk_dhdt = 0\n",
    "            lkavgdhdt_var += [avg_lk_dhdt]\n",
    "            vol_var = avg_lk_dhdt*variable_area\n",
    "            vols_var += [vol_var]\n",
    "    axes[0].set(xlim=(x_min, x_max), ylim=(y_min, y_max))\n",
    "    # change polar stereographic m to km\n",
    "    km_scale = 1e3\n",
    "    ticks_x = ticker.FuncFormatter(lambda x, pos: '{0:g}'.format(x/km_scale))\n",
    "    axes[0].xaxis.set_major_formatter(ticks_x)\n",
    "    ticks_y = ticker.FuncFormatter(lambda x, pos: '{0:g}'.format(x/km_scale))\n",
    "    axes[0].yaxis.set_major_formatter(ticks_y)  \n",
    "    # label axes\n",
    "    axes[0].set_xlabel('x [km]', size=15)\n",
    "    axes[0].set_ylabel('y [km]', size=15)\n",
    "    # add colorbar\n",
    "    m = plt.cm.ScalarMappable(cmap=cmap)\n",
    "    m.set_array(np.array([datetime2fracyear(date_idx) for date_idx in dates[0:-1]]))\n",
    "    divider = make_axes_locatable(axes[0])\n",
    "    cax = divider.append_axes('bottom', size='2.5%', pad=0.7)\n",
    "    clb = fig.colorbar(m, cax=cax, orientation='horizontal', ticks=np.array([2019,2020,2021])).set_label('Year', size=15)\n",
    "    # overlay published outlines for visual comparison \n",
    "    Smith2009_outlines.boundary.plot(ax=axes[0], color='darkturquoise', linestyle=(0, (1, 5)), linewidth=1)\n",
    "    # SiegfriedFricker2018_SF18outlines.boundary.plot(ax=axes[0], color='darkturquoise', linestyle=(0, (1, 1)), linewidth=1)\n",
    "    # create lines for legends\n",
    "    Smith2009 = plt.Line2D((0, 1), (0, 0), color='darkturquoise', linestyle=(0, (1, 5)), linewidth=2)\n",
    "    SiegfriedFricker2018 = plt.Line2D((0, 1), (0, 0), color='darkturquoise', linestyle=(0, (1, 1)), linewidth=2)\n",
    "    uplift = plt.Line2D((0, 1), (0, 0), color='k', linestyle=(0, (3, 1, 1, 1)), linewidth=2)\n",
    "    subsidence = plt.Line2D((0, 1), (0, 0), color='k', linestyle=(0, (5, 1)), linewidth=1)\n",
    "    variable_outlines = plt.Line2D((0, 1), (0, 0), color='k', linestyle='dashdot', linewidth=2)\n",
    "    axes[0].legend([Smith2009,\n",
    "        #SiegfriedFricker2018,\n",
    "        uplift, subsidence],\n",
    "        ['Smith and others, 2009 static outline',\n",
    "        #'Siegfried & Fricker, 2018 static outline',\n",
    "        ('+'+str(thres)+' m uplift (filling) variable outline'), '–'+str(thres)+' m subsidence (draining) variable outline'], \n",
    "        loc='upper right')\n",
    "    # plot inset map to show location \n",
    "    axIns = axes[0].inset_axes([0.005, -0.03, 0.3, 0.3])\n",
    "    axIns.patch.set_facecolor('lightskyblue')\n",
    "    axIns.set_aspect('equal')\n",
    "    axIns.scatter(((x_max+x_min)/2), ((y_max+y_min)/2), marker='*', \n",
    "        linewidth=1, edgecolor='k', facecolor='r', s=100, zorder=3)\n",
    "    Scripps_gl.plot(ax=axIns, color='ghostwhite', edgecolor='k', linewidth=0.5, zorder=2)\n",
    "    axIns.axis('off')\n",
    "    # plot dv subplot\n",
    "    axes[1].plot(dates[:idx+1], np.divide(np.cumsum(vols_SF18[:idx+1]), 1e+9), color='darkturquoise', linestyle=(0, (1, 5)))\n",
    "    axes[1].plot(dates[:idx+1], np.divide(np.cumsum(vols_var[:idx+1]), 1e+9), color='k', linestyle='dashdot')\n",
    "    locator = mdates.AutoDateLocator(minticks=1, maxticks=7)\n",
    "    formatter = mdates.ConciseDateFormatter(locator)\n",
    "    axes[1].xaxis.set_major_locator(locator)\n",
    "    axes[1].xaxis.set_major_formatter(formatter)\n",
    "    axes[1].set_xlabel('Year', size=15)\n",
    "    axes[1].set_ylabel('Volume change [km$^3$]', size=15)\n",
    "    axes[1].yaxis.tick_right()\n",
    "    axes[1].yaxis.set_label_position(\"right\")\n",
    "    axes[1].legend([Smith2009,\n",
    "        # SiegfriedFricker2018,\n",
    "        variable_outlines],\n",
    "        ['Smith and others, 2009 static outline',\n",
    "        #'Siegfried & Fricker, 2018 static outline',\n",
    "        '±{} m variable outlines'.format(thres)], \n",
    "                    loc='upper right')\n",
    "    # save and close figure\n",
    "    plt.savefig('/Users/Wilson/Documents/0-code/1-lakeshores/output_dhdvdt-using-variable-outlines/S09SF18varoutlines_agg_dvdt_plot/S09SF18varoutlines_agg_dvdt_plot-{}.png'\\\n",
    "        .format(lakename_SF18), dpi=300, bbox_inches = \"tight\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test on one lake to ensure working\n",
    "S09SF18varoutlines_agg_dvdt_plot('Mac6', 10000, 0.5, ATL15_dh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run func on all lakes from SF18 inventory with CS2 InSAR coverage\n",
    "for idx in range(len(SiegfriedFricker2018_SF18outlines_noInSAR)):\n",
    "    lakename = SiegfriedFricker2018_SF18outlines_noInSAR['name'][idx]\n",
    "    S09SF18varoutlines_agg_dvdt_plot(lakename, 10000, 0.5, ATL15_dh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare one S09 to one SF18 lakes (one redelineated)\n",
    "# for S09_SF18_compare_1to1_CS2InSAR\n",
    "def S09SF18varoutlines_agg_dvdt_plot(lakename_S09, lakename_SF18, buffer, thres, dataset1, dataset2): \n",
    "    '''\n",
    "    Create planview plot of an aggregated times series of variable outlines compared to known lakes alongside dv/dt time series. Uses geopandas buffer created bounding box around known lakes in Siegfried and Fricker, 2018 (SF18) inventory. Creates time-variable outlines using skimage contour to plot variable outline alongside published outlines for comparison. \n",
    "    Inputs: \n",
    "        lakename_SF18: lake of interest from SiegfriedFricker2018_outlines inventory\n",
    "        buffer: horizontal distance in meters away from SF18 lake outline used to create bounding box that is displayed around lake of interest\n",
    "        thres(hold): vertical distance in meters to delineate ice surface deformation contour\n",
    "        dataset: dataset to be analyzed (CS2_dh or ATL15_dh)\n",
    "    Outputs: \n",
    "        Aggregated time-variable lake outlines in regions of known lakes using CryoSat-2 or ICESat-2 ATL15 dh/dt data alongside dVol time series.\n",
    "    '''\n",
    "    # isolate individual lake using gpd buffer\n",
    "    #lake_gpd = Smith2009_outlines.loc[Smith2009_outlines['Name'] == lakename_SF18]\n",
    "    lake_S09 = Smith2009_outlines.loc[Smith2009_outlines['Name'] == lakename_S09]\n",
    "    lake_SF18 = SiegfriedFricker2018_outlines.loc[SiegfriedFricker2018_outlines['name'] == lakename_SF18]\n",
    "    lake_buffer = lake_SF18.buffer(buffer)\n",
    "    # define lake bounding box\n",
    "    x_min = lake_buffer.bounds.values[0,0]; x_max = lake_buffer.bounds.values[0,2]\n",
    "    y_min = lake_buffer.bounds.values[0,1]; y_max = lake_buffer.bounds.values[0,3]\n",
    "    # subset ATL15 data set to region of interest\n",
    "    mask_x = (dataset1.x >= x_min) & (dataset1.x <= x_max)\n",
    "    mask_y = (dataset1.y >= y_min) & (dataset1.y <= y_max)\n",
    "    ds_sub = dataset1.where(mask_x & mask_y, drop=True)\n",
    "    # find magnitude of ice surface deformation in bounding box / find appropriate color map scale\n",
    "    height_anom_pos = []\n",
    "    height_anom_neg = []\n",
    "    for cyc in range(len(ds_sub.time)-1):\n",
    "        pos = np.nanmax(ds_sub.delta_h[cyc+1,:,:]-ds_sub.delta_h[cyc,:,:])\n",
    "        neg = np.nanmin(ds_sub.delta_h[cyc+1,:,:]-ds_sub.delta_h[cyc,:,:])\n",
    "        height_anom_pos += [pos]\n",
    "        height_anom_neg += [neg]\n",
    "    max_height_anom_pos = max(height_anom_pos)\n",
    "    max_height_anom_neg = min(height_anom_neg)\n",
    "    max_height_anom_abs = max(max_height_anom_pos,abs(max_height_anom_neg))\n",
    "    v = np.round(max_height_anom_abs)\n",
    "    dates = []\n",
    "    lkavgdhdt_SF18 = []\n",
    "    lkavgdhdt_var = []\n",
    "    vols_S09 = []\n",
    "    vols_SF18 = []\n",
    "    vols_var = []\n",
    "    # plot figure\n",
    "    fig, axes = plt.subplots(2,2, figsize=(20,20))\n",
    "    # plt.subplots_adjust(wspace=0.10, hspace = 0.1)\n",
    "    cmap = plt.get_cmap('CMRmap')\n",
    "    norm = plt.Normalize(ds_sub.time.values[0],ds_sub.time.values[-1])    \n",
    "    for idx in range(len(ds_sub.time)-1): \n",
    "        dhdt = ds_sub.delta_h[idx+1,:,:]-ds_sub.delta_h[idx,:,:]\n",
    "        # calculate mid-cycle dates for plotting\n",
    "        if dataset1.fileName == 'mos_2010.5_2021.5.h5':\n",
    "            newdate = datetime.datetime(int(ds_sub.time.values[idx]), 1, 1) + datetime.timedelta(days = (ds_sub.time.values[idx] % 1) * 365.25)\n",
    "            newdate1 = datetime.datetime(int(ds_sub.time.values[idx+1]), 1, 1) + datetime.timedelta(days = (ds_sub.time.values[idx+1] % 1) * 365.25)\n",
    "            midcycdays = newdate1 - newdate\n",
    "            midcycdate = newdate + midcycdays/2\n",
    "            dates += [midcycdate]\n",
    "        elif dataset1.fileName == 'ATL15_AA_0311_01km_001_01.nc':    \n",
    "            date_time_str = '18-01-01'\n",
    "            date_time_obj = datetime.datetime.strptime(date_time_str, '%y-%m-%d')\n",
    "            newdate = date_time_obj + datetime.timedelta(days=ds_sub.time.values[idx])\n",
    "            newdate1 = date_time_obj + datetime.timedelta(days=ds_sub.time.values[idx+1])\n",
    "            midcycdays = newdate1 - newdate\n",
    "            midcycdate = newdate + midcycdays/2\n",
    "            dates += [midcycdate]\n",
    "        # subset data to dhdt diff between orbital cycles of delta_h\n",
    "        dhdt = ds_sub.delta_h[idx+1,:,:]-ds_sub.delta_h[idx,:,:]\n",
    "        # clip ATL15 data to just show (first set crs)\n",
    "        dhdt.rio.write_crs(3031, inplace=True)\n",
    "        dhdt_clip_S09 = dhdt.rio.clip(lake_S09.geometry.values, lake_S09.crs, drop=False, invert=False)\n",
    "        dhdt_clip_SF18 = dhdt.rio.clip(lake_SF18.geometry.values, lake_SF18.crs, drop=False, invert=False)\n",
    "        # calculate lake avg. dh/dt and dv/dt time series using published static outlines\n",
    "        avg_lk_dhdt_S09 = np.nanmean(dhdt_clip_S09)\n",
    "        avg_lk_dhdt_SF18 = np.nanmean(dhdt_clip_SF18)\n",
    "        lkavgdhdt_SF18 += [avg_lk_dhdt_SF18]\n",
    "        vol_S09 = avg_lk_dhdt_S09*Smith2009_outlines[Smith2009_outlines['Name'] == lakename_S09].area\n",
    "        vol_SF18 = avg_lk_dhdt_SF18*SiegfriedFricker2018_outlines[SiegfriedFricker2018_outlines['name'] == lakename_SF18]['area (m^2)']\n",
    "        vols_S09 += [vol_S09.values[0]]\n",
    "        vols_SF18 += [vol_SF18.values[0]]\n",
    "        # create contours of ice surface elevation height changes to delineate variable lake outlines\n",
    "        contours_fill = []\n",
    "        contours_drain = []   \n",
    "        polys = []\n",
    "        contour = measure.find_contours(dhdt.values, thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_fill += [contour]\n",
    "        contour = measure.find_contours(dhdt.values, -thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_drain += [contour]\n",
    "        # create mapping conversion factor to map array location to polar stereographic x,y\n",
    "        x_conv = (x_max-x_min)/dhdt.shape[1]\n",
    "        y_conv = (y_max-y_min)/dhdt.shape[0]\n",
    "        # plot variable outlines found in this time slice\n",
    "        # make polygons from variable outlines\n",
    "        for i in range(len(contours_fill)): \n",
    "            for j in range(len(contours_fill[i])):\n",
    "                axes[0,0].plot(x_min+contours_fill[i][j][:, 1]*x_conv, y_max-contours_fill[i][j][:, 0]*y_conv, \n",
    "                color=cmap(norm(ds_sub.time.values[idx])), linestyle=(0, (3, 1, 1, 1)), linewidth=1)\n",
    "                if len(contours_fill[i][j][:, 1]) > 2: \n",
    "                    poly = Polygon(list(zip(contours_fill[i][j][:, 1]*x_conv+x_min, y_max-contours_fill[i][j][:, 0]*y_conv))) \n",
    "                    polys += [poly]\n",
    "        for i in range(len(contours_drain)): \n",
    "            for j in range(len(contours_drain[i])):\n",
    "                axes[0,0].plot(x_min+contours_drain[i][j][:, 1]*x_conv, y_max-contours_drain[i][j][:, 0]*y_conv, color=cmap(norm(ds_sub.time.values[idx])), linestyle=(0, (5, 1)), linewidth=1)\n",
    "                if len(contours_drain[i][j][:, 1]) > 2: \n",
    "                    poly = Polygon(list(zip(contours_drain[i][j][:, 1]*x_conv+x_min, y_max-contours_drain[i][j][:, 0]*y_conv))) \n",
    "                    polys += [poly]\n",
    "        # set area to zero each time step\n",
    "        variable_area = 0\n",
    "        # if polygons are present at time step, \n",
    "        if len(polys) > 0: \n",
    "            # clip data to polygons\n",
    "            dhdt_clip = dhdt.rio.clip(polys, drop=False, invert=False)\n",
    "            # then calculate on-lake averages of dh/dt\n",
    "            avg_lk_dhdt = np.nanmean(dhdt_clip)\n",
    "            # occasionally small polygons will completely clip data resulting in nan's for lake avg. dh/dt\n",
    "            # replace with zeros\n",
    "            if math.isnan(avg_lk_dhdt): \n",
    "                avg_lk_dhdt = 0\n",
    "                lkavgdhdt_var += [avg_lk_dhdt]\n",
    "            else:\n",
    "                lkavgdhdt_var += [avg_lk_dhdt]\n",
    "                # and dv/dt\n",
    "            for i in range(len(polys)):\n",
    "                variable_area = variable_area + polys[i].area\n",
    "            vol_var = avg_lk_dhdt*variable_area\n",
    "            vols_var += [vol_var]\n",
    "        else: \n",
    "            variable_area = 0\n",
    "            avg_lk_dhdt = 0\n",
    "            lkavgdhdt_var += [avg_lk_dhdt]\n",
    "            vol_var = avg_lk_dhdt*variable_area\n",
    "            vols_var += [vol_var]\n",
    "    axes[0,0].set(xlim=(x_min, x_max), ylim=(y_min, y_max))\n",
    "    # change polar stereographic m to km\n",
    "    km_scale = 1e3\n",
    "    ticks_x = ticker.FuncFormatter(lambda x, pos: '{0:g}'.format(x/km_scale))\n",
    "    axes[0,0].xaxis.set_major_formatter(ticks_x)\n",
    "    ticks_y = ticker.FuncFormatter(lambda y, pos: '{0:g}'.format(y/km_scale))\n",
    "    axes[0,0].yaxis.set_major_formatter(ticks_y)\n",
    "    # adjust ticks\n",
    "    # axes[0,0].set_xticks(np.arange(y_min,y_max,5000))\n",
    "    # axes[0,0].set_yticks(np.arange(y_min,y_max,5000))\n",
    "    # display MOA visual imagery\n",
    "    # axes[0,0].imshow(mpimg.imread('Whillans_7.png'), extent=[x_min1,x_max1,y_min1,y_max1], alpha=1)\n",
    "    axes[0,0].set_xlabel('x [km]', size=15)\n",
    "    axes[0,0].set_ylabel('y [km]', size=15)\n",
    "    # axes[0].ticklabel_format(axis='both',scilimits=(0,0))\n",
    "    # axes[0].set_title('outline comparison', pad=7.5, fontsize=17.5)\n",
    "    m = plt.cm.ScalarMappable(cmap=cmap)\n",
    "    m.set_array(np.array([datetime2fracyear(date_idx) for date_idx in dates[0:-1]]))\n",
    "    divider = make_axes_locatable(axes[0,0])\n",
    "    cax = divider.append_axes('bottom', size='2.5%', pad=0.7)\n",
    "    clb = fig.colorbar(m, cax=cax, orientation='horizontal').set_label('Year', size=15)\n",
    "    # overlay published outlines for visual comparison \n",
    "    Smith2009_outlines.boundary.plot(ax=axes[0,0], color='darkturquoise', linestyle=(0, (1, 5)), linewidth=1)\n",
    "    SiegfriedFricker2018_SF18outlines.boundary.plot(ax=axes[0,0], color='darkturquoise', linestyle=(0, (1, 1)), linewidth=1)\n",
    "    # create lines for legends\n",
    "    Smith2009 = plt.Line2D((0, 1), (0, 0), color='darkturquoise', linestyle=(0, (1, 5)), linewidth=2)\n",
    "    SiegfriedFricker2018 = plt.Line2D((0, 1), (0, 0), color='darkturquoise', linestyle=(0, (1, 1)), linewidth=2)\n",
    "    uplift = plt.Line2D((0, 1), (0, 0), color='k', linestyle=(0, (3, 1, 1, 1)), linewidth=2)\n",
    "    subsidence = plt.Line2D((0, 1), (0, 0), color='k', linestyle=(0, (5, 1)), linewidth=1)\n",
    "    variable_outlines = plt.Line2D((0, 1), (0, 0), color='k', linestyle='dashdot', linewidth=2)\n",
    "    axes[0,0].legend([Smith2009,\n",
    "    SiegfriedFricker2018,\n",
    "    uplift, subsidence],\n",
    "        ['Smith and others, 2009 static outline',\n",
    "        'Siegfried & Fricker, 2018 outline',\n",
    "        ('+'+str(thres)+' m uplift (filling) variable outline'), '–'+str(thres)+' m subsidence (draining) variable outline'], \n",
    "        loc='upper right')\n",
    "    # plot inset map to show location \n",
    "    axIns = axes[0,0].inset_axes([0.005, -0.03, 0.3, 0.3])\n",
    "    axIns.patch.set_facecolor('lightskyblue')\n",
    "    axIns.set_aspect('equal')\n",
    "    axIns.scatter(((x_max+x_min)/2), ((y_max+y_min)/2), marker='*', \n",
    "        linewidth=1, edgecolor='k', facecolor='r', s=100, zorder=3)\n",
    "    Scripps_gl.plot(ax=axIns, color='ghostwhite', edgecolor='k', linewidth=0.5, zorder=2)\n",
    "    axIns.axis('off')\n",
    "    # plot dvdt subplot\n",
    "    # axes[0,1].plot(dates, np.divide(np.cumsum(vols_S09), 1e+9), color='k', linestyle=(0, (1, 5)))\n",
    "    # axes[0,1].plot(dates, np.divide(np.cumsum(vols_SF18), 1e+9), color='k', linestyle=(0, (1, 5)))\n",
    "    # axes[0,1].plot(dates, np.divide(np.cumsum(vols_var), 1e+9), color='darkturquoise', linestyle='dashdot')\n",
    "    axes[0,1].plot(dates[:idx+1], np.divide(np.cumsum(vols_S09[:idx+1]), 1e+9), color='darkturquoise', linestyle=(0, (1, 5)))\n",
    "    axes[0,1].plot(dates[:idx+1], np.divide(np.cumsum(vols_SF18[:idx+1]), 1e+9), color='darkturquoise', linestyle=(0, (1, 1)))\n",
    "    axes[0,1].plot(dates[:idx+1], np.divide(np.cumsum(vols_var[:idx+1]), 1e+9), color='k', linestyle='dashdot')\n",
    "    locator = mdates.AutoDateLocator(minticks=1, maxticks=7)\n",
    "    formatter = mdates.ConciseDateFormatter(locator)\n",
    "    axes[0,1].xaxis.set_major_locator(locator)\n",
    "    axes[0,1].xaxis.set_major_formatter(formatter)\n",
    "    #axes[1].set_title('dVol', fontsize=17.5)\n",
    "    axes[0,1].set_xlabel('Year', size=15)\n",
    "    axes[0,1].set_ylabel('Volume change [km$^3$]', size=15)\n",
    "    axes[0,1].yaxis.tick_right()\n",
    "    axes[0,1].yaxis.set_label_position(\"right\")\n",
    "    axes[0,1].legend([Smith2009,SiegfriedFricker2018,variable_outlines],\n",
    "        ['Smith and others, 2009 static outline', 'Siegfried & Fricker, 2018 static outline',\n",
    "        '±{} m variable outlines'.format(thres)], \n",
    "        loc='best') \n",
    "\n",
    "    # subset ATL15 data set to region of interest\n",
    "    mask_x = (dataset2.x >= x_min) & (dataset2.x <= x_max)\n",
    "    mask_y = (dataset2.y >= y_min) & (dataset2.y <= y_max)\n",
    "    ds_sub = dataset2.where(mask_x & mask_y, drop=True)\n",
    "    # find magnitude of ice surface deformation in bounding box / find appropriate color map scale\n",
    "    height_anom_pos = []\n",
    "    height_anom_neg = []\n",
    "    for cyc in range(len(ds_sub.time)-1):\n",
    "        pos = np.nanmax(ds_sub.delta_h[cyc+1,:,:]-ds_sub.delta_h[cyc,:,:])\n",
    "        neg = np.nanmin(ds_sub.delta_h[cyc+1,:,:]-ds_sub.delta_h[cyc,:,:])\n",
    "        height_anom_pos += [pos]\n",
    "        height_anom_neg += [neg]\n",
    "    max_height_anom_pos = max(height_anom_pos)\n",
    "    max_height_anom_neg = min(height_anom_neg)\n",
    "    max_height_anom_abs = max(max_height_anom_pos,abs(max_height_anom_neg))\n",
    "    v = np.round(max_height_anom_abs)\n",
    "    dates = []\n",
    "    lkavgdhdt_SF18 = []\n",
    "    lkavgdhdt_var = []\n",
    "    vols_S09 = []\n",
    "    vols_SF18 = []\n",
    "    vols_var = []\n",
    "    norm = plt.Normalize(ds_sub.time.values[0],ds_sub.time.values[-1])    \n",
    "    for idx in range(len(ds_sub.time)-1): \n",
    "        dhdt = ds_sub.delta_h[idx+1,:,:]-ds_sub.delta_h[idx,:,:]\n",
    "        # calculate mid-cycle dates for plotting\n",
    "        if dataset2.fileName == 'mos_2010.5_2021.5.h5':\n",
    "            newdate = datetime.datetime(int(ds_sub.time.values[idx]), 1, 1) + datetime.timedelta(days = (ds_sub.time.values[idx] % 1) * 365.25)\n",
    "            newdate1 = datetime.datetime(int(ds_sub.time.values[idx+1]), 1, 1) + datetime.timedelta(days = (ds_sub.time.values[idx+1] % 1) * 365.25)\n",
    "            midcycdays = newdate1 - newdate\n",
    "            midcycdate = newdate + midcycdays/2\n",
    "            dates += [midcycdate]\n",
    "        elif dataset2.fileName == 'ATL15_AA_0311_01km_001_01.nc':    \n",
    "            date_time_str = '18-01-01'\n",
    "            date_time_obj = datetime.datetime.strptime(date_time_str, '%y-%m-%d')\n",
    "            newdate = date_time_obj + datetime.timedelta(days=ds_sub.time.values[idx])\n",
    "            newdate1 = date_time_obj + datetime.timedelta(days=ds_sub.time.values[idx+1])\n",
    "            midcycdays = newdate1 - newdate\n",
    "            midcycdate = newdate + midcycdays/2\n",
    "            dates += [midcycdate]\n",
    "        # subset data to dhdt diff between orbital cycles of delta_h\n",
    "        dhdt = ds_sub.delta_h[idx+1,:,:]-ds_sub.delta_h[idx,:,:]\n",
    "        # clip data to lake area (first set crs)\n",
    "        dhdt.rio.write_crs(3031, inplace=True)\n",
    "        dhdt_clip_S09 = dhdt.rio.clip(lake_S09.geometry.values, lake_S09.crs, drop=False, invert=False)\n",
    "        dhdt_clip_SF18 = dhdt.rio.clip(lake_SF18.geometry.values, lake_SF18.crs, drop=False, invert=False)\n",
    "        # calculate lake avg. dh/dt and dv/dt time series using published static outlines\n",
    "        avg_lk_dhdt_S09 = np.nanmean(dhdt_clip_S09)\n",
    "        avg_lk_dhdt_SF18 = np.nanmean(dhdt_clip_SF18)\n",
    "        lkavgdhdt_SF18 += [avg_lk_dhdt_SF18]\n",
    "        vol_S09 = avg_lk_dhdt_S09*Smith2009_outlines[Smith2009_outlines['Name'] == lakename_S09].area\n",
    "        vol_SF18 = avg_lk_dhdt_SF18*SiegfriedFricker2018_outlines[SiegfriedFricker2018_outlines['name'] == lakename_SF18]['area (m^2)']\n",
    "        vols_S09 += [vol_S09.values[0]]\n",
    "        vols_SF18 += [vol_SF18.values[0]]\n",
    "        # create contours of ice surface elevation height changes to delineate variable lake outlines\n",
    "        contours_fill = []\n",
    "        contours_drain = []   \n",
    "        polys = []\n",
    "        contour = measure.find_contours(dhdt.values, thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_fill += [contour]\n",
    "        contour = measure.find_contours(dhdt.values, -thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_drain += [contour]\n",
    "        # create mapping conversion factor to map array location to polar stereographic x,y\n",
    "        x_conv = (x_max-x_min)/dhdt.shape[1]\n",
    "        y_conv = (y_max-y_min)/dhdt.shape[0]\n",
    "        # plot variable outlines found in this time slice\n",
    "        # make polygons from variable outlines\n",
    "        for i in range(len(contours_fill)): \n",
    "            for j in range(len(contours_fill[i])):\n",
    "                axes[1,0].plot(x_min+contours_fill[i][j][:, 1]*x_conv, y_max-contours_fill[i][j][:, 0]*y_conv, \n",
    "                color=cmap(norm(ds_sub.time.values[idx])), linestyle=(0, (3, 1, 1, 1)), linewidth=1)\n",
    "                if len(contours_fill[i][j][:, 1]) > 2: \n",
    "                    poly = Polygon(list(zip(contours_fill[i][j][:, 1]*x_conv+x_min, y_max-contours_fill[i][j][:, 0]*y_conv))) \n",
    "                    polys += [poly]\n",
    "        for i in range(len(contours_drain)): \n",
    "            for j in range(len(contours_drain[i])):\n",
    "                axes[1,0].plot(x_min+contours_drain[i][j][:, 1]*x_conv, y_max-contours_drain[i][j][:, 0]*y_conv, color=cmap(norm(ds_sub.time.values[idx])), linestyle=(0, (5, 1)), linewidth=1)\n",
    "                if len(contours_drain[i][j][:, 1]) > 2: \n",
    "                    poly = Polygon(list(zip(contours_drain[i][j][:, 1]*x_conv+x_min, y_max-contours_drain[i][j][:, 0]*y_conv))) \n",
    "                    polys += [poly]\n",
    "        # set area to zero each time step\n",
    "        variable_area = 0\n",
    "        # if polygons are present at time step, \n",
    "        if len(polys) > 0: \n",
    "            # clip data to polygons\n",
    "            dhdt_clip = dhdt.rio.clip(polys, drop=False, invert=False)\n",
    "            # then calculate on-lake averages of dh/dt\n",
    "            avg_lk_dhdt = np.nanmean(dhdt_clip)\n",
    "            # occasionally small polygons will completely clip data resulting in nan's for lake avg. dh/dt\n",
    "            # replace with zeros\n",
    "            if math.isnan(avg_lk_dhdt): \n",
    "                avg_lk_dhdt = 0\n",
    "                lkavgdhdt_var += [avg_lk_dhdt]\n",
    "            else:\n",
    "                lkavgdhdt_var += [avg_lk_dhdt]\n",
    "                # and dv/dt\n",
    "            for i in range(len(polys)):\n",
    "                variable_area = variable_area + polys[i].area\n",
    "            vol_var = avg_lk_dhdt*variable_area\n",
    "            vols_var += [vol_var]\n",
    "        else: \n",
    "            variable_area = 0\n",
    "            avg_lk_dhdt = 0\n",
    "            lkavgdhdt_var += [avg_lk_dhdt]\n",
    "            vol_var = avg_lk_dhdt*variable_area\n",
    "            vols_var += [vol_var]\n",
    "    axes[1,0].set(xlim=(x_min, x_max), ylim=(y_min, y_max))\n",
    "    # change polar stereographic m to km\n",
    "    km_scale = 1e3\n",
    "    ticks_x = ticker.FuncFormatter(lambda x, pos: '{0:g}'.format(x/km_scale))\n",
    "    axes[1,0].xaxis.set_major_formatter(ticks_x)\n",
    "    ticks_y = ticker.FuncFormatter(lambda x, pos: '{0:g}'.format(x/km_scale))\n",
    "    axes[1,0].yaxis.set_major_formatter(ticks_y)  \n",
    "    # adjust ticks\n",
    "    # axes[1,0].set_yticks(np.arange(y_min,y_max,5000))\n",
    "    # axes[1,0].set_xticks(np.arange(y_min,y_max,5000))\n",
    "    # display MOA visual imagery\n",
    "    # axes[1,0].imshow(mpimg.imread('Slessor23.png'), extent=[x_min,x_max,y_min,y_max], alpha=1)\n",
    "    axes[1,0].set_xlabel('x [km]', size=15)\n",
    "    axes[1,0].set_ylabel('y [km]', size=15)\n",
    "    # add colorbar\n",
    "    m = plt.cm.ScalarMappable(cmap=cmap)\n",
    "    m.set_array(np.array([datetime2fracyear(date_idx) for date_idx in dates[0:-1]]))\n",
    "    divider = make_axes_locatable(axes[1,0])\n",
    "    cax = divider.append_axes('bottom', size='2.5%', pad=0.7)\n",
    "    clb = fig.colorbar(m,  cax=cax, orientation='horizontal', ticks=np.array([2019,2020,2021])).set_label('Year', size=15)\n",
    "    # overlay published outlines for visual comparison \n",
    "    Smith2009_outlines.boundary.plot(ax=axes[1,0], color='darkturquoise', linestyle=(0, (1, 5)), linewidth=1)\n",
    "    SiegfriedFricker2018_SF18outlines.boundary.plot(ax=axes[1,0], color='darkturquoise', linestyle=(0, (1, 1)), linewidth=1)\n",
    "    axes[1,0].legend([Smith2009,\n",
    "    SiegfriedFricker2018,\n",
    "    uplift, subsidence],\n",
    "        ['Smith and others, 2009 static outline',\n",
    "        'Siegfried & Fricker, 2018 static outline',\n",
    "        ('+'+str(thres)+' m uplift (filling) variable outline'), '–'+str(thres)+' m subsidence (draining) variable outline'], \n",
    "        loc='upper right')\n",
    "    # plot inset map to show location \n",
    "    axIns = axes[1,0].inset_axes([0.005, -0.03, 0.3, 0.3])\n",
    "    axIns.patch.set_facecolor('lightskyblue')\n",
    "    axIns.set_aspect('equal')\n",
    "    axIns.scatter(((x_max+x_min)/2), ((y_max+y_min)/2), marker='*', \n",
    "        linewidth=1, edgecolor='k', facecolor='r', s=100, zorder=3)\n",
    "    Scripps_gl.plot(ax=axIns, color='ghostwhite', edgecolor='k', linewidth=0.5, zorder=2)\n",
    "    # SiegfriedFricker2018_outlines.boundary.plot(ax=axIns, color='k', linestyle=(0, (1, 1)), linewidth=1)\n",
    "    axIns.axis('off')\n",
    "    # plot dvdt subplot\n",
    "    axes[1,1].plot(dates[:idx+1], np.divide(np.cumsum(vols_S09[:idx+1]), 1e+9), color='darkturquoise', linestyle=(0, (1, 5)))\n",
    "    axes[1,1].plot(dates[:idx+1], np.divide(np.cumsum(vols_SF18[:idx+1]), 1e+9), color='darkturquoise', linestyle=(0, (1, 1)))\n",
    "    axes[1,1].plot(dates[:idx+1], np.divide(np.cumsum(vols_var[:idx+1]), 1e+9), color='k', linestyle='dashdot')\n",
    "    locator = mdates.AutoDateLocator(minticks=1, maxticks=7)\n",
    "    formatter = mdates.ConciseDateFormatter(locator)\n",
    "    axes[1,1].xaxis.set_major_locator(locator)\n",
    "    axes[1,1].xaxis.set_major_formatter(formatter)\n",
    "    min_vol = min(np.divide(min(np.cumsum(vols_S09)), 1e+9), \n",
    "                    np.divide(min(np.cumsum(vols_SF18)), 1e+9), \n",
    "                    np.divide(min(np.cumsum(vols_var)), 1e+9))\n",
    "    max_vol = max(np.divide(max(np.cumsum(vols_S09)), 1e+9), \n",
    "                    np.divide(max(np.cumsum(vols_SF18)), 1e+9), \n",
    "                    np.divide(max(np.cumsum(vols_var)), 1e+9))\n",
    "    if dataset2.fileName == 'mos_2010.5_2021.5.h5':\n",
    "        axes[1,1].set(xlim=(datetime.datetime(int(ds_sub.time.values[0]), 1, 1) + datetime.timedelta(days = (ds_sub.time.values[0] % 1) * 365.25), \n",
    "                            datetime.datetime(int(ds_sub.time.values[-1]), 1, 1) + datetime.timedelta(days = (ds_sub.time.values[-1] % 1) * 365.25)), \n",
    "                    ylim=((min_vol - (max_vol - min_vol)*0.05),\n",
    "                            (max_vol + (max_vol - min_vol)*0.05)))\n",
    "    elif dataset2.fileName == 'ATL15_AA_0311_01km_001_01.nc':    \n",
    "        axes[1,1].set(xlim=(date_time_obj + datetime.timedelta(days=ds_sub.time.values[1]),\n",
    "                            date_time_obj + datetime.timedelta(days=ds_sub.time.values[-1])), \n",
    "                    ylim=((min_vol - (max_vol - min_vol)*0.05), \n",
    "                            (max_vol + (max_vol - min_vol)*0.05)))\n",
    "    # axes[1].set_title('{} dVol'.format(lakename_SF18), pad=7.5, fontsize=17.5)\n",
    "    axes[1,1].set_xlabel('Year', size=15)\n",
    "    axes[1,1].set_ylabel('Volume change [km$^3$]', size=15)\n",
    "    axes[1,1].yaxis.tick_right()\n",
    "    axes[1,1].yaxis.set_label_position(\"right\")\n",
    "    variable_outlines = plt.Line2D((0, 1), (0, 0), color='darkturquoise', linestyle='dashdot', linewidth=2)\n",
    "    axes[1,1].legend([Smith2009,\n",
    "        SiegfriedFricker2018,variable_outlines],\n",
    "                    ['Smith and others, 2009 static outline',\n",
    "        'Siegfried & Fricker, 2018 static outline',\n",
    "        '±{} m variable outlines'.format(thres)], \n",
    "                    loc='upper right')\n",
    "    # save and close figure\n",
    "    plt.savefig('/Users/Wilson/Documents/0-code/1-lakeshores/output_dhdvdt-using-variable-outlines/S09SF18varoutlines_agg_dvdt_plot/S09SF18varoutlines_agg_dvdt_plot-{}.png'\\\n",
    "        .format(lakename_SF18), dpi=300, bbox_inches = \"tight\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tn/2b7yqbx51jxb820_x39chyc80000gn/T/ipykernel_10453/4181291109.py:115: RuntimeWarning: Mean of empty slice\n",
      "  avg_lk_dhdt = np.nanmean(dhdt_clip)\n"
     ]
    }
   ],
   "source": [
    "# test on one lake to ensure working\n",
    "idx=0\n",
    "S09SF18varoutlines_agg_dvdt_plot(S09_SF18_compare_1to1_CS2InSAR[idx][0],S09_SF18_compare_1to1_CS2InSAR[idx][1], 10000, 0.5, CS2_dh, ATL15_dh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tn/2b7yqbx51jxb820_x39chyc80000gn/T/ipykernel_10453/4181291109.py:115: RuntimeWarning: Mean of empty slice\n",
      "  avg_lk_dhdt = np.nanmean(dhdt_clip)\n",
      "/var/folders/tn/2b7yqbx51jxb820_x39chyc80000gn/T/ipykernel_10453/4181291109.py:115: RuntimeWarning: Mean of empty slice\n",
      "  avg_lk_dhdt = np.nanmean(dhdt_clip)\n",
      "/var/folders/tn/2b7yqbx51jxb820_x39chyc80000gn/T/ipykernel_10453/4181291109.py:115: RuntimeWarning: Mean of empty slice\n",
      "  avg_lk_dhdt = np.nanmean(dhdt_clip)\n",
      "/var/folders/tn/2b7yqbx51jxb820_x39chyc80000gn/T/ipykernel_10453/4181291109.py:289: RuntimeWarning: Mean of empty slice\n",
      "  avg_lk_dhdt = np.nanmean(dhdt_clip)\n",
      "/var/folders/tn/2b7yqbx51jxb820_x39chyc80000gn/T/ipykernel_10453/4181291109.py:115: RuntimeWarning: Mean of empty slice\n",
      "  avg_lk_dhdt = np.nanmean(dhdt_clip)\n",
      "/var/folders/tn/2b7yqbx51jxb820_x39chyc80000gn/T/ipykernel_10453/4181291109.py:115: RuntimeWarning: Mean of empty slice\n",
      "  avg_lk_dhdt = np.nanmean(dhdt_clip)\n",
      "/var/folders/tn/2b7yqbx51jxb820_x39chyc80000gn/T/ipykernel_10453/4181291109.py:115: RuntimeWarning: Mean of empty slice\n",
      "  avg_lk_dhdt = np.nanmean(dhdt_clip)\n",
      "/var/folders/tn/2b7yqbx51jxb820_x39chyc80000gn/T/ipykernel_10453/4181291109.py:115: RuntimeWarning: Mean of empty slice\n",
      "  avg_lk_dhdt = np.nanmean(dhdt_clip)\n",
      "/var/folders/tn/2b7yqbx51jxb820_x39chyc80000gn/T/ipykernel_10453/4181291109.py:115: RuntimeWarning: Mean of empty slice\n",
      "  avg_lk_dhdt = np.nanmean(dhdt_clip)\n",
      "/var/folders/tn/2b7yqbx51jxb820_x39chyc80000gn/T/ipykernel_10453/4181291109.py:115: RuntimeWarning: Mean of empty slice\n",
      "  avg_lk_dhdt = np.nanmean(dhdt_clip)\n",
      "/var/folders/tn/2b7yqbx51jxb820_x39chyc80000gn/T/ipykernel_10453/4181291109.py:115: RuntimeWarning: Mean of empty slice\n",
      "  avg_lk_dhdt = np.nanmean(dhdt_clip)\n",
      "/var/folders/tn/2b7yqbx51jxb820_x39chyc80000gn/T/ipykernel_10453/4181291109.py:289: RuntimeWarning: Mean of empty slice\n",
      "  avg_lk_dhdt = np.nanmean(dhdt_clip)\n"
     ]
    }
   ],
   "source": [
    "# cycle through list to generate plots using function\n",
    "for idx in range(len(S09_SF18_compare_1to1_CS2InSAR)):\n",
    "    S09SF18varoutlines_agg_dvdt_plot(S09_SF18_compare_1to1_CS2InSAR[idx][0],S09_SF18_compare_1to1_CS2InSAR[idx][1], 10000, 0.5, CS2_dh, ATL15_dh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare one S09 to one SF18 lakes (one redelineated)\n",
    "# for S09_SF18_compare_1to1_noInSAR\n",
    "def S09SF18varoutlines_agg_dvdt_plot(lakename_S09, lakename_SF18, buffer, thres, dataset1): \n",
    "    '''\n",
    "    Create planview plot of an aggregated times series of variable outlines compared to known lakes alongside dv/dt time series. Uses geopandas buffer created bounding box around known lakes in Siegfried and Fricker, 2018 (SF18) inventory. Creates time-variable outlines using skimage contour to plot variable outline alongside published outlines for comparison. \n",
    "    Inputs: \n",
    "        lakename_SF18: lake of interest from SiegfriedFricker2018_outlines inventory\n",
    "        buffer: horizontal distance in meters away from SF18 lake outline used to create bounding box that is displayed around lake of interest\n",
    "        thres(hold): vertical distance in meters to delineate ice surface deformation contour\n",
    "        dataset: dataset to be analyzed (CS2_dh or ATL15_dh)\n",
    "    Outputs: \n",
    "        Aggregated time-variable lake outlines in regions of known lakes using CryoSat-2 or ICESat-2 ATL15 dh/dt data alongside dVol time series.\n",
    "    '''\n",
    "    # isolate individual lake using gpd buffer\n",
    "    #lake_gpd = Smith2009_outlines.loc[Smith2009_outlines['Name'] == lakename_SF18]\n",
    "    lake_S09 = Smith2009_outlines.loc[Smith2009_outlines['Name'] == lakename_S09]\n",
    "    lake_SF18 = SiegfriedFricker2018_outlines.loc[SiegfriedFricker2018_outlines['name'] == lakename_SF18]\n",
    "    lake_buffer = lake_SF18.buffer(buffer)\n",
    "    # define lake bounding box\n",
    "    x_min = lake_buffer.bounds.values[0,0]; x_max = lake_buffer.bounds.values[0,2]\n",
    "    y_min = lake_buffer.bounds.values[0,1]; y_max = lake_buffer.bounds.values[0,3]\n",
    "    # subset ATL15 data set to region of interest\n",
    "    mask_x = (dataset1.x >= x_min) & (dataset1.x <= x_max)\n",
    "    mask_y = (dataset1.y >= y_min) & (dataset1.y <= y_max)\n",
    "    ds_sub = dataset1.where(mask_x & mask_y, drop=True)\n",
    "    # find magnitude of ice surface deformation in bounding box / find appropriate color map scale\n",
    "    height_anom_pos = []\n",
    "    height_anom_neg = []\n",
    "    for cyc in range(len(ds_sub.time)-1):\n",
    "        pos = np.nanmax(ds_sub.delta_h[cyc+1,:,:]-ds_sub.delta_h[cyc,:,:])\n",
    "        neg = np.nanmin(ds_sub.delta_h[cyc+1,:,:]-ds_sub.delta_h[cyc,:,:])\n",
    "        height_anom_pos += [pos]\n",
    "        height_anom_neg += [neg]\n",
    "    max_height_anom_pos = max(height_anom_pos)\n",
    "    max_height_anom_neg = min(height_anom_neg)\n",
    "    max_height_anom_abs = max(max_height_anom_pos,abs(max_height_anom_neg))\n",
    "    v = np.round(max_height_anom_abs)\n",
    "    dates = []\n",
    "    lkavgdhdt_SF18 = []\n",
    "    lkavgdhdt_var = []\n",
    "    vols_S09 = []\n",
    "    vols_SF18 = []\n",
    "    vols_var = []\n",
    "    # plot figure\n",
    "    fig, axes = plt.subplots(1,2, figsize=(20,10))\n",
    "    # plt.subplots_adjust(wspace=0.10, hspace = 0.1)\n",
    "    cmap = plt.get_cmap('CMRmap')\n",
    "    norm = plt.Normalize(ds_sub.time.values[0],ds_sub.time.values[-1])    \n",
    "    for idx in range(len(ds_sub.time)-1): \n",
    "        dhdt = ds_sub.delta_h[idx+1,:,:]-ds_sub.delta_h[idx,:,:]\n",
    "        # calculate mid-cycle dates for plotting\n",
    "        if dataset1.fileName == 'mos_2010.5_2021.5.h5':\n",
    "            newdate = datetime.datetime(int(ds_sub.time.values[idx]), 1, 1) + datetime.timedelta(days = (ds_sub.time.values[idx] % 1) * 365.25)\n",
    "            newdate1 = datetime.datetime(int(ds_sub.time.values[idx+1]), 1, 1) + datetime.timedelta(days = (ds_sub.time.values[idx+1] % 1) * 365.25)\n",
    "            midcycdays = newdate1 - newdate\n",
    "            midcycdate = newdate + midcycdays/2\n",
    "            dates += [midcycdate]\n",
    "        elif dataset1.fileName == 'ATL15_AA_0311_01km_001_01.nc':    \n",
    "            date_time_str = '18-01-01'\n",
    "            date_time_obj = datetime.datetime.strptime(date_time_str, '%y-%m-%d')\n",
    "            newdate = date_time_obj + datetime.timedelta(days=ds_sub.time.values[idx])\n",
    "            newdate1 = date_time_obj + datetime.timedelta(days=ds_sub.time.values[idx+1])\n",
    "            midcycdays = newdate1 - newdate\n",
    "            midcycdate = newdate + midcycdays/2\n",
    "            dates += [midcycdate]\n",
    "        # subset data to dhdt diff between orbital cycles of delta_h\n",
    "        dhdt = ds_sub.delta_h[idx+1,:,:]-ds_sub.delta_h[idx,:,:]\n",
    "        # clip ATL15 data to just show (first set crs)\n",
    "        dhdt.rio.write_crs(3031, inplace=True)\n",
    "        dhdt_clip_S09 = dhdt.rio.clip(lake_S09.geometry.values, lake_S09.crs, drop=False, invert=False)\n",
    "        dhdt_clip_SF18 = dhdt.rio.clip(lake_SF18.geometry.values, lake_SF18.crs, drop=False, invert=False)\n",
    "        # calculate lake avg. dh/dt and dv/dt time series using published static outlines\n",
    "        avg_lk_dhdt_S09 = np.nanmean(dhdt_clip_S09)\n",
    "        avg_lk_dhdt_SF18 = np.nanmean(dhdt_clip_SF18)\n",
    "        lkavgdhdt_SF18 += [avg_lk_dhdt_SF18]\n",
    "        vol_S09 = avg_lk_dhdt_S09*Smith2009_outlines[Smith2009_outlines['Name'] == lakename_S09].area\n",
    "        vol_SF18 = avg_lk_dhdt_SF18*SiegfriedFricker2018_outlines[SiegfriedFricker2018_outlines['name'] == lakename_SF18]['area (m^2)']\n",
    "        vols_S09 += [vol_S09.values[0]]\n",
    "        vols_SF18 += [vol_SF18.values[0]]\n",
    "        # create contours of ice surface elevation height changes to delineate variable lake outlines\n",
    "        contours_fill = []\n",
    "        contours_drain = []   \n",
    "        polys = []\n",
    "        contour = measure.find_contours(dhdt.values, thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_fill += [contour]\n",
    "        contour = measure.find_contours(dhdt.values, -thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_drain += [contour]\n",
    "        # create mapping conversion factor to map array location to polar stereographic x,y\n",
    "        x_conv = (x_max-x_min)/dhdt.shape[1]\n",
    "        y_conv = (y_max-y_min)/dhdt.shape[0]\n",
    "        # plot variable outlines found in this time slice\n",
    "        # make polygons from variable outlines\n",
    "        for i in range(len(contours_fill)): \n",
    "            for j in range(len(contours_fill[i])):\n",
    "                axes[0].plot(x_min+contours_fill[i][j][:, 1]*x_conv, y_max-contours_fill[i][j][:, 0]*y_conv, \n",
    "                color=cmap(norm(ds_sub.time.values[idx])), linestyle=(0, (3, 1, 1, 1)), linewidth=1)\n",
    "                if len(contours_fill[i][j][:, 1]) > 2: \n",
    "                    poly = Polygon(list(zip(contours_fill[i][j][:, 1]*x_conv+x_min, y_max-contours_fill[i][j][:, 0]*y_conv))) \n",
    "                    polys += [poly]\n",
    "        for i in range(len(contours_drain)): \n",
    "            for j in range(len(contours_drain[i])):\n",
    "                axes[0].plot(x_min+contours_drain[i][j][:, 1]*x_conv, y_max-contours_drain[i][j][:, 0]*y_conv, color=cmap(norm(ds_sub.time.values[idx])), linestyle=(0, (5, 1)), linewidth=1)\n",
    "                if len(contours_drain[i][j][:, 1]) > 2: \n",
    "                    poly = Polygon(list(zip(contours_drain[i][j][:, 1]*x_conv+x_min, y_max-contours_drain[i][j][:, 0]*y_conv))) \n",
    "                    polys += [poly]\n",
    "        # set area to zero each time step\n",
    "        variable_area = 0\n",
    "        # if polygons are present at time step, \n",
    "        if len(polys) > 0: \n",
    "            # clip data to polygons\n",
    "            dhdt_clip = dhdt.rio.clip(polys, drop=False, invert=False)\n",
    "            # then calculate on-lake averages of dh/dt\n",
    "            avg_lk_dhdt = np.nanmean(dhdt_clip)\n",
    "            # occasionally small polygons will completely clip data resulting in nan's for lake avg. dh/dt\n",
    "            # replace with zeros\n",
    "            if math.isnan(avg_lk_dhdt): \n",
    "                avg_lk_dhdt = 0\n",
    "                lkavgdhdt_var += [avg_lk_dhdt]\n",
    "            else:\n",
    "                lkavgdhdt_var += [avg_lk_dhdt]\n",
    "                # and dv/dt\n",
    "            for i in range(len(polys)):\n",
    "                variable_area = variable_area + polys[i].area\n",
    "            vol_var = avg_lk_dhdt*variable_area\n",
    "            vols_var += [vol_var]\n",
    "        else: \n",
    "            variable_area = 0\n",
    "            avg_lk_dhdt = 0\n",
    "            lkavgdhdt_var += [avg_lk_dhdt]\n",
    "            vol_var = avg_lk_dhdt*variable_area\n",
    "            vols_var += [vol_var]\n",
    "    axes[0].set(xlim=(x_min, x_max), ylim=(y_min, y_max))\n",
    "    # change polar stereographic m to km\n",
    "    km_scale = 1e3\n",
    "    ticks_x = ticker.FuncFormatter(lambda x, pos: '{0:g}'.format(x/km_scale))\n",
    "    axes[0].xaxis.set_major_formatter(ticks_x)\n",
    "    ticks_y = ticker.FuncFormatter(lambda y, pos: '{0:g}'.format(y/km_scale))\n",
    "    axes[0].yaxis.set_major_formatter(ticks_y)\n",
    "    # adjust ticks\n",
    "    # axes[0,0].set_xticks(np.arange(y_min,y_max,5000))\n",
    "    # axes[0,0].set_yticks(np.arange(y_min,y_max,5000))\n",
    "    # display MOA visual imagery\n",
    "    # axes[0,0].imshow(mpimg.imread('Whillans_7.png'), extent=[x_min1,x_max1,y_min1,y_max1], alpha=1)\n",
    "    axes[0].set_xlabel('x [km]', size=15)\n",
    "    axes[0].set_ylabel('y [km]', size=15)\n",
    "    # axes[0].ticklabel_format(axis='both',scilimits=(0,0))\n",
    "    # axes[0].set_title('outline comparison', pad=7.5, fontsize=17.5)\n",
    "    m = plt.cm.ScalarMappable(cmap=cmap)\n",
    "    m.set_array(np.array([datetime2fracyear(date_idx) for date_idx in dates[0:-1]]))\n",
    "    divider = make_axes_locatable(axes[0])\n",
    "    cax = divider.append_axes('bottom', size='2.5%', pad=0.7)\n",
    "    clb = fig.colorbar(m,  cax=cax, orientation='horizontal', ticks=np.array([2019,2020,2021])).set_label('Year', size=15)\n",
    "    # overlay published outlines for visual comparison \n",
    "    Smith2009_outlines.boundary.plot(ax=axes[0], color='darkturquoise', linestyle=(0, (1, 5)), linewidth=1)\n",
    "    SiegfriedFricker2018_SF18outlines.boundary.plot(ax=axes[0], color='darkturquoise', linestyle=(0, (1, 1)), linewidth=1)\n",
    "    # create lines for legends\n",
    "    Smith2009 = plt.Line2D((0, 1), (0, 0), color='darkturquoise', linestyle=(0, (1, 5)), linewidth=2)\n",
    "    SiegfriedFricker2018 = plt.Line2D((0, 1), (0, 0), color='darkturquoise', linestyle=(0, (1, 1)), linewidth=2)\n",
    "    uplift = plt.Line2D((0, 1), (0, 0), color='k', linestyle=(0, (3, 1, 1, 1)), linewidth=2)\n",
    "    subsidence = plt.Line2D((0, 1), (0, 0), color='k', linestyle=(0, (5, 1)), linewidth=1)\n",
    "    variable_outlines = plt.Line2D((0, 1), (0, 0), color='k', linestyle='dashdot', linewidth=2)\n",
    "    axes[0].legend([Smith2009,\n",
    "    SiegfriedFricker2018,\n",
    "    uplift, subsidence],\n",
    "        ['Smith and others, 2009 static outline',\n",
    "        'Siegfried & Fricker, 2018 outline',\n",
    "        ('+'+str(thres)+' m uplift (filling) variable outline'), '–'+str(thres)+' m subsidence (draining) variable outline'], \n",
    "        loc='upper right')\n",
    "    # plot inset map to show location \n",
    "    axIns = axes[0].inset_axes([0.005, -0.03, 0.3, 0.3])\n",
    "    axIns.patch.set_facecolor('lightskyblue')\n",
    "    axIns.set_aspect('equal')\n",
    "    axIns.scatter(((x_max+x_min)/2), ((y_max+y_min)/2), marker='*', \n",
    "        linewidth=1, edgecolor='k', facecolor='r', s=100, zorder=3)\n",
    "    Scripps_gl.plot(ax=axIns, color='ghostwhite', edgecolor='k', linewidth=0.5, zorder=2)\n",
    "    axIns.axis('off')\n",
    "    # plot dvdt subplot\n",
    "    # axes[0,1].plot(dates, np.divide(np.cumsum(vols_S09), 1e+9), color='k', linestyle=(0, (1, 5)))\n",
    "    # axes[0,1].plot(dates, np.divide(np.cumsum(vols_SF18), 1e+9), color='k', linestyle=(0, (1, 5)))\n",
    "    # axes[0,1].plot(dates, np.divide(np.cumsum(vols_var), 1e+9), color='darkturquoise', linestyle='dashdot')\n",
    "    axes[1].plot(dates[:idx+1], np.divide(np.cumsum(vols_S09[:idx+1]), 1e+9), color='darkturquoise', linestyle=(0, (1, 5)))\n",
    "    axes[1].plot(dates[:idx+1], np.divide(np.cumsum(vols_SF18[:idx+1]), 1e+9), color='darkturquoise', linestyle=(0, (1, 1)))\n",
    "    axes[1].plot(dates[:idx+1], np.divide(np.cumsum(vols_var[:idx+1]), 1e+9), color='k', linestyle='dashdot')\n",
    "    locator = mdates.AutoDateLocator(minticks=1, maxticks=7)\n",
    "    formatter = mdates.ConciseDateFormatter(locator)\n",
    "    axes[1].xaxis.set_major_locator(locator)\n",
    "    axes[1].xaxis.set_major_formatter(formatter)\n",
    "    #axes[1].set_title('dVol', fontsize=17.5)\n",
    "    axes[1].set_xlabel('Year', size=15)\n",
    "    axes[1].set_ylabel('Volume change [km$^3$]', size=15)\n",
    "    axes[1].yaxis.tick_right()\n",
    "    axes[1].yaxis.set_label_position(\"right\")\n",
    "    axes[1].legend([Smith2009,SiegfriedFricker2018,variable_outlines],\n",
    "        ['Smith and others, 2009 static outline', 'Siegfried & Fricker, 2018 static outline',\n",
    "        '±{} m variable outlines'.format(thres)], \n",
    "        loc='best') \n",
    "    # save and close figure\n",
    "    plt.savefig('/Users/Wilson/Documents/0-code/1-lakeshores/output_dhdvdt-using-variable-outlines/S09SF18varoutlines_agg_dvdt_plot/S09SF18varoutlines_agg_dvdt_plot-{}.png'\\\n",
    "        .format(lakename_SF18), dpi=300, bbox_inches = \"tight\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test on one lake to ensure working\n",
    "idx=0\n",
    "S09SF18varoutlines_agg_dvdt_plot(S09_SF18_compare_1to1_noInSAR[idx][0],S09_SF18_compare_1to1_noInSAR[idx][1], 10000, 0.5, ATL15_dh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cycle through list to generate plots using function\n",
    "for idx in range(len(S09_SF18_compare_1to1_noInSAR)):\n",
    "    S09SF18varoutlines_agg_dvdt_plot(S09_SF18_compare_1to1_noInSAR[idx][0],S09_SF18_compare_1to1_noInSAR[idx][1], 10000, 0.5, ATL15_dh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Func S09SF18varoutlines_dhdvdt_anim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding S09 area/vol calculations\n",
    "def S09SF18varoutlines_dhdvdt_anim_coords(lakename_S09, lakename_SF18, buffer, thres, dataset): \n",
    "    '''\n",
    "    Create dh/dt plots ice surface height changes using geopandas buffer created bounding box around known lakes in Siegfried and Fricker, 2018 inventory.\n",
    "    Create time-variable outlines using skimage contour to plot variable outline alongside published outlines for comparison. \n",
    "    Use time-variable outlines to calculate dv/dt.\n",
    "    Save images together into GIF animation.\n",
    "    Inputs: \n",
    "        lakename: lake of interest from SiegfriedFricker2018_outlines inventory\n",
    "        buffer: horizontal distance in meters to create bounding box around lake of interest\n",
    "        thres(hold): vertical distance in meters to delineate ice surface deformation contour\n",
    "        dataset: dataset to be analyzed (CS2_dh or ATL15_dh)\n",
    "    Outputs: \n",
    "        Animations of planview dh/dt visuals with variable ice surface deformation contours plotted to delineate time-variable lake boundary alongside 2-D line plots of cumulative dVol using static and variable outlines that updates simultaneously to planview dh/dt animation.\n",
    "    '''\n",
    "    # isolate individual lake using gpd buffer\n",
    "    #lake_gpd = Smith2009_outlines.loc[Smith2009_outlines['Name'] == lakename]\n",
    "    lake_S09 = Smith2009_outlines.loc[Smith2009_outlines['Name'] == lakename_S09]\n",
    "    lake_SF18 = SiegfriedFricker2018_outlines.loc[SiegfriedFricker2018_outlines['name'] == lakename_SF18]\n",
    "    lake_buffer = lake_SF18.buffer(buffer)\n",
    "    # define lake bounding box\n",
    "    x_min = lake_buffer.bounds.values[0,0]; x_max = lake_buffer.bounds.values[0,2]\n",
    "    y_min = lake_buffer.bounds.values[0,1]; y_max = lake_buffer.bounds.values[0,3]\n",
    "    # subset ATL15 data set to region of interest\n",
    "    mask_x = (dataset.x >= x_min) & (dataset.x <= x_max)\n",
    "    mask_y = (dataset.y >= y_min) & (dataset.y <= y_max)\n",
    "    ds_sub = dataset.where(mask_x & mask_y, drop=True)\n",
    "    # find magnitude of ice surface deformation in bounding box / find appropriate color map scale\n",
    "    height_anom_pos = []\n",
    "    height_anom_neg = []\n",
    "    for cyc in range(len(ds_sub.time)-1):\n",
    "        pos = np.nanmax(ds_sub.delta_h[cyc+1,:,:]-ds_sub.delta_h[cyc,:,:])\n",
    "        neg = np.nanmin(ds_sub.delta_h[cyc+1,:,:]-ds_sub.delta_h[cyc,:,:])\n",
    "        height_anom_pos += [pos]\n",
    "        height_anom_neg += [neg]\n",
    "    max_height_anom_pos = max(height_anom_pos)\n",
    "    max_height_anom_neg = min(height_anom_neg)\n",
    "    max_height_anom_abs = max(max_height_anom_pos,abs(max_height_anom_neg))\n",
    "    v = np.round(max_height_anom_abs)\n",
    "    # create empty lists to store calculated data\n",
    "    dates = []\n",
    "    lkavgdhdt_SF18 = []\n",
    "    lkavgdhdt_var = []\n",
    "    vols_S09 = []\n",
    "    vols_SF18 = []\n",
    "    vols_var = []\n",
    "    for idx in range(len(ds_sub.delta_h)-1): \n",
    "        dhdt = ds_sub.delta_h[idx+1,:,:]-ds_sub.delta_h[idx,:,:]\n",
    "        # calculate mid-cycle dates for plotting\n",
    "        if dataset.fileName == 'mos_2010.5_2021.5.h5':\n",
    "            newdate = datetime.datetime(int(ds_sub.time.values[idx]), 1, 1) + datetime.timedelta(days = (ds_sub.time.values[idx] % 1) * 365.25)\n",
    "            newdate1 = datetime.datetime(int(ds_sub.time.values[idx+1]), 1, 1) + datetime.timedelta(days = (ds_sub.time.values[idx+1] % 1) * 365.25)\n",
    "            midcycdays = newdate1 - newdate\n",
    "            midcycdate = newdate + midcycdays/2\n",
    "            dates += [midcycdate]\n",
    "        elif dataset.fileName == 'ATL15_AA_0311_01km_001_01.nc':    \n",
    "            date_time_str = '18-01-01'\n",
    "            date_time_obj = datetime.datetime.strptime(date_time_str, '%y-%m-%d')\n",
    "            newdate = date_time_obj + datetime.timedelta(days=ds_sub.time.values[idx])\n",
    "            newdate1 = date_time_obj + datetime.timedelta(days=ds_sub.time.values[idx+1])\n",
    "            midcycdays = newdate1 - newdate\n",
    "            midcycdate = newdate + midcycdays/2\n",
    "            dates += [midcycdate]\n",
    "        # clip ATL15 data to just show (first set crs)\n",
    "        dhdt.rio.write_crs(3031, inplace=True)\n",
    "        dhdt_clip_S09 = dhdt.rio.clip(lake_S09.geometry.values, lake_S09.crs, drop=False, invert=False)\n",
    "        dhdt_clip_SF18 = dhdt.rio.clip(lake_SF18.geometry.values, lake_SF18.crs, drop=False, invert=False)\n",
    "        # calculate lake avg. dh/dt and dv/dt time series using published stationary outlines\n",
    "        avg_lk_dhdt_S09 = np.nanmean(dhdt_clip_S09)\n",
    "        avg_lk_dhdt_SF18 = np.nanmean(dhdt_clip_SF18)\n",
    "        lkavgdhdt_SF18 += [avg_lk_dhdt_SF18]\n",
    "        vol_S09 = avg_lk_dhdt_S09*Smith2009_outlines[Smith2009_outlines['Name'] == lakename_S09].area\n",
    "        vol_SF18 = avg_lk_dhdt_SF18*SiegfriedFricker2018_outlines[SiegfriedFricker2018_outlines['name'] == lakename_SF18]['area (m^2)']\n",
    "        vols_S09 += [vol_S09.values[0]]\n",
    "        vols_SF18 += [vol_SF18.values[0]]\n",
    "        # create contours of ice surface elevation height changes to delineate lake outlines\n",
    "        contours_fill = []\n",
    "        contours_drain = []\n",
    "        polys = []\n",
    "        contour = measure.find_contours(dhdt.values, thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_fill += [contour]\n",
    "        contour = measure.find_contours(dhdt.values, -thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_drain += [contour]\n",
    "        # create mapping conversion factor to map array location to polar stereographic x,y\n",
    "        x_conv = (x_max-x_min)/dhdt.shape[1]\n",
    "        y_conv = (y_max-y_min)/dhdt.shape[0]\n",
    "        # make polygons from variable outlines\n",
    "        for i in range(len(contours_fill)): \n",
    "            for j in range(len(contours_fill[i])):\n",
    "                if len(contours_fill[i][j][:, 1]) > 2: \n",
    "                    poly = Polygon(list(zip(x_min+contours_fill[i][j][:, 1]*x_conv, y_max-contours_fill[i][j][:, 0]*y_conv))) \n",
    "                    polys += [poly]\n",
    "        for i in range(len(contours_drain)): \n",
    "            for j in range(len(contours_drain[i])):\n",
    "                if len(contours_drain[i][j][:, 1]) > 2: \n",
    "                    poly = Polygon(list(zip(x_min+contours_drain[i][j][:, 1]*x_conv, y_max-contours_drain[i][j][:, 0]*y_conv))) \n",
    "                    polys += [poly]\n",
    "        # start with baseline variable outline area of zero\n",
    "        variable_area = 0\n",
    "        # if polygons are present at time step, \n",
    "        if len(polys) > 0: \n",
    "            # clip data to polygons (first set crs)\n",
    "            # dhdt.rio.write_crs(3031, inplace=True) # done earlier in code, may not be needed here\n",
    "            dhdt_clip = dhdt.rio.clip(polys, drop=False, invert=False)\n",
    "            # then calculate on-lake averages of dh/dt\n",
    "            avg_lk_dhdt = np.nanmean(dhdt_clip)\n",
    "            # occasionally small polygons will completely clip data resulting in nan's for lake avg. dh/dt\n",
    "            # replace with zeros\n",
    "            if math.isnan(avg_lk_dhdt): \n",
    "                avg_lk_dhdt = 0\n",
    "                lkavgdhdt_var += [avg_lk_dhdt]\n",
    "            else:\n",
    "                lkavgdhdt_var += [avg_lk_dhdt]\n",
    "            # and dv/dt\n",
    "            for i in range(len(polys)):\n",
    "                variable_area = variable_area + polys[i].area # CHANGE TO GEODESIC AREA\n",
    "            vol_var = avg_lk_dhdt*variable_area\n",
    "            vols_var += [vol_var]\n",
    "        else: \n",
    "            avg_lk_dhdt = 0\n",
    "            lkavgdhdt_var += [avg_lk_dhdt]\n",
    "            vol_var = avg_lk_dhdt*variable_area\n",
    "            vols_var += [vol_var]\n",
    "    # create colorbar axis\n",
    "    fig, axes = plt.subplots(1,2, figsize=(20,10))\n",
    "    # fig.suptitle('{} outline and dVol comparison'.format(lakename_SF18), fontsize=24)\n",
    "    fig.suptitle('Mercer outline and $\\Delta$volume comparison', fontsize=30)\n",
    "    divider = make_axes_locatable(axes[0])\n",
    "    cax = divider.append_axes('right', size='5%', pad=0.2)\n",
    "    # create empty list to store animation im(age)s\n",
    "    ani = animation.PillowWriter(fps=1)\n",
    "    if dataset.fileName == 'mos_2010.5_2021.5.h5':\n",
    "        ani.setup(fig, '/Users/Wilson/Documents/0-code/1-lakeshores/output_dhdvdt-using-variable-outlines/S09SF18varoutlines_dhdvdt_anim/S09SF18varoutlines_dhdvdt_anim-{}-{}.gif'.format(lakename_SF18, 'CS2'), dpi=300)\n",
    "    elif dataset.fileName == 'ATL15_AA_0311_01km_001_01.nc':    \n",
    "        ani.setup(fig, '/Users/Wilson/Documents/0-code/1-lakeshores/output_dhdvdt-using-variable-outlines/S09SF18varoutlines_dhdvdt_anim/S09SF18varoutlines_dhdvdt_anim-{}-{}.gif'.format(lakename_SF18, 'IS2'), dpi=300)\n",
    "    for idx in range(len(ds_sub.delta_h)-1): \n",
    "        dhdt = ds_sub.delta_h[idx+1,:,:]-ds_sub.delta_h[idx,:,:]\n",
    "        img = axes[0].imshow(dhdt, extent=[x_min, x_max, y_min, y_max], \n",
    "            origin='upper', cmap=cmocean.cm.balance_r, vmin=-v, vmax=v)\n",
    "        # create contours of ice surface elevation height changes to delineate lake outlines\n",
    "        contours_fill = []\n",
    "        contours_drain = []\n",
    "        contour = measure.find_contours(dhdt.values, thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_fill += [contour]\n",
    "        contour = measure.find_contours(dhdt.values, -thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_drain += [contour]\n",
    "        # subplot 1: plot variable outlines found in this time slice\n",
    "        for i in range(len(contours_fill)): \n",
    "            for j in range(len(contours_fill[i])):\n",
    "                axes[0].plot(x_min+contours_fill[i][j][:, 1]*x_conv, y_max-contours_fill[i][j][:, 0]*y_conv, color='mediumblue', linestyle='dashdot', linewidth=2)\n",
    "        for i in range(len(contours_drain)): \n",
    "            for j in range(len(contours_drain[i])):\n",
    "                axes[0].plot(x_min+contours_drain[i][j][:, 1]*x_conv, y_max-contours_drain[i][j][:, 0]*y_conv, color='maroon', linestyle=(0, (3, 1, 1, 1)), linewidth=2)\n",
    "        axes[0].set(xlim=(x_min, x_max), ylim=(y_min, y_max))\n",
    "        axes[0].set_xlabel('polar stereographic x [m]', size=15)\n",
    "        axes[0].set_ylabel('polar stereographic y [m]', size=15)\n",
    "        axes[0].ticklabel_format(axis='both',scilimits=(0,0))\n",
    "        axes[0].set_title('dh/dt $h_{'+dates[idx].strftime('%m/%Y')+'} - h_{'+dates[idx-1].strftime('%m/%Y')+'}$', pad=7.5, fontsize=17.5)\n",
    "        fig.colorbar(img, cax=cax).set_label('Height (h) change [m]', size=15)\n",
    "        # overlay published outlines for visual comparison \n",
    "        Smith2009_outlines.boundary.plot(ax=axes[0], color='k', linestyle='--', linewidth=1)\n",
    "        SiegfriedFricker2018_outlines[SiegfriedFricker2018_outlines['cite'] != 'Smith and others, 2009, J. Glac., doi:10.3189/002214309789470879']\\\n",
    "            .boundary.plot(ax=axes[0], color='k', linestyle='-', linewidth=1)\n",
    "        Smith2009 = plt.Line2D((0, 1), (0, 0), color='k', linestyle='--', linewidth=2)\n",
    "        SiegfriedFricker2018 = plt.Line2D((0, 1), (0, 0), color='k', linestyle='-', linewidth=2)\n",
    "        uplift = plt.Line2D((0, 1), (0, 0), color='mediumblue', linestyle='dashdot', linewidth=2)\n",
    "        subsidence = plt.Line2D((0, 1), (0, 0), color='maroon', linestyle=(0, (3, 1, 1, 1)), linewidth=2)\n",
    "        axes[0].legend([Smith2009,SiegfriedFricker2018,uplift, subsidence],\n",
    "            ['Smith and others, 2009 static outline','Siegfried & Fricker, 2018 static outline',\n",
    "            ('+'+str(thres)+' m uplift (filling) variable outline'), '–'+str(thres)+' m subsidence (draining) variable outline'], \n",
    "            loc='upper right')\n",
    "        # plot inset map to show location \n",
    "        axIns = axes[0].inset_axes([0.001, 0.77, 0.25, 0.25])\n",
    "        axIns.patch.set_facecolor('lightskyblue')\n",
    "        axIns.set_aspect('equal')\n",
    "        axIns.scatter(((x_max+x_min)/2), ((y_max+y_min)/2), marker='*', \n",
    "            linewidth=1, edgecolor='k', facecolor='r', s=100, zorder=3)\n",
    "        Scripps_gl.plot(ax=axIns, color='ghostwhite', edgecolor='k', linewidth=0.5, zorder=2)\n",
    "        SiegfriedFricker2018_outlines.boundary.plot(ax=axIns, color='k', linestyle=(0, (1, 1)), linewidth=1)\n",
    "        axIns.axis('off')\n",
    "        # suplot 2: plot volume change time series\n",
    "        axes[1].plot(dates[:idx+1], np.divide(np.cumsum(vols_S09[:idx+1]), 1e+9), color='k', linestyle='--')\n",
    "        axes[1].plot(dates[:idx+1], np.divide(np.cumsum(vols_SF18[:idx+1]), 1e+9), color='k', linestyle='-')\n",
    "        axes[1].plot(dates[:idx+1], np.divide(np.cumsum(vols_var[:idx+1]), 1e+9), color='darkturquoise', linestyle='dashdot')\n",
    "        locator = mdates.AutoDateLocator(minticks=1, maxticks=7)\n",
    "        formatter = mdates.ConciseDateFormatter(locator)\n",
    "        axes[1].xaxis.set_major_locator(locator)\n",
    "        axes[1].xaxis.set_major_formatter(formatter)\n",
    "        min_vol = min(np.divide(min(np.cumsum(vols_S09)), 1e+9), \n",
    "                        np.divide(min(np.cumsum(vols_SF18)), 1e+9), \n",
    "                        np.divide(min(np.cumsum(vols_var)), 1e+9))\n",
    "        max_vol = max(np.divide(max(np.cumsum(vols_S09)), 1e+9), \n",
    "                        np.divide(max(np.cumsum(vols_SF18)), 1e+9), \n",
    "                        np.divide(max(np.cumsum(vols_var)), 1e+9))\n",
    "        if dataset.fileName == 'mos_2010.5_2021.5.h5':\n",
    "            axes[1].set(xlim=(datetime.datetime(int(ds_sub.time.values[0]), 1, 1) + datetime.timedelta(days = (ds_sub.time.values[0] % 1) * 365.25), \n",
    "                                datetime.datetime(int(ds_sub.time.values[-1]), 1, 1) + datetime.timedelta(days = (ds_sub.time.values[-1] % 1) * 365.25)), \n",
    "                        ylim=((min_vol - (max_vol - min_vol)*0.05),\n",
    "                                (max_vol + (max_vol - min_vol)*0.05)))\n",
    "        elif dataset.fileName == 'ATL15_AA_0311_01km_001_01.nc':    \n",
    "            axes[1].set(xlim=(date_time_obj + datetime.timedelta(days=ds_sub.time.values[1]),\n",
    "                                date_time_obj + datetime.timedelta(days=ds_sub.time.values[-1])), \n",
    "                        ylim=((min_vol - (max_vol - min_vol)*0.05), \n",
    "                                (max_vol + (max_vol - min_vol)*0.05)))\n",
    "        # axes[1].set_title('{} dVol'.format(lakename_SF18), pad=7.5, fontsize=17.5)\n",
    "        axes[1].set_xlabel('Year', size=15)\n",
    "        axes[1].set_ylabel('Volume change [km$^3$]', size=15)\n",
    "        axes[1].yaxis.tick_right()\n",
    "        axes[1].yaxis.set_label_position(\"right\")\n",
    "        variable_outlines = plt.Line2D((0, 1), (0, 0), color='darkturquoise', linestyle='dashdot', linewidth=2)\n",
    "        axes[1].legend([Smith2009,\n",
    "            SiegfriedFricker2018,variable_outlines],\n",
    "                        ['Smith and others, 2009 static outline',\n",
    "            'Siegfried & Fricker, 2018 static outline',\n",
    "            '±{} m variable outlines'.format(thres)], \n",
    "                        loc='upper left')\n",
    "        # append im(age) to ims list\n",
    "        ani.grab_frame()\n",
    "        axes[0].clear()\n",
    "    # create animation and save, adjust interval\n",
    "    ani.finish()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding S09 area/vol calculations\n",
    "def S09SF18varoutlines_dhdvdt_anim_coords(x_min, x_max, y_min, y_max, lakename_S09, lakename_SF18, buffer, thres, dataset): \n",
    "    '''\n",
    "    Create dh/dt plots ice surface height changes using geopandas buffer created bounding box around known lakes in Siegfried and Fricker, 2018 inventory.\n",
    "    Create time-variable outlines using skimage contour to plot variable outline alongside published outlines for comparison. \n",
    "    Use time-variable outlines to calculate dv/dt.\n",
    "    Save images together into GIF animation.\n",
    "    Inputs: \n",
    "        lakename: lake of interest from SiegfriedFricker2018_outlines inventory\n",
    "        buffer: horizontal distance in meters to create bounding box around lake of interest\n",
    "        thres(hold): vertical distance in meters to delineate ice surface deformation contour\n",
    "        dataset: dataset to be analyzed (CS2_dh or ATL15_dh)\n",
    "    Outputs: \n",
    "        Animations of planview dh/dt visuals with variable ice surface deformation contours plotted to delineate time-variable lake boundary alongside 2-D line plots of cumulative dVol using static and variable outlines that updates simultaneously to planview dh/dt animation.\n",
    "    '''\n",
    "    # isolate individual lake using gpd buffer\n",
    "    #lake_gpd = Smith2009_outlines.loc[Smith2009_outlines['Name'] == lakename]\n",
    "    lake_S09 = Smith2009_outlines.loc[Smith2009_outlines['Name'] == lakename_S09]\n",
    "    lake_SF18 = SiegfriedFricker2018_outlines.loc[SiegfriedFricker2018_outlines['name'] == lakename_SF18]\n",
    "    lake_buffer = lake_SF18.buffer(buffer)\n",
    "    # define lake bounding box\n",
    "    # x_min = lake_buffer.bounds.values[0,0]; x_max = lake_buffer.bounds.values[0,2]\n",
    "    # y_min = lake_buffer.bounds.values[0,1]; y_max = lake_buffer.bounds.values[0,3]\n",
    "    # subset ATL15 data set to region of interest\n",
    "    mask_x = (dataset.x >= x_min) & (dataset.x <= x_max)\n",
    "    mask_y = (dataset.y >= y_min) & (dataset.y <= y_max)\n",
    "    ds_sub = dataset.where(mask_x & mask_y, drop=True)\n",
    "    # find magnitude of ice surface deformation in bounding box / find appropriate color map scale\n",
    "    height_anom_pos = []\n",
    "    height_anom_neg = []\n",
    "    for cyc in range(len(ds_sub.time)-1):\n",
    "        pos = np.nanmax(ds_sub.delta_h[cyc+1,:,:]-ds_sub.delta_h[cyc,:,:])\n",
    "        neg = np.nanmin(ds_sub.delta_h[cyc+1,:,:]-ds_sub.delta_h[cyc,:,:])\n",
    "        height_anom_pos += [pos]\n",
    "        height_anom_neg += [neg]\n",
    "    max_height_anom_pos = max(height_anom_pos)\n",
    "    max_height_anom_neg = min(height_anom_neg)\n",
    "    max_height_anom_abs = max(max_height_anom_pos,abs(max_height_anom_neg))\n",
    "    v = np.round(max_height_anom_abs)\n",
    "    # create empty lists to store calculated data\n",
    "    dates = []\n",
    "    lkavgdhdt_SF18 = []\n",
    "    lkavgdhdt_var = []\n",
    "    vols_S09 = []\n",
    "    vols_SF18 = []\n",
    "    vols_var = []\n",
    "    for idx in range(len(ds_sub.delta_h)-1): \n",
    "        dhdt = ds_sub.delta_h[idx+1,:,:]-ds_sub.delta_h[idx,:,:]\n",
    "        # calculate mid-cycle dates for plotting\n",
    "        if dataset.fileName == 'mos_2010.5_2021.5.h5':\n",
    "            newdate = datetime.datetime(int(ds_sub.time.values[idx]), 1, 1) + datetime.timedelta(days = (ds_sub.time.values[idx] % 1) * 365.25)\n",
    "            newdate1 = datetime.datetime(int(ds_sub.time.values[idx+1]), 1, 1) + datetime.timedelta(days = (ds_sub.time.values[idx+1] % 1) * 365.25)\n",
    "            midcycdays = newdate1 - newdate\n",
    "            midcycdate = newdate + midcycdays/2\n",
    "            dates += [midcycdate]\n",
    "        elif dataset.fileName == 'ATL15_AA_0311_01km_001_01.nc':    \n",
    "            date_time_str = '18-01-01'\n",
    "            date_time_obj = datetime.datetime.strptime(date_time_str, '%y-%m-%d')\n",
    "            newdate = date_time_obj + datetime.timedelta(days=ds_sub.time.values[idx])\n",
    "            newdate1 = date_time_obj + datetime.timedelta(days=ds_sub.time.values[idx+1])\n",
    "            midcycdays = newdate1 - newdate\n",
    "            midcycdate = newdate + midcycdays/2\n",
    "            dates += [midcycdate]\n",
    "        # clip ATL15 data to just show (first set crs)\n",
    "        dhdt.rio.write_crs(3031, inplace=True)\n",
    "        dhdt_clip_S09 = dhdt.rio.clip(lake_S09.geometry.values, lake_S09.crs, drop=False, invert=False)\n",
    "        dhdt_clip_SF18 = dhdt.rio.clip(lake_SF18.geometry.values, lake_SF18.crs, drop=False, invert=False)\n",
    "        # calculate lake avg. dh/dt and dv/dt time series using published stationary outlines\n",
    "        avg_lk_dhdt_S09 = np.nanmean(dhdt_clip_S09)\n",
    "        avg_lk_dhdt_SF18 = np.nanmean(dhdt_clip_SF18)\n",
    "        lkavgdhdt_SF18 += [avg_lk_dhdt_SF18]\n",
    "        vol_S09 = avg_lk_dhdt_S09*Smith2009_outlines[Smith2009_outlines['Name'] == lakename_S09].area\n",
    "        vol_SF18 = avg_lk_dhdt_SF18*SiegfriedFricker2018_outlines[SiegfriedFricker2018_outlines['name'] == lakename_SF18]['area (m^2)']\n",
    "        vols_S09 += [vol_S09.values[0]]\n",
    "        vols_SF18 += [vol_SF18.values[0]]\n",
    "        # create contours of ice surface elevation height changes to delineate lake outlines\n",
    "        contours_fill = []\n",
    "        contours_drain = []\n",
    "        polys = []\n",
    "        contour = measure.find_contours(dhdt.values, thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_fill += [contour]\n",
    "        contour = measure.find_contours(dhdt.values, -thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_drain += [contour]\n",
    "        # create mapping conversion factor to map array location to polar stereographic x,y\n",
    "        x_conv = (x_max-x_min)/dhdt.shape[1]\n",
    "        y_conv = (y_max-y_min)/dhdt.shape[0]\n",
    "        # make polygons from variable outlines\n",
    "        for i in range(len(contours_fill)): \n",
    "            for j in range(len(contours_fill[i])):\n",
    "                if len(contours_fill[i][j][:, 1]) > 2: \n",
    "                    poly = Polygon(list(zip(x_min+contours_fill[i][j][:, 1]*x_conv, y_max-contours_fill[i][j][:, 0]*y_conv))) \n",
    "                    polys += [poly]\n",
    "        for i in range(len(contours_drain)): \n",
    "            for j in range(len(contours_drain[i])):\n",
    "                if len(contours_drain[i][j][:, 1]) > 2: \n",
    "                    poly = Polygon(list(zip(x_min+contours_drain[i][j][:, 1]*x_conv, y_max-contours_drain[i][j][:, 0]*y_conv))) \n",
    "                    polys += [poly]\n",
    "        # start with baseline variable outline area of zero\n",
    "        variable_area = 0\n",
    "        # if polygons are present at time step, \n",
    "        if len(polys) > 0: \n",
    "            # clip data to polygons (first set crs)\n",
    "            # dhdt.rio.write_crs(3031, inplace=True) # done earlier in code, may not be needed here\n",
    "            dhdt_clip = dhdt.rio.clip(polys, drop=False, invert=False)\n",
    "            # then calculate on-lake averages of dh/dt\n",
    "            avg_lk_dhdt = np.nanmean(dhdt_clip)\n",
    "            # occasionally small polygons will completely clip data resulting in nan's for lake avg. dh/dt\n",
    "            # replace with zeros\n",
    "            if math.isnan(avg_lk_dhdt): \n",
    "                avg_lk_dhdt = 0\n",
    "                lkavgdhdt_var += [avg_lk_dhdt]\n",
    "            else:\n",
    "                lkavgdhdt_var += [avg_lk_dhdt]\n",
    "            # and dv/dt\n",
    "            for i in range(len(polys)):\n",
    "                variable_area = variable_area + polys[i].area # CHANGE TO GEODESIC AREA\n",
    "            vol_var = avg_lk_dhdt*variable_area\n",
    "            vols_var += [vol_var]\n",
    "        else: \n",
    "            avg_lk_dhdt = 0\n",
    "            lkavgdhdt_var += [avg_lk_dhdt]\n",
    "            vol_var = avg_lk_dhdt*variable_area\n",
    "            vols_var += [vol_var]\n",
    "    # create colorbar axis\n",
    "    fig, axes = plt.subplots(1,2, figsize=(20,10))\n",
    "    # fig.suptitle('{} outline and dVol comparison'.format(lakename_SF18), fontsize=24)\n",
    "    fig.suptitle('Mercer outline and $\\Delta$volume comparison', fontsize=30)\n",
    "    divider = make_axes_locatable(axes[0])\n",
    "    cax = divider.append_axes('right', size='5%', pad=0.2)\n",
    "    # create empty list to store animation im(age)s\n",
    "    ani = animation.PillowWriter(fps=1)\n",
    "    if dataset.fileName == 'mos_2010.5_2021.5.h5':\n",
    "        ani.setup(fig, '/Users/Wilson/Documents/0-code/1-lakeshores/output_dhdvdt-using-variable-outlines/S09SF18varoutlines_dhdvdt_anim/S09SF18varoutlines_dhdvdt_anim-{}-{}.gif'.format(lakename_SF18, 'CS2'), dpi=300)\n",
    "    elif dataset.fileName == 'ATL15_AA_0311_01km_001_01.nc':    \n",
    "        ani.setup(fig, '/Users/Wilson/Documents/0-code/1-lakeshores/output_dhdvdt-using-variable-outlines/S09SF18varoutlines_dhdvdt_anim/S09SF18varoutlines_dhdvdt_anim-{}-{}.gif'.format(lakename_SF18, 'IS2'), dpi=300)\n",
    "    for idx in range(len(ds_sub.delta_h)-1): \n",
    "        dhdt = ds_sub.delta_h[idx+1,:,:]-ds_sub.delta_h[idx,:,:]\n",
    "        img = axes[0].imshow(dhdt, extent=[x_min, x_max, y_min, y_max], \n",
    "            origin='upper', cmap=cmocean.cm.balance_r, vmin=-v, vmax=v)\n",
    "        # create contours of ice surface elevation height changes to delineate lake outlines\n",
    "        contours_fill = []\n",
    "        contours_drain = []\n",
    "        contour = measure.find_contours(dhdt.values, thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_fill += [contour]\n",
    "        contour = measure.find_contours(dhdt.values, -thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_drain += [contour]\n",
    "        # subplot 1: plot variable outlines found in this time slice\n",
    "        for i in range(len(contours_fill)): \n",
    "            for j in range(len(contours_fill[i])):\n",
    "                axes[0].plot(x_min+contours_fill[i][j][:, 1]*x_conv, y_max-contours_fill[i][j][:, 0]*y_conv, color='mediumblue', linestyle='dashdot', linewidth=2)\n",
    "        for i in range(len(contours_drain)): \n",
    "            for j in range(len(contours_drain[i])):\n",
    "                axes[0].plot(x_min+contours_drain[i][j][:, 1]*x_conv, y_max-contours_drain[i][j][:, 0]*y_conv, color='maroon', linestyle=(0, (3, 1, 1, 1)), linewidth=2)\n",
    "        axes[0].set(xlim=(x_min, x_max), ylim=(y_min, y_max))\n",
    "        axes[0].set_xlabel('polar stereographic x [m]', size=15)\n",
    "        axes[0].set_ylabel('polar stereographic y [m]', size=15)\n",
    "        axes[0].ticklabel_format(axis='both',scilimits=(0,0))\n",
    "        axes[0].set_title('dh/dt $h_{'+dates[idx].strftime('%m/%Y')+'} - h_{'+dates[idx-1].strftime('%m/%Y')+'}$', pad=7.5, fontsize=17.5)\n",
    "        fig.colorbar(img, cax=cax).set_label('Height (h) change [m]', size=15)\n",
    "        # overlay published outlines for visual comparison \n",
    "        Smith2009_outlines.boundary.plot(ax=axes[0], color='k', linestyle='--', linewidth=1)\n",
    "        SiegfriedFricker2018_outlines[SiegfriedFricker2018_outlines['cite'] != 'Smith and others, 2009, J. Glac., doi:10.3189/002214309789470879']\\\n",
    "            .boundary.plot(ax=axes[0], color='k', linestyle='-', linewidth=1)\n",
    "        Smith2009 = plt.Line2D((0, 1), (0, 0), color='k', linestyle='--', linewidth=2)\n",
    "        SiegfriedFricker2018 = plt.Line2D((0, 1), (0, 0), color='k', linestyle='-', linewidth=2)\n",
    "        uplift = plt.Line2D((0, 1), (0, 0), color='mediumblue', linestyle='dashdot', linewidth=2)\n",
    "        subsidence = plt.Line2D((0, 1), (0, 0), color='maroon', linestyle=(0, (3, 1, 1, 1)), linewidth=2)\n",
    "        axes[0].legend([Smith2009,SiegfriedFricker2018,uplift, subsidence],\n",
    "            ['Smith and others, 2009 static outline','Siegfried & Fricker, 2018 static outline',\n",
    "            ('+'+str(thres)+' m uplift (filling) variable outline'), '–'+str(thres)+' m subsidence (draining) variable outline'], \n",
    "            loc='upper right')\n",
    "        # plot inset map to show location \n",
    "        axIns = axes[0].inset_axes([0.001, 0.77, 0.25, 0.25])\n",
    "        axIns.patch.set_facecolor('lightskyblue')\n",
    "        axIns.set_aspect('equal')\n",
    "        axIns.scatter(((x_max+x_min)/2), ((y_max+y_min)/2), marker='*', \n",
    "            linewidth=1, edgecolor='k', facecolor='r', s=100, zorder=3)\n",
    "        Scripps_gl.plot(ax=axIns, color='ghostwhite', edgecolor='k', linewidth=0.5, zorder=2)\n",
    "        SiegfriedFricker2018_outlines.boundary.plot(ax=axIns, color='k', linestyle=(0, (1, 1)), linewidth=1)\n",
    "        axIns.axis('off')\n",
    "        # suplot 2: plot volume change time series\n",
    "        axes[1].plot(dates[:idx+1], np.divide(np.cumsum(vols_S09[:idx+1]), 1e+9), color='k', linestyle='--')\n",
    "        axes[1].plot(dates[:idx+1], np.divide(np.cumsum(vols_SF18[:idx+1]), 1e+9), color='k', linestyle='-')\n",
    "        axes[1].plot(dates[:idx+1], np.divide(np.cumsum(vols_var[:idx+1]), 1e+9), color='darkturquoise', linestyle='dashdot')\n",
    "        locator = mdates.AutoDateLocator(minticks=1, maxticks=7)\n",
    "        formatter = mdates.ConciseDateFormatter(locator)\n",
    "        axes[1].xaxis.set_major_locator(locator)\n",
    "        axes[1].xaxis.set_major_formatter(formatter)\n",
    "        min_vol = min(np.divide(min(np.cumsum(vols_S09)), 1e+9), \n",
    "                        np.divide(min(np.cumsum(vols_SF18)), 1e+9), \n",
    "                        np.divide(min(np.cumsum(vols_var)), 1e+9))\n",
    "        max_vol = max(np.divide(max(np.cumsum(vols_S09)), 1e+9), \n",
    "                        np.divide(max(np.cumsum(vols_SF18)), 1e+9), \n",
    "                        np.divide(max(np.cumsum(vols_var)), 1e+9))\n",
    "        if dataset.fileName == 'mos_2010.5_2021.5.h5':\n",
    "            axes[1].set(xlim=(datetime.datetime(int(ds_sub.time.values[0]), 1, 1) + datetime.timedelta(days = (ds_sub.time.values[0] % 1) * 365.25), \n",
    "                                datetime.datetime(int(ds_sub.time.values[-1]), 1, 1) + datetime.timedelta(days = (ds_sub.time.values[-1] % 1) * 365.25)), \n",
    "                        ylim=((min_vol - (max_vol - min_vol)*0.05),\n",
    "                                (max_vol + (max_vol - min_vol)*0.05)))\n",
    "        elif dataset.fileName == 'ATL15_AA_0311_01km_001_01.nc':    \n",
    "            axes[1].set(xlim=(date_time_obj + datetime.timedelta(days=ds_sub.time.values[1]),\n",
    "                                date_time_obj + datetime.timedelta(days=ds_sub.time.values[-1])), \n",
    "                        ylim=((min_vol - (max_vol - min_vol)*0.05), \n",
    "                                (max_vol + (max_vol - min_vol)*0.05)))\n",
    "        # axes[1].set_title('{} dVol'.format(lakename_SF18), pad=7.5, fontsize=17.5)\n",
    "        axes[1].set_xlabel('Year', size=15)\n",
    "        axes[1].set_ylabel('Volume change [km$^3$]', size=15)\n",
    "        axes[1].yaxis.tick_right()\n",
    "        axes[1].yaxis.set_label_position(\"right\")\n",
    "        variable_outlines = plt.Line2D((0, 1), (0, 0), color='darkturquoise', linestyle='dashdot', linewidth=2)\n",
    "        axes[1].legend([Smith2009,\n",
    "            SiegfriedFricker2018,variable_outlines],\n",
    "                        ['Smith and others, 2009 static outline',\n",
    "            'Siegfried & Fricker, 2018 static outline',\n",
    "            '±{} m variable outlines'.format(thres)], \n",
    "                        loc='upper left')\n",
    "        # append im(age) to ims list\n",
    "        ani.grab_frame()\n",
    "        axes[0].clear()\n",
    "    # create animation and save, adjust interval\n",
    "    ani.finish()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding middle panel of areal extent for fall 2022 IS2 sci symposium\n",
    "def S09SF18varoutlines_dhdadvdt_anim_coords(x_min, x_max, y_min, y_max, lakename_S09, lakename_SF18, buffer, thres, dataset): \n",
    "    '''\n",
    "    Create dh/dt plots ice surface height changes using geopandas buffer created bounding box around known lakes in Siegfried and Fricker, 2018 inventory.\n",
    "    Create time-variable outlines using skimage contour to plot variable outline alongside published outlines for comparison. \n",
    "    Use time-variable outlines to calculate dv/dt.\n",
    "    Save images together into GIF animation.\n",
    "    Inputs: \n",
    "        lakename: lake of interest from SiegfriedFricker2018_outlines inventory\n",
    "        buffer: horizontal distance in meters to create bounding box around lake of interest\n",
    "        thres(hold): vertical distance in meters to delineate ice surface deformation contour\n",
    "        dataset: dataset to be analyzed (CS2_dh or ATL15_dh)\n",
    "    Outputs: \n",
    "        Animations of planview dh/dt visuals with variable ice surface deformation contours plotted to delineate time-variable lake boundary alongside 2-D line plots of cumulative dVol using static and variable outlines that updates simultaneously to planview dh/dt animation.\n",
    "    '''\n",
    "    # isolate individual lake using gpd buffer\n",
    "    lake_S09 = Smith2009_outlines.loc[Smith2009_outlines['Name'] == lakename_S09]\n",
    "    lake_SF18 = SiegfriedFricker2018_outlines.loc[SiegfriedFricker2018_outlines['name'] == lakename_SF18]\n",
    "    lake_buffer = lake_S09.buffer(buffer)\n",
    "    # lake_buffer = lake_SF18.buffer(buffer)\n",
    "    # define lake bounding box\n",
    "    # x_min = lake_buffer.bounds.values[0,0]; x_max = lake_buffer.bounds.values[0,2]\n",
    "    # y_min = lake_buffer.bounds.values[0,1]; y_max = lake_buffer.bounds.values[0,3]\n",
    "    # subset ATL15 data set to region of interest\n",
    "    mask_x = (dataset.x >= x_min) & (dataset.x <= x_max)\n",
    "    mask_y = (dataset.y >= y_min) & (dataset.y <= y_max)\n",
    "    ds_sub = dataset.where(mask_x & mask_y, drop=True)\n",
    "    # find magnitude of ice surface deformation in bounding box / find appropriate color map scale\n",
    "    height_anom_pos = []\n",
    "    height_anom_neg = []\n",
    "    for cyc in range(len(ds_sub.time)-1):\n",
    "        pos = np.nanmax(ds_sub.delta_h[cyc+1,:,:]-ds_sub.delta_h[cyc,:,:])\n",
    "        neg = np.nanmin(ds_sub.delta_h[cyc+1,:,:]-ds_sub.delta_h[cyc,:,:])\n",
    "        height_anom_pos += [pos]\n",
    "        height_anom_neg += [neg]\n",
    "    max_height_anom_pos = max(height_anom_pos)\n",
    "    max_height_anom_neg = min(height_anom_neg)\n",
    "    max_height_anom_abs = max(max_height_anom_pos,abs(max_height_anom_neg))\n",
    "    v = np.round(max_height_anom_abs)\n",
    "    # create empty lists to store calculated data\n",
    "    dates = []\n",
    "    lkavgdhdt_SF18 = []\n",
    "    lkavgdhdt_var = []\n",
    "    areas_var = []\n",
    "    vols_S09 = []\n",
    "    # vols_SF18 = []\n",
    "    vols_var = []\n",
    "    for idx in range(len(ds_sub.delta_h)-1): \n",
    "        dhdt = ds_sub.delta_h[idx+1,:,:]-ds_sub.delta_h[idx,:,:]\n",
    "        # calculate mid-cycle dates for plotting\n",
    "        if dataset.fileName == 'mos_2010.5_2021.5.h5':\n",
    "            newdate = datetime.datetime(int(ds_sub.time.values[idx]), 1, 1) + datetime.timedelta(days = (ds_sub.time.values[idx] % 1) * 365.25)\n",
    "            newdate1 = datetime.datetime(int(ds_sub.time.values[idx+1]), 1, 1) + datetime.timedelta(days = (ds_sub.time.values[idx+1] % 1) * 365.25)\n",
    "            midcycdays = newdate1 - newdate\n",
    "            midcycdate = newdate + midcycdays/2\n",
    "            dates += [midcycdate]\n",
    "        elif dataset.fileName == 'ATL15_AA_0311_01km_001_01.nc':    \n",
    "            date_time_str = '18-01-01'\n",
    "            date_time_obj = datetime.datetime.strptime(date_time_str, '%y-%m-%d')\n",
    "            newdate = date_time_obj + datetime.timedelta(days=ds_sub.time.values[idx])\n",
    "            newdate1 = date_time_obj + datetime.timedelta(days=ds_sub.time.values[idx+1])\n",
    "            midcycdays = newdate1 - newdate\n",
    "            midcycdate = newdate + midcycdays/2\n",
    "            dates += [midcycdate]\n",
    "        # clip ATL15 data to just show (first set crs)\n",
    "        dhdt.rio.write_crs(3031, inplace=True)\n",
    "        dhdt_clip_S09 = dhdt.rio.clip(lake_S09.geometry.values, lake_S09.crs, drop=False, invert=False)\n",
    "        dhdt_clip_SF18 = dhdt.rio.clip(lake_SF18.geometry.values, lake_SF18.crs, drop=False, invert=False)\n",
    "        # calculate lake avg. dh/dt and dv/dt time series using published stationary outlines\n",
    "        avg_lk_dhdt_S09 = np.nanmean(dhdt_clip_S09)\n",
    "        avg_lk_dhdt_SF18 = np.nanmean(dhdt_clip_SF18)\n",
    "        lkavgdhdt_SF18 += [avg_lk_dhdt_SF18]\n",
    "        vol_S09 = avg_lk_dhdt_S09*Smith2009_outlines[Smith2009_outlines['Name'] == lakename_S09].area\n",
    "        #vol_SF18 = avg_lk_dhdt_SF18*SiegfriedFricker2018_outlines[SiegfriedFricker2018_outlines['name'] == lakename_SF18]['area (m^2)']\n",
    "        vols_S09 += [vol_S09.values[0]]\n",
    "        # vols_SF18 += [vol_SF18.values[0]]\n",
    "        # create contours of ice surface elevation height changes to delineate lake outlines\n",
    "        contours_fill = []\n",
    "        contours_drain = []\n",
    "        polys = []\n",
    "        contour = measure.find_contours(dhdt.values, thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_fill += [contour]\n",
    "        contour = measure.find_contours(dhdt.values, -thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_drain += [contour]\n",
    "        # create mapping conversion factor to map array location to polar stereographic x,y\n",
    "        x_conv = (x_max-x_min)/dhdt.shape[1]\n",
    "        y_conv = (y_max-y_min)/dhdt.shape[0]\n",
    "        # make polygons from variable outlines\n",
    "        for i in range(len(contours_fill)): \n",
    "            for j in range(len(contours_fill[i])):\n",
    "                if len(contours_fill[i][j][:, 1]) > 2: \n",
    "                    poly = Polygon(list(zip(x_min+contours_fill[i][j][:, 1]*x_conv, y_max-contours_fill[i][j][:, 0]*y_conv))) \n",
    "                    polys += [poly]\n",
    "        for i in range(len(contours_drain)): \n",
    "            for j in range(len(contours_drain[i])):\n",
    "                if len(contours_drain[i][j][:, 1]) > 2: \n",
    "                    poly = Polygon(list(zip(x_min+contours_drain[i][j][:, 1]*x_conv, y_max-contours_drain[i][j][:, 0]*y_conv))) \n",
    "                    polys += [poly]\n",
    "        # start with baseline variable outline area of zero\n",
    "        variable_area = 0\n",
    "        # if polygons are present at time step, \n",
    "        if len(polys) > 0: \n",
    "            # clip data to polygons (first set crs)\n",
    "            # dhdt.rio.write_crs(3031, inplace=True) # done earlier in code, may not be needed here\n",
    "            dhdt_clip = dhdt.rio.clip(polys, drop=False, invert=False)\n",
    "            # then calculate on-lake averages of dh/dt\n",
    "            avg_lk_dhdt = np.nanmean(dhdt_clip)\n",
    "            # occasionally small polygons will completely clip data resulting in nan's for lake avg. dh/dt\n",
    "            # replace with zeros\n",
    "            if math.isnan(avg_lk_dhdt): \n",
    "                avg_lk_dhdt = 0\n",
    "                lkavgdhdt_var += [avg_lk_dhdt]\n",
    "            else:\n",
    "                lkavgdhdt_var += [avg_lk_dhdt]                \n",
    "            # and dv/dt\n",
    "            for i in range(len(polys)):\n",
    "                variable_area = variable_area + polys[i].area # CHANGE TO GEODESIC AREA\n",
    "            vol_var = avg_lk_dhdt*variable_area\n",
    "            vols_var += [vol_var]\n",
    "            # store areas in list \n",
    "            areas_var += [variable_area]\n",
    "        else: \n",
    "            avg_lk_dhdt = 0\n",
    "            lkavgdhdt_var += [avg_lk_dhdt]\n",
    "            vol_var = avg_lk_dhdt*variable_area\n",
    "            vols_var += [vol_var]\n",
    "            # store areas in list \n",
    "            areas_var += [variable_area]\n",
    "    # create colorbar axis\n",
    "    fig, axes = plt.subplots(1,3, figsize=(31,10))\n",
    "    fig.subplots_adjust(wspace=0.3)\n",
    "    # fig.suptitle('{} outline and dVol comparison'.format(lakename_SF18), fontsize=24)\n",
    "    # fig.suptitle('Mercer outline, areal extent, and $\\Delta$volume comparison', fontsize=30)\n",
    "    divider = make_axes_locatable(axes[0])\n",
    "    cax = divider.append_axes('right', size='5%', pad=0.2)\n",
    "    # create empty list to store animation im(age)s\n",
    "    ani = animation.PillowWriter(fps=1)\n",
    "    if dataset.fileName == 'mos_2010.5_2021.5.h5':\n",
    "        ani.setup(fig, '/Users/Wilson/Documents/0-code/1-lakeshores/output_dhdvdt-using-variable-outlines/S09SF18varoutlines_dhdadvdt_anim/S09SF18varoutlines_dhdadvdt_anim-{}-{}.gif'.format(lakename_SF18, 'CS2'), dpi=300)\n",
    "    elif dataset.fileName == 'ATL15_AA_0311_01km_001_01.nc':    \n",
    "        ani.setup(fig, '/Users/Wilson/Documents/0-code/1-lakeshores/output_dhdvdt-using-variable-outlines/S09SF18varoutlines_dhdadvdt_anim/S09SF18varoutlines_dhdadvdt_anim-{}-{}.gif'.format(lakename_SF18, 'IS2'), dpi=300)\n",
    "    for idx in range(len(ds_sub.delta_h)-1): \n",
    "        dhdt = ds_sub.delta_h[idx+1,:,:]-ds_sub.delta_h[idx,:,:]\n",
    "        img = axes[0].imshow(dhdt, extent=[x_min, x_max, y_min, y_max],\n",
    "            origin='upper', cmap=cmocean.cm.balance_r, vmin=-v, vmax=v)\n",
    "        # create contours of ice surface elevation height changes to delineate lake outlines\n",
    "        contours_fill = []\n",
    "        contours_drain = []\n",
    "        contour = measure.find_contours(dhdt.values, thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_fill += [contour]\n",
    "        contour = measure.find_contours(dhdt.values, -thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_drain += [contour]\n",
    "        # subplot 0: plot variable outlines found in this time slice\n",
    "        for i in range(len(contours_fill)): \n",
    "            for j in range(len(contours_fill[i])):\n",
    "                axes[0].plot(x_min+contours_fill[i][j][:, 1]*x_conv, y_max-contours_fill[i][j][:, 0]*y_conv, color='mediumblue', linestyle='dashdot', linewidth=2)\n",
    "        for i in range(len(contours_drain)): \n",
    "            for j in range(len(contours_drain[i])):\n",
    "                axes[0].plot(x_min+contours_drain[i][j][:, 1]*x_conv, y_max-contours_drain[i][j][:, 0]*y_conv, color='maroon', linestyle=(0, (3, 1, 1, 1)), linewidth=2)\n",
    "        # Change polar stereographic m to km\n",
    "        km_scale = 1e3\n",
    "        ticks_x = ticker.FuncFormatter(lambda x, pos: '{0:g}'.format(x/km_scale))\n",
    "        axes[0].xaxis.set_major_formatter(ticks_x)\n",
    "        ticks_y = ticker.FuncFormatter(lambda x, pos: '{0:g}'.format(x/km_scale))\n",
    "        axes[0].yaxis.set_major_formatter(ticks_y)  \n",
    "        # adjust ticks\n",
    "        axes[0].set_xticks(np.arange(x_min,x_max,5000))\n",
    "        axes[0].set_yticks(np.arange(y_min,y_max,5000))\n",
    "        axes[0].set(xlim=(x_min, x_max), ylim=(y_min, y_max))\n",
    "        axes[0].set_xlabel('x [km]', size=15)\n",
    "        axes[0].set_ylabel('y [km]', size=15)\n",
    "        axes[0].set_title('dh $h_{'+dates[idx].strftime('%m/%Y')+'} - h_{'+dates[idx-1].strftime('%m/%Y')+'}$', pad=7.5, fontsize=17.5)\n",
    "        fig.colorbar(img, cax=cax).set_label('Height (h) change [m]', size=15)\n",
    "        # overlay published outlines for visual comparison \n",
    "        Smith2009_outlines.boundary.plot(ax=axes[0], color='k', linestyle='--', linewidth=1)\n",
    "        SiegfriedFricker2018_outlines[SiegfriedFricker2018_outlines['cite'] != 'Smith and others, 2009, J. Glac., doi:10.3189/002214309789470879']\\\n",
    "            .boundary.plot(ax=axes[0], color='k', linestyle='-', linewidth=1)\n",
    "        Smith2009 = plt.Line2D((0, 1), (0, 0), color='k', linestyle='--', linewidth=2)\n",
    "        SiegfriedFricker2018 = plt.Line2D((0, 1), (0, 0), color='k', linestyle='-', linewidth=2)\n",
    "        uplift = plt.Line2D((0, 1), (0, 0), color='mediumblue', linestyle='dashdot', linewidth=2)\n",
    "        subsidence = plt.Line2D((0, 1), (0, 0), color='maroon', linestyle=(0, (3, 1, 1, 1)), linewidth=2)\n",
    "        axes[0].legend([Smith2009,\n",
    "            # SiegfriedFricker2018,\n",
    "            uplift, subsidence],\n",
    "            ['Smith and others, 2009 static outline',\n",
    "            # 'Siegfried & Fricker, 2018 static outline',\n",
    "            ('+'+str(thres)+' m uplift (filling) variable outline'), '–'+str(thres)+' m subsidence (draining) variable outline'], \n",
    "            loc='upper right')\n",
    "        # plot inset map to show location \n",
    "        axIns = axes[0].inset_axes([0.001, -0.01, 0.25, 0.25])\n",
    "        axIns.patch.set_facecolor('lightskyblue')\n",
    "        axIns.set_aspect('equal')\n",
    "        axIns.scatter(((x_max+x_min)/2), ((y_max+y_min)/2), marker='*', \n",
    "            linewidth=1, edgecolor='k', facecolor='r', s=100, zorder=3)\n",
    "        Scripps_gl.plot(ax=axIns, color='ghostwhite', edgecolor='k', linewidth=0.5, zorder=2)\n",
    "        SiegfriedFricker2018_outlines.boundary.plot(ax=axIns, color='k', linestyle=(0, (1, 1)), linewidth=1)\n",
    "        axIns.axis('off')\n",
    "        # suplot 1: plot area change time series\n",
    "        # axes[1].axhline(np.divide(Smith2009_outlines[Smith2009_outlines['Name'] == lakename_S09].area.values[0], 1e6), color='k', linestyle='--')\n",
    "        axes[1].axhline(np.divide(SiegfriedFricker2018_outlines[SiegfriedFricker2018_outlines['name'] == lakename_SF18]['area (m^2)'].values[0], 1e6), color='k', linestyle='-')\n",
    "        axes[1].plot(dates[:idx+1], np.divide(areas_var[:idx+1], 1e6), color='darkturquoise', linestyle='dashdot')\n",
    "        locator = mdates.AutoDateLocator(minticks=1, maxticks=7)\n",
    "        formatter = mdates.ConciseDateFormatter(locator)\n",
    "        axes[1].xaxis.set_major_locator(locator)\n",
    "        axes[1].xaxis.set_major_formatter(formatter)\n",
    "        min_area = min(#Smith2009_outlines[Smith2009_outlines['Name'] == lakename_S09].area.values[0], \n",
    "                        #SiegfriedFricker2018_outlines[SiegfriedFricker2018_outlines['name'] == lakename_SF18]['area (m^2)'].values[0], \n",
    "                    #   min(\n",
    "                        np.divide(np.cumsum(areas_var),1e6))\n",
    "        max_area = max(#Smith2009_outlines[Smith2009_outlines['Name'] == lakename_S09].area.values[0], \n",
    "                        #SiegfriedFricker2018_outlines[SiegfriedFricker2018_outlines['name'] == lakename_SF18]['area (m^2)'].values[0], \n",
    "                    #   max(\n",
    "                        np.divide(np.cumsum(areas_var),1e6))\n",
    "        if dataset.fileName == 'mos_2010.5_2021.5.h5':\n",
    "            axes[1].set(xlim=(datetime.datetime(int(ds_sub.time.values[0]), 1, 1) + datetime.timedelta(days = (ds_sub.time.values[0] % 1) * 365.25), \n",
    "                                datetime.datetime(int(ds_sub.time.values[-1]), 1, 1) + datetime.timedelta(days = (ds_sub.time.values[-1] % 1) * 365.25)), \n",
    "                        ylim=((0,#min_area - (max_area - min_area)*0.05),\n",
    "                                (max_area + (max_area - min_area)*0.05))))\n",
    "        elif dataset.fileName == 'ATL15_AA_0311_01km_001_01.nc':    \n",
    "            axes[1].set(xlim=(date_time_obj + datetime.timedelta(days=ds_sub.time.values[1]),\n",
    "                                date_time_obj + datetime.timedelta(days=ds_sub.time.values[-1])), \n",
    "                        ylim=(0,np.divide(200000000,1e6)))#(min_area - (max_area - min_area)*0.05), \n",
    "                            #   (max_area + (max_area - min_area)*0.05)))\n",
    "        # axes[1].set_title('{} dVol'.format(lakename_SF18), pad=7.5, fontsize=17.5)\n",
    "        axes[1].set_xlabel('Year', size=15)\n",
    "        axes[1].set_ylabel('Areal extent [km$^2$]', size=15)\n",
    "        axes[1].yaxis.tick_right()\n",
    "        axes[1].yaxis.set_label_position(\"right\")\n",
    "        variable_outlines = plt.Line2D((0, 1), (0, 0), color='darkturquoise', linestyle='dashdot', linewidth=2)\n",
    "        axes[1].legend([Smith2009,\n",
    "            # SiegfriedFricker2018,\n",
    "            variable_outlines],\n",
    "                        ['Smith and others, 2009 static outline',\n",
    "            # 'Siegfried & Fricker, 2018 static outline',\n",
    "            '±{} m variable outlines'.format(thres)], \n",
    "                        loc='upper left')\n",
    "        # suplot 2: plot volume change time series\n",
    "        axes[2].plot(dates[:idx+1], np.divide(np.cumsum(vols_S09[:idx+1]), 1e+9), color='k', linestyle='--')\n",
    "        # axes[2].plot(dates[:idx+1], np.divide(np.cumsum(vols_SF18[:idx+1]), 1e+9), color='k', linestyle='-')\n",
    "        axes[2].plot(dates[:idx+1], np.divide(np.cumsum(vols_var[:idx+1]), 1e+9), color='darkturquoise', linestyle='dashdot')\n",
    "        locator = mdates.AutoDateLocator(minticks=1, maxticks=7)\n",
    "        formatter = mdates.ConciseDateFormatter(locator)\n",
    "        axes[2].xaxis.set_major_locator(locator)\n",
    "        axes[2].xaxis.set_major_formatter(formatter)\n",
    "        min_vol = min(np.divide(min(np.cumsum(vols_S09)), 1e+9), \n",
    "                    #   np.divide(min(np.cumsum(vols_SF18)), 1e+9), \n",
    "                        np.divide(min(np.cumsum(vols_var)), 1e+9))\n",
    "        max_vol = max(np.divide(max(np.cumsum(vols_S09)), 1e+9), \n",
    "                    #   np.divide(max(np.cumsum(vols_SF18)), 1e+9), \n",
    "                        np.divide(max(np.cumsum(vols_var)), 1e+9))\n",
    "        if dataset.fileName == 'mos_2010.5_2021.5.h5':\n",
    "            axes[2].set(xlim=(datetime.datetime(int(ds_sub.time.values[0]), 1, 1) + datetime.timedelta(days = (ds_sub.time.values[0] % 1) * 365.25), \n",
    "                                datetime.datetime(int(ds_sub.time.values[-1]), 1, 1) + datetime.timedelta(days = (ds_sub.time.values[-1] % 1) * 365.25)), \n",
    "                        ylim=((min_vol - (max_vol - min_vol)*0.05),\n",
    "                                (max_vol + (max_vol - min_vol)*0.05)))\n",
    "        elif dataset.fileName == 'ATL15_AA_0311_01km_001_01.nc':    \n",
    "            axes[2].set(xlim=(date_time_obj + datetime.timedelta(days=ds_sub.time.values[1]),\n",
    "                                date_time_obj + datetime.timedelta(days=ds_sub.time.values[-1])), \n",
    "                        ylim=((min_vol - (max_vol - min_vol)*0.05), \n",
    "                                (max_vol + (max_vol - min_vol)*0.05)))\n",
    "        # axes[1].set_title('{} dVol'.format(lakename_SF18), pad=7.5, fontsize=17.5)\n",
    "        axes[2].set_xlabel('Year', size=15)\n",
    "        axes[2].set_ylabel('Volume change [km$^3$]', size=15)\n",
    "        axes[2].yaxis.tick_right()\n",
    "        axes[2].yaxis.set_label_position(\"right\")\n",
    "        # variable_outlines = plt.Line2D((0, 1), (0, 0), color='darkturquoise', linestyle='dashdot', linewidth=2)\n",
    "        # axes[2].legend([Smith2009,\n",
    "        #     SiegfriedFricker2018,variable_outlines],\n",
    "        #                 ['Smith and others, 2009 static outline',\n",
    "        #     'Siegfried & Fricker, 2018 static outline',\n",
    "        #     '±{} m variable outlines'.format(thres)], \n",
    "        #                 loc='upper left')\n",
    "        # append im(age) to ims list\n",
    "        ani.grab_frame()\n",
    "        axes[0].clear()\n",
    "    # create animation and save, adjust interval\n",
    "    ani.finish()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tn/2b7yqbx51jxb820_x39chyc80000gn/T/ipykernel_20263/1558121810.py:111: RuntimeWarning: Mean of empty slice\n",
      "  avg_lk_dhdt = np.nanmean(dhdt_clip)\n"
     ]
    }
   ],
   "source": [
    "# test function working using one lake\n",
    "# strange error:\n",
    "# S09SF18varoutlines_dhdadvdt_anim_coords(-3.05e5,-2.8e5,-4.85e5,-5.12e5, 'Mercer_2', 'MercerSubglacialLake', 10000, 0.5, CS2_dh) \n",
    "# not saving file:\n",
    "S09SF18varoutlines_dhdadvdt_anim_coords(-5.65e5,-5.3e5,-5.1e5,-4.9e5, 'Whillans_7', 'Whillans_7', 10000, 0.5, ATL15_dh)\n",
    "# S09SF18varoutlines_dhdadvdt_anim_coords(-3.05e5,-2.79e5,-5.12e5,-4.82e5, 'Mercer_2', 'MercerSubglacialLake', 10000, 0.5, ATL15_dh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_min = -4.25e5\n",
    "x_max = -3.9e5\n",
    "y_min = 1.015e6\n",
    "y_max = 1.05e6\n",
    "S09SF18varoutlines_dhdadvdt_anim_coords(x_min, x_max, y_min, y_max, 'Slessor_2', 'Slessor_23', 10000, 0.5, ATL15_dh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(len(SiegfriedFricker2018_outlines)-1):\n",
    "    lakename = SiegfriedFricker2018_outlines['name'][idx]\n",
    "    S09SF18varoutlines_dhdadvdt_anim_coords(lakename, 7500, 0.75, CS2_dh)\n",
    "    S09SF18varoutlines_dhdadvdt_anim_coords(lakename, 7500, 0.75, ATL15_dh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Func S09SF18varoutlines_dhdvdt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def S09SF18varoutlines_dhdvdt(lakename_SF18, buffer, thres, dataset): \n",
    "    '''\n",
    "    Function to calculate the lake avg. dh/dt and dv/dt using static and time-variable subglacial\n",
    "    lake outlines from the latest published lake inventories and a time-variable method to create outlines\n",
    "    based on contours of ice surface height anomalies. \n",
    "    Lake avg. dh/dt and dv/dt are plotted as 2D line plots for comparison.\n",
    "    Inputs: \n",
    "        lakename_SF18: lake of interest from SiegfriedFricker2018_outlines inventory\n",
    "        buffer: horizontal distance in meters to create bounding box around lakes of interest\n",
    "        thres(hold): vertical distance in meters to delineate ice surface deformation contour\n",
    "        dataset: dataset to be analyzed (CS2_dh or ATL15_dh)\n",
    "    Outputs: \n",
    "        Exported 2-D line plots of lake avg. dh/dt and dv/dt and lakes delineated \n",
    "        using outlines from two compilations in available in literature and \n",
    "        time-variable outlines created from ice surface deformation contours.\n",
    "    '''\n",
    "    # isolate individual lake using gpd buffer\n",
    "    #lake_S09 = Smith2009_outlines.loc[Smith2009_outlines['Name'] == lakename_S09]\n",
    "    lake_SF18 = SiegfriedFricker2018_outlines.loc[SiegfriedFricker2018_outlines['name'] == lakename_SF18]\n",
    "    lake_buffer_SF18 = lake_SF18.buffer(buffer)\n",
    "    # define lake bounding box\n",
    "    x_min = lake_buffer_SF18.bounds.values[0,0]\n",
    "    x_max = lake_buffer_SF18.bounds.values[0,2]\n",
    "    y_min = lake_buffer_SF18.bounds.values[0,1]\n",
    "    y_max = lake_buffer_SF18.bounds.values[0,3]\n",
    "    # subset ATL15 data set to region of interest\n",
    "    mask_x = (dataset.x >= x_min) & (dataset.x <= x_max)\n",
    "    mask_y = (dataset.y >= y_min) & (dataset.y <= y_max)\n",
    "    ds_sub = dataset.where(mask_x & mask_y, drop=True)\n",
    "    # find magnitude of ice surface deformation in bounding box\n",
    "    height_anom_pos = []\n",
    "    height_anom_neg = []\n",
    "    for cyc in range(len(ds_sub.time)-1):\n",
    "        pos = np.nanmax(ds_sub.delta_h[cyc+1,:,:]-ds_sub.delta_h[cyc,:,:])\n",
    "        neg = np.nanmin(ds_sub.delta_h[cyc+1,:,:]-ds_sub.delta_h[cyc,:,:])\n",
    "        height_anom_pos += [pos]\n",
    "        height_anom_neg += [neg]\n",
    "    max_height_anom_pos = max(height_anom_pos)\n",
    "    max_height_anom_neg = min(height_anom_neg)\n",
    "    max_height_anom_abs = max(max_height_anom_pos,abs(max_height_anom_neg))\n",
    "    v = np.round(max_height_anom_abs)\n",
    "    # create empty lists to store calculated data\n",
    "    dates = []\n",
    "    lkavgdhdt_SF18 = []\n",
    "    lkavgdhdt_var = []\n",
    "    vols_SF18 = []\n",
    "    vols_var = []\n",
    "    for idx in range(len(ds_sub.delta_h)-1): \n",
    "        # calculate mid-cycle dates for plotting\n",
    "        if dataset.fileName == 'mos_2010.5_2021.5.h5':\n",
    "            newdate = datetime.datetime(int(ds_sub.time.values[idx]), 1, 1) + datetime.timedelta(days = (ds_sub.time.values[idx] % 1) * 365.25)\n",
    "            newdate1 = datetime.datetime(int(ds_sub.time.values[idx+1]), 1, 1) + datetime.timedelta(days = (ds_sub.time.values[idx+1] % 1) * 365.25)\n",
    "            midcycdays = newdate1 - newdate\n",
    "            midcycdate = newdate + midcycdays/2\n",
    "            dates += [midcycdate]\n",
    "        elif dataset.fileName == 'ATL15_AA_0311_01km_001_01.nc':    \n",
    "            date_time_str = '18-01-01'\n",
    "            date_time_obj = datetime.datetime.strptime(date_time_str, '%y-%m-%d')\n",
    "            newdate = date_time_obj + datetime.timedelta(days=ds_sub.time.values[idx])\n",
    "            newdate1 = date_time_obj + datetime.timedelta(days=ds_sub.time.values[idx+1])\n",
    "            midcycdays = newdate1 - newdate\n",
    "            midcycdate = newdate + midcycdays/2\n",
    "            dates += [midcycdate]\n",
    "        # subset data to dhdt diff between orbital cycles of delta_h\n",
    "        dhdt = ds_sub.delta_h[idx+1,:,:]-ds_sub.delta_h[idx,:,:]\n",
    "        # clip ATL15 data to just show (first set crs)\n",
    "        dhdt.rio.write_crs(3031, inplace=True)\n",
    "        dhdt_clip_SF18 = dhdt.rio.clip(lake_SF18.geometry.values, lake_SF18.crs, drop=False, invert=False)\n",
    "        # calculate lake avg. dh/dt and dv/dt time series using published stationary outlines\n",
    "        avg_lk_dhdt_SF18 = np.nanmean(dhdt_clip_SF18)\n",
    "        lkavgdhdt_SF18 += [avg_lk_dhdt_SF18]\n",
    "        vol_SF18 = avg_lk_dhdt_SF18*SiegfriedFricker2018_outlines[SiegfriedFricker2018_outlines['name'] == lakename_SF18]['area (m^2)']\n",
    "        vols_SF18 += [vol_SF18.values[0]]\n",
    "        # create contours of ice surface elevation height changes to delineate lake outlines using time-variable method\n",
    "        contours_fill = []\n",
    "        contours_drain = []\n",
    "        contour = measure.find_contours(dhdt.values, thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_fill += [contour]\n",
    "        contour = measure.find_contours(dhdt.values, -thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_drain += [contour]\n",
    "        # create mapping conversion factor to map array location to polar stereographic x,y\n",
    "        x_conv = (x_max-x_min)/dhdt.shape[1]\n",
    "        y_conv = (y_max-y_min)/dhdt.shape[0]\n",
    "        polys = []\n",
    "        for i in range(len(contours_fill)): \n",
    "            for j in range(len(contours_fill[i])):\n",
    "                if len(contours_fill[i][j][:, 1]) > 2: \n",
    "                    poly = Polygon(list(zip(contours_fill[i][j][:, 1]*x_conv+x_min, y_max-contours_fill[i][j][:, 0]*y_conv))) \n",
    "                    polys += [poly]\n",
    "        for i in range(len(contours_drain)): \n",
    "            for j in range(len(contours_drain[i])):\n",
    "                if len(contours_drain[i][j][:, 1]) > 2: \n",
    "                    poly = Polygon(list(zip(contours_drain[i][j][:, 1]*x_conv+x_min, y_max-contours_drain[i][j][:, 0]*y_conv))) \n",
    "                    polys += [poly]\n",
    "        # if polygons are present at time step, \n",
    "        variable_area = 0\n",
    "        if len(polys) > 0: \n",
    "            # clip data to polygons (first set crs)\n",
    "            # dhdt.rio.write_crs(3031, inplace=True) # done earlier in code, may not be needed here\n",
    "            dhdt_clip = dhdt.rio.clip(polys, drop=False, invert=False)\n",
    "            # then calculate on-lake averages of dh/dt\n",
    "            avg_lk_dhdt = np.nanmean(dhdt_clip)\n",
    "            # occasionally small polygons will completely clip data resulting in nan's for lake avg. dh/dt\n",
    "            # replay with zeros\n",
    "            if math.isnan(avg_lk_dhdt): \n",
    "                avg_lk_dhdt = 0\n",
    "                lkavgdhdt_var += [avg_lk_dhdt]\n",
    "            else:\n",
    "                lkavgdhdt_var += [avg_lk_dhdt]\n",
    "                # and dv/dt\n",
    "            for i in range(len(polys)):\n",
    "                variable_area = variable_area + polys[i].area\n",
    "            vol_var = avg_lk_dhdt*variable_area\n",
    "            vols_var += [vol_var]\n",
    "        else: \n",
    "            avg_lk_dhdt = 0\n",
    "            lkavgdhdt_var += [avg_lk_dhdt]\n",
    "            vol_var = avg_lk_dhdt*variable_area\n",
    "            vols_var += [vol_var]\n",
    "    # plot lake avg. height time series\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(dates, lkavgdhdt_SF18, color='k', linestyle='dashed')   \n",
    "    ax.plot(dates, lkavgdhdt_var, color='darkturquoise', linestyle='dashdot')\n",
    "    locator = mdates.AutoDateLocator(minticks=1, maxticks=7)\n",
    "    formatter = mdates.ConciseDateFormatter(locator)\n",
    "    ax.xaxis.set_major_locator(locator)\n",
    "    ax.xaxis.set_major_formatter(formatter)\n",
    "    ax.set_title('{} vs. variable outlines \\nlake average dh/dt'.format(lakename_SF18))\n",
    "    ax.set_xlabel('Year')\n",
    "    ax.set_ylabel('Avg. height change from previous cycle [m]')\n",
    "    Smith2009 = plt.Line2D((0, 1), (0, 0), color='k', linestyle='dotted', linewidth=2)\n",
    "    SiegfriedFricker2018 = plt.Line2D((0, 1), (0, 0), color='k', linestyle='dashed', linewidth=2)\n",
    "    variable_outlines = plt.Line2D((0, 1), (0, 0), color='darkturquoise', linestyle='dashdot', linewidth=2)\n",
    "    ax.legend([SiegfriedFricker2018,variable_outlines],\n",
    "        ['Siegfried & Fricker, 2018',\n",
    "        '±{} m variable outlines'.format(thres)], \n",
    "        loc='best')          \n",
    "    if dataset.fileName == 'mos_2010.5_2021.5.h5':\n",
    "        plt.savefig('/Users/Wilson/Documents/0-code/1-lakeshores/output_dhdvdt-using-variable-outlines/S09SF18varoutlines_dhdvdt/S09SF18varoutlines_dhdt-{}-{}.png'\\\n",
    "            .format(lakename_SF18, 'CS2'), dpi=300, bbox_inches = \"tight\")\n",
    "    elif dataset.fileName == 'ATL15_AA_0311_01km_001_01.nc':    \n",
    "        plt.savefig('/Users/Wilson/Documents/0-code/1-lakeshores/output_dhdvdt-using-variable-outlines/S09SF18varoutlines_dhdvdt/S09SF18varoutlines_dhdt-{}-{}.png'\\\n",
    "            .format(lakename_SF18, 'IS2'), dpi=300, bbox_inches = \"tight\")\n",
    "    plt.close()\n",
    "    # plot volume change time series\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(dates, np.divide(np.cumsum(vols_SF18), 1e+9), color='k', linestyle='dashed')\n",
    "    ax.plot(dates, np.divide(np.cumsum(vols_var), 1e+9), color='darkturquoise', linestyle='dashdot')\n",
    "    locator = mdates.AutoDateLocator(minticks=1, maxticks=7)\n",
    "    formatter = mdates.ConciseDateFormatter(locator)\n",
    "    ax.xaxis.set_major_locator(locator)\n",
    "    ax.xaxis.set_major_formatter(formatter)\n",
    "    # ax.set_title('{} vs. variable outlines \\nvolume change time series'.format(lakename_SF18))\n",
    "    ax.set_xlabel('Year')\n",
    "    ax.set_ylabel('Volume change from previous cycle [km$^3$]')\n",
    "    ax.legend([SiegfriedFricker2018,variable_outlines],\n",
    "        ['Siegfried & Fricker, 2018',\n",
    "        '±{} m variable outlines'.format(thres)], \n",
    "        loc='best')  \n",
    "    if dataset.fileName == 'mos_2010.5_2021.5.h5':\n",
    "        plt.savefig('/Users/Wilson/Documents/0-code/1-lakeshores/output_dhdvdt-using-variable-outlines/S09SF18varoutlines_dhdvdt/S09SF18varoutlines_dvdt-{}-{}.png'\\\n",
    "            .format(lakename_SF18, 'CS2'), dpi=300, bbox_inches = \"tight\")\n",
    "    elif dataset.fileName == 'ATL15_AA_0311_01km_001_01.nc':    \n",
    "        plt.savefig('/Users/Wilson/Documents/0-code/1-lakeshores/output_dhdvdt-using-variable-outlines/S09SF18varoutlines_dhdvdt/S09SF18varoutlines_dvdt-{}-{}.png'\\\n",
    "            .format(lakename_SF18, 'IS2'), dpi=300, bbox_inches = \"tight\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test function working using one lake\n",
    "# S09SF18varoutlines_dhdvdt('Whillans_7', 10000, 0.75, CS2_dh)\n",
    "S09SF18varoutlines_dhdvdt('Whillans_7', 10000, 0.75, ATL15_dh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# may make more sense do this function on individual lakes after seeing their dhdt plot to confirm all of variable outline is capture in bounding box\n",
    "# for idx in range(len(SiegfriedFricker2018_outlines)-1):\n",
    "#     lakename=SiegfriedFricker2018_outlines['name'][idx]\n",
    "#     S09SF18varoutlines_dhdvdt(lakename, 5000, 0.75, CS2_dh)\n",
    "#     # S09SF18varoutlines_dhdvdt(lakename, 5000, 0.75, ATL15_dh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# increase buffer for one lake\n",
    "dhdvdt_compare_static_variable_outlines('Slessor_23', 7500, 0.75, CS2_dh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ATL15_dhdvdt_compare_2static_variable_outlines(lakename_S09, lakename_SF18, buffer, thres): \n",
    "    '''\n",
    "    Function to calculate the lake avg. dh/dt and dv/dt using static and time-variable subglacial\n",
    "    lake outlines from two lake inventories and a time-variable method to create outlines. Lake avg. \n",
    "    dh/dt and dv/dt are plotted as 2D line plots for comparison.\n",
    "    Inputs: \n",
    "        lakename_S09: lake of interest from Smith2009_outlines inventory\n",
    "        lakename_SF18: co-located lake of interest from SiegfriedFricker2018_outlines inventory\n",
    "        buffer: horizontal distance in meters to create bounding box around lakes of interest\n",
    "        thres(hold): vertical distance in meters to delineate ice surface deformation contour\n",
    "    Outputs: \n",
    "        Exported 2-D line plots of lake avg. dh/dt and dv/dt using ICESat-2 ATL15 data and \n",
    "        lakes delineated using outlines from two compilations in available in literature and \n",
    "        time-variable outlines created from ice surface deformation contours.\n",
    "    '''\n",
    "    # isolate individual lake using gpd buffer\n",
    "    lake_S09 = Smith2009_outlines.loc[Smith2009_outlines['Name'] == lakename_S09]\n",
    "    lake_SF18 = SiegfriedFricker2018_outlines.loc[SiegfriedFricker2018_outlines['name'] == lakename_SF18]\n",
    "    lake_buffer_S09 = lake_S09.buffer(buffer)\n",
    "    lake_buffer_SF18 = lake_SF18.buffer(buffer)\n",
    "    # define lake bounding box\n",
    "    x_min = min(lake_buffer_S09.bounds.values[0,0],lake_buffer_SF18.bounds.values[0,0])\n",
    "    x_max = max(lake_buffer_S09.bounds.values[0,2],lake_buffer_SF18.bounds.values[0,2])\n",
    "    y_min = min(lake_buffer_S09.bounds.values[0,1],lake_buffer_SF18.bounds.values[0,1])\n",
    "    y_max = max(lake_buffer_S09.bounds.values[0,3],lake_buffer_SF18.bounds.values[0,3])\n",
    "    # subset ATL15 data set to region of interest\n",
    "    mask_x = (ATL15_dh.x >= x_min) & (ATL15_dh.x <= x_max)\n",
    "    mask_y = (ATL15_dh.y >= y_min) & (ATL15_dh.y <= y_max)\n",
    "    ATL15_dh_sub = ATL15_dh.where(mask_x & mask_y, drop=True)\n",
    "    # find magnitude of ice surface deformation in bounding box\n",
    "    height_anom_pos = []\n",
    "    height_anom_neg = []\n",
    "    for cyc in range(len(ATL15_dh_sub.time)-1):\n",
    "        pos = np.nanmax(ATL15_dh_sub.delta_h[cyc+1,:,:]-ATL15_dh_sub.delta_h[cyc,:,:])\n",
    "        neg = np.nanmin(ATL15_dh_sub.delta_h[cyc+1,:,:]-ATL15_dh_sub.delta_h[cyc,:,:])\n",
    "        height_anom_pos += [pos]\n",
    "        height_anom_neg += [neg]\n",
    "    max_height_anom_pos = max(height_anom_pos)\n",
    "    max_height_anom_neg = min(height_anom_neg)\n",
    "    max_height_anom_abs = max(max_height_anom_pos,abs(max_height_anom_neg))\n",
    "    v = np.round(max_height_anom_abs)\n",
    "    # create empty lists to store calculated data\n",
    "    IS2_dates = []\n",
    "    IS2_lkavgdhdt_S09 = []\n",
    "    IS2_lkavgdhdt_SF18 = []\n",
    "    IS2_lkavgdhdt = []\n",
    "    IS2_vols_S09 = []\n",
    "    IS2_vols_SF18 = []\n",
    "    IS2_vols = []\n",
    "    for idx in range(len(ATL15_dh_sub.delta_h)-1): \n",
    "        # calculate mid-cycle dates for plotting\n",
    "        date_time_str = '18-01-01'\n",
    "        date_time_obj = datetime.datetime.strptime(date_time_str, '%y-%m-%d')\n",
    "        newdate = date_time_obj + datetime.timedelta(days=ATL15_dh_sub.time.values[idx])\n",
    "        newdate1 = date_time_obj + datetime.timedelta(days=ATL15_dh_sub.time.values[idx+1])\n",
    "        midcycdays = newdate1 - newdate\n",
    "        midcycdate = newdate + midcycdays/2\n",
    "        IS2_dates += [midcycdate]\n",
    "        # subset data to dhdt diff between orbital cycles of delta_h\n",
    "        dhdt = ATL15_dh_sub.delta_h[idx+1,:,:]-ATL15_dh_sub.delta_h[idx,:,:]\n",
    "        # clip ATL15 data to just show (first set crs)\n",
    "        dhdt.rio.write_crs(3031, inplace=True)\n",
    "        dhdt_clip_S09 = dhdt.rio.clip(lake_S09.geometry.values, lake_S09.crs, drop=False, invert=False)\n",
    "        dhdt_clip_SF18 = dhdt.rio.clip(lake_SF18.geometry.values, lake_SF18.crs, drop=False, invert=False)\n",
    "        # calculate lake avg. dh/dt and dv/dt time series using published stationary outlines\n",
    "        avg_lk_dhdt_S09 = np.ma.average(np.ma.MaskedArray(dhdt_clip_S09, mask=np.isnan(dhdt_clip_S09)))\n",
    "        IS2_lkavgdhdt_S09 += [avg_lk_dhdt_S09]\n",
    "        vol_S09 = avg_lk_dhdt_S09*Smith2009_outlines[Smith2009_outlines['Name'] == lakename_S09].area\n",
    "        IS2_vols_S09 += [vol_S09.values[0]]\n",
    "        avg_lk_dhdt_SF18 = np.ma.average(np.ma.MaskedArray(dhdt_clip_SF18, mask=np.isnan(dhdt_clip_SF18)))\n",
    "        IS2_lkavgdhdt_SF18 += [avg_lk_dhdt_SF18]\n",
    "        vol_SF18 = avg_lk_dhdt_SF18*SiegfriedFricker2018_outlines[SiegfriedFricker2018_outlines['name'] == lakename_SF18]['area (m^2)']\n",
    "        IS2_vols_SF18 += [vol_SF18.values[0]]\n",
    "        # create contours of ice surface elevation height changes to delineate lake outlines using time-variable method\n",
    "        contours_fill = []\n",
    "        contours_drain = []\n",
    "        contour = measure.find_contours(dhdt.values, thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_fill += [contour]\n",
    "        contour = measure.find_contours(dhdt.values, -thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_drain += [contour]\n",
    "        # create mapping conversion factor to map array location to polar stereographic x,y\n",
    "        x_conv = (x_max-x_min)/dhdt.shape[1]\n",
    "        y_conv = (y_max-y_min)/dhdt.shape[0]\n",
    "        # make polygons from contours\n",
    "        polys = []\n",
    "        for i in range(len(contours_fill)): \n",
    "            for j in range(len(contours_fill[i])):\n",
    "                if len(contours_fill[i][j][:, 1]) > 2: \n",
    "                    poly = Polygon(list(zip(contours_fill[i][j][:, 1]*x_conv+x_min, y_max-contours_fill[i][j][:, 0]*y_conv))) \n",
    "                    polys += [poly]\n",
    "        for i in range(len(contours_drain)): \n",
    "            for j in range(len(contours_drain[i])):\n",
    "                if len(contours_drain[i][j][:, 1]) > 2: \n",
    "                    poly = Polygon(list(zip(contours_drain[i][j][:, 1]*x_conv+x_min, y_max-contours_drain[i][j][:, 0]*y_conv))) \n",
    "                    polys += [poly]\n",
    "        # if polygons are present at time step, \n",
    "        variable_area = 0\n",
    "        if len(polys) > 0: \n",
    "            # clip data to polygons (first set crs)\n",
    "            # dhdt.rio.write_crs(3031, inplace=True) # done earlier in code, may not be needed here\n",
    "            dhdt_clip = dhdt.rio.clip(polys, drop=False, invert=False)\n",
    "            # then calculate on-lake averages of dh/dt\n",
    "            avg_lk_dhdt = np.nanmean(dhdt_clip)\n",
    "            # occaisionally small polygons will completely clip data resulting in nan's for lake avg. dh/dt\n",
    "            # replay with zeros\n",
    "            if math.isnan(avg_lk_dhdt): \n",
    "                avg_lk_dhdt = 0\n",
    "                IS2_lkavgdhdt += [avg_lk_dhdt]\n",
    "            else:\n",
    "                IS2_lkavgdhdt += [avg_lk_dhdt]\n",
    "                # and dv/dt\n",
    "            for i in range(len(polys)):\n",
    "                variable_area = variable_area + polys[i].area\n",
    "            vol = avg_lk_dhdt*variable_area\n",
    "            IS2_vols += [vol]\n",
    "        else: \n",
    "            avg_lk_dhdt = 0\n",
    "            IS2_lkavgdhdt += [avg_lk_dhdt]\n",
    "            vol = avg_lk_dhdt*variable_area\n",
    "            IS2_vols += [vol]\n",
    "\n",
    "    # plot lake avg. height time series\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(IS2_dates, IS2_lkavgdhdt_S09, color='k', linestyle='dotted')\n",
    "    ax.plot(IS2_dates, IS2_lkavgdhdt_SF18, color='k', linestyle='dashed')   \n",
    "    ax.plot(IS2_dates, IS2_lkavgdhdt, color='darkturquoise', linestyle='dashdot')\n",
    "    locator = mdates.AutoDateLocator(minticks=1, maxticks=7)\n",
    "    formatter = mdates.ConciseDateFormatter(locator)\n",
    "    ax.xaxis.set_major_locator(locator)\n",
    "    ax.xaxis.set_major_formatter(formatter)\n",
    "    ax.set_title('{} vs. {} vs. variable outlines \\nlake average dh/dt'.format(lakename_S09, lakename_SF18))\n",
    "    ax.set_xlabel('Year')\n",
    "    ax.set_ylabel('Avg. height change from previous cycle [m]')\n",
    "    Smith2009 = plt.Line2D((0, 1), (0, 0), color='k', linestyle='dotted', linewidth=2)\n",
    "    SiegfriedFricker2018 = plt.Line2D((0, 1), (0, 0), color='k', linestyle='dashed', linewidth=2)\n",
    "    variable_outlines = plt.Line2D((0, 1), (0, 0), color='darkturquoise', linestyle='dashdot', linewidth=2)\n",
    "    ax.legend([Smith2009,SiegfriedFricker2018,variable_outlines],\n",
    "        ['Smith and others, 2009','Siegfried & Fricker, 2018',\n",
    "        'variable outlines'], \n",
    "        loc='best')          \n",
    "    plt.savefig('/Users/Wilson/Documents/0-code/1-lakeshores/output_dhdvdt-using-variable-outlines/IS2-outlinecompare-lineplots/IS2-avglkdhdt-{}vs{}.png'\\\n",
    "    .format(lakename_S09, lakename_SF18), dpi=300, bbox_inches = \"tight\")\n",
    "    plt.close()\n",
    "    # plot volume change time series\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(IS2_dates, np.divide(np.cumsum(IS2_vols_S09), 1e+9), color='k', linestyle='dotted')\n",
    "    ax.plot(IS2_dates, np.divide(np.cumsum(IS2_vols_SF18), 1e+9), color='k', linestyle='dashed')\n",
    "    ax.plot(IS2_dates, np.divide(np.cumsum(IS2_vols), 1e+9), color='darkturquoise', linestyle='dashdot')\n",
    "    locator = mdates.AutoDateLocator(minticks=1, maxticks=7)\n",
    "    formatter = mdates.ConciseDateFormatter(locator)\n",
    "    ax.xaxis.set_major_locator(locator)\n",
    "    ax.xaxis.set_major_formatter(formatter)\n",
    "    ax.set_title('{} vs. {} vs. variable outlines \\ndv/dt'.format(lakename_S09, lakename_SF18))\n",
    "    ax.set_xlabel('Year')\n",
    "    ax.set_ylabel('Volume change from previous cycle [km$^3$]')\n",
    "    ax.legend([Smith2009,SiegfriedFricker2018,variable_outlines],\n",
    "        ['Smith and others, 2009','Siegfried & Fricker, 2018',\n",
    "        'variable outlines'], \n",
    "        loc='best')  \n",
    "    plt.savefig('/Users/Wilson/Documents/0-code/1-lakeshores/output_dhdvdt-using-variable-outlines/IS2-outlinecompare-lineplots/IS2-dvdt-{}vs{}.png'\\\n",
    "    .format(lakename_S09, lakename_SF18), dpi=300, bbox_inches = \"tight\")\n",
    "    plt.close()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tn/2b7yqbx51jxb820_x39chyc80000gn/T/ipykernel_54289/1590254623.py:107: RuntimeWarning: Mean of empty slice\n",
      "  avg_lk_dhdt = np.nanmean(dhdt_clip)\n",
      "/var/folders/tn/2b7yqbx51jxb820_x39chyc80000gn/T/ipykernel_54289/1590254623.py:107: RuntimeWarning: Mean of empty slice\n",
      "  avg_lk_dhdt = np.nanmean(dhdt_clip)\n"
     ]
    }
   ],
   "source": [
    "# cycle through list to generate plots using function\n",
    "for idx in range(len(S09_SF18_compare)):\n",
    "    ATL15_dhdvdt_compare_2static_variable_outlines(S09_SF18_compare[idx][0],S09_SF18_compare[idx][1], 1000, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recently added dataset kwarg but haven't debugged yet\n",
    "def dhdvdt_compare_2to1static_variable_outlines(lakename1_S09, lakename2_S09, lakename_SF18, buffer, thres, dataset): \n",
    "    '''\n",
    "    Function to calculate the lake avg. dh/dt and dv/dt using static and time-variable subglacial\n",
    "    lake outlines from two lake inventories (where 2 lakes were redelineated as 1) and a time-variable \n",
    "    method to create outlines. Lake avg. dh/dt and dv/dt are plotted as 2D line plots for comparison.\n",
    "    Inputs: \n",
    "        lakename1_S09: first lake of interest from Smith2009_outlines inventory\n",
    "        lakename2_S09: second lake of interest from Smith2009_outlines inventory\n",
    "        lakename_SF18: co-located lake of interest from SiegfriedFricker2018_outlines inventory\n",
    "        buffer: horizontal distance in meters to create bounding box around lakes of interest\n",
    "        thres(hold): vertical distance in meters to delineate ice surface deformation contour\n",
    "    Outputs: \n",
    "        Exported 2-D line plots of lake avg. dh/dt and dv/dt using ICESat-2 ATL15 data and \n",
    "        lakes delineated using outlines from two compilations in available in literature and \n",
    "        time-variable outlines created from ice surface deformation contours.\n",
    "    '''\n",
    "    # isolate individual lake using gpd buffer\n",
    "    lake1_S09 = Smith2009_outlines.loc[Smith2009_outlines['Name'] == lakename1_S09]\n",
    "    lake2_S09 = Smith2009_outlines.loc[Smith2009_outlines['Name'] == lakename2_S09]\n",
    "    lake_SF18 = SiegfriedFricker2018_outlines.loc[SiegfriedFricker2018_outlines['name'] == lakename_SF18]\n",
    "    lake1_buffer_S09 = lake1_S09.buffer(buffer)\n",
    "    lake2_buffer_S09 = lake2_S09.buffer(buffer)\n",
    "    lake_buffer_SF18 = lake_SF18.buffer(buffer)\n",
    "    # define lake bounding box\n",
    "    x_min = min(lake1_buffer_S09.bounds.values[0,0],lake2_buffer_S09.bounds.values[0,0],lake_buffer_SF18.bounds.values[0,0])\n",
    "    x_max = max(lake1_buffer_S09.bounds.values[0,2],lake2_buffer_S09.bounds.values[0,2],lake_buffer_SF18.bounds.values[0,2])\n",
    "    y_min = min(lake1_buffer_S09.bounds.values[0,1],lake2_buffer_S09.bounds.values[0,1],lake_buffer_SF18.bounds.values[0,1])\n",
    "    y_max = max(lake1_buffer_S09.bounds.values[0,3],lake2_buffer_S09.bounds.values[0,3],lake_buffer_SF18.bounds.values[0,3])\n",
    "    # subset ATL15 data set to region of interest\n",
    "    mask_x = (dataset.x >= x_min) & (dataset.x <= x_max)\n",
    "    mask_y = (dataset.y >= y_min) & (dataset.y <= y_max)\n",
    "    ds_sub = dataset.where(mask_x & mask_y, drop=True)\n",
    "    # find magnitude of ice surface deformation in bounding box\n",
    "    height_anom_pos = []\n",
    "    height_anom_neg = []\n",
    "    for cyc in range(len(ds_sub.time)-1):\n",
    "        pos = np.nanmax(ds_sub.delta_h[cyc+1,:,:]-ds_sub.delta_h[cyc,:,:])\n",
    "        neg = np.nanmin(ds_sub.delta_h[cyc+1,:,:]-ds_sub.delta_h[cyc,:,:])\n",
    "        height_anom_pos += [pos]\n",
    "        height_anom_neg += [neg]\n",
    "    max_height_anom_pos = max(height_anom_pos)\n",
    "    max_height_anom_neg = min(height_anom_neg)\n",
    "    max_height_anom_abs = max(max_height_anom_pos,abs(max_height_anom_neg))\n",
    "    v = np.round(max_height_anom_abs)\n",
    "    # create empty lists to store calculated data\n",
    "    IS2_dates = []\n",
    "    IS2_lkavgdhdt_S09_lake1 = []\n",
    "    IS2_lkavgdhdt_S09_lake2 = []\n",
    "    IS2_lkavgdhdt_SF18 = []\n",
    "    IS2_lkavgdhdt = []\n",
    "    IS2_vols_S09_lake1 = []\n",
    "    IS2_vols_S09_lake2 = []\n",
    "    IS2_vols_S09 = []\n",
    "    IS2_vols_SF18 = []\n",
    "    IS2_vols = []\n",
    "    for idx in range(len(ds_sub.delta_h)-1): \n",
    "        # subset data to dhdt diff between orbital cycles of delta_h\n",
    "        dhdt = ds_sub.delta_h[idx+1,:,:]-ds_sub.delta_h[idx,:,:]\n",
    "        # calculate mid-cycle dates for plotting\n",
    "        if dataset.fileName == 'mos_2010.5_2021.5.h5':\n",
    "            newdate = datetime.datetime(int(ds_sub.time.values[idx]), 1, 1) + datetime.timedelta(days = (ds_sub.time.values[idx] % 1) * 365.25)\n",
    "            newdate1 = datetime.datetime(int(ds_sub.time.values[idx+1]), 1, 1) + datetime.timedelta(days = (ds_sub.time.values[idx+1] % 1) * 365.25)\n",
    "            midcycdays = newdate1 - newdate\n",
    "            midcycdate = newdate + midcycdays/2\n",
    "            dates += [midcycdate]\n",
    "        elif dataset.fileName == 'ATL15_AA_0311_01km_001_01.nc':    \n",
    "            date_time_str = '18-01-01'\n",
    "            date_time_obj = datetime.datetime.strptime(date_time_str, '%y-%m-%d')\n",
    "            newdate = date_time_obj + datetime.timedelta(days=ds_sub.time.values[idx])\n",
    "            newdate1 = date_time_obj + datetime.timedelta(days=ds_sub.time.values[idx+1])\n",
    "            midcycdays = newdate1 - newdate\n",
    "            midcycdate = newdate + midcycdays/2\n",
    "            dates += [midcycdate]\n",
    "        # clip ATL15 data to just show (first set crs)\n",
    "        dhdt.rio.write_crs(3031, inplace=True)\n",
    "        dhdt_clip_S09_lake1 = dhdt.rio.clip(lake1_S09.geometry.values, lake1_S09.crs, drop=False, invert=False)\n",
    "        dhdt_clip_S09_lake2 = dhdt.rio.clip(lake2_S09.geometry.values, lake2_S09.crs, drop=False, invert=False)\n",
    "        dhdt_clip_SF18 = dhdt.rio.clip(lake_SF18.geometry.values, lake_SF18.crs, drop=False, invert=False)\n",
    "        # calculate lake avg. dh/dt and dv/dt time series using published stationary outlines\n",
    "        avg_lk_dhdt_S09_lake1 = np.ma.average(np.ma.MaskedArray(dhdt_clip_S09_lake1, mask=np.isnan(dhdt_clip_S09_lake1)))\n",
    "        IS2_lkavgdhdt_S09_lake1 += [avg_lk_dhdt_S09_lake1]\n",
    "        vol_S09_lake1 = avg_lk_dhdt_S09_lake1*Smith2009_outlines[Smith2009_outlines['Name'] == lakename1_S09].area\n",
    "        IS2_vols_S09_lake1 += [vol_S09_lake1.values[0]]\n",
    "        avg_lk_dhdt_S09_lake2 = np.ma.average(np.ma.MaskedArray(dhdt_clip_S09_lake2, mask=np.isnan(dhdt_clip_S09_lake2)))\n",
    "        IS2_lkavgdhdt_S09_lake2 += [avg_lk_dhdt_S09_lake2]\n",
    "        vol_S09_lake2 = avg_lk_dhdt_S09_lake2*Smith2009_outlines[Smith2009_outlines['Name'] == lakename2_S09].area\n",
    "        IS2_vols_S09_lake2 += [vol_S09_lake2.values[0]]\n",
    "        avg_lk_dhdt_SF18 = np.ma.average(np.ma.MaskedArray(dhdt_clip_SF18, mask=np.isnan(dhdt_clip_SF18)))\n",
    "        IS2_lkavgdhdt_SF18 += [avg_lk_dhdt_SF18]\n",
    "        vol_SF18 = avg_lk_dhdt_SF18*SiegfriedFricker2018_outlines[SiegfriedFricker2018_outlines['name'] == lakename_SF18]['area (m^2)']\n",
    "        IS2_vols_SF18 += [vol_SF18.values[0]]\n",
    "        # create contours of ice surface elevation height changes to delineate lake outlines using time-variable method\n",
    "        contours_fill = []\n",
    "        contours_drain = []\n",
    "        contour = measure.find_contours(dhdt.values, thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_fill += [contour]\n",
    "        contour = measure.find_contours(dhdt.values, -thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_drain += [contour]\n",
    "        # create mapping conversion factor to map array location to polar stereographic x,y\n",
    "        x_conv = (x_max-x_min)/dhdt.shape[1]\n",
    "        y_conv = (y_max-y_min)/dhdt.shape[0]\n",
    "        # make polygons from contours\n",
    "        polys = []\n",
    "        for i in range(len(contours_fill)): \n",
    "            for j in range(len(contours_fill[i])):\n",
    "                if len(contours_fill[i][j][:, 1]) > 2: \n",
    "                    poly = Polygon(list(zip(contours_fill[i][j][:, 1]*x_conv+x_min, y_max-contours_fill[i][j][:, 0]*y_conv))) \n",
    "                    polys += [poly]\n",
    "        for i in range(len(contours_drain)): \n",
    "            for j in range(len(contours_drain[i])):\n",
    "                if len(contours_drain[i][j][:, 1]) > 2: \n",
    "                    poly = Polygon(list(zip(contours_drain[i][j][:, 1]*x_conv+x_min, y_max-contours_drain[i][j][:, 0]*y_conv))) \n",
    "                    polys += [poly]\n",
    "        # if polygons are present at time step, \n",
    "        variable_area = 0\n",
    "        if len(polys) > 0: \n",
    "            # clip data to polygons (first set crs)\n",
    "            # dhdt.rio.write_crs(3031, inplace=True) # done earlier in code, may not be needed here\n",
    "            dhdt_clip = dhdt.rio.clip(polys, drop=False, invert=False)\n",
    "            # then calculate on-lake averages of dh/dt\n",
    "            avg_lk_dhdt = np.nanmean(dhdt_clip)\n",
    "            # occaisionally small polygons will completely clip data resulting in nan's for lake avg. dh/dt\n",
    "            # replay with zeros\n",
    "            if math.isnan(avg_lk_dhdt): \n",
    "                avg_lk_dhdt = 0\n",
    "                IS2_lkavgdhdt += [avg_lk_dhdt]\n",
    "            else:\n",
    "                IS2_lkavgdhdt += [avg_lk_dhdt]\n",
    "                # and dv/dt\n",
    "            for i in range(len(polys)):\n",
    "                variable_area = variable_area + polys[i].area\n",
    "            vol = avg_lk_dhdt*variable_area\n",
    "            IS2_vols += [vol]\n",
    "        else: \n",
    "            avg_lk_dhdt = 0\n",
    "            IS2_lkavgdhdt += [avg_lk_dhdt]\n",
    "            vol = avg_lk_dhdt*variable_area\n",
    "            IS2_vols += [vol]\n",
    "\n",
    "    # plot lake avg. height time series\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(IS2_dates, [sum(x) for x in zip(IS2_lkavgdhdt_S09_lake1, IS2_lkavgdhdt_S09_lake2)], color='k', linestyle='dotted')\n",
    "    ax.plot(IS2_dates, IS2_lkavgdhdt_SF18, color='k', linestyle='dashed')   \n",
    "    ax.plot(IS2_dates, IS2_lkavgdhdt, color='darkturquoise', linestyle='dashdot')\n",
    "    locator = mdates.AutoDateLocator(minticks=1, maxticks=7)\n",
    "    formatter = mdates.ConciseDateFormatter(locator)\n",
    "    ax.xaxis.set_major_locator(locator)\n",
    "    ax.xaxis.set_major_formatter(formatter)\n",
    "    ax.set_title('{}+{} vs. {} vs. variable outlines \\nlake average dh/dt'.format(lakename1_S09, lakename2_S09, lakename_SF18))\n",
    "    ax.set_xlabel('Year')\n",
    "    ax.set_ylabel('Avg. height change from previous cycle [m]')\n",
    "    Smith2009 = plt.Line2D((0, 1), (0, 0), color='k', linestyle='dotted', linewidth=2)\n",
    "    SiegfriedFricker2018 = plt.Line2D((0, 1), (0, 0), color='k', linestyle='dashed', linewidth=2)\n",
    "    variable_outlines = plt.Line2D((0, 1), (0, 0), color='darkturquoise', linestyle='dashdot', linewidth=2)\n",
    "    ax.legend([Smith2009,SiegfriedFricker2018,variable_outlines],\n",
    "        ['Smith and others, 2009','Siegfried & Fricker, 2018',\n",
    "        'variable outlines'], \n",
    "        loc='best')          \n",
    "    plt.savefig('/Users/Wilson/Documents/0-code/1-lakeshores/output_dhdvdt-using-variable-outlines/IS2-outlinecompare-lineplots/IS2-avglkdhdt-{}+{}vs{}vs-var-outline.png'\\\n",
    "    .format(lakename1_S09, lakename2_S09, lakename_SF18), dpi=300, bbox_inches = \"tight\")\n",
    "    plt.close()\n",
    "    # plot volume change time series\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(IS2_dates, np.divide([sum(x) for x in zip(IS2_vols_S09_lake1, IS2_vols_S09_lake2)], 1e+9), color='k', linestyle='dotted')\n",
    "    ax.plot(IS2_dates, np.divide(np.cumsum(IS2_vols_SF18), 1e+9), color='k', linestyle='dashed')\n",
    "    ax.plot(IS2_dates, np.divide(np.cumsum(IS2_vols), 1e+9), color='darkturquoise', linestyle='dashdot')\n",
    "    locator = mdates.AutoDateLocator(minticks=1, maxticks=7)\n",
    "    formatter = mdates.ConciseDateFormatter(locator)\n",
    "    ax.xaxis.set_major_locator(locator)\n",
    "    ax.xaxis.set_major_formatter(formatter)\n",
    "    ax.set_title('{}+{} vs. {} vs. variable outlines \\nvolume change time series'.format(lakename1_S09, lakename2_S09, lakename_SF18))\n",
    "    ax.set_xlabel('Year')\n",
    "    ax.set_ylabel('Volume change from previous cycle [km$^3$]')\n",
    "    ax.legend([Smith2009,SiegfriedFricker2018,variable_outlines],\n",
    "        ['Smith and others, 2009','Siegfried & Fricker, 2018',\n",
    "        'variable outlines'], \n",
    "        loc='best')  \n",
    "    plt.savefig('/Users/Wilson/Documents/0-code/1-lakeshores/output_dhdvdt-using-variable-outlines/IS2-outlinecompare-lineplots/IS2-dvdt-{}+{}vs{}vs-var-outline.png'\\\n",
    "    .format(lakename1_S09, lakename2_S09, lakename_SF18), dpi=300, bbox_inches = \"tight\")\n",
    "    plt.close()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cycle through list to generate plots using function\n",
    "for idx in range(len(S09_SF18_compare_2to1)):\n",
    "    ATL15_dhdvdt_compare_2to1static_variable_outlines(S09_SF18_compare_2to1[idx][0],S09_SF18_compare_2to1[idx][1],S09_SF18_compare_2to1[idx][2],1000,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function for 1 S09 converted to 2 SF18 lakes\n",
    "def dhdvdt_compare_1to2static_variable_outlines(lakename1_S09, lakename1_SF18, lakename2_SF18, buffer, thres, dataset): \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cycle through list to generate plots using function\n",
    "for idx in range(len(S09_SF18_compare_2to1)):\n",
    "    dhdvdt_compare_1to2static_variable_outlines(S09_SF18_compare_1to2[idx][0],S09_SF18_compare_1to2[idx][1],S09_SF18_compare_1to2[idx][2],1000,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2018.750399543379"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# determine date of first IS-2 cycle to compare to CS-2\n",
    "cyc_dates = []\n",
    "midcyc_dates = []\n",
    "for idx in range(len(ATL15_dh.time)-1): \n",
    "    date_time_str = '18-01-01'\n",
    "    date_time_obj = datetime.datetime.strptime(date_time_str, '%y-%m-%d')\n",
    "    newdate = date_time_obj + datetime.timedelta(days=ATL15_dh.time.values[idx])\n",
    "    cyc_dates += [newdate]\n",
    "    newdate1 = date_time_obj + datetime.timedelta(days=ATL15_dh.time.values[idx+1])\n",
    "    midcycdays = newdate1 - newdate\n",
    "    midcycdate = newdate + midcycdays/2\n",
    "    midcyc_dates += [midcycdate]\n",
    "datetime2fracyear(cyc_dates[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparison of CS2 and IS2\n",
    "# modifying to plot just dhdt and diff\n",
    "def S09SF18varoutlines_dhdt_CS2vsIS2_anim(lakename_SF18, buffer, thres): \n",
    "    '''\n",
    "    Create CryoSat-2 (CS2) and ICESat-2 (IS2) dh/dt plots of ice surface height changes using geopandas buffer created bounding box around known lakes in Siegfried and Fricker, 2018 inventory.\n",
    "    Create time-variable outlines using skimage contour to plot variable outline alongside published outlines for comparison. \n",
    "    Use statis and time-variable outlines to calculate dv/dt in both CryoSat-2 and ICESat-2.\n",
    "    Save images together into GIF animation.\n",
    "    Inputs: \n",
    "        lakename: lake of interest from SiegfriedFricker2018_outlines inventory\n",
    "        buffer: horizontal distance in meters to create bounding box around lake of interest\n",
    "        thres(hold): vertical distance in meters to delineate ice surface deformation contour\n",
    "    Outputs: \n",
    "        Animations of planview dh/dt visuals with variable ice surface deformation contours plotted to delineate time-variable lake boundary \n",
    "        alongside 2-D line plots of cumulative dv/dt using static and variable outlines that updates simultaneously to planview dh/dt animation.\n",
    "    '''\n",
    "    # isolate individual lake using gpd buffer\n",
    "    #lake_gpd = Smith2009_outlines.loc[Smith2009_outlines['Name'] == lakename]\n",
    "    lake_SF18 = SiegfriedFricker2018_outlines.loc[SiegfriedFricker2018_outlines['name'] == lakename_SF18]\n",
    "    lake_buffer = lake_SF18.buffer(buffer)\n",
    "    # define lake bounding box\n",
    "    x_min = lake_buffer.bounds.values[0,0]; x_max = lake_buffer.bounds.values[0,2]\n",
    "    y_min = lake_buffer.bounds.values[0,1]; y_max = lake_buffer.bounds.values[0,3]\n",
    "    # subset CS2 data set to region of interest\n",
    "    dataset = CS2_dh\n",
    "    mask_x = (dataset.x >= x_min) & (dataset.x <= x_max)\n",
    "    mask_y = (dataset.y >= y_min) & (dataset.y <= y_max)\n",
    "    mask_t = (dataset.time >= 2018.75)\n",
    "    CS2_dh_sub = dataset.where(mask_x & mask_y & mask_t, drop=True)\n",
    "    # subset ATL15 data set to region of interest\n",
    "    dataset = ATL15_dh\n",
    "    mask_x = (dataset.x >= x_min) & (dataset.x <= x_max)\n",
    "    mask_y = (dataset.y >= y_min) & (dataset.y <= y_max)\n",
    "    ATL15_dh_sub = dataset.where(mask_x & mask_y, drop=True)\n",
    "    # find magnitude of ice surface deformation in bounding box / find appropriate color map scale\n",
    "    height_anom_pos = []\n",
    "    height_anom_neg = []\n",
    "    for cyc in range(len(CS2_dh_sub)-1):\n",
    "        pos = np.nanmax(CS2_dh_sub.delta_h[cyc+1,:,:]-CS2_dh_sub.delta_h[cyc,:,:])\n",
    "        neg = np.nanmin(CS2_dh_sub.delta_h[cyc+1,:,:]-CS2_dh_sub.delta_h[cyc,:,:])\n",
    "        height_anom_pos += [pos]\n",
    "        height_anom_neg += [neg]\n",
    "    for cyc in range(len(ATL15_dh_sub.time)-1):\n",
    "        pos = np.nanmax(ATL15_dh_sub.delta_h[cyc+1,:,:]-ATL15_dh_sub.delta_h[cyc,:,:])\n",
    "        neg = np.nanmin(ATL15_dh_sub.delta_h[cyc+1,:,:]-ATL15_dh_sub.delta_h[cyc,:,:])\n",
    "        height_anom_pos += [pos]\n",
    "        height_anom_neg += [neg]\n",
    "    max_height_anom_pos = max(height_anom_pos)\n",
    "    max_height_anom_neg = min(height_anom_neg)\n",
    "    max_height_anom_abs = max(max_height_anom_pos,abs(max_height_anom_neg))\n",
    "    v = np.round(max_height_anom_abs)\n",
    "    # create empty lists to store calculated data\n",
    "    dates_CS2 = []\n",
    "    dates_IS2 = []\n",
    "    dhdt_onlakeavg_SF18_CS2 = []\n",
    "    dhdt_onlakeavg_SF18_IS2 = []\n",
    "    dvdt_SF18_CS2 = []\n",
    "    dvdt_SF18_IS2 = []\n",
    "    dhdt_onlakeavg_var_CS2 = []\n",
    "    dhdt_onlakeavg_var_IS2 = []\n",
    "    dvdt_var_CS2 = []\n",
    "    dvdt_var_IS2 = []\n",
    "    for idx in range(len(CS2_dh_sub.delta_h)-1): \n",
    "        dhdt_CS2 = CS2_dh_sub.delta_h[idx+1,:,:]-CS2_dh_sub.delta_h[idx,:,:]\n",
    "        dhdt_IS2 = ATL15_dh_sub.delta_h[idx+1,:,:]-ATL15_dh_sub.delta_h[idx,:,:]\n",
    "        # calculate mid-cycle dates for plotting\n",
    "        # CryoSat-2\n",
    "        newdate = datetime.datetime(int(CS2_dh_sub.time.values[idx]), 1, 1) + datetime.timedelta(days = (CS2_dh_sub.time.values[idx] % 1) * 365.25)\n",
    "        newdate1 = datetime.datetime(int(CS2_dh_sub.time.values[idx+1]), 1, 1) + datetime.timedelta(days = (CS2_dh_sub.time.values[idx+1] % 1) * 365.25)\n",
    "        midcycdays = newdate1 - newdate\n",
    "        midcycdate = newdate + midcycdays/2\n",
    "        dates_CS2 += [midcycdate]\n",
    "        # ICESat-2\n",
    "        date_time_str = '18-01-01'\n",
    "        date_time_obj = datetime.datetime.strptime(date_time_str, '%y-%m-%d')\n",
    "        newdate = date_time_obj + datetime.timedelta(days=ATL15_dh_sub.time.values[idx])\n",
    "        newdate1 = date_time_obj + datetime.timedelta(days=ATL15_dh_sub.time.values[idx+1])\n",
    "        midcycdays = newdate1 - newdate\n",
    "        midcycdate = newdate + midcycdays/2\n",
    "        dates_IS2 += [midcycdate]\n",
    "        # clip ATL15 data to just show (first set crs)\n",
    "        dhdt_CS2.rio.write_crs(3031, inplace=True)\n",
    "        dhdt_IS2.rio.write_crs(3031, inplace=True)\n",
    "        dhdt_CS2_clip_SF18 = dhdt_CS2.rio.clip(lake_SF18.geometry.values, lake_SF18.crs, drop=False, invert=False)\n",
    "        dhdt_IS2_clip_SF18 = dhdt_IS2.rio.clip(lake_SF18.geometry.values, lake_SF18.crs, drop=False, invert=False)\n",
    "        # calculate lake avg. dh/dt and dv/dt time series using published stationary outlines\n",
    "        dhdt_CS2_lkavg_SF18 = np.nanmean(dhdt_CS2_clip_SF18)\n",
    "        dhdt_IS2_lkavg_SF18 = np.nanmean(dhdt_IS2_clip_SF18)\n",
    "        dhdt_onlakeavg_SF18_CS2 += [dhdt_CS2_lkavg_SF18]\n",
    "        dhdt_onlakeavg_SF18_IS2 += [dhdt_IS2_lkavg_SF18]\n",
    "        dhdt_CS2_vol_SF18 = dhdt_CS2_lkavg_SF18 * SiegfriedFricker2018_outlines[SiegfriedFricker2018_outlines['name'] == lakename_SF18]['area (m^2)']\n",
    "        dhdt_IS2_vol_SF18 = dhdt_IS2_lkavg_SF18 * SiegfriedFricker2018_outlines[SiegfriedFricker2018_outlines['name'] == lakename_SF18]['area (m^2)']\n",
    "        dvdt_SF18_CS2 += [dhdt_CS2_vol_SF18.values[0]]\n",
    "        dvdt_SF18_IS2 += [dhdt_IS2_vol_SF18.values[0]]\n",
    "        # create contours of ice surface elevation height changes to delineate lake outlines\n",
    "        contours_fill_CS2 = []\n",
    "        contours_drain_CS2 = []\n",
    "        contours_fill_IS2 = []\n",
    "        contours_drain_IS2 = []\n",
    "        # create CryoSat-2 variable outliens\n",
    "        contour = measure.find_contours(dhdt_CS2.values, thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_fill_CS2 += [contour]\n",
    "        contour = measure.find_contours(dhdt_CS2.values, -thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_drain_CS2 += [contour]\n",
    "        # create mapping conversion factor to map array location to polar stereographic x,y\n",
    "        x_conv = (x_max-x_min)/dhdt_CS2.shape[1] # CONSIDER MOVING OUT OF DHDT FOR LOOP SO THAT THIS CONSTANT CONVERSION FACTOR IS NOT CALCULATED EACH LOOP\n",
    "        y_conv = (y_max-y_min)/dhdt_CS2.shape[0]\n",
    "        # make polygons from variable outlines\n",
    "        polys_CS2 = []\n",
    "        for i in range(len(contours_fill_CS2)): \n",
    "            for j in range(len(contours_fill_CS2[i])):\n",
    "                if len(contours_fill_CS2[i][j][:, 1]) > 2: \n",
    "                    poly = Polygon(list(zip(x_min+contours_fill_CS2[i][j][:, 1]*x_conv, y_max-contours_fill_CS2[i][j][:, 0]*y_conv))) \n",
    "                    polys_CS2 += [poly]\n",
    "        for i in range(len(contours_drain_CS2)): \n",
    "            for j in range(len(contours_drain_CS2[i])):\n",
    "                if len(contours_drain_CS2[i][j][:, 1]) > 2: \n",
    "                    poly = Polygon(list(zip(x_min+contours_drain_CS2[i][j][:, 1]*x_conv, y_max-contours_drain_CS2[i][j][:, 0]*y_conv))) \n",
    "                    polys_CS2 += [poly]\n",
    "        # create ICESat-2 variable outlines\n",
    "        contour = measure.find_contours(dhdt_IS2.values, thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_fill_IS2 += [contour]\n",
    "        contour = measure.find_contours(dhdt_IS2.values, -thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_drain_IS2 += [contour]\n",
    "        # create mapping conversion factor to map array location to polar stereographic x,y\n",
    "        x_conv = (x_max-x_min)/dhdt_IS2.shape[1]\n",
    "        y_conv = (y_max-y_min)/dhdt_IS2.shape[0]\n",
    "        # make polygons from variable outlines\n",
    "        polys_IS2 = []  \n",
    "        for i in range(len(contours_fill_IS2)): \n",
    "            for j in range(len(contours_fill_IS2[i])):\n",
    "                if len(contours_fill_IS2[i][j][:, 1]) > 2: \n",
    "                    poly = Polygon(list(zip(x_min+contours_fill_IS2[i][j][:,1]*x_conv, y_max-contours_fill_IS2[i][j][:,0]*y_conv))) \n",
    "                    polys_IS2 += [poly]\n",
    "        for i in range(len(contours_drain_IS2)): \n",
    "            for j in range(len(contours_drain_IS2[i])):\n",
    "                if len(contours_drain_IS2[i][j][:, 1]) > 2: \n",
    "                    poly = Polygon(list(zip(x_min+contours_drain_IS2[i][j][:,1]*x_conv, y_max-contours_drain_IS2[i][j][:,0]*y_conv))) \n",
    "                    polys_IS2 += [poly]\n",
    "        # start with baseline variable outline area of zero\n",
    "        variable_area = 0\n",
    "        # CryoSat-2\n",
    "        # if polygons are present at time step, \n",
    "        if len(polys_CS2) > 0: \n",
    "            # clip data to polygons\n",
    "            dhdt_clip = dhdt_CS2.rio.clip(polys_CS2, drop=False, invert=False)\n",
    "            # then calculate on-lake averages of dh/dt\n",
    "            avg_lk_dhdt = np.nanmean(dhdt_clip)\n",
    "            # occasionally small polygons will completely clip data resulting in nan's for lake avg. dh/dt; replace with zeros\n",
    "            if math.isnan(avg_lk_dhdt): \n",
    "                avg_lk_dhdt = 0\n",
    "                dhdt_onlakeavg_var_CS2 += [avg_lk_dhdt]\n",
    "            else:\n",
    "                dhdt_onlakeavg_var_CS2 += [avg_lk_dhdt]\n",
    "            # and dv/dt\n",
    "            for i in range(len(polys_CS2)):\n",
    "                variable_area = variable_area + polys_CS2[i].area # CHANGE TO GEODESIC AREA\n",
    "            vol_var = avg_lk_dhdt*variable_area\n",
    "            dvdt_var_CS2 += [vol_var]\n",
    "        else: \n",
    "            avg_lk_dhdt = 0\n",
    "            dhdt_onlakeavg_var_CS2 += [avg_lk_dhdt]\n",
    "            vol_var = avg_lk_dhdt*variable_area\n",
    "            dvdt_var_CS2 += [vol_var]\n",
    "        # ICESat-2\n",
    "        # if polygons are present at time step, \n",
    "        if len(polys_IS2) > 0: \n",
    "            # clip data to polygons\n",
    "            dhdt_clip = dhdt_IS2.rio.clip(polys_IS2, drop=False, invert=False)\n",
    "            # then calculate on-lake averages of dh/dt\n",
    "            avg_lk_dhdt = np.nanmean(dhdt_clip)\n",
    "            # occasionally small polygons will completely clip data resulting in nan's for lake avg. dh/dt\n",
    "            # replace with zeros\n",
    "            if math.isnan(avg_lk_dhdt): \n",
    "                avg_lk_dhdt = 0\n",
    "                dhdt_onlakeavg_var_IS2 += [avg_lk_dhdt]\n",
    "            else:\n",
    "                dhdt_onlakeavg_var_IS2 += [avg_lk_dhdt]\n",
    "            # and dv/dt\n",
    "            for i in range(len(polys_IS2)):\n",
    "                variable_area = variable_area + polys_IS2[i].area # CHANGE TO GEODESIC AREA\n",
    "            vol_var = avg_lk_dhdt*variable_area\n",
    "            dvdt_var_IS2 += [vol_var]\n",
    "        else: \n",
    "            avg_lk_dhdt = 0\n",
    "            dhdt_onlakeavg_var_IS2 += [avg_lk_dhdt]\n",
    "            vol_var = avg_lk_dhdt*variable_area\n",
    "            dvdt_var_IS2 += [vol_var]\n",
    "    # create fig, axes\n",
    "    fig, axes = plt.subplots(1,3, sharey=True, figsize=(25,7))\n",
    "    # create colorbar axes for dh/dt subplots\n",
    "    # divider0 = make_axes_locatable(axes[0,0])\n",
    "    # cax0 = divider0.append_axes('right', size='5%', pad=0.2)\n",
    "    # create empty list to store animation im(age)s\n",
    "    ani = animation.PillowWriter(fps=1)\n",
    "    ani.setup(fig, '/Users/Wilson/Documents/0-code/1-lakeshores/output_dhdvdt-using-variable-outlines/S09SF18varoutlines_dhdt_CS2vsIS2_anim/S09SF18varoutlines_dhdt_CS2vsIS2_anim-{}.gif'.format(lakename_SF18), dpi=300)\n",
    "    # for loop through dh/dt acquisition cycles to construct animation\n",
    "    for idx in range(len(CS2_dh_sub.delta_h)-1): \n",
    "        dhdt_CS2 = CS2_dh_sub.delta_h[idx+1,:,:]-CS2_dh_sub.delta_h[idx,:,:]\n",
    "        dhdt_IS2 = ATL15_dh_sub.delta_h[idx+1,:,:]-ATL15_dh_sub.delta_h[idx,:,:]\n",
    "        # create contours of ice surface elevation height changes to delineate lake outlines\n",
    "        contours_fill_CS2 = []\n",
    "        contours_drain_CS2 = []\n",
    "        contours_fill_IS2 = []\n",
    "        contours_drain_IS2 = []\n",
    "        # create CryoSat-2 variable outliens\n",
    "        contour = measure.find_contours(dhdt_CS2.values, thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_fill_CS2 += [contour]\n",
    "        contour = measure.find_contours(dhdt_CS2.values, -thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_drain_CS2 += [contour]\n",
    "        # create ICESat-2 variable outlines\n",
    "        contour = measure.find_contours(dhdt_IS2.values, thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_fill_IS2 += [contour]\n",
    "        contour = measure.find_contours(dhdt_IS2.values, -thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_drain_IS2 += [contour]\n",
    "        # subplot 0: plot planview dhdt and variable outlines found in CryoSat-2 time slice\n",
    "        img0 = axes[0].imshow(dhdt_CS2, extent=[x_min, x_max, y_min, y_max], \n",
    "            origin='upper', cmap=cmocean.cm.balance_r, vmin=-v, vmax=v)\n",
    "        divider0 = make_axes_locatable(axes[0])\n",
    "        cax0 = divider0.append_axes('right', size='5%', pad=0.2)\n",
    "        cax0.axis('off')            \n",
    "        for i in range(len(contours_fill_CS2)): \n",
    "            for j in range(len(contours_fill_CS2[i])):\n",
    "                axes[0].plot(x_min+contours_fill_CS2[i][j][:, 1]*x_conv, y_max-contours_fill_CS2[i][j][:, 0]*y_conv, color='mediumblue', linestyle='dashdot', linewidth=2)\n",
    "        for i in range(len(contours_drain_CS2)): \n",
    "            for j in range(len(contours_drain_CS2[i])):\n",
    "                axes[0].plot(x_min+contours_drain_CS2[i][j][:, 1]*x_conv, y_max-contours_drain_CS2[i][j][:, 0]*y_conv, color='maroon', linestyle=(0, (3, 1, 1, 1)), linewidth=2)\n",
    "        axes[0].set(xlim=(x_min, x_max), ylim=(y_min, y_max))\n",
    "        # change polar stereographic m to km for cleaner-looking axes labels\n",
    "        km_scale = 1e3\n",
    "        ticks_x = ticker.FuncFormatter(lambda x, pos: '{0:g}'.format(x/km_scale))\n",
    "        ax.xaxis.set_major_formatter(ticks_x)\n",
    "        ticks_y = ticker.FuncFormatter(lambda x, pos: '{0:g}'.format(x/km_scale))\n",
    "        ax.yaxis.set_major_formatter(ticks_y)  \n",
    "        ax.set_xlabel('x [km]', size=15)\n",
    "        ax.set_ylabel('y [km]', size=15)\n",
    "        axes[0].set_title('CryoSat-2 dh', fontsize=17.5)\n",
    "        fig.suptitle(lakename_SF18+' dh $h_{'+dates_CS2[idx].strftime('%m/%Y')+'} - h_{'+dates_CS2[idx-1].strftime('%m/%Y')+'}$', fontsize=24)\n",
    "        # ax.set_title(lakename_SF18+' dh/dt + outline comparison \\n$h_{'+newdate1.strftime('%m/%Y')+'} - h_{'+newdate.strftime('%m/%Y')+'}$', pad=7.5, fontsize=17.5)\n",
    "        plt.subplots_adjust(wspace=0.001)\n",
    "        # fig.colorbar(img0, cax=cax0).set_label('Height (h) change [m]', size=15)\n",
    "        # overlay published outlines for visual comparison \n",
    "        Smith2009_outlines.boundary.plot(ax=axes[0], color='k', linestyle='--', linewidth=1)\n",
    "        SiegfriedFricker2018_outlines[SiegfriedFricker2018_outlines['cite'] \\\n",
    "            != 'Smith and others, 2009, J. Glac., doi:10.3189/002214309789470879'] \\\n",
    "            .boundary.plot(ax=axes[0], color='k', linestyle='-', linewidth=1)\n",
    "        # create 2D lines for legend\n",
    "        Smith2009 = plt.Line2D((0, 1), (0, 0), color='k', linestyle='--', linewidth=2)\n",
    "        SiegfriedFricker2018 = plt.Line2D((0, 1), (0, 0), color='k', linestyle='-', linewidth=2)\n",
    "        uplift = plt.Line2D((0, 1), (0, 0), color='mediumblue', linestyle='dashdot', linewidth=2)\n",
    "        subsidence = plt.Line2D((0, 1), (0, 0), color='maroon', linestyle=(0, (3, 1, 1, 1)), linewidth=2)\n",
    "        axes[0].legend([Smith2009, SiegfriedFricker2018, uplift, subsidence],\n",
    "            ['Smith and others, 2009 static outline','Siegfried & Fricker, 2018 static outline',\n",
    "            ('+'+str(thres)+' m uplift (filling) variable outline'), '–'+str(thres)+' m subsidence (draining) variable outline'], \n",
    "            loc='upper left')\n",
    "        # subplot 1: plot planview dhdt and variable outlines found in ICESat-2 time slice\n",
    "        divider1 = make_axes_locatable(axes[1])\n",
    "        cax1 = divider1.append_axes('right', size='5%', pad=0.2)\n",
    "        cax1.axis('off')\n",
    "        img1 = axes[1].imshow(dhdt_IS2, extent=[x_min, x_max, y_min, y_max], \n",
    "            origin='upper', cmap=cmocean.cm.balance_r, vmin=-v, vmax=v)\n",
    "        for i in range(len(contours_fill_IS2)): \n",
    "            for j in range(len(contours_fill_IS2[i])):\n",
    "                axes[1].plot(x_min+contours_fill_IS2[i][j][:, 1]*x_conv, y_max-contours_fill_IS2[i][j][:, 0]*y_conv, color='mediumblue', linestyle='dashdot', linewidth=2)\n",
    "        for i in range(len(contours_drain_IS2)): \n",
    "            for j in range(len(contours_drain_IS2[i])):\n",
    "                axes[1].plot(x_min+contours_drain_IS2[i][j][:, 1]*x_conv, y_max-contours_drain_IS2[i][j][:, 0]*y_conv, color='maroon', linestyle=(0, (3, 1, 1, 1)), linewidth=2)\n",
    "        axes[1].set(xlim=(x_min, x_max), ylim=(y_min, y_max))\n",
    "        axes[1].set_xlabel('polar stereographic x [m]', size=15)\n",
    "        axes[1].ticklabel_format(axis='both', scilimits=(0,0))\n",
    "        axes[1].set_title('ICESat-2 dh', fontsize=17.5)\n",
    "        # fig.colorbar(img1, cax=cax1).set_label('Height (h) change [m]', size=15)\n",
    "        # overlay published outlines for visual comparison \n",
    "        Smith2009_outlines.boundary.plot(ax=axes[1], color='k', linestyle='--', linewidth=1)\n",
    "        SiegfriedFricker2018_outlines[SiegfriedFricker2018_outlines['cite'] \\\n",
    "            != 'Smith and others, 2009, J. Glac., doi:10.3189/002214309789470879'] \\\n",
    "            .boundary.plot(ax=axes[1], color='k', linestyle='-', linewidth=1)\n",
    "        # axes[1].legend([Smith2009, SiegfriedFricker2018, uplift, subsidence],\n",
    "        #     ['Smith and others, 2009 static outline','Siegfried & Fricker, 2018 static outline',\n",
    "        #     ('+'+str(thres)+' m uplift (filling) variable outline'), '–'+str(thres)+' m subsidence (draining) variable outline'], \n",
    "        #     loc='upper left')\n",
    "        # plot inset map to show location \n",
    "        axIns = axes[1].inset_axes([0.02, 0.71, 0.29, 0.29])\n",
    "        axIns.patch.set_facecolor('lightskyblue')\n",
    "        axIns.set_aspect('equal')\n",
    "        axIns.scatter(((x_max+x_min)/2), ((y_max+y_min)/2), marker='*', \n",
    "            linewidth=1, edgecolor='k', facecolor='r', s=100, zorder=3)\n",
    "        Scripps_gl.plot(ax=axIns, color='ghostwhite', edgecolor='k', linewidth=0.5, zorder=2)\n",
    "        # SiegfriedFricker2018_outlines.boundary.plot(ax=axIns, color='k', linestyle='-', linewidth=1)\n",
    "        axIns.axis('off')\n",
    "        # subplot 2: plot difference: \n",
    "        img2 = axes[2].imshow(dhdt_CS2-dhdt_IS2, extent=[x_min, x_max, y_min, y_max], \n",
    "            origin='upper', cmap=cmocean.cm.balance_r, vmin=-v, vmax=v)\n",
    "        divider2 = make_axes_locatable(axes[2])\n",
    "        cax2 = divider2.append_axes('right', size='5%', pad=0.2)\n",
    "        # for i in range(len(contours_fill_IS2)): \n",
    "        #     for j in range(len(contours_fill_IS2[i])):\n",
    "        #         axes[1].plot(x_min+contours_fill_IS2[i][j][:, 1]*x_conv, y_max-contours_fill_IS2[i][j][:, 0]*y_conv, color='mediumblue', linestyle='dashdot', linewidth=2)\n",
    "        # for i in range(len(contours_drain_IS2)): \n",
    "        #     for j in range(len(contours_drain_IS2[i])):\n",
    "        #         axes[1].plot(x_min+contours_drain_IS2[i][j][:, 1]*x_conv, y_max-contours_drain_IS2[i][j][:, 0]*y_conv, color='maroon', linestyle=(0, (3, 1, 1, 1)), linewidth=2)\n",
    "        axes[2].set(xlim=(x_min, x_max), ylim=(y_min, y_max))\n",
    "        axes[2].set_xlabel('polar stereographic x [m]', size=15)\n",
    "        axes[2].ticklabel_format(axis='both',scilimits=(0,0))\n",
    "        axes[2].set_title('CryoSat-2 - ICESat-2 dh', fontsize=17.5)\n",
    "        # overlay published outlines for visual comparison \n",
    "        Smith2009_outlines.boundary.plot(ax=axes[2], color='k', linestyle='--', linewidth=1)\n",
    "        SiegfriedFricker2018_outlines[SiegfriedFricker2018_outlines['cite'] \\\n",
    "            != 'Smith and others, 2009, J. Glac., doi:10.3189/002214309789470879'] \\\n",
    "            .boundary.plot(ax=axes[2], color='k', linestyle='-', linewidth=1)\n",
    "        # axes[2].legend([Smith2009, SiegfriedFricker2018, uplift, subsidence],\n",
    "        #     ['Smith and others, 2009 static outline','Siegfried & Fricker, 2018 static outline',\n",
    "        #     ('+'+str(thres)+' m uplift (filling) variable outline'), '–'+str(thres)+' m subsidence (draining) variable outline'], \n",
    "        #     loc='upper left')\n",
    "        fig.colorbar(img2, cax=cax2).set_label('Height (h) difference [m]', size=15)\n",
    "        # # suplot 2: plot CS2 dvdt time series\n",
    "        # axes[1,0].plot(dates_CS2[:idx+1], np.divide(np.cumsum(dvdt_SF18_CS2[:idx+1]), 1e+9), color='k', linestyle='dashed')\n",
    "        # axes[1,0].plot(dates_CS2[:idx+1], np.divide(np.cumsum(dvdt_var_CS2[:idx+1]), 1e+9), color='darkturquoise', linestyle='dashdot')\n",
    "        # locator = mdates.AutoDateLocator(minticks=1, maxticks=7)\n",
    "        # formatter = mdates.ConciseDateFormatter(locator)\n",
    "        # axes[1,0].xaxis.set_major_locator(locator)\n",
    "        # axes[1,0].xaxis.set_major_formatter(formatter)\n",
    "        # # CONSIDER MOVING OUT OF FOR LOOP SO IT'S NOT CALCULATING CONSTANTS EVERY LOOP\n",
    "        # dvdt_min = min(np.divide(min(np.cumsum(dvdt_SF18_CS2)), 1e+9), np.divide(min(np.cumsum(dvdt_var_CS2)), 1e+9), np.divide(min(np.cumsum(dvdt_SF18_IS2)), 1e+9), np.divide(min(np.cumsum(dvdt_var_IS2)), 1e+9))\n",
    "        # dvdt_max = max(np.divide(max(np.cumsum(dvdt_SF18_CS2)), 1e+9), np.divide(max(np.cumsum(dvdt_var_CS2)), 1e+9), np.divide(max(np.cumsum(dvdt_SF18_IS2)), 1e+9), np.divide(max(np.cumsum(dvdt_var_IS2)), 1e+9))\n",
    "        # dvdt_range = dvdt_max - dvdt_min\n",
    "        # ylim_min = dvdt_min - (dvdt_range * 0.1)\n",
    "        # ylim_max = dvdt_max + (dvdt_range * 0.1)\n",
    "        # axes[1,0].set(xlim=(\n",
    "        #     datetime.datetime(int(CS2_dh_sub.time.values[0]), 1, 1) + datetime.timedelta(days = (CS2_dh_sub.time.values[0] % 1) * 365.25), \n",
    "        #     datetime.datetime(int(CS2_dh_sub.time.values[-1]), 1, 1) + datetime.timedelta(days = (CS2_dh_sub.time.values[-1] % 1) * 365.25)), \n",
    "        #     ylim=(ylim_min, ylim_max))\n",
    "        # axes[1,0].set_title('{} CryoSat-2 volume change time series'.format(lakename_SF18), pad=7.5, fontsize=17.5)\n",
    "        # axes[1,0].set_xlabel('Year', size=15)\n",
    "        # axes[1,0].set_ylabel('Volume change [km$^3$]', size=15)\n",
    "        # variable_outlines = plt.Line2D((0, 1), (0, 0), color='darkturquoise', linestyle='dashdot', linewidth=2)\n",
    "        # axes[1,0].legend([#Smith2009,\n",
    "        #     SiegfriedFricker2018, variable_outlines],\n",
    "        #     [#'Smith and others, 2009',\n",
    "        #     'Siegfried & Fricker, 2018',\n",
    "        #     '±{} m variable outlines'.format(thres)], \n",
    "        #     loc='upper left')\n",
    "        # # suplot 3: plot IS2 dvdt time series\n",
    "        # axes[1,1].plot(dates_IS2[:idx+1], np.divide(np.cumsum(dvdt_SF18_IS2[:idx+1]), 1e+9), color='k', linestyle='dashed')\n",
    "        # axes[1,1].plot(dates_IS2[:idx+1], np.divide(np.cumsum(dvdt_var_IS2[:idx+1]), 1e+9), color='darkturquoise', linestyle='dashdot')\n",
    "        # locator = mdates.AutoDateLocator(minticks=1, maxticks=7)\n",
    "        # formatter = mdates.ConciseDateFormatter(locator)\n",
    "        # axes[1,1].xaxis.set_major_locator(locator)\n",
    "        # axes[1,1].xaxis.set_major_formatter(formatter)\n",
    "        # axes[1,1].set(xlim=(\n",
    "        #     date_time_obj + datetime.timedelta(days=ATL15_dh_sub.time.values[0]),\n",
    "        #     date_time_obj + datetime.timedelta(days=ATL15_dh_sub.time.values[-1])), \n",
    "        #     ylim=(ylim_min, ylim_max))\n",
    "        # axes[1,1].set_title('{} ICESat-2 volume change time series'.format(lakename_SF18), pad=7.5, fontsize=17.5)\n",
    "        # axes[1,1].set_xlabel('Year', size=15)\n",
    "        # axes[1,1].set_ylabel('Volume change [km$^3$]', size=15)\n",
    "        # variable_outlines = plt.Line2D((0, 1), (0, 0), color='darkturquoise', linestyle='dashdot', linewidth=2)\n",
    "        # axes[1,1].legend([#Smith2009,\n",
    "        #     SiegfriedFricker2018, variable_outlines],\n",
    "        #     [#'Smith and others, 2009',\n",
    "        #     'Siegfried & Fricker, 2018',\n",
    "        #     '±{} m variable outlines'.format(thres)], \n",
    "        #     loc='upper left')\n",
    "        # append im(age) to ims list\n",
    "        ani.grab_frame()\n",
    "        axes[0].clear()\n",
    "        axes[1].clear()\n",
    "        axes[2].clear()\n",
    "    # create animation and save, adjust interval\n",
    "    ani.finish()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tn/2b7yqbx51jxb820_x39chyc80000gn/T/ipykernel_45859/2115389283.py:39: RuntimeWarning: All-NaN axis encountered\n",
      "  pos = np.nanmax(CS2_dh_sub.delta_h[cyc+1,:,:]-CS2_dh_sub.delta_h[cyc,:,:])\n",
      "/var/folders/tn/2b7yqbx51jxb820_x39chyc80000gn/T/ipykernel_45859/2115389283.py:40: RuntimeWarning: All-NaN axis encountered\n",
      "  neg = np.nanmin(CS2_dh_sub.delta_h[cyc+1,:,:]-CS2_dh_sub.delta_h[cyc,:,:])\n",
      "/var/folders/tn/2b7yqbx51jxb820_x39chyc80000gn/T/ipykernel_45859/2115389283.py:39: RuntimeWarning: All-NaN axis encountered\n",
      "  pos = np.nanmax(CS2_dh_sub.delta_h[cyc+1,:,:]-CS2_dh_sub.delta_h[cyc,:,:])\n",
      "/var/folders/tn/2b7yqbx51jxb820_x39chyc80000gn/T/ipykernel_45859/2115389283.py:40: RuntimeWarning: All-NaN axis encountered\n",
      "  neg = np.nanmin(CS2_dh_sub.delta_h[cyc+1,:,:]-CS2_dh_sub.delta_h[cyc,:,:])\n"
     ]
    }
   ],
   "source": [
    "# test function working using one lake\n",
    "S09SF18varoutlines_dhdt_CS2vsIS2_anim('Bindschadler_1', 7500, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run func on all lakes from SF18 inventory\n",
    "for idx in range(len(SiegfriedFricker2018_outlines)-1):\n",
    "    lakename = SiegfriedFricker2018_outlines['name'][idx]\n",
    "    S09SF18varoutlines_dhdt_CS2vsIS2_anim(lakename, 7500, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def S09SF18varoutlines_dhdvdt_CS2vsIS2_anim(lakename_SF18, buffer, thres): \n",
    "    '''\n",
    "    Create CryoSat-2 (CS2) and ICESat-2 (IS2) dh/dt plots of ice surface height changes using geopandas buffer created bounding box around known lakes in Siegfried and Fricker, 2018 inventory.\n",
    "    Create time-variable outlines using skimage contour to plot variable outline alongside published outlines for comparison. \n",
    "    Use static and time-variable outlines to calculate dv/dt in both CryoSat-2 and ICESat-2.\n",
    "    Save images together into GIF animation.\n",
    "    Inputs: \n",
    "        lakename: lake of interest from SiegfriedFricker2018_outlines inventory\n",
    "        buffer: horizontal distance in meters to create bounding box around lake of interest\n",
    "        thres(hold): vertical distance in meters to delineate ice surface deformation contour\n",
    "    Outputs: \n",
    "        Animations of planview dh/dt visuals with variable ice surface deformation contours plotted to delineate time-variable lake boundary \n",
    "        alongside 2-D line plots of cumulative dv/dt using static and variable outlines that updates simultaneously to planview dh/dt animation.\n",
    "    '''\n",
    "    # isolate individual lake using gpd buffer\n",
    "    #lake_gpd = Smith2009_outlines.loc[Smith2009_outlines['Name'] == lakename]\n",
    "    lake_SF18 = SiegfriedFricker2018_outlines.loc[SiegfriedFricker2018_outlines['name'] == lakename_SF18]\n",
    "    lake_buffer = lake_SF18.buffer(buffer)\n",
    "    # define lake bounding box\n",
    "    x_min = lake_buffer.bounds.values[0,0]; x_max = lake_buffer.bounds.values[0,2]\n",
    "    y_min = lake_buffer.bounds.values[0,1]; y_max = lake_buffer.bounds.values[0,3]\n",
    "    # subset CS2 data set to region of interest\n",
    "    dataset = CS2_dh\n",
    "    mask_x = (dataset.x >= x_min) & (dataset.x <= x_max)\n",
    "    mask_y = (dataset.y >= y_min) & (dataset.y <= y_max)\n",
    "    mask_t = (dataset.time >= 2018.75)\n",
    "    CS2_dh_sub = dataset.where(mask_x & mask_y & mask_t, drop=True)\n",
    "    # subset ATL15 data set to region of interest\n",
    "    dataset = ATL15_dh\n",
    "    mask_x = (dataset.x >= x_min) & (dataset.x <= x_max)\n",
    "    mask_y = (dataset.y >= y_min) & (dataset.y <= y_max)\n",
    "    ATL15_dh_sub = dataset.where(mask_x & mask_y, drop=True)\n",
    "    # find magnitude of ice surface deformation in bounding box / find appropriate color map scale\n",
    "    height_anom_pos = []\n",
    "    height_anom_neg = []\n",
    "    for cyc in range(len(CS2_dh_sub)-1): # SHOULD ONLY CLIP TO CYCS IN IS2 ERA\n",
    "        pos = np.nanmax(CS2_dh_sub.delta_h[cyc+1,:,:]-CS2_dh_sub.delta_h[cyc,:,:])\n",
    "        neg = np.nanmin(CS2_dh_sub.delta_h[cyc+1,:,:]-CS2_dh_sub.delta_h[cyc,:,:])\n",
    "        height_anom_pos += [pos]\n",
    "        height_anom_neg += [neg]\n",
    "    for cyc in range(len(ATL15_dh_sub.time)-1): \n",
    "        pos = np.nanmax(ATL15_dh_sub.delta_h[cyc+1,:,:]-ATL15_dh_sub.delta_h[cyc,:,:])\n",
    "        neg = np.nanmin(ATL15_dh_sub.delta_h[cyc+1,:,:]-ATL15_dh_sub.delta_h[cyc,:,:])\n",
    "        height_anom_pos += [pos]\n",
    "        height_anom_neg += [neg]\n",
    "    max_height_anom_pos = max(height_anom_pos)\n",
    "    max_height_anom_neg = min(height_anom_neg)\n",
    "    max_height_anom_abs = max(max_height_anom_pos,abs(max_height_anom_neg))\n",
    "    v = np.round(max_height_anom_abs)\n",
    "    # only plot lakes with signal above arbitrary background noise\n",
    "    # create empty lists to store calculated data\n",
    "    dates_CS2 = []\n",
    "    dates_IS2 = []\n",
    "    dhdt_onlakeavg_SF18_CS2 = []\n",
    "    dhdt_onlakeavg_SF18_IS2 = []\n",
    "    dvdt_SF18_CS2 = []\n",
    "    dvdt_SF18_IS2 = []\n",
    "    dhdt_onlakeavg_var_CS2 = []\n",
    "    dhdt_onlakeavg_var_IS2 = []\n",
    "    dvdt_var_CS2 = []\n",
    "    dvdt_var_IS2 = []\n",
    "    for idx in range(len(CS2_dh_sub.delta_h)-1): \n",
    "        dhdt_CS2 = CS2_dh_sub.delta_h[idx+1,:,:]-CS2_dh_sub.delta_h[idx,:,:]\n",
    "        dhdt_IS2 = ATL15_dh_sub.delta_h[idx+1,:,:]-ATL15_dh_sub.delta_h[idx,:,:]\n",
    "        # calculate mid-cycle dates for plotting\n",
    "        # CryoSat-2\n",
    "        newdate = datetime.datetime(int(CS2_dh_sub.time.values[idx]), 1, 1) + datetime.timedelta(days = (CS2_dh_sub.time.values[idx] % 1) * 365.25)\n",
    "        newdate1 = datetime.datetime(int(CS2_dh_sub.time.values[idx+1]), 1, 1) + datetime.timedelta(days = (CS2_dh_sub.time.values[idx+1] % 1) * 365.25)\n",
    "        midcycdays = newdate1 - newdate\n",
    "        midcycdate = newdate + midcycdays/2\n",
    "        dates_CS2 += [midcycdate]\n",
    "        # ICESat-2\n",
    "        date_time_str = '18-01-01'\n",
    "        date_time_obj = datetime.datetime.strptime(date_time_str, '%y-%m-%d')\n",
    "        newdate = date_time_obj + datetime.timedelta(days=ATL15_dh_sub.time.values[idx])\n",
    "        newdate1 = date_time_obj + datetime.timedelta(days=ATL15_dh_sub.time.values[idx+1])\n",
    "        midcycdays = newdate1 - newdate\n",
    "        midcycdate = newdate + midcycdays/2\n",
    "        dates_IS2 += [midcycdate]\n",
    "        # clip data to get lake stats (first set crs)\n",
    "        dhdt_CS2.rio.write_crs(3031, inplace=True)\n",
    "        dhdt_IS2.rio.write_crs(3031, inplace=True)\n",
    "        dhdt_CS2_clip_SF18 = dhdt_CS2.rio.clip(lake_SF18.geometry.values, lake_SF18.crs, drop=False, invert=False)\n",
    "        dhdt_IS2_clip_SF18 = dhdt_IS2.rio.clip(lake_SF18.geometry.values, lake_SF18.crs, drop=False, invert=False)\n",
    "        # calculate lake avg. dh/dt and dv/dt time series using published stationary outlines\n",
    "        dhdt_CS2_lkavg_SF18 = np.nanmean(dhdt_CS2_clip_SF18)\n",
    "        dhdt_IS2_lkavg_SF18 = np.nanmean(dhdt_IS2_clip_SF18)\n",
    "        dhdt_onlakeavg_SF18_CS2 += [dhdt_CS2_lkavg_SF18]\n",
    "        dhdt_onlakeavg_SF18_IS2 += [dhdt_IS2_lkavg_SF18]\n",
    "        dhdt_CS2_vol_SF18 = dhdt_CS2_lkavg_SF18 * SiegfriedFricker2018_outlines[SiegfriedFricker2018_outlines['name'] == lakename_SF18]['area (m^2)']\n",
    "        dhdt_IS2_vol_SF18 = dhdt_IS2_lkavg_SF18 * SiegfriedFricker2018_outlines[SiegfriedFricker2018_outlines['name'] == lakename_SF18]['area (m^2)']\n",
    "        dvdt_SF18_CS2 += [dhdt_CS2_vol_SF18.values[0]]\n",
    "        dvdt_SF18_IS2 += [dhdt_IS2_vol_SF18.values[0]]\n",
    "        # create contours of ice surface elevation height changes to delineate lake outlines\n",
    "        contours_fill_CS2 = []\n",
    "        contours_drain_CS2 = []\n",
    "        contours_fill_IS2 = []\n",
    "        contours_drain_IS2 = []\n",
    "        # create CryoSat-2 variable outliens\n",
    "        contour = measure.find_contours(dhdt_CS2.values, thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_fill_CS2 += [contour]\n",
    "        contour = measure.find_contours(dhdt_CS2.values, -thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_drain_CS2 += [contour]\n",
    "        # create mapping conversion factor to map array location to polar stereographic x,y\n",
    "        x_conv = (x_max-x_min)/dhdt_CS2.shape[1] # MOVE OUT OF DHDT FOR LOOP SO THAT THIS CONSTANT CONVERSION FACTOR IS NOT CALCULATED EACH LOOP\n",
    "        y_conv = (y_max-y_min)/dhdt_CS2.shape[0]\n",
    "        # make polygons from variable outlines\n",
    "        polys_CS2 = []\n",
    "        for i in range(len(contours_fill_CS2)): \n",
    "            for j in range(len(contours_fill_CS2[i])):\n",
    "                if len(contours_fill_CS2[i][j][:, 1]) > 2: \n",
    "                    poly = Polygon(list(zip(x_min+contours_fill_CS2[i][j][:, 1]*x_conv, y_max-contours_fill_CS2[i][j][:, 0]*y_conv))) \n",
    "                    polys_CS2 += [poly]\n",
    "        for i in range(len(contours_drain_CS2)): \n",
    "            for j in range(len(contours_drain_CS2[i])):\n",
    "                if len(contours_drain_CS2[i][j][:, 1]) > 2: \n",
    "                    poly = Polygon(list(zip(x_min+contours_drain_CS2[i][j][:, 1]*x_conv, y_max-contours_drain_CS2[i][j][:, 0]*y_conv))) \n",
    "                    polys_CS2 += [poly]\n",
    "        # create ICESat-2 variable outlines\n",
    "        contour = measure.find_contours(dhdt_IS2.values, thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_fill_IS2 += [contour]\n",
    "        contour = measure.find_contours(dhdt_IS2.values, -thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_drain_IS2 += [contour]\n",
    "        # create mapping conversion factor to map array location to polar stereographic x,y\n",
    "        x_conv = (x_max-x_min)/dhdt_IS2.shape[1]\n",
    "        y_conv = (y_max-y_min)/dhdt_IS2.shape[0]\n",
    "        # make polygons from variable outlines\n",
    "        polys_IS2 = []  \n",
    "        for i in range(len(contours_fill_IS2)): \n",
    "            for j in range(len(contours_fill_IS2[i])):\n",
    "                if len(contours_fill_IS2[i][j][:, 1]) > 2: \n",
    "                    poly = Polygon(list(zip(x_min+contours_fill_IS2[i][j][:, 1]*x_conv, y_max-contours_fill_IS2[i][j][:, 0]*y_conv))) \n",
    "                    polys_IS2 += [poly]\n",
    "        for i in range(len(contours_drain_IS2)): \n",
    "            for j in range(len(contours_drain_IS2[i])):\n",
    "                if len(contours_drain_IS2[i][j][:, 1]) > 2: \n",
    "                    poly = Polygon(list(zip(x_min+contours_drain_IS2[i][j][:, 1]*x_conv, y_max-contours_drain_IS2[i][j][:, 0]*y_conv))) \n",
    "                    polys_IS2 += [poly]\n",
    "        # start with baseline variable outline area of zero\n",
    "        variable_area = 0\n",
    "        # CryoSat-2\n",
    "        # if polygons are present at time step, \n",
    "        if len(polys_CS2) > 0: \n",
    "            # clip data to polygons\n",
    "            dhdt_clip = dhdt_CS2.rio.clip(polys_CS2, drop=False, invert=False)\n",
    "            # then calculate on-lake averages of dh/dt\n",
    "            avg_lk_dhdt = np.nanmean(dhdt_clip)\n",
    "            # occasionally small polygons will completely clip data resulting in nan's for lake avg. dh/dt; replace with zeros\n",
    "            if math.isnan(avg_lk_dhdt): \n",
    "                avg_lk_dhdt = 0\n",
    "                dhdt_onlakeavg_var_CS2 += [avg_lk_dhdt]\n",
    "            else:\n",
    "                dhdt_onlakeavg_var_CS2 += [avg_lk_dhdt]\n",
    "            # and dv/dt\n",
    "            for i in range(len(polys_CS2)):\n",
    "                variable_area = variable_area + polys_CS2[i].area # CHANGE TO GEODESIC AREA\n",
    "            vol_var = avg_lk_dhdt*variable_area\n",
    "            dvdt_var_CS2 += [vol_var]\n",
    "        else: \n",
    "            avg_lk_dhdt = 0\n",
    "            dhdt_onlakeavg_var_CS2 += [avg_lk_dhdt]\n",
    "            vol_var = avg_lk_dhdt*variable_area\n",
    "            dvdt_var_CS2 += [vol_var]\n",
    "        # ICESat-2\n",
    "        # if polygons are present at time step, \n",
    "        if len(polys_IS2) > 0: \n",
    "            # clip data to polygons\n",
    "            dhdt_clip = dhdt_IS2.rio.clip(polys_IS2, drop=False, invert=False)\n",
    "            # then calculate on-lake averages of dh/dt\n",
    "            avg_lk_dhdt = np.nanmean(dhdt_clip)\n",
    "            # occasionally small polygons will completely clip data resulting in nan's for lake avg. dh/dt\n",
    "            # replace with zeros\n",
    "            if math.isnan(avg_lk_dhdt): \n",
    "                avg_lk_dhdt = 0\n",
    "                dhdt_onlakeavg_var_IS2 += [avg_lk_dhdt]\n",
    "            else:\n",
    "                dhdt_onlakeavg_var_IS2 += [avg_lk_dhdt]\n",
    "            # and dv/dt\n",
    "            for i in range(len(polys_IS2)):\n",
    "                variable_area = variable_area + polys_IS2[i].area # CHANGE TO GEODESIC AREA\n",
    "            vol_var = avg_lk_dhdt*variable_area\n",
    "            dvdt_var_IS2 += [vol_var]\n",
    "        else: \n",
    "            avg_lk_dhdt = 0\n",
    "            dhdt_onlakeavg_var_IS2 += [avg_lk_dhdt]\n",
    "            vol_var = avg_lk_dhdt*variable_area\n",
    "            dvdt_var_IS2 += [vol_var]\n",
    "    # create fig, axes\n",
    "    fig, axes = plt.subplots(2,2, figsize=(20,20))\n",
    "    # create colorbar axes for dh/dt subplots\n",
    "    # divider0 = make_axes_locatable(axes[0,0])\n",
    "    # cax0 = divider0.append_axes('right', size='5%', pad=0.2)\n",
    "    divider1 = make_axes_locatable(axes[0,1])\n",
    "    cax1 = divider1.append_axes('right', size='5%', pad=0.2)\n",
    "    # create empty list to store animation im(age)s\n",
    "    ani = animation.PillowWriter(fps=1)\n",
    "    ani.setup(fig, '/Users/Wilson/Documents/0-code/1-lakeshores/output_dhdvdt-using-variable-outlines/S09SF18varoutlines_dhdvdt_CS2vsIS2_anim/anim/S09SF18varoutlines_dhdvdt_CS2vsIS2_anim-{}.gif'.format(lakename_SF18), dpi=300)\n",
    "    # for loop through dh/dt acquisition cycles to construct animation\n",
    "    for idx in range(len(CS2_dh_sub.delta_h)-1): \n",
    "        dhdt_CS2 = CS2_dh_sub.delta_h[idx+1,:,:]-CS2_dh_sub.delta_h[idx,:,:]\n",
    "        dhdt_IS2 = ATL15_dh_sub.delta_h[idx+1,:,:]-ATL15_dh_sub.delta_h[idx,:,:]\n",
    "        # create contours of ice surface elevation height changes to delineate lake outlines\n",
    "        contours_fill_CS2 = []\n",
    "        contours_drain_CS2 = []\n",
    "        contours_fill_IS2 = []\n",
    "        contours_drain_IS2 = []\n",
    "        # create CryoSat-2 variable outliens\n",
    "        contour = measure.find_contours(dhdt_CS2.values, thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_fill_CS2 += [contour]\n",
    "        contour = measure.find_contours(dhdt_CS2.values, -thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_drain_CS2 += [contour]\n",
    "        # create ICESat-2 variable outlines\n",
    "        contour = measure.find_contours(dhdt_IS2.values, thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_fill_IS2 += [contour]\n",
    "        contour = measure.find_contours(dhdt_IS2.values, -thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_drain_IS2 += [contour]\n",
    "        # subplot 0: plot planview dhdt and variable outlines found in CryoSat-2 time slice\n",
    "        img0 = axes[0,0].imshow(dhdt_CS2, extent=[x_min, x_max, y_min, y_max], \n",
    "            origin='upper', cmap=cmocean.cm.balance_r, vmin=-v, vmax=v)\n",
    "        for i in range(len(contours_fill_CS2)): \n",
    "            for j in range(len(contours_fill_CS2[i])):\n",
    "                axes[0,0].plot(x_min+contours_fill_CS2[i][j][:, 1]*x_conv, y_max-contours_fill_CS2[i][j][:, 0]*y_conv, color='mediumblue', linestyle='dashdot', linewidth=2)\n",
    "        for i in range(len(contours_drain_CS2)): \n",
    "            for j in range(len(contours_drain_CS2[i])):\n",
    "                axes[0,0].plot(x_min+contours_drain_CS2[i][j][:, 1]*x_conv, y_max-contours_drain_CS2[i][j][:, 0]*y_conv, color='maroon', linestyle=(0, (3, 1, 1, 1)), linewidth=2)\n",
    "        axes[0,0].set(xlim=(x_min, x_max), ylim=(y_min, y_max))\n",
    "        # change polar stereographic m to km for cleaner-looking axes labels\n",
    "        km_scale = 1e3\n",
    "        ticks_x = ticker.FuncFormatter(lambda x, pos: '{0:g}'.format(x/km_scale))\n",
    "        axes[0,0].xaxis.set_major_formatter(ticks_x)\n",
    "        ticks_y = ticker.FuncFormatter(lambda x, pos: '{0:g}'.format(x/km_scale))\n",
    "        axes[0,0].yaxis.set_major_formatter(ticks_y)  \n",
    "        axes[0,0].set_xlabel('x [km]', size=15)\n",
    "        axes[0,0].set_ylabel('y [km]', size=15)\n",
    "        axes[0,0].set_title(lakename_SF18+' CryoSat-2 dh \\n$h_{'+dates_CS2[idx].strftime('%m/%Y')+'} - h_{'+dates_CS2[idx-1].strftime('%m/%Y')+'}$', pad=7.5, fontsize=17.5)\n",
    "        # fig.colorbar(img0, cax=cax0).set_label('Height (h) change [m]', size=15)\n",
    "        # overlay published outlines for visual comparison \n",
    "        Smith2009_outlines.boundary.plot(ax=axes[0,0], color='k', linestyle='--', linewidth=1)\n",
    "        SiegfriedFricker2018_outlines[SiegfriedFricker2018_outlines['cite'] \\\n",
    "            != 'Smith and others, 2009, J. Glac., doi:10.3189/002214309789470879'] \\\n",
    "            .boundary.plot(ax=axes[0,0], color='k', linestyle='-', linewidth=1)\n",
    "        # create 2D lines for legend\n",
    "        Smith2009 = plt.Line2D((0, 1), (0, 0), color='k', linestyle='--', linewidth=2)\n",
    "        SiegfriedFricker2018 = plt.Line2D((0, 1), (0, 0), color='k', linestyle='-', linewidth=2)\n",
    "        uplift = plt.Line2D((0, 1), (0, 0), color='mediumblue', linestyle='dashdot', linewidth=2)\n",
    "        subsidence = plt.Line2D((0, 1), (0, 0), color='maroon', linestyle=(0, (3, 1, 1, 1)), linewidth=2)\n",
    "        axes[0,0].legend([Smith2009, SiegfriedFricker2018, uplift, subsidence],\n",
    "            ['Smith and others, 2009 static outline','Siegfried & Fricker, 2018 static outline',\n",
    "            ('+'+str(thres)+' m uplift (filling) variable outline'), '–'+str(thres)+' m subsidence (draining) variable outline'], \n",
    "            loc='upper left')\n",
    "        # plot inset map to show location \n",
    "        axIns = axes[0,0].inset_axes([0.001, 0.001, 0.25, 0.25])\n",
    "        axIns.patch.set_facecolor('lightskyblue')\n",
    "        axIns.set_aspect('equal')\n",
    "        axIns.scatter(((x_max+x_min)/2), ((y_max+y_min)/2), marker='*', \n",
    "            linewidth=1, edgecolor='k', facecolor='r', s=100, zorder=3)\n",
    "        Scripps_gl.plot(ax=axIns, color='ghostwhite', edgecolor='k', linewidth=0.5, zorder=2)\n",
    "        axIns.axis('off')\n",
    "        \n",
    "        # subplot 1: plot planview dhdt and variable outlines found in ICESat-2 time slice\n",
    "        img1 = axes[0,1].imshow(dhdt_IS2, extent=[x_min, x_max, y_min, y_max], \n",
    "            origin='upper', cmap=cmocean.cm.balance_r, vmin=-v, vmax=v)\n",
    "        for i in range(len(contours_fill_IS2)): \n",
    "            for j in range(len(contours_fill_IS2[i])):\n",
    "                axes[0,1].plot(x_min+contours_fill_IS2[i][j][:, 1]*x_conv, y_max-contours_fill_IS2[i][j][:, 0]*y_conv, color='mediumblue', linestyle='dashdot', linewidth=2)\n",
    "        for i in range(len(contours_drain_IS2)): \n",
    "            for j in range(len(contours_drain_IS2[i])):\n",
    "                axes[0,1].plot(x_min+contours_drain_IS2[i][j][:, 1]*x_conv, y_max-contours_drain_IS2[i][j][:, 0]*y_conv, color='maroon', linestyle=(0, (3, 1, 1, 1)), linewidth=2)\n",
    "        axes[0,1].set(xlim=(x_min, x_max), ylim=(y_min, y_max))\n",
    "        # change polar stereographic m to km for cleaner-looking axes labels\n",
    "        km_scale = 1e3\n",
    "        ticks_x = ticker.FuncFormatter(lambda x, pos: '{0:g}'.format(x/km_scale))\n",
    "        axes[0,1].xaxis.set_major_formatter(ticks_x)\n",
    "        ticks_y = ticker.FuncFormatter(lambda x, pos: '{0:g}'.format(x/km_scale))\n",
    "        axes[0,1].yaxis.set_major_formatter(ticks_y)  \n",
    "        axes[0,1].set_xlabel('x [km]', size=15)\n",
    "        # ax.set_ylabel('y [km]', size=15)\n",
    "        axes[0,1].set_title(lakename_SF18+' ICESat-2 dh \\n$h_{'+dates_IS2[idx].strftime('%m/%Y')+'} - h_{'+dates_IS2[idx-1].strftime('%m/%Y')+'}$', pad=7.5, fontsize=17.5)\n",
    "        fig.colorbar(img1, cax=cax1).set_label('Height change (dh) [m]', size=15)\n",
    "        # overlay published outlines for visual comparison \n",
    "        Smith2009_outlines.boundary.plot(ax=axes[0,1], color='k', linestyle='--', linewidth=1)\n",
    "        SiegfriedFricker2018_outlines[SiegfriedFricker2018_outlines['cite'] \\\n",
    "            != 'Smith and others, 2009, J. Glac., doi:10.3189/002214309789470879'] \\\n",
    "            .boundary.plot(ax=axes[0,1], color='k', linestyle='-', linewidth=1)\n",
    "        axes[0,1].legend([Smith2009, SiegfriedFricker2018, uplift, subsidence],\n",
    "            ['Smith and others, 2009 static outline','Siegfried & Fricker, 2018 static outline',\n",
    "            ('+'+str(thres)+' m uplift (filling) variable outline'), '–'+str(thres)+' m subsidence (draining) variable outline'], \n",
    "            loc='upper left')\n",
    "\n",
    "        # suplot 2: plot CS2 dvdt time series\n",
    "        axes[1,0].plot(dates_CS2[:idx+1], np.divide(np.cumsum(dvdt_SF18_CS2[:idx+1]), 1e+9), color='k', linestyle='dashed')\n",
    "        axes[1,0].plot(dates_CS2[:idx+1], np.divide(np.cumsum(dvdt_var_CS2[:idx+1]), 1e+9), color='darkturquoise', linestyle='dashdot')\n",
    "        locator = mdates.AutoDateLocator(minticks=1, maxticks=7)\n",
    "        formatter = mdates.ConciseDateFormatter(locator)\n",
    "        axes[1,0].xaxis.set_major_locator(locator)\n",
    "        axes[1,0].xaxis.set_major_formatter(formatter)\n",
    "        # CONSIDER MOVING OUT OF FOR LOOP SO IT'S NOT CALCULATING CONSTANTS EVERY LOOP\n",
    "        dvdt_min = min(np.divide(min(np.cumsum(dvdt_SF18_CS2)), 1e+9), np.divide(min(np.cumsum(dvdt_var_CS2)), 1e+9), np.divide(min(np.cumsum(dvdt_SF18_IS2)), 1e+9), np.divide(min(np.cumsum(dvdt_var_IS2)), 1e+9))\n",
    "        dvdt_max = max(np.divide(max(np.cumsum(dvdt_SF18_CS2)), 1e+9), np.divide(max(np.cumsum(dvdt_var_CS2)), 1e+9), np.divide(max(np.cumsum(dvdt_SF18_IS2)), 1e+9), np.divide(max(np.cumsum(dvdt_var_IS2)), 1e+9))\n",
    "        dvdt_range = dvdt_max - dvdt_min\n",
    "        ylim_min = dvdt_min - (dvdt_range * 0.1)\n",
    "        ylim_max = dvdt_max + (dvdt_range * 0.1)\n",
    "        axes[1,0].set(xlim=(\n",
    "            datetime.datetime(int(CS2_dh_sub.time.values[0]), 1, 1) + datetime.timedelta(days = (CS2_dh_sub.time.values[0] % 1) * 365.25), \n",
    "            datetime.datetime(int(CS2_dh_sub.time.values[-1]), 1, 1) + datetime.timedelta(days = (CS2_dh_sub.time.values[-1] % 1) * 365.25)), \n",
    "            ylim=(ylim_min, ylim_max))\n",
    "        axes[1,0].set_title('{} CryoSat-2 dv'.format(lakename_SF18), pad=7.5, fontsize=17.5)\n",
    "        axes[1,0].set_xlabel('Year', size=15)\n",
    "        axes[1,0].set_ylabel('Volume change [km$^3$]', size=15)\n",
    "        variable_outlines = plt.Line2D((0, 1), (0, 0), color='darkturquoise', linestyle='dashdot', linewidth=2)\n",
    "        axes[1,0].legend([#Smith2009,\n",
    "            SiegfriedFricker2018, variable_outlines],\n",
    "            [#'Smith and others, 2009',\n",
    "            'Siegfried & Fricker, 2018',\n",
    "            '±{} m variable outlines'.format(thres)], \n",
    "            loc='upper left')\n",
    "\n",
    "        # suplot 3: plot IS2 dvdt time series\n",
    "        axes[1,1].plot(dates_IS2[:idx+1], np.divide(np.cumsum(dvdt_SF18_IS2[:idx+1]), 1e+9), color='k', linestyle='dashed')\n",
    "        axes[1,1].plot(dates_IS2[:idx+1], np.divide(np.cumsum(dvdt_var_IS2[:idx+1]), 1e+9), color='darkturquoise', linestyle='dashdot')\n",
    "        locator = mdates.AutoDateLocator(minticks=1, maxticks=7)\n",
    "        formatter = mdates.ConciseDateFormatter(locator)\n",
    "        axes[1,1].xaxis.set_major_locator(locator)\n",
    "        axes[1,1].xaxis.set_major_formatter(formatter)\n",
    "        axes[1,1].set(xlim=(\n",
    "            date_time_obj + datetime.timedelta(days=ATL15_dh_sub.time.values[0]),\n",
    "            date_time_obj + datetime.timedelta(days=ATL15_dh_sub.time.values[-1])), \n",
    "            ylim=(ylim_min, ylim_max))\n",
    "        axes[1,1].set_title('{} ICESat-2 dv'.format(lakename_SF18), pad=7.5, fontsize=17.5)\n",
    "        axes[1,1].set_xlabel('Year', size=15)\n",
    "        axes[1,1].set_ylabel('Volume change [km$^3$]', size=15)\n",
    "        variable_outlines = plt.Line2D((0, 1), (0, 0), color='darkturquoise', linestyle='dashdot', linewidth=2)\n",
    "        axes[1,1].legend([#Smith2009,\n",
    "            SiegfriedFricker2018, variable_outlines],\n",
    "            [#'Smith and others, 2009',\n",
    "            'Siegfried & Fricker, 2018',\n",
    "            '±{} m variable outlines'.format(thres)], \n",
    "            loc='upper left')\n",
    "            \n",
    "        # save and close figure\n",
    "        plt.savefig('/Users/Wilson/Documents/0-code/1-lakeshores/output_dhdvdt-using-variable-outlines/S09SF18varoutlines_dhdvdt_CS2vsIS2_anim/plot/S09SF18varoutlines_dhdvdt_CS2vsIS2_anim-{}-dhdt-{}.png'.format(lakename_SF18,midcycdate.strftime('%Y-%m')), dpi=300, bbox_inches = \"tight\")  \n",
    "        # append im(age) to ims list\n",
    "        ani.grab_frame()\n",
    "        axes[0,0].clear()\n",
    "        axes[0,1].clear()\n",
    "        axes[1,0].clear()\n",
    "        axes[1,1].clear()\n",
    "    # create animation and save, adjust interval\n",
    "    ani.finish()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test function working using one lake\n",
    "S09SF18varoutlines_dhdvdt_CS2vsIS2_anim('ConwaySubglacialLake', 12500, 0.5)\n",
    "# S09SF18varoutlines_dhdvdt_CS2vsIS2_anim('Whillans_7', 7500, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run func on all lakes from SF18 inventory\n",
    "for idx in range(len(SiegfriedFricker2018_outlines)-1):\n",
    "    lakename = SiegfriedFricker2018_outlines['name'][idx]\n",
    "    S09SF18varoutlines_dhdvdt_CS2vsIS2_anim(lakename, 7500, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding explicit bbox boundaries\n",
    "def S09SF18varoutlines_dhdvdt_CS2vsIS2_anim(x_min, x_max, y_min, y_max, lakename_SF18, buffer, thres): \n",
    "    '''\n",
    "    Create CryoSat-2 (CS2) and ICESat-2 (IS2) dh/dt plots of ice surface height changes using geopandas buffer created bounding box around known lakes in Siegfried and Fricker, 2018 inventory.\n",
    "    Create time-variable outlines using skimage contour to plot variable outline alongside published outlines for comparison. \n",
    "    Use static and time-variable outlines to calculate dv/dt in both CryoSat-2 and ICESat-2.\n",
    "    Save images together into GIF animation.\n",
    "    Inputs: \n",
    "        lakename: lake of interest from SiegfriedFricker2018_outlines inventory\n",
    "        buffer: horizontal distance in meters to create bounding box around lake of interest\n",
    "        thres(hold): vertical distance in meters to delineate ice surface deformation contour\n",
    "    Outputs: \n",
    "        Animations of planview dh/dt visuals with variable ice surface deformation contours plotted to delineate time-variable lake boundary \n",
    "        alongside 2-D line plots of cumulative dv/dt using static and variable outlines that updates simultaneously to planview dh/dt animation.\n",
    "    '''\n",
    "    # isolate individual lake using gpd buffer\n",
    "    #lake_gpd = Smith2009_outlines.loc[Smith2009_outlines['Name'] == lakename]\n",
    "    lake_SF18 = SiegfriedFricker2018_outlines.loc[SiegfriedFricker2018_outlines['name'] == lakename_SF18]\n",
    "    lake_buffer = lake_SF18.buffer(buffer)\n",
    "    # define lake bounding box\n",
    "    # x_min = lake_buffer.bounds.values[0,0]; x_max = lake_buffer.bounds.values[0,2]\n",
    "    # y_min = lake_buffer.bounds.values[0,1]; y_max = lake_buffer.bounds.values[0,3]\n",
    "    # subset CS2 data set to region of interest\n",
    "    dataset = CS2_dh\n",
    "    mask_x = (dataset.x >= x_min) & (dataset.x <= x_max)\n",
    "    mask_y = (dataset.y >= y_min) & (dataset.y <= y_max)\n",
    "    mask_t = (dataset.time >= 2018.75)\n",
    "    CS2_dh_sub = dataset.where(mask_x & mask_y & mask_t, drop=True)\n",
    "    # subset ATL15 data set to region of interest\n",
    "    dataset = ATL15_dh\n",
    "    mask_x = (dataset.x >= x_min) & (dataset.x <= x_max)\n",
    "    mask_y = (dataset.y >= y_min) & (dataset.y <= y_max)\n",
    "    ATL15_dh_sub = dataset.where(mask_x & mask_y, drop=True)\n",
    "    # find magnitude of ice surface deformation in bounding box / find appropriate color map scale\n",
    "    height_anom_pos = []\n",
    "    height_anom_neg = []\n",
    "    for cyc in range(len(CS2_dh_sub)-1): # SHOULD ONLY CLIP TO CYCS IN IS2 ERA\n",
    "        pos = np.nanmax(CS2_dh_sub.delta_h[cyc+1,:,:]-CS2_dh_sub.delta_h[cyc,:,:])\n",
    "        neg = np.nanmin(CS2_dh_sub.delta_h[cyc+1,:,:]-CS2_dh_sub.delta_h[cyc,:,:])\n",
    "        height_anom_pos += [pos]\n",
    "        height_anom_neg += [neg]\n",
    "    for cyc in range(len(ATL15_dh_sub.time)-1): \n",
    "        pos = np.nanmax(ATL15_dh_sub.delta_h[cyc+1,:,:]-ATL15_dh_sub.delta_h[cyc,:,:])\n",
    "        neg = np.nanmin(ATL15_dh_sub.delta_h[cyc+1,:,:]-ATL15_dh_sub.delta_h[cyc,:,:])\n",
    "        height_anom_pos += [pos]\n",
    "        height_anom_neg += [neg]\n",
    "    max_height_anom_pos = max(height_anom_pos)\n",
    "    max_height_anom_neg = min(height_anom_neg)\n",
    "    max_height_anom_abs = max(max_height_anom_pos,abs(max_height_anom_neg))\n",
    "    v = np.round(max_height_anom_abs)\n",
    "    # create empty lists to store calculated data\n",
    "    dates_CS2 = []\n",
    "    dates_IS2 = []\n",
    "    dhdt_onlakeavg_SF18_CS2 = []\n",
    "    dhdt_onlakeavg_SF18_IS2 = []\n",
    "    dvdt_SF18_CS2 = []\n",
    "    dvdt_SF18_IS2 = []\n",
    "    dhdt_onlakeavg_var_CS2 = []\n",
    "    dhdt_onlakeavg_var_IS2 = []\n",
    "    dvdt_var_CS2 = []\n",
    "    dvdt_var_IS2 = []\n",
    "    for idx in range(len(CS2_dh_sub.delta_h)-1): \n",
    "        dhdt_CS2 = CS2_dh_sub.delta_h[idx+1,:,:]-CS2_dh_sub.delta_h[idx,:,:]\n",
    "        dhdt_IS2 = ATL15_dh_sub.delta_h[idx+1,:,:]-ATL15_dh_sub.delta_h[idx,:,:]\n",
    "        # calculate mid-cycle dates for plotting\n",
    "        # CryoSat-2\n",
    "        newdate = datetime.datetime(int(CS2_dh_sub.time.values[idx]), 1, 1) + datetime.timedelta(days = (CS2_dh_sub.time.values[idx] % 1) * 365.25)\n",
    "        newdate1 = datetime.datetime(int(CS2_dh_sub.time.values[idx+1]), 1, 1) + datetime.timedelta(days = (CS2_dh_sub.time.values[idx+1] % 1) * 365.25)\n",
    "        midcycdays = newdate1 - newdate\n",
    "        midcycdate = newdate + midcycdays/2\n",
    "        dates_CS2 += [midcycdate]\n",
    "        # ICESat-2\n",
    "        date_time_str = '18-01-01'\n",
    "        date_time_obj = datetime.datetime.strptime(date_time_str, '%y-%m-%d')\n",
    "        newdate = date_time_obj + datetime.timedelta(days=ATL15_dh_sub.time.values[idx])\n",
    "        newdate1 = date_time_obj + datetime.timedelta(days=ATL15_dh_sub.time.values[idx+1])\n",
    "        midcycdays = newdate1 - newdate\n",
    "        midcycdate = newdate + midcycdays/2\n",
    "        dates_IS2 += [midcycdate]\n",
    "        # clip data to get lake stats (first set crs)\n",
    "        dhdt_CS2.rio.write_crs(3031, inplace=True)\n",
    "        dhdt_IS2.rio.write_crs(3031, inplace=True)\n",
    "        dhdt_CS2_clip_SF18 = dhdt_CS2.rio.clip(lake_SF18.geometry.values, lake_SF18.crs, drop=False, invert=False)\n",
    "        dhdt_IS2_clip_SF18 = dhdt_IS2.rio.clip(lake_SF18.geometry.values, lake_SF18.crs, drop=False, invert=False)\n",
    "        # calculate lake avg. dh/dt and dv/dt time series using published stationary outlines\n",
    "        dhdt_CS2_lkavg_SF18 = np.nanmean(dhdt_CS2_clip_SF18)\n",
    "        dhdt_IS2_lkavg_SF18 = np.nanmean(dhdt_IS2_clip_SF18)\n",
    "        dhdt_onlakeavg_SF18_CS2 += [dhdt_CS2_lkavg_SF18]\n",
    "        dhdt_onlakeavg_SF18_IS2 += [dhdt_IS2_lkavg_SF18]\n",
    "        dhdt_CS2_vol_SF18 = dhdt_CS2_lkavg_SF18 * SiegfriedFricker2018_outlines[SiegfriedFricker2018_outlines['name'] == lakename_SF18]['area (m^2)']\n",
    "        dhdt_IS2_vol_SF18 = dhdt_IS2_lkavg_SF18 * SiegfriedFricker2018_outlines[SiegfriedFricker2018_outlines['name'] == lakename_SF18]['area (m^2)']\n",
    "        dvdt_SF18_CS2 += [dhdt_CS2_vol_SF18.values[0]]\n",
    "        dvdt_SF18_IS2 += [dhdt_IS2_vol_SF18.values[0]]\n",
    "        # create contours of ice surface elevation height changes to delineate lake outlines\n",
    "        contours_fill_CS2 = []\n",
    "        contours_drain_CS2 = []\n",
    "        contours_fill_IS2 = []\n",
    "        contours_drain_IS2 = []\n",
    "        # create CryoSat-2 variable outliens\n",
    "        contour = measure.find_contours(dhdt_CS2.values, thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_fill_CS2 += [contour]\n",
    "        contour = measure.find_contours(dhdt_CS2.values, -thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_drain_CS2 += [contour]\n",
    "        # create mapping conversion factor to map array location to polar stereographic x,y\n",
    "        x_conv = (x_max-x_min)/dhdt_CS2.shape[1] # MOVE OUT OF DHDT FOR LOOP SO THAT THIS CONSTANT CONVERSION FACTOR IS NOT CALCULATED EACH LOOP\n",
    "        y_conv = (y_max-y_min)/dhdt_CS2.shape[0]\n",
    "        # make polygons from variable outlines\n",
    "        polys_CS2 = []\n",
    "        for i in range(len(contours_fill_CS2)): \n",
    "            for j in range(len(contours_fill_CS2[i])):\n",
    "                if len(contours_fill_CS2[i][j][:, 1]) > 2: \n",
    "                    poly = Polygon(list(zip(x_min+contours_fill_CS2[i][j][:, 1]*x_conv, y_max-contours_fill_CS2[i][j][:, 0]*y_conv))) \n",
    "                    polys_CS2 += [poly]\n",
    "        for i in range(len(contours_drain_CS2)): \n",
    "            for j in range(len(contours_drain_CS2[i])):\n",
    "                if len(contours_drain_CS2[i][j][:, 1]) > 2: \n",
    "                    poly = Polygon(list(zip(x_min+contours_drain_CS2[i][j][:, 1]*x_conv, y_max-contours_drain_CS2[i][j][:, 0]*y_conv))) \n",
    "                    polys_CS2 += [poly]\n",
    "        # create ICESat-2 variable outlines\n",
    "        contour = measure.find_contours(dhdt_IS2.values, thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_fill_IS2 += [contour]\n",
    "        contour = measure.find_contours(dhdt_IS2.values, -thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_drain_IS2 += [contour]\n",
    "        # create mapping conversion factor to map array location to polar stereographic x,y\n",
    "        x_conv = (x_max-x_min)/dhdt_IS2.shape[1]\n",
    "        y_conv = (y_max-y_min)/dhdt_IS2.shape[0]\n",
    "        # make polygons from variable outlines\n",
    "        polys_IS2 = []  \n",
    "        for i in range(len(contours_fill_IS2)): \n",
    "            for j in range(len(contours_fill_IS2[i])):\n",
    "                if len(contours_fill_IS2[i][j][:, 1]) > 2: \n",
    "                    poly = Polygon(list(zip(x_min+contours_fill_IS2[i][j][:, 1]*x_conv, y_max-contours_fill_IS2[i][j][:, 0]*y_conv))) \n",
    "                    polys_IS2 += [poly]\n",
    "        for i in range(len(contours_drain_IS2)): \n",
    "            for j in range(len(contours_drain_IS2[i])):\n",
    "                if len(contours_drain_IS2[i][j][:, 1]) > 2: \n",
    "                    poly = Polygon(list(zip(x_min+contours_drain_IS2[i][j][:, 1]*x_conv, y_max-contours_drain_IS2[i][j][:, 0]*y_conv))) \n",
    "                    polys_IS2 += [poly]\n",
    "        # start with baseline variable outline area of zero\n",
    "        variable_area = 0\n",
    "        # CryoSat-2\n",
    "        # if polygons are present at time step, \n",
    "        if len(polys_CS2) > 0: \n",
    "            # clip data to polygons\n",
    "            dhdt_clip = dhdt_CS2.rio.clip(polys_CS2, drop=False, invert=False)\n",
    "            # then calculate on-lake averages of dh/dt\n",
    "            avg_lk_dhdt = np.nanmean(dhdt_clip)\n",
    "            # occasionally small polygons will completely clip data resulting in nan's for lake avg. dh/dt; replace with zeros\n",
    "            if math.isnan(avg_lk_dhdt): \n",
    "                avg_lk_dhdt = 0\n",
    "                dhdt_onlakeavg_var_CS2 += [avg_lk_dhdt]\n",
    "            else:\n",
    "                dhdt_onlakeavg_var_CS2 += [avg_lk_dhdt]\n",
    "            # and dv/dt\n",
    "            for i in range(len(polys_CS2)):\n",
    "                variable_area = variable_area + polys_CS2[i].area # CHANGE TO GEODESIC AREA\n",
    "            vol_var = avg_lk_dhdt*variable_area\n",
    "            dvdt_var_CS2 += [vol_var]\n",
    "        else: \n",
    "            avg_lk_dhdt = 0\n",
    "            dhdt_onlakeavg_var_CS2 += [avg_lk_dhdt]\n",
    "            vol_var = avg_lk_dhdt*variable_area\n",
    "            dvdt_var_CS2 += [vol_var]\n",
    "        # ICESat-2\n",
    "        # if polygons are present at time step, \n",
    "        if len(polys_IS2) > 0: \n",
    "            # clip data to polygons\n",
    "            dhdt_clip = dhdt_IS2.rio.clip(polys_IS2, drop=False, invert=False)\n",
    "            # then calculate on-lake averages of dh/dt\n",
    "            avg_lk_dhdt = np.nanmean(dhdt_clip)\n",
    "            # occasionally small polygons will completely clip data resulting in nan's for lake avg. dh/dt\n",
    "            # replace with zeros\n",
    "            if math.isnan(avg_lk_dhdt): \n",
    "                avg_lk_dhdt = 0\n",
    "                dhdt_onlakeavg_var_IS2 += [avg_lk_dhdt]\n",
    "            else:\n",
    "                dhdt_onlakeavg_var_IS2 += [avg_lk_dhdt]\n",
    "            # and dv/dt\n",
    "            for i in range(len(polys_IS2)):\n",
    "                variable_area = variable_area + polys_IS2[i].area # CHANGE TO GEODESIC AREA\n",
    "            vol_var = avg_lk_dhdt*variable_area\n",
    "            dvdt_var_IS2 += [vol_var]\n",
    "        else: \n",
    "            avg_lk_dhdt = 0\n",
    "            dhdt_onlakeavg_var_IS2 += [avg_lk_dhdt]\n",
    "            vol_var = avg_lk_dhdt*variable_area\n",
    "            dvdt_var_IS2 += [vol_var]\n",
    "    # create fig, axes\n",
    "    fig, axes = plt.subplots(2,2, figsize=(20,20))\n",
    "    # create colorbar axes for dh/dt subplots\n",
    "    # divider0 = make_axes_locatable(axes[0,0])\n",
    "    # cax0 = divider0.append_axes('right', size='5%', pad=0.2)\n",
    "    divider1 = make_axes_locatable(axes[0,1])\n",
    "    cax1 = divider1.append_axes('right', size='5%', pad=0.2)\n",
    "    # create empty list to store animation im(age)s\n",
    "    ani = animation.PillowWriter(fps=1)\n",
    "    ani.setup(fig, '/Users/Wilson/Documents/0-code/1-lakeshores/output_dhdvdt-using-variable-outlines/S09SF18varoutlines_dhdvdt_CS2vsIS2_anim/S09SF18varoutlines_dhdvdt_CS2vsIS2_anim-{}.gif'.format(lakename_SF18), dpi=300)\n",
    "    # for loop through dh/dt acquisition cycles to construct animation\n",
    "    for idx in range(len(CS2_dh_sub.delta_h)-1): \n",
    "        dhdt_CS2 = CS2_dh_sub.delta_h[idx+1,:,:]-CS2_dh_sub.delta_h[idx,:,:]\n",
    "        dhdt_IS2 = ATL15_dh_sub.delta_h[idx+1,:,:]-ATL15_dh_sub.delta_h[idx,:,:]\n",
    "        # create contours of ice surface elevation height changes to delineate lake outlines\n",
    "        contours_fill_CS2 = []\n",
    "        contours_drain_CS2 = []\n",
    "        contours_fill_IS2 = []\n",
    "        contours_drain_IS2 = []\n",
    "        # create CryoSat-2 variable outliens\n",
    "        contour = measure.find_contours(dhdt_CS2.values, thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_fill_CS2 += [contour]\n",
    "        contour = measure.find_contours(dhdt_CS2.values, -thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_drain_CS2 += [contour]\n",
    "        # create ICESat-2 variable outlines\n",
    "        contour = measure.find_contours(dhdt_IS2.values, thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_fill_IS2 += [contour]\n",
    "        contour = measure.find_contours(dhdt_IS2.values, -thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_drain_IS2 += [contour]\n",
    "        # subplot 0: plot planview dhdt and variable outlines found in CryoSat-2 time slice\n",
    "        img0 = axes[0,0].imshow(dhdt_CS2, extent=[x_min, x_max, y_min, y_max], \n",
    "            origin='upper', cmap=cmocean.cm.balance_r, vmin=-v, vmax=v)\n",
    "        for i in range(len(contours_fill_CS2)): \n",
    "            for j in range(len(contours_fill_CS2[i])):\n",
    "                axes[0,0].plot(x_min+contours_fill_CS2[i][j][:, 1]*x_conv, y_max-contours_fill_CS2[i][j][:, 0]*y_conv, color='mediumblue', linestyle='dashdot', linewidth=2)\n",
    "        for i in range(len(contours_drain_CS2)): \n",
    "            for j in range(len(contours_drain_CS2[i])):\n",
    "                axes[0,0].plot(x_min+contours_drain_CS2[i][j][:, 1]*x_conv, y_max-contours_drain_CS2[i][j][:, 0]*y_conv, color='maroon', linestyle=(0, (3, 1, 1, 1)), linewidth=2)\n",
    "        axes[0,0].set(xlim=(x_min, x_max), ylim=(y_min, y_max))\n",
    "        axes[0,0].set_xlabel('polar stereographic x [m]', size=15)\n",
    "        axes[0,0].set_ylabel('polar stereographic y [m]', size=15)\n",
    "        axes[0,0].ticklabel_format(axis='both',scilimits=(0,0))\n",
    "        axes[0,0].set_title(lakename_SF18+' CryoSat-2 dh \\n$h_{'+dates_CS2[idx].strftime('%m/%Y')+'} - h_{'+dates_CS2[idx-1].strftime('%m/%Y')+'}$', pad=7.5, fontsize=17.5)\n",
    "        # fig.colorbar(img0, cax=cax0).set_label('Height (h) change [m]', size=15)\n",
    "        # overlay published outlines for visual comparison \n",
    "        Smith2009_outlines.boundary.plot(ax=axes[0,0], color='k', linestyle='--', linewidth=1)\n",
    "        SiegfriedFricker2018_outlines[SiegfriedFricker2018_outlines['cite'] \\\n",
    "            != 'Smith and others, 2009, J. Glac., doi:10.3189/002214309789470879'] \\\n",
    "            .boundary.plot(ax=axes[0,0], color='k', linestyle='-', linewidth=1)\n",
    "        # create 2D lines for legend\n",
    "        Smith2009 = plt.Line2D((0, 1), (0, 0), color='k', linestyle='--', linewidth=2)\n",
    "        SiegfriedFricker2018 = plt.Line2D((0, 1), (0, 0), color='k', linestyle='-', linewidth=2)\n",
    "        uplift = plt.Line2D((0, 1), (0, 0), color='mediumblue', linestyle='dashdot', linewidth=2)\n",
    "        subsidence = plt.Line2D((0, 1), (0, 0), color='maroon', linestyle=(0, (3, 1, 1, 1)), linewidth=2)\n",
    "        axes[0,0].legend([Smith2009, SiegfriedFricker2018, uplift, subsidence],\n",
    "            ['Smith and others, 2009 static outline','Siegfried & Fricker, 2018 static outline',\n",
    "            ('+'+str(thres)+' m uplift (filling) variable outline'), '–'+str(thres)+' m subsidence (draining) variable outline'], \n",
    "            loc='upper left')\n",
    "        # subplot 1: plot planview dhdt and variable outlines found in ICESat-2 time slice\n",
    "        img1 = axes[0,1].imshow(dhdt_IS2, extent=[x_min, x_max, y_min, y_max], \n",
    "            origin='upper', cmap=cmocean.cm.balance_r, vmin=-v, vmax=v)\n",
    "        for i in range(len(contours_fill_IS2)): \n",
    "            for j in range(len(contours_fill_IS2[i])):\n",
    "                axes[0,1].plot(x_min+contours_fill_IS2[i][j][:, 1]*x_conv, y_max-contours_fill_IS2[i][j][:, 0]*y_conv, color='mediumblue', linestyle='dashdot', linewidth=2)\n",
    "        for i in range(len(contours_drain_IS2)): \n",
    "            for j in range(len(contours_drain_IS2[i])):\n",
    "                axes[0,1].plot(x_min+contours_drain_IS2[i][j][:, 1]*x_conv, y_max-contours_drain_IS2[i][j][:, 0]*y_conv, color='maroon', linestyle=(0, (3, 1, 1, 1)), linewidth=2)\n",
    "        axes[0,1].set(xlim=(x_min, x_max), ylim=(y_min, y_max))\n",
    "        axes[0,1].set_xlabel('polar stereographic x [m]', size=15)\n",
    "        axes[0,1].ticklabel_format(axis='both',scilimits=(0,0))\n",
    "        axes[0,1].set_title(lakename_SF18+' ICESat-2 dh \\n$h_{'+dates_IS2[idx].strftime('%m/%Y')+'} - h_{'+dates_IS2[idx-1].strftime('%m/%Y')+'}$', pad=7.5, fontsize=17.5)\n",
    "        fig.colorbar(img1, cax=cax1).set_label('Height change (dh) [m]', size=15)\n",
    "        # overlay published outlines for visual comparison \n",
    "        Smith2009_outlines.boundary.plot(ax=axes[0,1], color='k', linestyle='--', linewidth=1)\n",
    "        SiegfriedFricker2018_outlines[SiegfriedFricker2018_outlines['cite'] \\\n",
    "            != 'Smith and others, 2009, J. Glac., doi:10.3189/002214309789470879'] \\\n",
    "            .boundary.plot(ax=axes[0,1], color='k', linestyle='-', linewidth=1)\n",
    "        axes[0,1].legend([Smith2009, SiegfriedFricker2018, uplift, subsidence],\n",
    "            ['Smith and others, 2009 static outline','Siegfried & Fricker, 2018 static outline',\n",
    "            ('+'+str(thres)+' m uplift (filling) variable outline'), '–'+str(thres)+' m subsidence (draining) variable outline'], \n",
    "            loc='upper left')\n",
    "        # suplot 2: plot CS2 dvdt time series\n",
    "        axes[1,0].plot(dates_CS2[:idx+1], np.divide(np.cumsum(dvdt_SF18_CS2[:idx+1]), 1e+9), color='k', linestyle='dashed')\n",
    "        axes[1,0].plot(dates_CS2[:idx+1], np.divide(np.cumsum(dvdt_var_CS2[:idx+1]), 1e+9), color='darkturquoise', linestyle='dashdot')\n",
    "        locator = mdates.AutoDateLocator(minticks=1, maxticks=7)\n",
    "        formatter = mdates.ConciseDateFormatter(locator)\n",
    "        axes[1,0].xaxis.set_major_locator(locator)\n",
    "        axes[1,0].xaxis.set_major_formatter(formatter)\n",
    "        # CONSIDER MOVING OUT OF FOR LOOP SO IT'S NOT CALCULATING CONSTANTS EVERY LOOP\n",
    "        dvdt_min = min(np.divide(min(np.cumsum(dvdt_SF18_CS2)), 1e+9), np.divide(min(np.cumsum(dvdt_var_CS2)), 1e+9), np.divide(min(np.cumsum(dvdt_SF18_IS2)), 1e+9), np.divide(min(np.cumsum(dvdt_var_IS2)), 1e+9))\n",
    "        dvdt_max = max(np.divide(max(np.cumsum(dvdt_SF18_CS2)), 1e+9), np.divide(max(np.cumsum(dvdt_var_CS2)), 1e+9), np.divide(max(np.cumsum(dvdt_SF18_IS2)), 1e+9), np.divide(max(np.cumsum(dvdt_var_IS2)), 1e+9))\n",
    "        dvdt_range = dvdt_max - dvdt_min\n",
    "        ylim_min = dvdt_min - (dvdt_range * 0.1)\n",
    "        ylim_max = dvdt_max + (dvdt_range * 0.1)\n",
    "        axes[1,0].set(xlim=(\n",
    "            datetime.datetime(int(CS2_dh_sub.time.values[0]), 1, 1) + datetime.timedelta(days = (CS2_dh_sub.time.values[0] % 1) * 365.25), \n",
    "            datetime.datetime(int(CS2_dh_sub.time.values[-1]), 1, 1) + datetime.timedelta(days = (CS2_dh_sub.time.values[-1] % 1) * 365.25)), \n",
    "            ylim=(ylim_min, ylim_max))\n",
    "        axes[1,0].set_title('{} CryoSat-2 dv'.format(lakename_SF18), pad=7.5, fontsize=17.5)\n",
    "        axes[1,0].set_xlabel('Year', size=15)\n",
    "        axes[1,0].set_ylabel('Volume change [km$^3$]', size=15)\n",
    "        variable_outlines = plt.Line2D((0, 1), (0, 0), color='darkturquoise', linestyle='dashdot', linewidth=2)\n",
    "        axes[1,0].legend([#Smith2009,\n",
    "            SiegfriedFricker2018, variable_outlines],\n",
    "            [#'Smith and others, 2009',\n",
    "            'Siegfried & Fricker, 2018',\n",
    "            '±{} m variable outlines'.format(thres)], \n",
    "            loc='upper left')\n",
    "        # suplot 3: plot IS2 dvdt time series\n",
    "        axes[1,1].plot(dates_IS2[:idx+1], np.divide(np.cumsum(dvdt_SF18_IS2[:idx+1]), 1e+9), color='k', linestyle='dashed')\n",
    "        axes[1,1].plot(dates_IS2[:idx+1], np.divide(np.cumsum(dvdt_var_IS2[:idx+1]), 1e+9), color='darkturquoise', linestyle='dashdot')\n",
    "        locator = mdates.AutoDateLocator(minticks=1, maxticks=7)\n",
    "        formatter = mdates.ConciseDateFormatter(locator)\n",
    "        axes[1,1].xaxis.set_major_locator(locator)\n",
    "        axes[1,1].xaxis.set_major_formatter(formatter)\n",
    "        axes[1,1].set(xlim=(\n",
    "            date_time_obj + datetime.timedelta(days=ATL15_dh_sub.time.values[0]),\n",
    "            date_time_obj + datetime.timedelta(days=ATL15_dh_sub.time.values[-1])), \n",
    "            ylim=(ylim_min, ylim_max))\n",
    "        axes[1,1].set_title('{} ICESat-2 dv'.format(lakename_SF18), pad=7.5, fontsize=17.5)\n",
    "        axes[1,1].set_xlabel('Year', size=15)\n",
    "        axes[1,1].set_ylabel('Volume change [km$^3$]', size=15)\n",
    "        variable_outlines = plt.Line2D((0, 1), (0, 0), color='darkturquoise', linestyle='dashdot', linewidth=2)\n",
    "        axes[1,1].legend([#Smith2009,\n",
    "            SiegfriedFricker2018, variable_outlines],\n",
    "            [#'Smith and others, 2009',\n",
    "            'Siegfried & Fricker, 2018',\n",
    "            '±{} m variable outlines'.format(thres)], \n",
    "            loc='upper left')\n",
    "        # append im(age) to ims list\n",
    "        ani.grab_frame()\n",
    "        axes[0,0].clear()\n",
    "        axes[0,1].clear()\n",
    "        axes[1,0].clear()\n",
    "        axes[1,1].clear()\n",
    "    # create animation and save, adjust interval\n",
    "    ani.finish()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tn/2b7yqbx51jxb820_x39chyc80000gn/T/ipykernel_14205/3844828962.py:176: RuntimeWarning: Mean of empty slice\n",
      "  avg_lk_dhdt = np.nanmean(dhdt_clip)\n"
     ]
    }
   ],
   "source": [
    "# test function working using one lake\n",
    "S09SF18varoutlines_dhdvdt_CS2vsIS2_anim(-5.57e5,-5.3e5,-5.1e5,-4.9e5, 'Whillans_7', 7500, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding S09 to area calcs\n",
    "def S09SF18varoutlines_dhdvdt_CS2vsIS2_anim(lakename_S09, lakename_SF18, buffer, thres): \n",
    "    '''\n",
    "    Create CryoSat-2 (CS2) and ICESat-2 (IS2) dh/dt plots of ice surface height changes using geopandas buffer created bounding box around known lakes in Siegfried and Fricker, 2018 inventory.\n",
    "    Create time-variable outlines using skimage contour to plot variable outline alongside published outlines for comparison. \n",
    "    Use static and time-variable outlines to calculate dv/dt in both CryoSat-2 and ICESat-2.\n",
    "    Save images together into GIF animation.\n",
    "    Inputs: \n",
    "        lakename: lake of interest from SiegfriedFricker2018_outlines inventory\n",
    "        buffer: horizontal distance in meters to create bounding box around lake of interest\n",
    "        thres(hold): vertical distance in meters to delineate ice surface deformation contour\n",
    "    Outputs: \n",
    "        Animations of planview dh/dt visuals with variable ice surface deformation contours plotted to delineate time-variable lake boundary \n",
    "        alongside 2-D line plots of cumulative dv/dt using static and variable outlines that updates simultaneously to planview dh/dt animation.\n",
    "    '''\n",
    "    # isolate individual lake using gpd buffer\n",
    "    lake_S09 = Smith2009_outlines.loc[Smith2009_outlines['Name'] == lakename_S09]\n",
    "    lake_SF18 = SiegfriedFricker2018_outlines.loc[SiegfriedFricker2018_outlines['name'] == lakename_SF18]\n",
    "    lake_buffer = lake_SF18.buffer(buffer)\n",
    "    # define lake bounding box\n",
    "    x_min = lake_buffer.bounds.values[0,0]; x_max = lake_buffer.bounds.values[0,2]\n",
    "    y_min = lake_buffer.bounds.values[0,1]; y_max = lake_buffer.bounds.values[0,3]\n",
    "    # subset CS2 data set to region of interest\n",
    "    dataset = CS2_dh\n",
    "    mask_x = (dataset.x >= x_min) & (dataset.x <= x_max)\n",
    "    mask_y = (dataset.y >= y_min) & (dataset.y <= y_max)\n",
    "    mask_t = (dataset.time >= 2018.75)\n",
    "    CS2_dh_sub = dataset.where(mask_x & mask_y & mask_t, drop=True)\n",
    "    # subset ATL15 data set to region of interest\n",
    "    dataset = ATL15_dh\n",
    "    mask_x = (dataset.x >= x_min) & (dataset.x <= x_max)\n",
    "    mask_y = (dataset.y >= y_min) & (dataset.y <= y_max)\n",
    "    ATL15_dh_sub = dataset.where(mask_x & mask_y, drop=True)\n",
    "    # find magnitude of ice surface deformation in bounding box / find appropriate color map scale\n",
    "    height_anom_pos = []\n",
    "    height_anom_neg = []\n",
    "    for cyc in range(len(CS2_dh_sub)-1): # SHOULD ONLY CLIP TO CYCS IN IS2 ERA\n",
    "        pos = np.nanmax(CS2_dh_sub.delta_h[cyc+1,:,:]-CS2_dh_sub.delta_h[cyc,:,:])\n",
    "        neg = np.nanmin(CS2_dh_sub.delta_h[cyc+1,:,:]-CS2_dh_sub.delta_h[cyc,:,:])\n",
    "        height_anom_pos += [pos]\n",
    "        height_anom_neg += [neg]\n",
    "    for cyc in range(len(ATL15_dh_sub.time)-1): \n",
    "        pos = np.nanmax(ATL15_dh_sub.delta_h[cyc+1,:,:]-ATL15_dh_sub.delta_h[cyc,:,:])\n",
    "        neg = np.nanmin(ATL15_dh_sub.delta_h[cyc+1,:,:]-ATL15_dh_sub.delta_h[cyc,:,:])\n",
    "        height_anom_pos += [pos]\n",
    "        height_anom_neg += [neg]\n",
    "    max_height_anom_pos = max(height_anom_pos)\n",
    "    max_height_anom_neg = min(height_anom_neg)\n",
    "    max_height_anom_abs = max(max_height_anom_pos,abs(max_height_anom_neg))\n",
    "    v = np.round(max_height_anom_abs)\n",
    "    # create empty lists to store calculated data\n",
    "    dates_CS2 = []\n",
    "    dates_IS2 = []\n",
    "    dhdt_onlakeavg_S09_CS2 = []\n",
    "    dhdt_onlakeavg_S09_IS2 = []\n",
    "    dvdt_S09_CS2 = []\n",
    "    dvdt_S09_IS2 = []\n",
    "    dhdt_onlakeavg_SF18_CS2 = []\n",
    "    dhdt_onlakeavg_SF18_IS2 = []\n",
    "    dvdt_SF18_CS2 = []\n",
    "    dvdt_SF18_IS2 = []\n",
    "    dhdt_onlakeavg_var_CS2 = []\n",
    "    dhdt_onlakeavg_var_IS2 = []\n",
    "    dvdt_var_CS2 = []\n",
    "    dvdt_var_IS2 = []\n",
    "    for idx in range(len(CS2_dh_sub.delta_h)-1): \n",
    "        dhdt_CS2 = CS2_dh_sub.delta_h[idx+1,:,:]-CS2_dh_sub.delta_h[idx,:,:]\n",
    "        dhdt_IS2 = ATL15_dh_sub.delta_h[idx+1,:,:]-ATL15_dh_sub.delta_h[idx,:,:]\n",
    "        # calculate mid-cycle dates for plotting\n",
    "        # CryoSat-2\n",
    "        newdate = datetime.datetime(int(CS2_dh_sub.time.values[idx]), 1, 1) + datetime.timedelta(days = (CS2_dh_sub.time.values[idx] % 1) * 365.25)\n",
    "        newdate1 = datetime.datetime(int(CS2_dh_sub.time.values[idx+1]), 1, 1) + datetime.timedelta(days = (CS2_dh_sub.time.values[idx+1] % 1) * 365.25)\n",
    "        midcycdays = newdate1 - newdate\n",
    "        midcycdate = newdate + midcycdays/2\n",
    "        dates_CS2 += [midcycdate]\n",
    "        # ICESat-2\n",
    "        date_time_str = '18-01-01'\n",
    "        date_time_obj = datetime.datetime.strptime(date_time_str, '%y-%m-%d')\n",
    "        newdate = date_time_obj + datetime.timedelta(days=ATL15_dh_sub.time.values[idx])\n",
    "        newdate1 = date_time_obj + datetime.timedelta(days=ATL15_dh_sub.time.values[idx+1])\n",
    "        midcycdays = newdate1 - newdate\n",
    "        midcycdate = newdate + midcycdays/2\n",
    "        dates_IS2 += [midcycdate]\n",
    "        # clip data to get lake stats (first set crs)\n",
    "        dhdt_CS2.rio.write_crs(3031, inplace=True)\n",
    "        dhdt_IS2.rio.write_crs(3031, inplace=True)\n",
    "        dhdt_CS2_clip_S09 = dhdt_CS2.rio.clip(lake_S09.geometry.values, lake_SF18.crs, drop=False, invert=False)\n",
    "        dhdt_IS2_clip_S09 = dhdt_IS2.rio.clip(lake_S09.geometry.values, lake_SF18.crs, drop=False, invert=False)\n",
    "        dhdt_CS2_clip_SF18 = dhdt_CS2.rio.clip(lake_SF18.geometry.values, lake_SF18.crs, drop=False, invert=False)\n",
    "        dhdt_IS2_clip_SF18 = dhdt_IS2.rio.clip(lake_SF18.geometry.values, lake_SF18.crs, drop=False, invert=False)\n",
    "        # calculate lake avg. dh/dt and dv/dt time series using published stationary outlines\n",
    "        # S09\n",
    "        dhdt_CS2_lkavg_S09 = np.nanmean(dhdt_CS2_clip_S09)\n",
    "        dhdt_IS2_lkavg_S09 = np.nanmean(dhdt_IS2_clip_S09)\n",
    "        dhdt_onlakeavg_S09_CS2 += [dhdt_CS2_lkavg_S09]\n",
    "        dhdt_onlakeavg_S09_IS2 += [dhdt_IS2_lkavg_S09]\n",
    "        dhdt_CS2_vol_S09 = dhdt_CS2_lkavg_S09 * SiegfriedFricker2018_outlines[SiegfriedFricker2018_outlines['name'] == lakename_SF18]['area (m^2)']\n",
    "        dhdt_IS2_vol_S09 = dhdt_IS2_lkavg_S09 * SiegfriedFricker2018_outlines[SiegfriedFricker2018_outlines['name'] == lakename_SF18]['area (m^2)']\n",
    "        dvdt_S09_CS2 += [dhdt_CS2_vol_S09.values[0]]\n",
    "        dvdt_S09_IS2 += [dhdt_IS2_vol_S09.values[0]]\n",
    "        # SF18\n",
    "        dhdt_CS2_lkavg_SF18 = np.nanmean(dhdt_CS2_clip_SF18)\n",
    "        dhdt_IS2_lkavg_SF18 = np.nanmean(dhdt_IS2_clip_SF18)\n",
    "        dhdt_onlakeavg_SF18_CS2 += [dhdt_CS2_lkavg_SF18]\n",
    "        dhdt_onlakeavg_SF18_IS2 += [dhdt_IS2_lkavg_SF18]\n",
    "        dhdt_CS2_vol_SF18 = dhdt_CS2_lkavg_SF18 * SiegfriedFricker2018_outlines[SiegfriedFricker2018_outlines['name'] == lakename_SF18]['area (m^2)']\n",
    "        dhdt_IS2_vol_SF18 = dhdt_IS2_lkavg_SF18 * SiegfriedFricker2018_outlines[SiegfriedFricker2018_outlines['name'] == lakename_SF18]['area (m^2)']\n",
    "        dvdt_SF18_CS2 += [dhdt_CS2_vol_SF18.values[0]]\n",
    "        dvdt_SF18_IS2 += [dhdt_IS2_vol_SF18.values[0]]\n",
    "        # create contours of ice surface elevation height changes to delineate lake outlines\n",
    "        contours_fill_CS2 = []\n",
    "        contours_drain_CS2 = []\n",
    "        contours_fill_IS2 = []\n",
    "        contours_drain_IS2 = []\n",
    "        # create CryoSat-2 variable outliens\n",
    "        contour = measure.find_contours(dhdt_CS2.values, thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_fill_CS2 += [contour]\n",
    "        contour = measure.find_contours(dhdt_CS2.values, -thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_drain_CS2 += [contour]\n",
    "        # create mapping conversion factor to map array location to polar stereographic x,y\n",
    "        x_conv = (x_max-x_min)/dhdt_CS2.shape[1] # MOVE OUT OF DHDT FOR LOOP SO THAT THIS CONSTANT CONVERSION FACTOR IS NOT CALCULATED EACH LOOP\n",
    "        y_conv = (y_max-y_min)/dhdt_CS2.shape[0]\n",
    "        # make polygons from variable outlines\n",
    "        polys_CS2 = []\n",
    "        for i in range(len(contours_fill_CS2)): \n",
    "            for j in range(len(contours_fill_CS2[i])):\n",
    "                if len(contours_fill_CS2[i][j][:, 1]) > 2: \n",
    "                    poly = Polygon(list(zip(x_min+contours_fill_CS2[i][j][:, 1]*x_conv, y_max-contours_fill_CS2[i][j][:, 0]*y_conv))) \n",
    "                    polys_CS2 += [poly]\n",
    "        for i in range(len(contours_drain_CS2)): \n",
    "            for j in range(len(contours_drain_CS2[i])):\n",
    "                if len(contours_drain_CS2[i][j][:, 1]) > 2: \n",
    "                    poly = Polygon(list(zip(x_min+contours_drain_CS2[i][j][:, 1]*x_conv, y_max-contours_drain_CS2[i][j][:, 0]*y_conv))) \n",
    "                    polys_CS2 += [poly]\n",
    "        # create ICESat-2 variable outlines\n",
    "        contour = measure.find_contours(dhdt_IS2.values, thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_fill_IS2 += [contour]\n",
    "        contour = measure.find_contours(dhdt_IS2.values, -thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_drain_IS2 += [contour]\n",
    "        # create mapping conversion factor to map array location to polar stereographic x,y\n",
    "        x_conv = (x_max-x_min)/dhdt_IS2.shape[1]\n",
    "        y_conv = (y_max-y_min)/dhdt_IS2.shape[0]\n",
    "        # make polygons from variable outlines\n",
    "        polys_IS2 = []  \n",
    "        for i in range(len(contours_fill_IS2)): \n",
    "            for j in range(len(contours_fill_IS2[i])):\n",
    "                if len(contours_fill_IS2[i][j][:, 1]) > 2: \n",
    "                    poly = Polygon(list(zip(x_min+contours_fill_IS2[i][j][:, 1]*x_conv, y_max-contours_fill_IS2[i][j][:, 0]*y_conv))) \n",
    "                    polys_IS2 += [poly]\n",
    "        for i in range(len(contours_drain_IS2)): \n",
    "            for j in range(len(contours_drain_IS2[i])):\n",
    "                if len(contours_drain_IS2[i][j][:, 1]) > 2: \n",
    "                    poly = Polygon(list(zip(x_min+contours_drain_IS2[i][j][:, 1]*x_conv, y_max-contours_drain_IS2[i][j][:, 0]*y_conv))) \n",
    "                    polys_IS2 += [poly]\n",
    "        # start with baseline variable outline area of zero\n",
    "        variable_area = 0\n",
    "        # CryoSat-2\n",
    "        # if polygons are present at time step, \n",
    "        if len(polys_CS2) > 0: \n",
    "            # clip data to polygons\n",
    "            dhdt_clip = dhdt_CS2.rio.clip(polys_CS2, drop=False, invert=False)\n",
    "            # then calculate on-lake averages of dh/dt\n",
    "            avg_lk_dhdt = np.nanmean(dhdt_clip)\n",
    "            # occasionally small polygons will completely clip data resulting in nan's for lake avg. dh/dt; replace with zeros\n",
    "            if math.isnan(avg_lk_dhdt): \n",
    "                avg_lk_dhdt = 0\n",
    "                dhdt_onlakeavg_var_CS2 += [avg_lk_dhdt]\n",
    "            else:\n",
    "                dhdt_onlakeavg_var_CS2 += [avg_lk_dhdt]\n",
    "            # and dv/dt\n",
    "            for i in range(len(polys_CS2)):\n",
    "                variable_area = variable_area + polys_CS2[i].area # CHANGE TO GEODESIC AREA\n",
    "            vol_var = avg_lk_dhdt*variable_area\n",
    "            dvdt_var_CS2 += [vol_var]\n",
    "        else: \n",
    "            avg_lk_dhdt = 0\n",
    "            dhdt_onlakeavg_var_CS2 += [avg_lk_dhdt]\n",
    "            vol_var = avg_lk_dhdt*variable_area\n",
    "            dvdt_var_CS2 += [vol_var]\n",
    "        # ICESat-2\n",
    "        # if polygons are present at time step, \n",
    "        if len(polys_IS2) > 0: \n",
    "            # clip data to polygons\n",
    "            dhdt_clip = dhdt_IS2.rio.clip(polys_IS2, drop=False, invert=False)\n",
    "            # then calculate on-lake averages of dh/dt\n",
    "            avg_lk_dhdt = np.nanmean(dhdt_clip)\n",
    "            # occasionally small polygons will completely clip data resulting in nan's for lake avg. dh/dt\n",
    "            # replace with zeros\n",
    "            if math.isnan(avg_lk_dhdt): \n",
    "                avg_lk_dhdt = 0\n",
    "                dhdt_onlakeavg_var_IS2 += [avg_lk_dhdt]\n",
    "            else:\n",
    "                dhdt_onlakeavg_var_IS2 += [avg_lk_dhdt]\n",
    "            # and dv/dt\n",
    "            for i in range(len(polys_IS2)):\n",
    "                variable_area = variable_area + polys_IS2[i].area # CHANGE TO GEODESIC AREA\n",
    "            vol_var = avg_lk_dhdt*variable_area\n",
    "            dvdt_var_IS2 += [vol_var]\n",
    "        else: \n",
    "            avg_lk_dhdt = 0\n",
    "            dhdt_onlakeavg_var_IS2 += [avg_lk_dhdt]\n",
    "            vol_var = avg_lk_dhdt*variable_area\n",
    "            dvdt_var_IS2 += [vol_var]\n",
    "    # create fig, axes\n",
    "    fig, axes = plt.subplots(2,2, figsize=(20,20))\n",
    "    # create colorbar axes for dh/dt subplots\n",
    "    divider0 = make_axes_locatable(axes[0,0])\n",
    "    cax0 = divider0.append_axes('right', size='5%', pad=0.2)\n",
    "    divider1 = make_axes_locatable(axes[0,1])\n",
    "    cax1 = divider1.append_axes('right', size='5%', pad=0.2)\n",
    "    # create empty list to store animation im(age)s\n",
    "    ani = animation.PillowWriter(fps=1)\n",
    "    ani.setup(fig, '/Users/Wilson/Documents/0-code/1-lakeshores/output_dhdvdt-using-variable-outlines/S09SF18varoutlines_dhdt_CS2vsIS2_anim/S09SF18varoutlines_dhdt_CS2vsIS2_anim-{}.gif'.format(lakename_SF18), dpi=300)\n",
    "    # for loop through dh/dt acquisition cycles to construct animation\n",
    "    for idx in range(len(CS2_dh_sub.delta_h)-1): \n",
    "        dhdt_CS2 = CS2_dh_sub.delta_h[idx+1,:,:]-CS2_dh_sub.delta_h[idx,:,:]\n",
    "        dhdt_IS2 = ATL15_dh_sub.delta_h[idx+1,:,:]-ATL15_dh_sub.delta_h[idx,:,:]\n",
    "        # create contours of ice surface elevation height changes to delineate lake outlines\n",
    "        contours_fill_CS2 = []\n",
    "        contours_drain_CS2 = []\n",
    "        contours_fill_IS2 = []\n",
    "        contours_drain_IS2 = []\n",
    "        # create CryoSat-2 variable outliens\n",
    "        contour = measure.find_contours(dhdt_CS2.values, thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_fill_CS2 += [contour]\n",
    "        contour = measure.find_contours(dhdt_CS2.values, -thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_drain_CS2 += [contour]\n",
    "        # create ICESat-2 variable outlines\n",
    "        contour = measure.find_contours(dhdt_IS2.values, thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_fill_IS2 += [contour]\n",
    "        contour = measure.find_contours(dhdt_IS2.values, -thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_drain_IS2 += [contour]\n",
    "        # subplot 0: plot planview dhdt and variable outlines found in CryoSat-2 time slice\n",
    "        img0 = axes[0,0].imshow(dhdt_CS2, extent=[x_min, x_max, y_min, y_max], \n",
    "            origin='upper', cmap=cmocean.cm.balance_r, vmin=-v, vmax=v)\n",
    "        for i in range(len(contours_fill_CS2)): \n",
    "            for j in range(len(contours_fill_CS2[i])):\n",
    "                axes[0,0].plot(x_min+contours_fill_CS2[i][j][:, 1]*x_conv, y_max-contours_fill_CS2[i][j][:, 0]*y_conv, color='mediumblue', linestyle='dashdot', linewidth=2)\n",
    "        for i in range(len(contours_drain_CS2)): \n",
    "            for j in range(len(contours_drain_CS2[i])):\n",
    "                axes[0,0].plot(x_min+contours_drain_CS2[i][j][:, 1]*x_conv, y_max-contours_drain_CS2[i][j][:, 0]*y_conv, color='maroon', linestyle=(0, (3, 1, 1, 1)), linewidth=2)\n",
    "        axes[0,0].set(xlim=(x_min, x_max), ylim=(y_min, y_max))\n",
    "        axes[0,0].set_xlabel('polar stereographic x [m]', size=15)\n",
    "        axes[0,0].set_ylabel('polar stereographic y [m]', size=15)\n",
    "        axes[0,0].ticklabel_format(axis='both',scilimits=(0,0))\n",
    "        axes[0,0].set_title(lakename_SF18+' CryoSat-2 dh \\n$h_{'+dates_CS2[idx].strftime('%m/%Y')+'} - h_{'+dates_CS2[idx-1].strftime('%m/%Y')+'}$', pad=7.5, fontsize=17.5)\n",
    "        # fig.colorbar(img0, cax=cax0).set_label('Height (h) change [m]', size=15)\n",
    "        # overlay published outlines for visual comparison \n",
    "        Smith2009_outlines.boundary.plot(ax=axes[0,0], color='k', linestyle='--', linewidth=1)\n",
    "        SiegfriedFricker2018_outlines[SiegfriedFricker2018_outlines['cite'] \\\n",
    "            != 'Smith and others, 2009, J. Glac., doi:10.3189/002214309789470879'] \\\n",
    "            .boundary.plot(ax=axes[0,0], color='k', linestyle='-', linewidth=1)\n",
    "        # create 2D lines for legend\n",
    "        Smith2009 = plt.Line2D((0, 1), (0, 0), color='k', linestyle='--', linewidth=2)\n",
    "        SiegfriedFricker2018 = plt.Line2D((0, 1), (0, 0), color='k', linestyle='-', linewidth=2)\n",
    "        uplift = plt.Line2D((0, 1), (0, 0), color='mediumblue', linestyle='dashdot', linewidth=2)\n",
    "        subsidence = plt.Line2D((0, 1), (0, 0), color='maroon', linestyle=(0, (3, 1, 1, 1)), linewidth=2)\n",
    "        axes[0,0].legend([Smith2009, SiegfriedFricker2018, uplift, subsidence],\n",
    "            ['Smith and others, 2009 static outline','Siegfried & Fricker, 2018 static outline',\n",
    "            ('+'+str(thres)+' m uplift (filling) variable outline'), '–'+str(thres)+' m subsidence (draining) variable outline'], \n",
    "            loc='upper left')\n",
    "        # subplot 1: plot planview dhdt and variable outlines found in ICESat-2 time slice\n",
    "        img1 = axes[0,1].imshow(dhdt_IS2, extent=[x_min, x_max, y_min, y_max], \n",
    "            origin='upper', cmap=cmocean.cm.balance_r, vmin=-v, vmax=v)\n",
    "        for i in range(len(contours_fill_IS2)): \n",
    "            for j in range(len(contours_fill_IS2[i])):\n",
    "                axes[0,1].plot(x_min+contours_fill_IS2[i][j][:, 1]*x_conv, y_max-contours_fill_IS2[i][j][:, 0]*y_conv, color='mediumblue', linestyle='dashdot', linewidth=2)\n",
    "        for i in range(len(contours_drain_IS2)): \n",
    "            for j in range(len(contours_drain_IS2[i])):\n",
    "                axes[0,1].plot(x_min+contours_drain_IS2[i][j][:, 1]*x_conv, y_max-contours_drain_IS2[i][j][:, 0]*y_conv, color='maroon', linestyle=(0, (3, 1, 1, 1)), linewidth=2)\n",
    "        axes[0,1].set(xlim=(x_min, x_max), ylim=(y_min, y_max))\n",
    "        axes[0,1].set_xlabel('polar stereographic x [m]', size=15)\n",
    "        axes[0,1].ticklabel_format(axis='both',scilimits=(0,0))\n",
    "        axes[0,1].set_title(lakename_SF18+' ICESat-2 dh \\n$h_{'+dates_IS2[idx].strftime('%m/%Y')+'} - h_{'+dates_IS2[idx-1].strftime('%m/%Y')+'}$', pad=7.5, fontsize=17.5)\n",
    "        fig.colorbar(img1, cax=cax1).set_label('Height change (dh) [m]', size=15)\n",
    "        # overlay published outlines for visual comparison \n",
    "        Smith2009_outlines.boundary.plot(ax=axes[0,1], color='k', linestyle='--', linewidth=1)\n",
    "        SiegfriedFricker2018_outlines[SiegfriedFricker2018_outlines['cite'] \\\n",
    "            != 'Smith and others, 2009, J. Glac., doi:10.3189/002214309789470879'] \\\n",
    "            .boundary.plot(ax=axes[0,1], color='k', linestyle='-', linewidth=1)\n",
    "        axes[0,1].legend([Smith2009, SiegfriedFricker2018, uplift, subsidence],\n",
    "            ['Smith and others, 2009 static outline','Siegfried & Fricker, 2018 static outline',\n",
    "            ('+'+str(thres)+' m uplift (filling) variable outline'), '–'+str(thres)+' m subsidence (draining) variable outline'], \n",
    "            loc='upper left')\n",
    "        # suplot 2: plot CS2 dvdt time series\n",
    "        axes[1,0].plot(dates_CS2[:idx+1], np.divide(np.cumsum(dvdt_SF18_CS2[:idx+1]), 1e+9), color='k', linestyle='-')\n",
    "        axes[1,0].plot(dates_CS2[:idx+1], np.divide(np.cumsum(dvdt_S09_CS2[:idx+1]), 1e+9), color='k', linestyle='--')\n",
    "        axes[1,0].plot(dates_CS2[:idx+1], np.divide(np.cumsum(dvdt_var_CS2[:idx+1]), 1e+9), color='darkturquoise', linestyle='dashdot')\n",
    "        locator = mdates.AutoDateLocator(minticks=1, maxticks=7)\n",
    "        formatter = mdates.ConciseDateFormatter(locator)\n",
    "        axes[1,0].xaxis.set_major_locator(locator)\n",
    "        axes[1,0].xaxis.set_major_formatter(formatter)\n",
    "        # CONSIDER MOVING OUT OF FOR LOOP SO IT'S NOT CALCULATING CONSTANTS EVERY LOOP\n",
    "        dvdt_min = min(np.divide(min(np.cumsum(dvdt_SF18_CS2)), 1e+9), np.divide(min(np.cumsum(dvdt_var_CS2)), 1e+9), np.divide(min(np.cumsum(dvdt_SF18_IS2)), 1e+9), np.divide(min(np.cumsum(dvdt_var_IS2)), 1e+9))\n",
    "        dvdt_max = max(np.divide(max(np.cumsum(dvdt_SF18_CS2)), 1e+9), np.divide(max(np.cumsum(dvdt_var_CS2)), 1e+9), np.divide(max(np.cumsum(dvdt_SF18_IS2)), 1e+9), np.divide(max(np.cumsum(dvdt_var_IS2)), 1e+9))\n",
    "        dvdt_range = dvdt_max - dvdt_min\n",
    "        ylim_min = dvdt_min - (dvdt_range * 0.1)\n",
    "        ylim_max = dvdt_max + (dvdt_range * 0.1)\n",
    "        axes[1,0].set(xlim=(\n",
    "            datetime.datetime(int(CS2_dh_sub.time.values[0]), 1, 1) + datetime.timedelta(days = (CS2_dh_sub.time.values[0] % 1) * 365.25), \n",
    "            datetime.datetime(int(CS2_dh_sub.time.values[-1]), 1, 1) + datetime.timedelta(days = (CS2_dh_sub.time.values[-1] % 1) * 365.25)), \n",
    "            ylim=(ylim_min, ylim_max))\n",
    "        axes[1,0].set_title('{} CryoSat-2 dv'.format(lakename_SF18), pad=7.5, fontsize=17.5)\n",
    "        axes[1,0].set_xlabel('Year', size=15)\n",
    "        axes[1,0].set_ylabel('Volume change [km$^3$]', size=15)\n",
    "        variable_outlines = plt.Line2D((0, 1), (0, 0), color='darkturquoise', linestyle='dashdot', linewidth=2)\n",
    "        axes[1,0].legend([Smith2009,\n",
    "            SiegfriedFricker2018, variable_outlines],\n",
    "            ['Smith and others, 2009',\n",
    "            'Siegfried & Fricker, 2018',\n",
    "            '±{} m variable outlines'.format(thres)], \n",
    "            loc='upper left')\n",
    "        # suplot 3: plot IS2 dvdt time series\n",
    "        axes[1,1].plot(dates_IS2[:idx+1], np.divide(np.cumsum(dvdt_SF18_IS2[:idx+1]), 1e+9), color='k', linestyle='-')\n",
    "        axes[1,1].plot(dates_IS2[:idx+1], np.divide(np.cumsum(dvdt_S09_IS2[:idx+1]), 1e+9), color='k', linestyle='--')\n",
    "        axes[1,1].plot(dates_IS2[:idx+1], np.divide(np.cumsum(dvdt_var_IS2[:idx+1]), 1e+9), color='darkturquoise', linestyle='dashdot')\n",
    "        locator = mdates.AutoDateLocator(minticks=1, maxticks=7)\n",
    "        formatter = mdates.ConciseDateFormatter(locator)\n",
    "        axes[1,1].xaxis.set_major_locator(locator)\n",
    "        axes[1,1].xaxis.set_major_formatter(formatter)\n",
    "        axes[1,1].set(xlim=(\n",
    "            date_time_obj + datetime.timedelta(days=ATL15_dh_sub.time.values[0]),\n",
    "            date_time_obj + datetime.timedelta(days=ATL15_dh_sub.time.values[-1])), \n",
    "            ylim=(ylim_min, ylim_max))\n",
    "        axes[1,1].set_title('{} ICESat-2 dv'.format(lakename_SF18), pad=7.5, fontsize=17.5)\n",
    "        axes[1,1].set_xlabel('Year', size=15)\n",
    "        axes[1,1].set_ylabel('Volume change [km$^3$]', size=15)\n",
    "        variable_outlines = plt.Line2D((0, 1), (0, 0), color='darkturquoise', linestyle='dashdot', linewidth=2)\n",
    "        axes[1,1].legend([Smith2009,\n",
    "            SiegfriedFricker2018, variable_outlines],\n",
    "            ['Smith and others, 2009',\n",
    "            'Siegfried & Fricker, 2018',\n",
    "            '±{} m variable outlines'.format(thres)], \n",
    "            loc='upper left')\n",
    "        # append im(age) to ims list\n",
    "        ani.grab_frame()\n",
    "        axes[0,0].clear()\n",
    "        axes[0,1].clear()\n",
    "    # create animation and save, adjust interval\n",
    "    ani.finish()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tn/2b7yqbx51jxb820_x39chyc80000gn/T/ipykernel_24230/2589628447.py:192: RuntimeWarning: Mean of empty slice\n",
      "  avg_lk_dhdt = np.nanmean(dhdt_clip)\n"
     ]
    }
   ],
   "source": [
    "# test function working using one lake\n",
    "S09SF18varoutlines_dhdvdt_CS2vsIS2_anim('Whillans_4', 'ConwaySubglacialLake', 7500, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run func on all lakes from SF18 inventory\n",
    "for idx in range(len(SiegfriedFricker2018_outlines)-1):\n",
    "    lakename=SiegfriedFricker2018_outlines['name'][idx]\n",
    "    S09SF18varoutlines_dhdvdt_CS2vsIS2_anim(lakename, 7500, 0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>geometry</th>\n",
       "      <th>area (m^2)</th>\n",
       "      <th>perimeter (m)</th>\n",
       "      <th>cite</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>Mac5</td>\n",
       "      <td>POLYGON ((-734575.010 -842800.020, -734449.990...</td>\n",
       "      <td>5.998647e+07</td>\n",
       "      <td>31080.268636</td>\n",
       "      <td>Fricker and others, 2010, J. Glac., doi:10.318...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    name                                           geometry    area (m^2)  \\\n",
       "89  Mac5  POLYGON ((-734575.010 -842800.020, -734449.990...  5.998647e+07   \n",
       "\n",
       "    perimeter (m)                                               cite  \n",
       "89   31080.268636  Fricker and others, 2010, J. Glac., doi:10.318...  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find idx of Mac5 causing issue with func\n",
    "SiegfriedFricker2018_outlines[SiegfriedFricker2018_outlines['name'] == Mac5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run func on all lakes from SF18 inventory after Mac5 because it's causing issue\n",
    "for idx in np.arange(90,131):\n",
    "    lakename = SiegfriedFricker2018_outlines['name'][idx]\n",
    "    S09SF18varoutlines_dhdvdt_CS2vsIS2_anim(lakename, 7500, 0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mac5 breaks code S09SF18varoutlines_dhdvdt_CS2vsIS2_anim func; explore why\n",
    "lakename_SF18 = 'Mac_5'\n",
    "#lake_gpd = Smith2009_outlines.loc[Smith2009_outlines['Name'] == lakename]\n",
    "lake_SF18 = SiegfriedFricker2018_outlines.loc[SiegfriedFricker2018_outlines['name'] == lakename_SF18]\n",
    "lake_buffer = lake_SF18.buffer(buffer)\n",
    "# define lake bounding box\n",
    "x_min = lake_buffer.bounds.values[0,0]; x_max = lake_buffer.bounds.values[0,2]\n",
    "x_min"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (lakeshores)",
   "language": "python",
   "name": "lakeshores"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2 | packaged by conda-forge | (main, Jan 14 2022, 08:02:37) [Clang 11.1.0 ]"
  },
  "vscode": {
   "interpreter": {
    "hash": "5038e8bb49eb1923c23fc273b1aa630416e586fa7c50462a6108d15c8378e95d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
