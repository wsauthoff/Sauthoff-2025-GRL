{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "# HIGH PRIORITY\n",
    "# make thresholding dynamic based on avg. dh/dt in bounding box\n",
    "# calc off-lake dh/dt to subtract from on-lake dh/dt like SF18 to remove secular change; start by quantifying off-lake dh/dt to see if significant?\n",
    "# convert polys[i].area to calc geodesic area instead\n",
    "# overlay ICESat tracks to see where we see new lakes\n",
    "# use CS2 served product\n",
    "# overlay ATL11 data points on ATL15 interpolated data to know where data points are\n",
    "# make dvdt plots have symbols for actual data points and dotted lines between\n",
    "# change all plots to have km scale; make sure using np.round to get nice round tick labels\n",
    "# ensure SiegfriedFricker2018_SF18outlines being plotted instead of SiegfriedFricker2018_outlines\n",
    "# create mean lake outline from variable outlines\n",
    "# interpolate between outlines at time resolution of passes to see if individual IS2 tracks match interpolated outlines\n",
    "\n",
    "# MID PRIORITY\n",
    "# tried variable outline code on ATL11 data\n",
    "# make functions intake a list of S09 and a list of SF18 lakes to be included in plot (to create bbox around multiple lakes)\n",
    "# -> may need to create new gpd dataframe that has corresponding S09 and SF18 lakes in same row that can be indexed in the function call\n",
    "# create and heavily comment introductory cell on the general outline delineation procedure\n",
    "# have dv/dt 2D line plots label the threshold level selected\n",
    "# from lake-hydropotential.ipynb, import function 'SF18lakes_hydropot' to plot \n",
    "    # 1) hydropotential with agg plot to see if time-evolving outlines follow hydropotential contours and \n",
    "    # 2) make a time-variable plot with changing hydropotential and each time slice with its corresponding variable outline\n",
    "# plots for combined Mac 4+5 and Slessor 4+5 since so close and hard to disentangle (use arg of bbox coords vs using lake name)\n",
    "# when making contours, perhaps clip to buffer area around lake outline (vs. square bbox) once you know rough bounds of where off-lake extensions will be so you can clip out other nearby actvity?\n",
    "# add gl to plots\n",
    "# change S09SF18varoutlines_dhdvdt_anim to add buffer to ylimits that is alternative to *1.1, which doesn't work for zero (fix on others); i think i've already done this in other functions; find and put into all\n",
    "# investigate why S09SF18varoutlines_dhdvdt_CS2vsIS2_anim trips on 'Mac5'\n",
    "# have functions append volume change time series into a pandas data frame (and/or export to csv)\n",
    "# have function add polygons to geopandas geodataframe (done in contours2polygons notebook; adopt here)\n",
    "# change x-limits to start at 2nd time step, eg date_time_obj + datetime.timedelta(days=ds_sub.time.values[1]) so that vol change time series starts at left xaxis limit?\n",
    "# S09SF18varoutlines_dhdvdt_CS2vsIS2_anim: should clip vmax,min to only CS2 cycs in IS2 era vs. all cycles\n",
    "# make explicit bounding box coords optional arg as list to func\n",
    "# Make colorbar appear horizontally and/or w/in plot like a legend? For shoreline agg plots to look more like timescale for agg outline plots: pl.colorbar(orientation=\"h\", cax=cax); put vertical line in to indicate time slice being plotted\n",
    "# S09SF18varoutlines_dhdvdt_CS2vsIS2_anim overwrites each plot (being name the same date); look into why this is happening\n",
    "# change colormap limits to reflect rounded min and max instead of highest abs value of two; fix weird tick marks (?)\n",
    "# some functions calc v = np.round(max_height_anom_abs), but don't end up using it; delete that code; esp. if you make colorbar asymmetric\n",
    "# -> dh/dt plots should have vmax and vmin that reflect actual vs. the max of one\n",
    "# clb = fig.colorbar(m, ticks=np.array([2019,2020,2021]),  cax=cax); why assign to clb; where is 'Year' label added?\n",
    "# change S09 and SF18 outlines to be two shades of cyan so they are more distinguishable from black end of colormap of varoutiles or remove black portion of colormap or select different colormap that doesn't have black in it\n",
    "# for storing function outputs in folders, first ensure folders are created for future users\n",
    "\n",
    "# LOW PRIORITY\n",
    "# perhaps add an empty colorbar to plots without colorbar so that size of all the plots is the same regardless of whether it has a colorbar or not\n",
    "# make legend dynamic where it will include S09 citation if there is a S09 lake within the bounding box; same with SF18; perhaps with gpd.contains?\n",
    "# have animations end on last frame and can pause (make into mp4 vs gif) \n",
    "# modify S09SF18varoutlines_agg_plot to also create animation building agg plot with agg plot as last frame; save animation; save last frame as separate file\n",
    "# filter CS_dh to use at least 0.5/1? data point to not view highly interpolated areas (only if using Smith 2017 method)\n",
    "# find faster thresholding method to use CS2 count to look at data based on a threshold of data points (only if using Smith 2017 method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Code to delineate subglacial lakes using variable outlines based on \n",
    "# ice surface height deformation contours, visualize and quantify lake \n",
    "# average dh/dt and lake dv/dt. \n",
    "#\n",
    "# Written 2022-06-06 by W. Sauthoff (sauthoff@mines.edu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import internal packages\n",
    "import os\n",
    "\n",
    "# Import external packages\n",
    "import datetime\n",
    "import geopandas as gpd\n",
    "import math\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.path as mpath\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from matplotlib import animation\n",
    "from matplotlib.patches import Ellipse, Rectangle\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import rioxarray\n",
    "from skimage import measure\n",
    "import time\n",
    "import xarray\n",
    "\n",
    "# Set ffmpeg location\n",
    "plt.rcParams['animation.ffmpeg_path'] = '/usr/local/bin/ffmpeg'\n",
    "\n",
    "# Define data directories dependent on home environment (replace with your data directory file path(s))\n",
    "if os.getenv('HOME') == '/home/jovyan':\n",
    "    DATA_DIR = '/home/jovyan/data_dir'\n",
    "    SCRIPT_DIR = '/home/jovyan/repos_my/script_dir'\n",
    "    OUTPUT_DIR = '/home/jovyan/1_outlines_candidates/output/'\n",
    "elif os.getenv('HOME') == '/Users/Wilson': \n",
    "    DATA_DIR = '/Volumes/ExtremeSSD/data'\n",
    "    SCRIPT_DIR = '/Users/Wilson/Documents/0-code/repos_my/script_dir'\n",
    "    OUTPUT_DIR = '/Users/Wilson/Documents/0-code/1_outlines_candidates/output'\n",
    "\n",
    "# Define utility function\n",
    "def datetime2fracyear(date):\n",
    "    start = datetime.date(date.year, 1, 1).toordinal()\n",
    "    year_length = datetime.date(date.year+1, 1, 1).toordinal() - start\n",
    "    return date.year + float(date.toordinal() - start) / year_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # import CryoSat-2 data (closed-source data acquired from Ben Smith)\n",
    "# CS2_data = open(script_dir + '/Smith_CS2.py')\n",
    "# read_file = CS2_data.read()\n",
    "# exec(read_file)\n",
    "\n",
    "# # view data set\n",
    "# CS2_dh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "# Import CryoTEMPO EOLIS SWATH THEMATIC GRIDDED PRODUCT\n",
    "# https://cryotempo-eolis.org/gridded-product/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import ICESat-2 ATL15 Gridded Antarctic and Arctic Land Ice Height Change data product \n",
    "# https://doi.org/10.5067/ATLAS/ATL15.002\n",
    "if os.getenv('HOME') == '/home/jovyan':\n",
    "    # TODO: Grab ATL15 data using earthaccess or icepyx\n",
    "    # s3url = 's3://nsidc-cumulus-prod-protected/ATLAS/ATL15/002/2019/ATL15_GL_0314_01km_002_01.nc'\n",
    "    # FIXME: temporary workaround\n",
    "    os.environ['AWS_NO_SIGN_REQUEST'] = 'YES'\n",
    "    granule = 's3://is2view/ATLAS/ATL15/002/2019/ATL15_AA_0314_01km_002_02.nc'\n",
    "    group = 'delta_h'\n",
    "    ATL15_dh = rioxarray.open_rasterio(granule, group=group, masked=True)\n",
    "    ATL15_dh\n",
    "    \n",
    "elif os.getenv('HOME') == '/Users/Wilson': \n",
    "    file = DATA_DIR + '/altimetry/ICESat2/ATL15.002-Ant/ATL15_AA_0314_01km_002_02.nc'\n",
    "    ATL15_dh = rioxarray.open_rasterio(file, group='delta_h', masked=True)\n",
    "    # Display xarray data set metadata\n",
    "    ATL15_dh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Scripps Grounding Line\n",
    "# https://doi.pangaea.de/10.1594/PANGAEA.819147\n",
    "Scripps_gl = gpd.read_file(DATA_DIR + '/boundaries/Depoorter2013-boundaries/scripps_antarctica_polygons_v1.shp' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import MODIS MOA 2009 and 2014 coastline and grounding line for plotting inset maps\n",
    "# https://nsidc.org/data/nsidc-0593/versions/1\n",
    "shp = DATA_DIR + '/boundaries/MODIS-MOA/2009/moa_2009_coastline_v02.0.shp' \n",
    "moa_2009_coastline = gpd.read_file(shp)\n",
    "shp = DATA_DIR + '/boundaries/MODIS-MOA/2009/moa_2009_groundingline_v02.0.shp' \n",
    "moa_2009_groundingline = gpd.read_file(shp)\n",
    "# https://nsidc.org/data/nsidc-0730/versions/1\n",
    "shp = DATA_DIR + '/boundaries/MODIS-MOA/2014/moa2014_coastline_v01.shp' \n",
    "moa_2014_coastline = gpd.read_file(shp)\n",
    "shp = DATA_DIR + '/boundaries/MODIS-MOA/2014/moa2014_grounding_line_v01.shp' \n",
    "moa_2014_groundingline = gpd.read_file(shp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import subglacial lake outline inventories\n",
    "exec(open(SCRIPT_DIR + '/Smith2009_outlines.py').read())\n",
    "exec(open(SCRIPT_DIR + '/SiegfriedFricker2018_outlines.py').read())\n",
    "exec(open(SCRIPT_DIR + '/Sauthoff2023_outlines.py').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create list of S09 lakes redelineated in SF18\n",
    "S09_SF18_compare_1to1 = [['Cook_E2', 'Cook_E2'],\n",
    "    ['KambTrunk_1', 'KT1'],\n",
    "    ['Macayeal_1', 'Mac1'],\n",
    "    ['Macayeal_2', 'Mac2'],\n",
    "    ['Mercer_1', 'Lake78'],\n",
    "    ['Mercer_2', 'MercerSubglacialLake'],\n",
    "    ['Recovery_3', 'Rec2'],\n",
    "    ['Recovery_4', 'Rec3'],\n",
    "    ['Recovery_5', 'Rec4'], \n",
    "    ['Recovery_6', 'Rec5'],\n",
    "    ['Recovery_7', 'Rec6'],\n",
    "    ['Recovery_9', 'Rec8'],\n",
    "    ['Recovery_10', 'Rec9'],\n",
    "    ['Recovery_11', 'Rec10'],     \n",
    "    ['Whillans_1', 'EngelhardtSubglacialLake'],            \n",
    "    ['Whillans_2a', 'Lake12'],\n",
    "    ['Whillans_2b', 'Lake10'],\n",
    "    ['Whillans_3', 'WhillansSubglacialLake'],\n",
    "    ['Whillans_4', 'ConwaySubglacialLake'],\n",
    "    ['Whillans_5', 'UpperSubglacialLakeConway']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create list of two S09 lakes converted to one SF18 lake\n",
    "S09_SF18_compare_2to1 = [['Slessor_2', 'Slessor_3', 'Slessor_23'],\n",
    "    ['Recovery_1', 'Recovery_2', 'Rec1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create list of one S09 lake converted to two SF18 lakes\n",
    "S09_SF18_compare_1to2 = [['Macayeal_3', 'Mac4', 'Mac5']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "# Introduction to time-variable outline delineation method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Code explaining method here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "# Func S09SF18S23_dhdt_height_thresholds_plot_anim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/Wilson/opt/anaconda3/envs/lakeshores/bin/ffmpeg\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Download a static FFmpeg build and add it to PATH.\n",
    "exist = !which ffmpeg\n",
    "if not exist:\n",
    "  !curl https://johnvansickle.com/ffmpeg/releases/ffmpeg-release-amd64-static.tar.xz -o ffmpeg.tar.xz \\\n",
    "     && tar -xf ffmpeg.tar.xz && rm ffmpeg.tar.xz\n",
    "  ffmdir = !find . -iname ffmpeg-*-static\n",
    "  path = %env PATH\n",
    "  path = path + ':' + ffmdir[0]\n",
    "  %env PATH $path\n",
    "print('')\n",
    "!which ffmpeg\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "image_folder = '/Users/Wilson/Documents/0-code/1_outlines_candidates/output/dhdvdt-using-variable-outlines/S09SF18S23_dhdt_height_thresholds_plot_anim/plot'\n",
    "video_name = 'video.avi'\n",
    "\n",
    "images = [img for img in os.listdir(image_folder) if img.endswith(\".png\")]\n",
    "frame = cv2.imread(os.path.join(image_folder, images[0]))\n",
    "height, width, layers = frame.shape\n",
    "\n",
    "video = cv2.VideoWriter(video_name, 0, 1, (width,height))\n",
    "\n",
    "for image in images:\n",
    "    video.write(cv2.imread(os.path.join(image_folder, image)))\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# changing output to mp4 instead of gif\n",
    "\n",
    "def S09SF18S23_dhdt_height_thresholds_plot_anim(lakename_S23, buffer, thres, dataset): \n",
    "    '''\n",
    "    Create planview dh/dt plots of ice surface height changes in bounding box created using geopandas buffer around known lakes outlines\n",
    "    in Siegfried and Fricker, 2018 inventory and lake points in Livingstone and others, 2023 (collated in Sauthoff2023_outlines inventory).\n",
    "    Create time-variable outlines using skimage contour to plot variable outline alongside published outlines for comparison. Plots the pos./neg.\n",
    "    thresholds input.\n",
    "    Inputs: \n",
    "        lakename: lake of interest from Sauthoff2023_outlines inventory\n",
    "        buffer: horizontal distance in meters away from SF18 lake outline used to create bounding box that is displayed around lake of interest\n",
    "        thres(hold): vertical distance in meters to delineate ice surface deformation contour\n",
    "        dataset: dataset to be analyzed (CS2_dh or ATL15_dh)\n",
    "    Outputs: \n",
    "        Sequence of planview dh/dt visuals of CryoSat-2 or ICESat-2 ATL15 with variable ice surface deformation contours plotted to delineate time-variable lake boundary.\n",
    "    '''\n",
    "    # Isolate individual lake using gpd buffer\n",
    "    lake_gpd = Sauthoff2023_outlines.loc[Sauthoff2023_outlines['name'] == lakename_S23]  \n",
    "    lake_buffer = lake_gpd.buffer(buffer)\n",
    "    \n",
    "    # Define lake bounding box\n",
    "    x_min = lake_buffer.bounds.values[0,0]; x_max = lake_buffer.bounds.values[0,2]\n",
    "    y_min = lake_buffer.bounds.values[0,1]; y_max = lake_buffer.bounds.values[0,3]\n",
    "    \n",
    "    # Subset ATL15 data set to region of interest\n",
    "    mask_x = (dataset.x >= x_min) & (dataset.x <= x_max)\n",
    "    mask_y = (dataset.y >= y_min) & (dataset.y <= y_max)\n",
    "    ds_sub = dataset.where(mask_x & mask_y, drop=True)\n",
    "    \n",
    "    # Find magnitude of ice surface deformation in bounding box to create appropriate color map scale\n",
    "    height_anom_pos = []\n",
    "    height_anom_neg = []\n",
    "    for cyc in range(len(ds_sub.time)-1):\n",
    "        pos = np.nanmax(ds_sub.delta_h[cyc+1,:,:]-ds_sub.delta_h[cyc,:,:])\n",
    "        neg = np.nanmin(ds_sub.delta_h[cyc+1,:,:]-ds_sub.delta_h[cyc,:,:])\n",
    "        height_anom_pos += [pos]\n",
    "        height_anom_neg += [neg]\n",
    "    max_height_anom_pos = max(height_anom_pos)\n",
    "    max_height_anom_neg = min(height_anom_neg)\n",
    "        # max_height_anom_abs = max(max_height_anom_pos,abs(max_height_anom_neg))\n",
    "    # v = np.round(max_height_anom_abs) # TODO: plot asymetric colorbar to show true scale of change\n",
    "    \n",
    "    # Create fig, ax, colorbar\n",
    "    fig, ax = plt.subplots(figsize=(8,8))\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes('right', size='5%', pad=0.2)\n",
    "    \n",
    "    # if dataset.fileName == 'mos_2010.5_2021.5.h5':\n",
    "    #             ani.setup(fig, OUTPUT_DIR + \n",
    "    #               '/dhdvdt-using-variable-outlines/S09SF18S23_dhdt_height_thresholds_plot_anim/anim/S09SF18S23_dhdt_height_thresholds_anim-{}-{}.gif'\n",
    "    #               .format(lakename_S23, 'CS2'), dpi=300)\n",
    "    # elif dataset.fileName == 'ATL15_AA_0314_01km_002_02.nc':    \n",
    "    #     with writer.saving(fig, OUTPUT_DIR + \n",
    "    #               '/dhdvdt-using-variable-outlines/S09SF18S23_dhdt_height_thresholds_plot_anim/anim/S09SF18S23_dhdt_height_thresholds_anim-{}-{}.mp4'\n",
    "    #               .format(lakename_S23, 'IS2'), dpi=300): \n",
    "\n",
    "    ani = animation.PillowWriter(fps=1)\n",
    "    if dataset.fileName == 'mos_2010.5_2021.5.h5':\n",
    "        ani.setup(fig, OUTPUT_DIR + \n",
    "                  '/dhdvdt-using-variable-outlines/S09SF18S23_dhdt_height_thresholds_plot_anim/anim/S09SF18S23_dhdt_height_thresholds_anim-{}-{}.gif'\n",
    "                  .format(lakename_S23, 'CS2'), dpi=300)\n",
    "    elif dataset.fileName == 'ATL15_AA_0314_01km_002_02.nc':    \n",
    "        ani.setup(fig, OUTPUT_DIR + \n",
    "                  '/dhdvdt-using-variable-outlines/S09SF18S23_dhdt_height_thresholds_plot_anim/anim/S09SF18S23_dhdt_height_thresholds_anim-{}-{}.gif'\n",
    "                  .format(lakename_S23, 'IS2'), dpi=300)\n",
    "    \n",
    "    # Create empty list to store dates\n",
    "    dates = []\n",
    "    for idx in range(len(ds_sub.time)-1): \n",
    "        dhdt = ds_sub.delta_h[idx+1,:,:]-ds_sub.delta_h[idx,:,:]\n",
    "        # Calculate mid-cycle dates for plotting\n",
    "        if dataset.fileName == 'mos_2010.5_2021.5.h5':\n",
    "            newdate = datetime.datetime(int(ds_sub.time.values[idx]), 1, 1) + datetime.timedelta(days = (ds_sub.time.values[idx] % 1) * 365.25)\n",
    "            newdate1 = datetime.datetime(int(ds_sub.time.values[idx+1]), 1, 1) + datetime.timedelta(days = (ds_sub.time.values[idx+1] % 1) * 365.25)\n",
    "            midcycdays = newdate1 - newdate\n",
    "            midcycdate = newdate + midcycdays/2\n",
    "            dates += [midcycdate]\n",
    "        elif dataset.fileName == 'ATL15_AA_0314_01km_002_02.nc':    \n",
    "            date_time_str = '18-01-01'\n",
    "            date_time_obj = datetime.datetime.strptime(date_time_str, '%y-%m-%d')\n",
    "            newdate = date_time_obj + datetime.timedelta(days=ds_sub.time.values[idx])\n",
    "            newdate1 = date_time_obj + datetime.timedelta(days=ds_sub.time.values[idx+1])\n",
    "            midcycdays = newdate1 - newdate\n",
    "            midcycdate = newdate + midcycdays/2\n",
    "            dates += [midcycdate]\n",
    "    \n",
    "        # Create difference from one acquisition cycle to the next\n",
    "        dhdt = ds_sub.delta_h[idx+1,:,:]-ds_sub.delta_h[idx,:,:]\n",
    "    \n",
    "        # Establish diverging colorbar\n",
    "        divnorm=colors.TwoSlopeNorm(vmin=max_height_anom_neg, vcenter=0., vmax=max_height_anom_pos)\n",
    "    \n",
    "        # Plot figure\n",
    "        img = ax.imshow(dhdt, extent=[x_min, x_max, y_min, y_max], \n",
    "            origin='upper', cmap='RdBu', norm=divnorm)\n",
    "        # Create contours of ice surface elevation height changes to delineate lake outlines\n",
    "        contours_fill = []\n",
    "        contours_drain = []\n",
    "        for thres_i in thres:     \n",
    "            contour = measure.find_contours(dhdt.values, thres_i)\n",
    "            if len(contour) > 0: \n",
    "                contours_fill += [contour]\n",
    "            contour = measure.find_contours(dhdt.values, -thres_i)\n",
    "            if len(contour) > 0: \n",
    "                contours_drain += [contour]\n",
    "        \n",
    "        # Create mapping conversion factor to map array location to polar stereographic x,y\n",
    "        x_conv = (x_max-x_min)/dhdt.shape[1]\n",
    "        y_conv = (y_max-y_min)/dhdt.shape[0]\n",
    "        \n",
    "        # Plot variable outlines found in this time slice\n",
    "        for i in range(len(contours_fill)): \n",
    "            for j in range(len(contours_fill[i])):\n",
    "                ax.plot(x_min+contours_fill[i][j][:,1]*x_conv, y_max-contours_fill[i][j][:,0]*y_conv, color='mediumblue', linestyle='dashdot', linewidth=1)\n",
    "        for i in range(len(contours_drain)): \n",
    "            for j in range(len(contours_drain[i])):\n",
    "                ax.plot(x_min+contours_drain[i][j][:,1]*x_conv, y_max-contours_drain[i][j][:,0]*y_conv, color='maroon', linestyle=(0, (3, 1, 1, 1)), linewidth=1)\n",
    "        ax.set(xlim=(x_min, x_max), ylim=(y_min, y_max))\n",
    "        \n",
    "        # Change polar stereographic m to km\n",
    "        km_scale = 1e3\n",
    "        ticks_x = ticker.FuncFormatter(lambda x, pos: '{0:g}'.format(x/km_scale))\n",
    "        ax.xaxis.set_major_formatter(ticks_x)\n",
    "        ticks_y = ticker.FuncFormatter(lambda x, pos: '{0:g}'.format(x/km_scale))\n",
    "        ax.yaxis.set_major_formatter(ticks_y)  \n",
    "        \n",
    "        # Label axes\n",
    "        ax.set_xlabel('x [km]', size=15)\n",
    "        ax.set_ylabel('y [km]', size=15)\n",
    "        \n",
    "        # Add title and colorbar\n",
    "        ax.set_title(lakename_S23+' dh + outline comparison \\nh$_{'+newdate1.strftime('%m/%Y')+'}$ - h$_{'+newdate.strftime('%m/%Y')+'}$', pad=7.5, fontsize=17.5)\n",
    "        fig.colorbar(img, cax=cax).set_label('height change (dh) [m]', size=15)\n",
    "        \n",
    "        # Overlay published outlines for visual comparison \n",
    "        Smith2009_outlines.boundary.plot(ax=ax, color='k', linestyle='--', linewidth=1)\n",
    "        SiegfriedFricker2018_outlines.boundary.plot(ax=ax, color='k', linestyle='-', linewidth=1)\n",
    "        Smith2009 = plt.Line2D((0, 1), (0, 0), color='k', linestyle='--', linewidth=2)\n",
    "        SiegfriedFricker2018 = plt.Line2D((0, 1), (0, 0), color='k', linestyle='-', linewidth=2)\n",
    "        uplift = plt.Line2D((0, 1), (0, 0), color='mediumblue', linestyle='dashdot', linewidth=2)\n",
    "        subsidence = plt.Line2D((0, 1), (0, 0), color='maroon', linestyle=(0, (3, 1, 1, 1)), linewidth=2)\n",
    "        \n",
    "        # Create legend\n",
    "        ax.legend([Smith2009, SiegfriedFricker2018, uplift, subsidence],\n",
    "            ['Smith and others, 2009 outline','Siegfried & Fricker, 2018 outline',\n",
    "            ('+'+str(thres)+' m uplift (filling) variable outline'), 'â€“'+str(thres)+' m subsidence (draining) variable outline'], \n",
    "            loc='upper left')\n",
    "        \n",
    "        # Plot inset map to show location \n",
    "        axIns = ax.inset_axes([0.01, 0.01, 0.25, 0.25]) # [left, bottom, width, height] (fractional axes coordinates)\n",
    "        axIns.set_aspect('equal')\n",
    "        moa_2014_coastline.plot(ax=axIns, color='gray', edgecolor='k', linewidth=0.1, zorder=3)\n",
    "        moa_2014_groundingline.plot(ax=axIns, color='ghostwhite', edgecolor='k', linewidth=0.1, zorder=3)\n",
    "        rect = Rectangle((x_min, y_min), (x_max-x_min), (y_max-y_min), fill=False, linewidth=2, color='k', zorder=3)\n",
    "        axIns.add_artist(rect) \n",
    "        axIns.axis('off')\n",
    "    \n",
    "        # Save fig\n",
    "        if dataset.fileName == 'mos_2010.5_2021.5.h5':\n",
    "            plt.savefig(OUTPUT_DIR + \n",
    "                        '/dhdvdt-using-variable-outlines/S09SF18S23_dhdt_height_thresholds_plot_anim/plot/S09SF18S23_dhdt_height_thresholds_plot-{}-{}-{}.png'\n",
    "                        .format(lakename_S23,'CS2',midcycdate.strftime('%Y-%m')), dpi=300, bbox_inches = \"tight\")\n",
    "        elif dataset.fileName == 'ATL15_AA_0314_01km_002_02.nc':    \n",
    "            plt.savefig(OUTPUT_DIR + \n",
    "                        '/dhdvdt-using-variable-outlines/S09SF18S23_dhdt_height_thresholds_plot_anim/plot/S09SF18S23_dhdt_height_thresholds_plot-{}-{}-{}.png'\n",
    "                        .format(lakename_S23,'IS2',midcycdate.strftime('%Y-%m')), dpi=300, bbox_inches = \"tight\")      \n",
    "        \n",
    "        # Append image to animation list\n",
    "        ani.grab_frame()\n",
    "        # Clear axis to create next plot\n",
    "        ax.clear()\n",
    "    \n",
    "    # Finish animation and close fig\n",
    "    ani.finish()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'list' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/Wilson/Documents/0-code/1_outlines_candidates/Sauthoff-2023-J.Glaciol./dhdvdt-using-variable-outlines.ipynb Cell 17\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/Wilson/Documents/0-code/1_outlines_candidates/Sauthoff-2023-J.Glaciol./dhdvdt-using-variable-outlines.ipynb#Y164sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Test function working using one lake\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/Wilson/Documents/0-code/1_outlines_candidates/Sauthoff-2023-J.Glaciol./dhdvdt-using-variable-outlines.ipynb#Y164sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m# S09SF18S23_dhdt_height_thresholds_plot_anim('ConwaySubglacialLake', 10000, [0.2, 0.4, 0.6, 0.8], CS2_dh)\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/Wilson/Documents/0-code/1_outlines_candidates/Sauthoff-2023-J.Glaciol./dhdvdt-using-variable-outlines.ipynb#Y164sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# S09SF18S23_dhdt_height_thresholds_plot_anim('ConwaySubglacialLake', 10000, [0.2, 0.4, 0.6, 0.8], ATL15_dh)\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/Wilson/Documents/0-code/1_outlines_candidates/Sauthoff-2023-J.Glaciol./dhdvdt-using-variable-outlines.ipynb#Y164sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# S09SF18S23_dhdt_height_thresholds_plot_anim('Lambert_1', 10000, [0.2, 0.4, 0.6, 0.8], CS2_dh)\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/Wilson/Documents/0-code/1_outlines_candidates/Sauthoff-2023-J.Glaciol./dhdvdt-using-variable-outlines.ipynb#Y164sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# S09SF18S23_dhdt_height_thresholds_plot_anim('Lambert_1', 10000, [0.25, 0.5, 0.75], ATL15_dh)\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/Wilson/Documents/0-code/1_outlines_candidates/Sauthoff-2023-J.Glaciol./dhdvdt-using-variable-outlines.ipynb#Y164sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m S09SF18S23_dhdt_height_thresholds_plot_anim(\u001b[39m'\u001b[39;49m\u001b[39mThw_70\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m10000\u001b[39;49m, [\u001b[39m1.0\u001b[39;49m], ATL15_dh)\n",
      "\u001b[1;32m/Users/Wilson/Documents/0-code/1_outlines_candidates/Sauthoff-2023-J.Glaciol./dhdvdt-using-variable-outlines.ipynb Cell 17\u001b[0m in \u001b[0;36mS09SF18S23_dhdt_height_thresholds_plot_anim\u001b[0;34m(lakename_S23, buffer, thres, dataset)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/Wilson/Documents/0-code/1_outlines_candidates/Sauthoff-2023-J.Glaciol./dhdvdt-using-variable-outlines.ipynb#Y164sZmlsZQ%3D%3D?line=176'>177</a>\u001b[0m     ax\u001b[39m.\u001b[39mclear()\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/Wilson/Documents/0-code/1_outlines_candidates/Sauthoff-2023-J.Glaciol./dhdvdt-using-variable-outlines.ipynb#Y164sZmlsZQ%3D%3D?line=178'>179</a>\u001b[0m \u001b[39m# Finish animation and close fig\u001b[39;00m\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/Wilson/Documents/0-code/1_outlines_candidates/Sauthoff-2023-J.Glaciol./dhdvdt-using-variable-outlines.ipynb#Y164sZmlsZQ%3D%3D?line=179'>180</a>\u001b[0m ani \u001b[39m=\u001b[39m animation\u001b[39m.\u001b[39;49mFuncAnimation(fig, ims, frames\u001b[39m=\u001b[39;49m\u001b[39mrange\u001b[39;49m(\u001b[39mlen\u001b[39;49m(ds_sub[\u001b[39m'\u001b[39;49m\u001b[39mtime\u001b[39;49m\u001b[39m'\u001b[39;49m])), \n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/Wilson/Documents/0-code/1_outlines_candidates/Sauthoff-2023-J.Glaciol./dhdvdt-using-variable-outlines.ipynb#Y164sZmlsZQ%3D%3D?line=180'>181</a>\u001b[0m                       interval\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, blit\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/Wilson/Documents/0-code/1_outlines_candidates/Sauthoff-2023-J.Glaciol./dhdvdt-using-variable-outlines.ipynb#Y164sZmlsZQ%3D%3D?line=181'>182</a>\u001b[0m FFwriter \u001b[39m=\u001b[39m animation\u001b[39m.\u001b[39mFFMpegWriter(fps\u001b[39m=\u001b[39m\u001b[39m30\u001b[39m, extra_args\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39m-vcodec\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mlibx264\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/Wilson/Documents/0-code/1_outlines_candidates/Sauthoff-2023-J.Glaciol./dhdvdt-using-variable-outlines.ipynb#Y164sZmlsZQ%3D%3D?line=182'>183</a>\u001b[0m anim\u001b[39m.\u001b[39msave(\u001b[39m'\u001b[39m\u001b[39mbasic_animation.mp4\u001b[39m\u001b[39m'\u001b[39m, writer \u001b[39m=\u001b[39m FFwriter)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/lakeshores/lib/python3.10/site-packages/matplotlib/animation.py:1636\u001b[0m, in \u001b[0;36mFuncAnimation.__init__\u001b[0;34m(self, fig, func, frames, init_func, fargs, save_count, cache_frame_data, **kwargs)\u001b[0m\n\u001b[1;32m   1633\u001b[0m \u001b[39m# Needs to be initialized so the draw functions work without checking\u001b[39;00m\n\u001b[1;32m   1634\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_save_seq \u001b[39m=\u001b[39m []\n\u001b[0;32m-> 1636\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(fig, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1638\u001b[0m \u001b[39m# Need to reset the saved seq, since right now it will contain data\u001b[39;00m\n\u001b[1;32m   1639\u001b[0m \u001b[39m# for a single frame from init, which is not what we want.\u001b[39;00m\n\u001b[1;32m   1640\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_save_seq \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/lakeshores/lib/python3.10/site-packages/matplotlib/animation.py:1398\u001b[0m, in \u001b[0;36mTimedAnimation.__init__\u001b[0;34m(self, fig, interval, repeat_delay, repeat, event_source, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1396\u001b[0m \u001b[39mif\u001b[39;00m event_source \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1397\u001b[0m     event_source \u001b[39m=\u001b[39m fig\u001b[39m.\u001b[39mcanvas\u001b[39m.\u001b[39mnew_timer(interval\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interval)\n\u001b[0;32m-> 1398\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(fig, event_source\u001b[39m=\u001b[39;49mevent_source, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/lakeshores/lib/python3.10/site-packages/matplotlib/animation.py:885\u001b[0m, in \u001b[0;36mAnimation.__init__\u001b[0;34m(self, fig, event_source, blit)\u001b[0m\n\u001b[1;32m    882\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_close_id \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fig\u001b[39m.\u001b[39mcanvas\u001b[39m.\u001b[39mmpl_connect(\u001b[39m'\u001b[39m\u001b[39mclose_event\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m    883\u001b[0m                                               \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stop)\n\u001b[1;32m    884\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_blit:\n\u001b[0;32m--> 885\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_setup_blit()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/lakeshores/lib/python3.10/site-packages/matplotlib/animation.py:1199\u001b[0m, in \u001b[0;36mAnimation._setup_blit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1196\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_drawn_artists \u001b[39m=\u001b[39m []\n\u001b[1;32m   1197\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_resize_id \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fig\u001b[39m.\u001b[39mcanvas\u001b[39m.\u001b[39mmpl_connect(\u001b[39m'\u001b[39m\u001b[39mresize_event\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   1198\u001b[0m                                                \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_on_resize)\n\u001b[0;32m-> 1199\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_post_draw(\u001b[39mNone\u001b[39;49;00m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_blit)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/lakeshores/lib/python3.10/site-packages/matplotlib/animation.py:1152\u001b[0m, in \u001b[0;36mAnimation._post_draw\u001b[0;34m(self, framedata, blit)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_blit_draw(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_drawn_artists)\n\u001b[1;32m   1151\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1152\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fig\u001b[39m.\u001b[39;49mcanvas\u001b[39m.\u001b[39;49mdraw_idle()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/lakeshores/lib/python3.10/site-packages/matplotlib/backend_bases.py:2060\u001b[0m, in \u001b[0;36mFigureCanvasBase.draw_idle\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2058\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_idle_drawing:\n\u001b[1;32m   2059\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_idle_draw_cntx():\n\u001b[0;32m-> 2060\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdraw(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/lakeshores/lib/python3.10/site-packages/matplotlib/backends/backend_agg.py:436\u001b[0m, in \u001b[0;36mFigureCanvasAgg.draw\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[39m# Acquire a lock on the shared font cache.\u001b[39;00m\n\u001b[1;32m    433\u001b[0m \u001b[39mwith\u001b[39;00m RendererAgg\u001b[39m.\u001b[39mlock, \\\n\u001b[1;32m    434\u001b[0m      (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtoolbar\u001b[39m.\u001b[39m_wait_cursor_for_draw_cm() \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtoolbar\n\u001b[1;32m    435\u001b[0m       \u001b[39melse\u001b[39;00m nullcontext()):\n\u001b[0;32m--> 436\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfigure\u001b[39m.\u001b[39;49mdraw(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrenderer)\n\u001b[1;32m    437\u001b[0m     \u001b[39m# A GUI class may be need to update a window using this draw, so\u001b[39;00m\n\u001b[1;32m    438\u001b[0m     \u001b[39m# don't forget to call the superclass.\u001b[39;00m\n\u001b[1;32m    439\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mdraw()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/lakeshores/lib/python3.10/site-packages/matplotlib/artist.py:73\u001b[0m, in \u001b[0;36m_finalize_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[39m@wraps\u001b[39m(draw)\n\u001b[1;32m     72\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdraw_wrapper\u001b[39m(artist, renderer, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m---> 73\u001b[0m     result \u001b[39m=\u001b[39m draw(artist, renderer, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     74\u001b[0m     \u001b[39mif\u001b[39;00m renderer\u001b[39m.\u001b[39m_rasterizing:\n\u001b[1;32m     75\u001b[0m         renderer\u001b[39m.\u001b[39mstop_rasterizing()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/lakeshores/lib/python3.10/site-packages/matplotlib/artist.py:50\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     48\u001b[0m         renderer\u001b[39m.\u001b[39mstart_filter()\n\u001b[0;32m---> 50\u001b[0m     \u001b[39mreturn\u001b[39;00m draw(artist, renderer)\n\u001b[1;32m     51\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/lakeshores/lib/python3.10/site-packages/matplotlib/figure.py:2820\u001b[0m, in \u001b[0;36mFigure.draw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   2817\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m   2818\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstale \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m-> 2820\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcanvas\u001b[39m.\u001b[39;49mdraw_event(renderer)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/lakeshores/lib/python3.10/site-packages/matplotlib/backend_bases.py:1779\u001b[0m, in \u001b[0;36mFigureCanvasBase.draw_event\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   1777\u001b[0m s \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mdraw_event\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   1778\u001b[0m event \u001b[39m=\u001b[39m DrawEvent(s, \u001b[39mself\u001b[39m, renderer)\n\u001b[0;32m-> 1779\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcallbacks\u001b[39m.\u001b[39;49mprocess(s, event)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/lakeshores/lib/python3.10/site-packages/matplotlib/cbook/__init__.py:292\u001b[0m, in \u001b[0;36mCallbackRegistry.process\u001b[0;34m(self, s, *args, **kwargs)\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n\u001b[1;32m    291\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexception_handler \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 292\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexception_handler(exc)\n\u001b[1;32m    293\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    294\u001b[0m         \u001b[39mraise\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/lakeshores/lib/python3.10/site-packages/matplotlib/cbook/__init__.py:96\u001b[0m, in \u001b[0;36m_exception_printer\u001b[0;34m(exc)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_exception_printer\u001b[39m(exc):\n\u001b[1;32m     95\u001b[0m     \u001b[39mif\u001b[39;00m _get_running_interactive_framework() \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mheadless\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m]:\n\u001b[0;32m---> 96\u001b[0m         \u001b[39mraise\u001b[39;00m exc\n\u001b[1;32m     97\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     98\u001b[0m         traceback\u001b[39m.\u001b[39mprint_exc()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/lakeshores/lib/python3.10/site-packages/matplotlib/cbook/__init__.py:287\u001b[0m, in \u001b[0;36mCallbackRegistry.process\u001b[0;34m(self, s, *args, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[39mif\u001b[39;00m func \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    286\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 287\u001b[0m         func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    288\u001b[0m     \u001b[39m# this does not capture KeyboardInterrupt, SystemExit,\u001b[39;00m\n\u001b[1;32m    289\u001b[0m     \u001b[39m# and GeneratorExit\u001b[39;00m\n\u001b[1;32m    290\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/lakeshores/lib/python3.10/site-packages/matplotlib/animation.py:909\u001b[0m, in \u001b[0;36mAnimation._start\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    906\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fig\u001b[39m.\u001b[39mcanvas\u001b[39m.\u001b[39mmpl_disconnect(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_first_draw_id)\n\u001b[1;32m    908\u001b[0m \u001b[39m# Now do any initial draw\u001b[39;00m\n\u001b[0;32m--> 909\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_init_draw()\n\u001b[1;32m    911\u001b[0m \u001b[39m# Add our callback for stepping the animation and\u001b[39;00m\n\u001b[1;32m    912\u001b[0m \u001b[39m# actually start the event_source.\u001b[39;00m\n\u001b[1;32m    913\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mevent_source\u001b[39m.\u001b[39madd_callback(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_step)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/lakeshores/lib/python3.10/site-packages/matplotlib/animation.py:1698\u001b[0m, in \u001b[0;36mFuncAnimation._init_draw\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1690\u001b[0m         warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m   1691\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mCan not start iterating the frames for the initial draw. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1692\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mThis can be caused by passing in a 0 length sequence \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1695\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mit may be exhausted due to a previous display or save.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1696\u001b[0m         )\n\u001b[1;32m   1697\u001b[0m         \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m-> 1698\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_draw_frame(frame_data)\n\u001b[1;32m   1699\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1700\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_drawn_artists \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_func()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/lakeshores/lib/python3.10/site-packages/matplotlib/animation.py:1720\u001b[0m, in \u001b[0;36mFuncAnimation._draw_frame\u001b[0;34m(self, framedata)\u001b[0m\n\u001b[1;32m   1716\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_save_seq \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_save_seq[\u001b[39m-\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave_count:]\n\u001b[1;32m   1718\u001b[0m \u001b[39m# Call the func with framedata and args. If blitting is desired,\u001b[39;00m\n\u001b[1;32m   1719\u001b[0m \u001b[39m# func needs to return a sequence of any artists that were modified.\u001b[39;00m\n\u001b[0;32m-> 1720\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_drawn_artists \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(framedata, \u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_args)\n\u001b[1;32m   1722\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_blit:\n\u001b[1;32m   1724\u001b[0m     err \u001b[39m=\u001b[39m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mThe animation function must return a sequence \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   1725\u001b[0m                        \u001b[39m'\u001b[39m\u001b[39mof Artist objects.\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'list' object is not callable"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test function working using one lake\n",
    "# S09SF18S23_dhdt_height_thresholds_plot_anim('ConwaySubglacialLake', 10000, [0.2, 0.4, 0.6, 0.8], CS2_dh)\n",
    "# S09SF18S23_dhdt_height_thresholds_plot_anim('ConwaySubglacialLake', 10000, [0.2, 0.4, 0.6, 0.8], ATL15_dh)\n",
    "# S09SF18S23_dhdt_height_thresholds_plot_anim('Lambert_1', 10000, [0.2, 0.4, 0.6, 0.8], CS2_dh)\n",
    "# S09SF18S23_dhdt_height_thresholds_plot_anim('Lambert_1', 10000, [0.25, 0.5, 0.75], ATL15_dh)\n",
    "S09SF18S23_dhdt_height_thresholds_plot_anim('Thw_70', 10000, [1.0], ATL15_dh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def S09SF18S23_dhdt_height_thresholds_plot_anim(lakename_S23, buffer, thres, dataset): \n",
    "    '''\n",
    "    Create planview dh/dt plots of ice surface height changes in bounding box created using geopandas buffer around known lakes outlines\n",
    "    in Siegfried and Fricker, 2018 inventory and lake points in Livingstone and others, 2023 (collated in Sauthoff2023_outlines inventory).\n",
    "    Create time-variable outlines using skimage contour to plot variable outline alongside published outlines for comparison. Plots the pos./neg.\n",
    "    thresholds input.\n",
    "    Inputs: \n",
    "        lakename: lake of interest from Sauthoff2023_outlines inventory\n",
    "        buffer: horizontal distance in meters away from SF18 lake outline used to create bounding box that is displayed around lake of interest\n",
    "        thres(hold): vertical distance in meters to delineate ice surface deformation contour\n",
    "        dataset: dataset to be analyzed (CS2_dh or ATL15_dh)\n",
    "    Outputs: \n",
    "        Sequence of planview dh/dt visuals of CryoSat-2 or ICESat-2 ATL15 with variable ice surface deformation contours plotted to delineate time-variable lake boundary.\n",
    "    '''\n",
    "    # Isolate individual lake using gpd buffer\n",
    "    lake_gpd = Sauthoff2023_outlines.loc[Sauthoff2023_outlines['name'] == lakename_S23]  \n",
    "    lake_buffer = lake_gpd.buffer(buffer)\n",
    "    \n",
    "    # Define lake bounding box\n",
    "    x_min = lake_buffer.bounds.values[0,0]; x_max = lake_buffer.bounds.values[0,2]\n",
    "    y_min = lake_buffer.bounds.values[0,1]; y_max = lake_buffer.bounds.values[0,3]\n",
    "    \n",
    "    # Subset ATL15 data set to region of interest\n",
    "    mask_x = (dataset.x >= x_min) & (dataset.x <= x_max)\n",
    "    mask_y = (dataset.y >= y_min) & (dataset.y <= y_max)\n",
    "    ds_sub = dataset.where(mask_x & mask_y, drop=True)\n",
    "    \n",
    "    # Find magnitude of ice surface deformation in bounding box to create appropriate color map scale\n",
    "    height_anom_pos = []\n",
    "    height_anom_neg = []\n",
    "    for cyc in range(len(ds_sub.time)-1):\n",
    "        pos = np.nanmax(ds_sub.delta_h[cyc+1,:,:]-ds_sub.delta_h[cyc,:,:])\n",
    "        neg = np.nanmin(ds_sub.delta_h[cyc+1,:,:]-ds_sub.delta_h[cyc,:,:])\n",
    "        height_anom_pos += [pos]\n",
    "        height_anom_neg += [neg]\n",
    "    max_height_anom_pos = max(height_anom_pos)\n",
    "    max_height_anom_neg = min(height_anom_neg)\n",
    "        # max_height_anom_abs = max(max_height_anom_pos,abs(max_height_anom_neg))\n",
    "    # v = np.round(max_height_anom_abs) # TODO: plot asymetric colorbar to show true scale of change\n",
    "    \n",
    "    # Create fig, ax, colorbar\n",
    "    fig, ax = plt.subplots(figsize=(8,8))\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes('right', size='5%', pad=0.2)\n",
    "    \n",
    "    # Create empty list to store animation images\n",
    "    ani = animation.PillowWriter(fps=1)\n",
    "    if dataset.fileName == 'mos_2010.5_2021.5.h5':\n",
    "        ani.setup(fig, OUTPUT_DIR + \n",
    "                  '/dhdvdt-using-variable-outlines/S09SF18S23_dhdt_height_thresholds_plot_anim/anim/S09SF18S23_dhdt_height_thresholds_anim-{}-{}.gif'\n",
    "                  .format(lakename_S23, 'CS2'), dpi=300)\n",
    "    elif dataset.fileName == 'ATL15_AA_0314_01km_002_02.nc':    \n",
    "        ani.setup(fig, OUTPUT_DIR + \n",
    "                  '/dhdvdt-using-variable-outlines/S09SF18S23_dhdt_height_thresholds_plot_anim/anim/S09SF18S23_dhdt_height_thresholds_anim-{}-{}.gif'\n",
    "                  .format(lakename_S23, 'IS2'), dpi=300)\n",
    "    \n",
    "    # Create empty list to store dates\n",
    "    dates = []\n",
    "    for idx in range(len(ds_sub.time)-1): \n",
    "        dhdt = ds_sub.delta_h[idx+1,:,:]-ds_sub.delta_h[idx,:,:]\n",
    "        # Calculate mid-cycle dates for plotting\n",
    "        if dataset.fileName == 'mos_2010.5_2021.5.h5':\n",
    "            newdate = datetime.datetime(int(ds_sub.time.values[idx]), 1, 1) + datetime.timedelta(days = (ds_sub.time.values[idx] % 1) * 365.25)\n",
    "            newdate1 = datetime.datetime(int(ds_sub.time.values[idx+1]), 1, 1) + datetime.timedelta(days = (ds_sub.time.values[idx+1] % 1) * 365.25)\n",
    "            midcycdays = newdate1 - newdate\n",
    "            midcycdate = newdate + midcycdays/2\n",
    "            dates += [midcycdate]\n",
    "        elif dataset.fileName == 'ATL15_AA_0314_01km_002_02.nc':    \n",
    "            date_time_str = '18-01-01'\n",
    "            date_time_obj = datetime.datetime.strptime(date_time_str, '%y-%m-%d')\n",
    "            newdate = date_time_obj + datetime.timedelta(days=ds_sub.time.values[idx])\n",
    "            newdate1 = date_time_obj + datetime.timedelta(days=ds_sub.time.values[idx+1])\n",
    "            midcycdays = newdate1 - newdate\n",
    "            midcycdate = newdate + midcycdays/2\n",
    "            dates += [midcycdate]\n",
    "    \n",
    "        # Create difference from one acquisition cycle to the next\n",
    "        dhdt = ds_sub.delta_h[idx+1,:,:]-ds_sub.delta_h[idx,:,:]\n",
    "    \n",
    "        # Establish diverging colorbar\n",
    "        divnorm=colors.TwoSlopeNorm(vmin=max_height_anom_neg, vcenter=0., vmax=max_height_anom_pos)\n",
    "    \n",
    "        # Plot figure\n",
    "        img = ax.imshow(dhdt, extent=[x_min, x_max, y_min, y_max], \n",
    "            origin='upper', cmap='RdBu', norm=divnorm)\n",
    "        # Create contours of ice surface elevation height changes to delineate lake outlines\n",
    "        contours_fill = []\n",
    "        contours_drain = []\n",
    "        for thres_i in thres:     \n",
    "            contour = measure.find_contours(dhdt.values, thres_i)\n",
    "            if len(contour) > 0: \n",
    "                contours_fill += [contour]\n",
    "            contour = measure.find_contours(dhdt.values, -thres_i)\n",
    "            if len(contour) > 0: \n",
    "                contours_drain += [contour]\n",
    "        \n",
    "        # Create mapping conversion factor to map array location to polar stereographic x,y\n",
    "        x_conv = (x_max-x_min)/dhdt.shape[1]\n",
    "        y_conv = (y_max-y_min)/dhdt.shape[0]\n",
    "        \n",
    "        # Plot variable outlines found in this time slice\n",
    "        for i in range(len(contours_fill)): \n",
    "            for j in range(len(contours_fill[i])):\n",
    "                ax.plot(x_min+contours_fill[i][j][:,1]*x_conv, y_max-contours_fill[i][j][:,0]*y_conv, color='mediumblue', linestyle='dashdot', linewidth=1)\n",
    "        for i in range(len(contours_drain)): \n",
    "            for j in range(len(contours_drain[i])):\n",
    "                ax.plot(x_min+contours_drain[i][j][:,1]*x_conv, y_max-contours_drain[i][j][:,0]*y_conv, color='maroon', linestyle=(0, (3, 1, 1, 1)), linewidth=1)\n",
    "        ax.set(xlim=(x_min, x_max), ylim=(y_min, y_max))\n",
    "        \n",
    "        # Change polar stereographic m to km\n",
    "        km_scale = 1e3\n",
    "        ticks_x = ticker.FuncFormatter(lambda x, pos: '{0:g}'.format(x/km_scale))\n",
    "        ax.xaxis.set_major_formatter(ticks_x)\n",
    "        ticks_y = ticker.FuncFormatter(lambda x, pos: '{0:g}'.format(x/km_scale))\n",
    "        ax.yaxis.set_major_formatter(ticks_y)  \n",
    "        \n",
    "        # Label axes\n",
    "        ax.set_xlabel('x [km]', size=15)\n",
    "        ax.set_ylabel('y [km]', size=15)\n",
    "        \n",
    "        # Add title and colorbar\n",
    "        ax.set_title(lakename_S23+' dh + outline comparison \\nh$_{'+newdate1.strftime('%m/%Y')+'}$ - h$_{'+newdate.strftime('%m/%Y')+'}$', pad=7.5, fontsize=17.5)\n",
    "        fig.colorbar(img, cax=cax).set_label('height change (dh) [m]', size=15)\n",
    "        \n",
    "        # Overlay published outlines for visual comparison \n",
    "        Smith2009_outlines.boundary.plot(ax=ax, color='k', linestyle='--', linewidth=1)\n",
    "        SiegfriedFricker2018_outlines.boundary.plot(ax=ax, color='k', linestyle='-', linewidth=1)\n",
    "        Smith2009 = plt.Line2D((0, 1), (0, 0), color='k', linestyle='--', linewidth=2)\n",
    "        SiegfriedFricker2018 = plt.Line2D((0, 1), (0, 0), color='k', linestyle='-', linewidth=2)\n",
    "        uplift = plt.Line2D((0, 1), (0, 0), color='mediumblue', linestyle='dashdot', linewidth=2)\n",
    "        subsidence = plt.Line2D((0, 1), (0, 0), color='maroon', linestyle=(0, (3, 1, 1, 1)), linewidth=2)\n",
    "        \n",
    "        # Create legend\n",
    "        ax.legend([Smith2009, SiegfriedFricker2018, uplift, subsidence],\n",
    "            ['Smith and others, 2009 outline','Siegfried & Fricker, 2018 outline',\n",
    "            ('+'+str(thres)+' m uplift (filling) variable outline'), 'â€“'+str(thres)+' m subsidence (draining) variable outline'], \n",
    "            loc='upper left')\n",
    "        \n",
    "        # Plot inset map to show location \n",
    "        axIns = ax.inset_axes([0.01, 0.01, 0.25, 0.25]) # [left, bottom, width, height] (fractional axes coordinates)\n",
    "        axIns.set_aspect('equal')\n",
    "        moa_2014_coastline.plot(ax=axIns, color='gray', edgecolor='k', linewidth=0.1, zorder=3)\n",
    "        moa_2014_groundingline.plot(ax=axIns, color='ghostwhite', edgecolor='k', linewidth=0.1, zorder=3)\n",
    "        rect = Rectangle((x_min, y_min), (x_max-x_min), (y_max-y_min), fill=False, linewidth=2, color='k', zorder=3)\n",
    "        axIns.add_artist(rect) \n",
    "        axIns.axis('off')\n",
    "       \n",
    "        # Save fig\n",
    "        if dataset.fileName == 'mos_2010.5_2021.5.h5':\n",
    "            plt.savefig(OUTPUT_DIR + \n",
    "                        '/dhdvdt-using-variable-outlines/S09SF18S23_dhdt_height_thresholds_plot_anim/plot/S09SF18S23_dhdt_height_thresholds_plot-{}-{}-{}.png'\n",
    "                        .format(lakename_S23,'CS2',midcycdate.strftime('%Y-%m')), dpi=300, bbox_inches = \"tight\")\n",
    "        elif dataset.fileName == 'ATL15_AA_0314_01km_002_02.nc':    \n",
    "            plt.savefig(OUTPUT_DIR + \n",
    "                        '/dhdvdt-using-variable-outlines/S09SF18S23_dhdt_height_thresholds_plot_anim/plot/S09SF18S23_dhdt_height_thresholds_plot-{}-{}-{}.png'\n",
    "                        .format(lakename_S23,'IS2',midcycdate.strftime('%Y-%m')), dpi=300, bbox_inches = \"tight\")      \n",
    "        \n",
    "        # Append image to animation list\n",
    "        ani.grab_frame()\n",
    "        ax.clear()\n",
    "    \n",
    "    # Finish animation and close fig\n",
    "    ani.finish()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test function working using one lake\n",
    "# S09SF18S23_dhdt_height_thresholds_plot_anim('ConwaySubglacialLake', 10000, [0.2, 0.4, 0.6, 0.8], CS2_dh)\n",
    "# S09SF18S23_dhdt_height_thresholds_plot_anim('ConwaySubglacialLake', 10000, [0.2, 0.4, 0.6, 0.8], ATL15_dh)\n",
    "# S09SF18S23_dhdt_height_thresholds_plot_anim('Lambert_1', 10000, [0.2, 0.4, 0.6, 0.8], CS2_dh)\n",
    "# S09SF18S23_dhdt_height_thresholds_plot_anim('Lambert_1', 10000, [0.25, 0.5, 0.75], ATL15_dh)\n",
    "S09SF18S23_dhdt_height_thresholds_plot_anim('Thw_70', 10000, [1.0], ATL15_dh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run func on all lakes from S23 inventory\n",
    "for idx in range(len(Sauthoff2023_outlines)-1):\n",
    "    lakename = Sauthoff2023_outlines['name'][idx]\n",
    "    S09SF18S23_dhdt_height_thresholds_plot_anim(lakename, 7500, [0.25, 0.5, 0.75], CS2_dh)\n",
    "    S09SF18S23_dhdt_height_thresholds_plot_anim(lakename, 7500, [0.25, 0.5, 0.75], ATL15_dh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "# Func S09SF18S23_dhdt_dynamic_height_thresholds_plot_anim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def S09SF18S23_dhdt_dynamic_height_thresholds_plot_anim(lakename_S23, buffer, dataset): \n",
    "    '''\n",
    "    Create planview dh/dt plots of ice surface height changes in bounding box created using geopandas buffer around known lakes outlines\n",
    "    in Siegfried and Fricker, 2018 inventory and lake points in Livingstone and others, 2023 (collated in Sauthoff2023_outlines inventory).\n",
    "    Create time-variable outlines using skimage contour to plot variable outline alongside published outlines for comparison. Plots the pos./neg.\n",
    "    threshold using a dynamic method based on the height change range of that region.\n",
    "    Inputs: \n",
    "        lakename: lake of interest from Sauthoff2023_outlines inventory\n",
    "        buffer: horizontal distance in meters away from SF18 lake outline used to create bounding box that is displayed around lake of interest\n",
    "        dataset: dataset to be analyzed (CS2_dh or ATL15_dh)\n",
    "    Outputs: \n",
    "        Sequence of planview dh/dt visuals of CryoSat-2 or ICESat-2 ATL15 with variable ice surface deformation contours plotted to delineate \n",
    "        time-variable lake outline.\n",
    "    '''\n",
    "    # Isolate individual lake using gpd buffer\n",
    "    lake_gpd = Sauthoff2023_outlines.loc[Sauthoff2023_outlines['name'] == lakename_S23]  \n",
    "    lake_buffer = lake_gpd.buffer(buffer)\n",
    "    \n",
    "    # Define lake bounding box\n",
    "    x_min = lake_buffer.bounds.values[0,0]; x_max = lake_buffer.bounds.values[0,2]\n",
    "    y_min = lake_buffer.bounds.values[0,1]; y_max = lake_buffer.bounds.values[0,3]\n",
    "\n",
    "    # Subset ATL15 data set to region of interest\n",
    "    mask_x = (dataset.x >= x_min) & (dataset.x <= x_max)\n",
    "    mask_y = (dataset.y >= y_min) & (dataset.y <= y_max)\n",
    "    ds_sub = dataset.where(mask_x & mask_y, drop=True)\n",
    "   \n",
    "    # Find magnitude of ice surface deformation in bounding box to create appropriate color map scale\n",
    "    # Create empty lists to store data\n",
    "    height_anom_pos = []\n",
    "    height_anom_neg = []\n",
    "    dhdt_das = []\n",
    "    for cyc in range(len(ds_sub.time)-1):\n",
    "        pos = np.nanmax(ds_sub.delta_h[cyc+1,:,:]-ds_sub.delta_h[cyc,:,:])\n",
    "        neg = np.nanmin(ds_sub.delta_h[cyc+1,:,:]-ds_sub.delta_h[cyc,:,:])\n",
    "        height_anom_pos += [pos]\n",
    "        height_anom_neg += [neg]\n",
    "        dhdt_da = ds_sub.delta_h[cyc+1,:,:]-ds_sub.delta_h[cyc,:,:]\n",
    "        dhdt_das.append(dhdt_da)\n",
    "    dhdt_ds = xarray.concat(dhdt_das, dim='delta_h')\n",
    "   \n",
    "    # Store max pos/neg height anomalies from all cycles to create colorbar bounds later\n",
    "    max_height_anom_pos = max(height_anom_pos)\n",
    "    max_height_anom_neg = min(height_anom_neg)\n",
    "    \n",
    "    # Create dynamic threshold based on height change range\n",
    "    thres = 2 * np.mean(abs(dhdt_ds)).values\n",
    "   \n",
    "    # Create fig, ax, colorbar\n",
    "    fig, ax = plt.subplots(figsize=(8,8))\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes('right', size='5%', pad=0.2)\n",
    "   \n",
    "    # Create empty list to store animation images\n",
    "    ani = animation.PillowWriter(fps=1)\n",
    "    if dataset.fileName == 'mos_2010.5_2021.5.h5':\n",
    "        ani.setup(fig, OUTPUT_DIR + \n",
    "                  '/dhdvdt-using-variable-outlines/S09SF18S23_dhdt_dynamic_height_thresholds_plot_anim/anim/S09SF18S23_dhdt_dynamic_height_thresholds_anim-{}-{}.gif'\n",
    "                  .format(lakename_S23, 'CS2'), dpi=300)\n",
    "    elif dataset.fileName == 'ATL15_AA_0314_01km_002_02.nc':    \n",
    "        ani.setup(fig, OUTPUT_DIR + \n",
    "                  '/dhdvdt-using-variable-outlines/S09SF18S23_dhdt_dynamic_height_thresholds_plot_anim/anim/S09SF18S23_dhdt_dynamic_height_thresholds_anim-{}-{}.gif'\n",
    "                  .format(lakename_S23, 'IS2'), dpi=300)\n",
    "   \n",
    "    # Create empty list to store dates\n",
    "    dates = []\n",
    "    for idx in range(len(ds_sub.time)-1): \n",
    "        dhdt = ds_sub.delta_h[idx+1,:,:]-ds_sub.delta_h[idx,:,:]\n",
    "        # Calculate mid-cycle dates for plotting\n",
    "        if dataset.fileName == 'mos_2010.5_2021.5.h5':\n",
    "            newdate = datetime.datetime(int(ds_sub.time.values[idx]), 1, 1) + datetime.timedelta(days = (ds_sub.time.values[idx] % 1) * 365.25)\n",
    "            newdate1 = datetime.datetime(int(ds_sub.time.values[idx+1]), 1, 1) + datetime.timedelta(days = (ds_sub.time.values[idx+1] % 1) * 365.25)\n",
    "            midcycdays = newdate1 - newdate\n",
    "            midcycdate = newdate + midcycdays/2\n",
    "            dates += [midcycdate]\n",
    "        elif dataset.fileName == 'ATL15_AA_0314_01km_002_02.nc':    \n",
    "            date_time_str = '18-01-01'\n",
    "            date_time_obj = datetime.datetime.strptime(date_time_str, '%y-%m-%d')\n",
    "            newdate = date_time_obj + datetime.timedelta(days=ds_sub.time.values[idx])\n",
    "            newdate1 = date_time_obj + datetime.timedelta(days=ds_sub.time.values[idx+1])\n",
    "            midcycdays = newdate1 - newdate\n",
    "            midcycdate = newdate + midcycdays/2\n",
    "            dates += [midcycdate]\n",
    "   \n",
    "        # Create difference from one acquisition cycle to the next\n",
    "        dhdt = ds_sub.delta_h[idx+1,:,:]-ds_sub.delta_h[idx,:,:]\n",
    "   \n",
    "        # Establish diverging colorbar\n",
    "        divnorm=colors.TwoSlopeNorm(vmin=max_height_anom_neg, vcenter=0., vmax=max_height_anom_pos)\n",
    "   \n",
    "        # Plot figure\n",
    "        img = ax.imshow(dhdt, extent=[x_min, x_max, y_min, y_max], \n",
    "            origin='upper', cmap='RdBu', norm=divnorm)\n",
    "   \n",
    "        # Create contours of ice surface elevation height changes to delineate lake outlines\n",
    "        contours_fill = []\n",
    "        contours_drain = []\n",
    "        contour = measure.find_contours(dhdt.values, thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_fill += [contour]\n",
    "        contour = measure.find_contours(dhdt.values, -thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_drain += [contour]\n",
    "   \n",
    "        # Create mapping conversion factor to map array location to polar stereographic x,y\n",
    "        x_conv = (x_max-x_min)/dhdt.shape[1]\n",
    "        y_conv = (y_max-y_min)/dhdt.shape[0]\n",
    "   \n",
    "        # Plot variable outlines found in this time slice\n",
    "        for i in range(len(contours_fill)): \n",
    "            for j in range(len(contours_fill[i])):\n",
    "                ax.plot(x_min+contours_fill[i][j][:,1]*x_conv, y_max-contours_fill[i][j][:,0]*y_conv, color='mediumblue', linestyle='dashdot', linewidth=1)\n",
    "        for i in range(len(contours_drain)): \n",
    "            for j in range(len(contours_drain[i])):\n",
    "                ax.plot(x_min+contours_drain[i][j][:,1]*x_conv, y_max-contours_drain[i][j][:,0]*y_conv, color='maroon', linestyle=(0, (3, 1, 1, 1)), linewidth=1)\n",
    "        ax.set(xlim=(x_min, x_max), ylim=(y_min, y_max))\n",
    "   \n",
    "        # Change polar stereographic m to km\n",
    "        km_scale = 1e3\n",
    "        ticks_x = ticker.FuncFormatter(lambda x, pos: '{0:g}'.format(x/km_scale))\n",
    "        ax.xaxis.set_major_formatter(ticks_x)\n",
    "        ticks_y = ticker.FuncFormatter(lambda x, pos: '{0:g}'.format(x/km_scale))\n",
    "        ax.yaxis.set_major_formatter(ticks_y)  \n",
    "   \n",
    "        # Label axes\n",
    "        ax.set_xlabel('x [km]', size=15)\n",
    "        ax.set_ylabel('y [km]', size=15)\n",
    "   \n",
    "        # Add title and colorbar\n",
    "        ax.set_title(lakename_S23+' dh + outline comparison \\nh$_{'+newdate1.strftime('%m/%Y')+'}$ - h$_{'+newdate.strftime('%m/%Y')+'}$', pad=7.5, fontsize=17.5)\n",
    "        fig.colorbar(img, cax=cax).set_label('height change (dh) [m]', size=15)\n",
    "   \n",
    "        # Overlay published outlines for visual comparison \n",
    "        Smith2009_outlines.boundary.plot(ax=ax, color='k', linestyle='--', linewidth=1)\n",
    "        SiegfriedFricker2018_outlines.boundary.plot(ax=ax, color='k', linestyle='-', linewidth=1)\n",
    "        Smith2009 = plt.Line2D((0, 1), (0, 0), color='k', linestyle='--', linewidth=2)\n",
    "        SiegfriedFricker2018 = plt.Line2D((0, 1), (0, 0), color='k', linestyle='-', linewidth=2)\n",
    "        uplift = plt.Line2D((0, 1), (0, 0), color='mediumblue', linestyle='dashdot', linewidth=2)\n",
    "        subsidence = plt.Line2D((0, 1), (0, 0), color='maroon', linestyle=(0, (3, 1, 1, 1)), linewidth=2)\n",
    "   \n",
    "        # Create legend\n",
    "        ax.legend([Smith2009, SiegfriedFricker2018, uplift, subsidence],\n",
    "            ['Smith and others, 2009 outline','Siegfried & Fricker, 2018 outline',\n",
    "            ('+ '+str(np.round(thres,1))+' m uplift (filling) variable outline'), 'â€“ '+str(np.round(thres,1))+' m subsidence (draining) variable outline'], \n",
    "            loc='upper left')\n",
    "       \n",
    "        # Plot inset map to show location \n",
    "        axIns = ax.inset_axes([0.01, 0.01, 0.25, 0.25]) # [left, bottom, width, height] (fractional axes coordinates)\n",
    "        axIns.set_aspect('equal')\n",
    "        moa_2009_coastline.plot(ax=axIns, color='gray', edgecolor='k', linewidth=0.1, zorder=3)\n",
    "        moa_2009_groundingline.plot(ax=axIns, color='ghostwhite', edgecolor='k', linewidth=0.1, zorder=3)\n",
    "        rect = Rectangle((x_min, y_min), (x_max-x_min), (y_max-y_min), fill=False, linewidth=2, color='k', zorder=3)\n",
    "        axIns.add_artist(rect) \n",
    "        axIns.axis('off')\n",
    "       \n",
    "        # Save fig\n",
    "        if dataset.fileName == 'mos_2010.5_2021.5.h5':\n",
    "            plt.savefig(OUTPUT_DIR + \n",
    "                        '/dhdvdt-using-variable-outlines/S09SF18S23_dhdt_dynamic_height_thresholds_plot_anim/plot/S09SF18S23_dhdt_dynamic_height_thresholds_plot-{}-{}-{}.png'\n",
    "                        .format(lakename_S23,'CS2',midcycdate.strftime('%Y-%m')), dpi=300, bbox_inches = \"tight\")\n",
    "        elif dataset.fileName == 'ATL15_AA_0314_01km_002_02.nc':    \n",
    "            plt.savefig(OUTPUT_DIR + \n",
    "                        '/dhdvdt-using-variable-outlines/S09SF18S23_dhdt_dynamic_height_thresholds_plot_anim/plot/S09SF18S23_dhdt_dynamic_height_thresholds_plot-{}-{}-{}.png'\n",
    "                        .format(lakename_S23,'IS2',midcycdate.strftime('%Y-%m')), dpi=300, bbox_inches = \"tight\")      \n",
    "        \n",
    "        # Append image to animation list\n",
    "        ani.grab_frame()\n",
    "        ax.clear()\n",
    "    \n",
    "    # Finish animation and close fig\n",
    "    ani.finish()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test function working using one lake\n",
    "# S09SF18S23_dhdt_dynamic_height_thresholds_plot_anim('ConwaySubglacialLake', 10000, CS2_dh)\n",
    "S09SF18S23_dhdt_dynamic_height_thresholds_plot_anim('ConwaySubglacialLake', 10000, ATL15_dh)\n",
    "# S09SF18S23_dhdt_dynamic_height_thresholds_plot_anim('Lambert_1', 10000, CS2_dh)\n",
    "# S09SF18S23_dhdt_dynamic_height_thresholds_plot_anim('Lambert_1', 10000, ATL15_dh)\n",
    "# S09SF18S23_dhdt_dynamic_height_thresholds_plot_anim('Thw_70', 10000, ATL15_dh)\n",
    "# S09SF18S23_dhdt_dynamic_height_thresholds_plot_anim('Thw_124', 10000, ATL15_dh)\n",
    "# S09SF18S23_dhdt_dynamic_height_thresholds_plot_anim('Thw_142', 10000, ATL15_dh)\n",
    "# S09SF18S23_dhdt_dynamic_height_thresholds_plot_anim('Thw_170', 10000, ATL15_dh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n",
      "posx and posy should be finite values\n"
     ]
    }
   ],
   "source": [
    "# Run func on all lakes from S23 inventory\n",
    "for idx in range(len(Sauthoff2023_outlines)-1):\n",
    "    lakename = Sauthoff2023_outlines['name'][idx]\n",
    "    # S09SF18S23_dhdt_dynamic_height_thresholds_plot_anim(lakename, 7500, CS2_dh)\n",
    "    S09SF18S23_dhdt_dynamic_height_thresholds_plot_anim(lakename, 7500, ATL15_dh)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Func S09SF18S23_dhdt_dynamic_height_thresholds_bbox_area_plot_anim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def S09SF18S23_dhdt_dynamic_height_thresholds_bbox_area_plot_anim(lakename_S23, surrounding_area_multiple, dataset): \n",
    "    '''\n",
    "    Create planview dh/dt plots of ice surface height changes in bounding box created using geopandas buffer around known lakes outlines\n",
    "    in Siegfried and Fricker, 2018 inventory and lake points in Livingstone and others, 2023 (collated in Sauthoff2023_outlines inventory).\n",
    "    Create time-variable outlines using skimage contour to plot variable outline alongside published outlines for comparison. Plots the pos./neg.\n",
    "    threshold using a dynamic method based on the height change range of that region.\n",
    "    Inputs: \n",
    "        lakename: lake of interest from Sauthoff2023_outlines inventory\n",
    "        buffer: horizontal distance in meters away from SF18 lake outline used to create bounding box that is displayed around lake of interest\n",
    "        dataset: dataset to be analyzed (CS2_dh or ATL15_dh)\n",
    "    Outputs: \n",
    "        Sequence of planview dh/dt visuals of CryoSat-2 or ICESat-2 ATL15 with variable ice surface deformation contours plotted to delineate \n",
    "        time-variable lake outline.\n",
    "    '''\n",
    "    # Isolate individual lake and find scene area based on lake area\n",
    "    lake_gpd = Sauthoff2023_outlines.loc[Sauthoff2023_outlines['name'] == lakename_S23]  \n",
    "    lake_area = lake_gpd['area (m^2)']\n",
    "    scene_area = surrounding_area_multiple * lake_area\n",
    "    scene_side_length = math.sqrt(scene_area)\n",
    "\n",
    "    # Define lake bounding box\n",
    "    x_min = lake_gpd.geometry.centroid.x.values[0] - 0.5 * scene_side_length\n",
    "    x_max = lake_gpd.geometry.centroid.x.values[0] + 0.5 * scene_side_length\n",
    "    y_min = lake_gpd.geometry.centroid.y.values[0] - 0.5 * scene_side_length\n",
    "    y_max = lake_gpd.geometry.centroid.y.values[0] + 0.5 * scene_side_length\n",
    "\n",
    "    # Subset ATL15 data set to region of interest\n",
    "    mask_x = (dataset.x >= x_min) & (dataset.x <= x_max)\n",
    "    mask_y = (dataset.y >= y_min) & (dataset.y <= y_max)\n",
    "    ds_sub = dataset.where(mask_x & mask_y, drop=True)\n",
    " \n",
    "    # Find magnitude of ice surface deformation in bounding box to create appropriate color map scale\n",
    "    # Create empty lists to store data\n",
    "    height_anom_pos = []\n",
    "    height_anom_neg = []\n",
    "    dhdt_das = []\n",
    "    for cyc in range(len(ds_sub.time)-1):\n",
    "        pos = np.nanmax(ds_sub.delta_h[cyc+1,:,:]-ds_sub.delta_h[cyc,:,:])\n",
    "        neg = np.nanmin(ds_sub.delta_h[cyc+1,:,:]-ds_sub.delta_h[cyc,:,:])\n",
    "        height_anom_pos += [pos]\n",
    "        height_anom_neg += [neg]\n",
    "        dhdt_da = ds_sub.delta_h[cyc+1,:,:]-ds_sub.delta_h[cyc,:,:]\n",
    "        dhdt_das.append(dhdt_da)\n",
    "    dhdt_ds = xarray.concat(dhdt_das, dim='delta_h')\n",
    "    \n",
    "    # Store max pos/neg height anomalies from all cycles to create colorbar bounds later\n",
    "    max_height_anom_pos = max(height_anom_pos)\n",
    "    max_height_anom_neg = min(height_anom_neg)\n",
    "    \n",
    "    # Create dynamic threshold based on height change range\n",
    "    thres = 2 * np.mean(abs(dhdt_ds)).values\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(8,8))\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes('right', size='5%', pad=0.2)\n",
    "    \n",
    "    # Create empty list to store animation images\n",
    "    ani = animation.PillowWriter(fps=1)\n",
    "    if dataset.fileName == 'mos_2010.5_2021.5.h5':\n",
    "        ani.setup(fig, OUTPUT_DIR + \n",
    "                  '/dhdvdt-using-variable-outlines/S09SF18S23_dhdt_dynamic_height_thresholds_bbox_area_plot_anim/anim/S09SF18S23_dhdt_dynamic_height_thresholds_bbox_area_anim-{}-{}.gif'\n",
    "                  .format(lakename_S23, 'CS2'), dpi=300)\n",
    "    elif dataset.fileName == 'ATL15_AA_0314_01km_002_02.nc':    \n",
    "        ani.setup(fig, OUTPUT_DIR + \n",
    "                  '/dhdvdt-using-variable-outlines/S09SF18S23_dhdt_dynamic_height_thresholds_bbox_area_plot_anim/anim/S09SF18S23_dhdt_dynamic_height_thresholds_bbox_area_anim-{}-{}.gif'\n",
    "                  .format(lakename_S23, 'IS2'), dpi=300)\n",
    "   \n",
    "    # Create empty list to store dates\n",
    "    dates = []\n",
    "    for idx in range(len(ds_sub.time)-1): \n",
    "        dhdt = ds_sub.delta_h[idx+1,:,:]-ds_sub.delta_h[idx,:,:]\n",
    "        # Calculate mid-cycle dates for plotting\n",
    "        if dataset.fileName == 'mos_2010.5_2021.5.h5':\n",
    "            newdate = datetime.datetime(int(ds_sub.time.values[idx]), 1, 1) + datetime.timedelta(days = (ds_sub.time.values[idx] % 1) * 365.25)\n",
    "            newdate1 = datetime.datetime(int(ds_sub.time.values[idx+1]), 1, 1) + datetime.timedelta(days = (ds_sub.time.values[idx+1] % 1) * 365.25)\n",
    "            midcycdays = newdate1 - newdate\n",
    "            midcycdate = newdate + midcycdays/2\n",
    "            dates += [midcycdate]\n",
    "        elif dataset.fileName == 'ATL15_AA_0314_01km_002_02.nc':    \n",
    "            date_time_str = '18-01-01'\n",
    "            date_time_obj = datetime.datetime.strptime(date_time_str, '%y-%m-%d')\n",
    "            newdate = date_time_obj + datetime.timedelta(days=ds_sub.time.values[idx])\n",
    "            newdate1 = date_time_obj + datetime.timedelta(days=ds_sub.time.values[idx+1])\n",
    "            midcycdays = newdate1 - newdate\n",
    "            midcycdate = newdate + midcycdays/2\n",
    "            dates += [midcycdate]\n",
    "        \n",
    "        # Create difference from one acquisition cycle to the next\n",
    "        dhdt = ds_sub.delta_h[idx+1,:,:]-ds_sub.delta_h[idx,:,:]\n",
    "        \n",
    "        # Establish diverging colorbar\n",
    "        divnorm=colors.TwoSlopeNorm(vmin=max_height_anom_neg, vcenter=0., vmax=max_height_anom_pos)\n",
    "        \n",
    "        # Plot figure\n",
    "        img = ax.imshow(dhdt, extent=[x_min, x_max, y_min, y_max], \n",
    "            origin='upper', cmap='RdBu', norm=divnorm)\n",
    "        \n",
    "        # Create contours of ice surface elevation height changes to delineate lake outlines\n",
    "        contours_fill = []\n",
    "        contours_drain = []\n",
    "        contour = measure.find_contours(dhdt.values, thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_fill += [contour]\n",
    "        contour = measure.find_contours(dhdt.values, -thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_drain += [contour]\n",
    "        \n",
    "        # Create mapping conversion factor to map array location to polar stereographic x,y\n",
    "        x_conv = (x_max-x_min)/dhdt.shape[1]\n",
    "        y_conv = (y_max-y_min)/dhdt.shape[0]\n",
    "        \n",
    "        # Plot variable outlines found in this time slice\n",
    "        for i in range(len(contours_fill)): \n",
    "            for j in range(len(contours_fill[i])):\n",
    "                ax.plot(x_min+contours_fill[i][j][:,1]*x_conv, y_max-contours_fill[i][j][:,0]*y_conv, color='mediumblue', linestyle='dashdot', linewidth=1)\n",
    "        for i in range(len(contours_drain)): \n",
    "            for j in range(len(contours_drain[i])):\n",
    "                ax.plot(x_min+contours_drain[i][j][:,1]*x_conv, y_max-contours_drain[i][j][:,0]*y_conv, color='maroon', linestyle=(0, (3, 1, 1, 1)), linewidth=1)\n",
    "                \n",
    "        # Set axes limits\n",
    "        ax.set(xlim=(x_min, x_max), ylim=(y_min, y_max))\n",
    "       \n",
    "        # Change polar stereographic m to km\n",
    "        km_scale = 1e3\n",
    "        ticks_x = ticker.FuncFormatter(lambda x, pos: '{0:g}'.format(x/km_scale))\n",
    "        ax.xaxis.set_major_formatter(ticks_x)\n",
    "        ticks_y = ticker.FuncFormatter(lambda x, pos: '{0:g}'.format(x/km_scale))\n",
    "        ax.yaxis.set_major_formatter(ticks_y)  \n",
    "       \n",
    "        # Label axes\n",
    "        ax.set_xlabel('x [km]', size=15)\n",
    "        ax.set_ylabel('y [km]', size=15)\n",
    "       \n",
    "        # Add title and colorbar\n",
    "        ax.set_title(lakename_S23+' dh + outline comparison \\nh$_{'+newdate1.strftime('%m/%Y')+'}$ - h$_{'+newdate.strftime('%m/%Y')+'}$', pad=7.5, fontsize=17.5)\n",
    "        fig.colorbar(img, cax=cax).set_label('height change (dh) [m]', size=15)\n",
    "       \n",
    "        # Overlay published outlines for visual comparison \n",
    "        Smith2009_outlines.boundary.plot(ax=ax, color='k', linestyle='--', linewidth=1)\n",
    "        SiegfriedFricker2018_outlines.boundary.plot(ax=ax, color='k', linestyle='-', linewidth=1)\n",
    "        Smith2009 = plt.Line2D((0, 1), (0, 0), color='k', linestyle='--', linewidth=2)\n",
    "        SiegfriedFricker2018 = plt.Line2D((0, 1), (0, 0), color='k', linestyle='-', linewidth=2)\n",
    "        uplift = plt.Line2D((0, 1), (0, 0), color='mediumblue', linestyle='dashdot', linewidth=2)\n",
    "        subsidence = plt.Line2D((0, 1), (0, 0), color='maroon', linestyle=(0, (3, 1, 1, 1)), linewidth=2)\n",
    "                \n",
    "        # Create legend\n",
    "        ax.legend([Smith2009, SiegfriedFricker2018, uplift, subsidence],\n",
    "            ['Smith and others, 2009 outline','Siegfried & Fricker, 2018 outline',\n",
    "            ('+ '+str(np.round(thres,1))+' m uplift (filling) variable outline'), 'â€“ '+str(np.round(thres,1))+' m subsidence (draining) variable outline'], \n",
    "            loc='upper left')\n",
    "        \n",
    "        # Plot inset map to show location \n",
    "        axIns = ax.inset_axes([0.99, 0.99, 0.25, 0.25]) # [left, bottom, width, height] (fractional axes coordinates)\n",
    "        axIns.set_aspect('equal')\n",
    "        moa_2009_coastline.plot(ax=axIns, color='gray', edgecolor='k', linewidth=0.1, zorder=3)\n",
    "        moa_2009_groundingline.plot(ax=axIns, color='ghostwhite', edgecolor='k', linewidth=0.1, zorder=3)\n",
    "        rect = Rectangle((x_min, y_min), (x_max-x_min), (y_max-y_min), fill=False, linewidth=2, color='k', zorder=3)\n",
    "        axIns.add_artist(rect) \n",
    "        axIns.axis('off')\n",
    "       \n",
    "        # Save and close figure\n",
    "        if dataset.fileName == 'mos_2010.5_2021.5.h5':\n",
    "            plt.savefig(OUTPUT_DIR + \n",
    "                        '/dhdvdt-using-variable-outlines/S09SF18S23_dhdt_dynamic_height_thresholds_bbox_area_plot_anim/plot/S09SF18S23_dhdt_dynamic_height_thresholds_bbox_area_plot-{}-{}-{}.png'\n",
    "                        .format(lakename_S23,'CS2',midcycdate.strftime('%Y-%m')), dpi=300, bbox_inches = \"tight\")\n",
    "        elif dataset.fileName == 'ATL15_AA_0314_01km_002_02.nc':    \n",
    "            plt.savefig(OUTPUT_DIR + \n",
    "                        '/dhdvdt-using-variable-outlines/S09SF18S23_dhdt_dynamic_height_thresholds_bbox_area_plot_anim/plot/S09SF18S23_dhdt_dynamic_height_thresholds_bbox_area_plot-{}-{}-{}.png'\n",
    "                        .format(lakename_S23,'IS2',midcycdate.strftime('%Y-%m')), dpi=300, bbox_inches = \"tight\")      \n",
    "        \n",
    "        # Append image to animation list\n",
    "        ani.grab_frame()\n",
    "        ax.clear()\n",
    "    \n",
    "    # Finish animation\n",
    "    ani.finish()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test function working using one lake\n",
    "# S09SF18S23_dhdt_dynamic_height_thresholds_plot_anim('ConwaySubglacialLake', 10000, CS2_dh)\n",
    "S09SF18S23_dhdt_dynamic_height_thresholds_bbox_area_plot_anim('ConwaySubglacialLake', 4, ATL15_dh)\n",
    "# S09SF18S23_dhdt_dynamic_height_thresholds_plot_anim('Lambert_1', 10000, CS2_dh)\n",
    "# S09SF18S23_dhdt_dynamic_height_thresholds_plot_anim('Lambert_1', 10000, ATL15_dh)\n",
    "# S09SF18S23_dhdt_dynamic_height_thresholds_bbox_area_plot_anim('Thw_70', 10000, ATL15_dh)\n",
    "# S09SF18S23_dhdt_dynamic_height_thresholds_plot_anim('Thw_124', 10000, ATL15_dh)\n",
    "# S09SF18S23_dhdt_dynamic_height_thresholds_plot_anim('Thw_142', 10000, ATL15_dh)\n",
    "# S09SF18S23_dhdt_dynamic_height_thresholds_plot_anim('Thw_170', 10000, ATL15_dh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run func on all lakes from S23 inventory\n",
    "for idx in range(len(Sauthoff2023_outlines)-1):\n",
    "    lakename = Sauthoff2023_outlines['name'][idx]\n",
    "    # S09SF18S23_dhdt_dynamic_height_thresholds_bbox_area_plot_anim(lakename, 7500, CS2_dh)\n",
    "    S09SF18S23_dhdt_dynamic_height_thresholds_bbox_area_plot_anim(lakename, 7500, ATL15_dh)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "# Func S09SF18S23_dhdadvdt_plot_anim "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def S09SF18S23_dhdadvdt_anim(lakename_S09, lakename_S23, buffer, thres, dataset): \n",
    "    '''\n",
    "    Create dh/dt plots ice surface height changes using geopandas buffer created bounding box around known lakes in Siegfried and Fricker, 2018 inventory.\n",
    "    Create time-variable outlines using skimage contour to plot variable outline alongside published outlines for comparison. \n",
    "    Use time-variable outlines to calculate dv/dt.\n",
    "    Save images together into GIF animation.\n",
    "    Inputs: \n",
    "        lakename: lake of interest from SiegfriedFricker2018_outlines inventory\n",
    "        buffer: horizontal distance in meters to create bounding box around lake of interest\n",
    "        thres(hold): vertical distance in meters to delineate ice surface deformation contour\n",
    "        dataset: dataset to be analyzed (CS2_dh or ATL15_dh)\n",
    "    Outputs: \n",
    "        1x3 plots of: \n",
    "        * Animations of planview dh/dt visuals with variable ice surface deformation contours plotted to delineate time-variable lake boundary alongside \n",
    "        * 2-D line plot of dArea and\n",
    "        * cumulative dVol using static and variable outlines that updates simultaneously to planview dh/dt animation.\n",
    "    '''\n",
    "    # isolate individual lake using gpd buffer\n",
    "    lake_S09 = Smith2009_outlines.loc[Smith2009_outlines['Name'] == lakename_S09]\n",
    "    lake_SF18 = SiegfriedFricker2018_outlines.loc[SiegfriedFricker2018_outlines['name'] == lakename_S23]\n",
    "    lake_buffer = lake_S09.buffer(buffer)\n",
    "    # lake_buffer = lake_SF18.buffer(buffer)\n",
    "    # define lake bounding box\n",
    "    # x_min = lake_buffer.bounds.values[0,0]; x_max = lake_buffer.bounds.values[0,2]\n",
    "    # y_min = lake_buffer.bounds.values[0,1]; y_max = lake_buffer.bounds.values[0,3]\n",
    "    # subset ATL15 data set to region of interest\n",
    "    mask_x = (dataset.x >= x_min) & (dataset.x <= x_max)\n",
    "    mask_y = (dataset.y >= y_min) & (dataset.y <= y_max)\n",
    "    ds_sub = dataset.where(mask_x & mask_y, drop=True)\n",
    "    # find magnitude of ice surface deformation in bounding box / find appropriate color map scale\n",
    "    height_anom_pos = []\n",
    "    height_anom_neg = []\n",
    "    for cyc in range(len(ds_sub.time)-1):\n",
    "        pos = np.nanmax(ds_sub.delta_h[cyc+1,:,:]-ds_sub.delta_h[cyc,:,:])\n",
    "        neg = np.nanmin(ds_sub.delta_h[cyc+1,:,:]-ds_sub.delta_h[cyc,:,:])\n",
    "        height_anom_pos += [pos]\n",
    "        height_anom_neg += [neg]\n",
    "    max_height_anom_pos = max(height_anom_pos)\n",
    "    max_height_anom_neg = min(height_anom_neg)\n",
    "    max_height_anom_abs = max(max_height_anom_pos,abs(max_height_anom_neg))\n",
    "    v = np.round(max_height_anom_abs)\n",
    "    # create empty lists to store calculated data\n",
    "    dates = []\n",
    "    lkavgdhdt_SF18 = []\n",
    "    lkavgdhdt_var = []\n",
    "    areas_var = []\n",
    "    vols_S09 = []\n",
    "    # vols_SF18 = []\n",
    "    vols_var = []\n",
    "    for idx in range(len(ds_sub.delta_h)-1): \n",
    "        dhdt = ds_sub.delta_h[idx+1,:,:]-ds_sub.delta_h[idx,:,:]\n",
    "        # calculate mid-cycle dates for plotting\n",
    "        if dataset.fileName == 'mos_2010.5_2021.5.h5':\n",
    "            newdate = datetime.datetime(int(ds_sub.time.values[idx]), 1, 1) + datetime.timedelta(days = (ds_sub.time.values[idx] % 1) * 365.25)\n",
    "            newdate1 = datetime.datetime(int(ds_sub.time.values[idx+1]), 1, 1) + datetime.timedelta(days = (ds_sub.time.values[idx+1] % 1) * 365.25)\n",
    "            midcycdays = newdate1 - newdate\n",
    "            midcycdate = newdate + midcycdays/2\n",
    "            dates += [midcycdate]\n",
    "        elif dataset.fileName == 'ATL15_AA_0311_01km_001_01.nc':    \n",
    "            date_time_str = '18-01-01'\n",
    "            date_time_obj = datetime.datetime.strptime(date_time_str, '%y-%m-%d')\n",
    "            newdate = date_time_obj + datetime.timedelta(days=ds_sub.time.values[idx])\n",
    "            newdate1 = date_time_obj + datetime.timedelta(days=ds_sub.time.values[idx+1])\n",
    "            midcycdays = newdate1 - newdate\n",
    "            midcycdate = newdate + midcycdays/2\n",
    "            dates += [midcycdate]\n",
    "        # clip ATL15 data to just show (first set crs)\n",
    "        dhdt.rio.write_crs(3031, inplace=True)\n",
    "        dhdt_clip_S09 = dhdt.rio.clip(lake_S09.geometry.values, lake_S09.crs, drop=False, invert=False)\n",
    "        dhdt_clip_SF18 = dhdt.rio.clip(lake_SF18.geometry.values, lake_SF18.crs, drop=False, invert=False)\n",
    "        # calculate lake avg. dh/dt and dv/dt time series using published stationary outlines\n",
    "        avg_lk_dhdt_S09 = np.nanmean(dhdt_clip_S09)\n",
    "        avg_lk_dhdt_SF18 = np.nanmean(dhdt_clip_SF18)\n",
    "        lkavgdhdt_SF18 += [avg_lk_dhdt_SF18]\n",
    "        vol_S09 = avg_lk_dhdt_S09*Smith2009_outlines[Smith2009_outlines['Name'] == lakename_S09].area\n",
    "        #vol_SF18 = avg_lk_dhdt_SF18*SiegfriedFricker2018_outlines[SiegfriedFricker2018_outlines['name'] == lakename_S23]['area (m^2)']\n",
    "        vols_S09 += [vol_S09.values[0]]\n",
    "        # vols_SF18 += [vol_SF18.values[0]]\n",
    "        # create contours of ice surface elevation height changes to delineate lake outlines\n",
    "        contours_fill = []\n",
    "        contours_drain = []\n",
    "        polys = []\n",
    "        contour = measure.find_contours(dhdt.values, thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_fill += [contour]\n",
    "        contour = measure.find_contours(dhdt.values, -thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_drain += [contour]\n",
    "        # create mapping conversion factor to map array location to polar stereographic x,y\n",
    "        x_conv = (x_max-x_min)/dhdt.shape[1]\n",
    "        y_conv = (y_max-y_min)/dhdt.shape[0]\n",
    "        # make polygons from variable outlines\n",
    "        for i in range(len(contours_fill)): \n",
    "            for j in range(len(contours_fill[i])):\n",
    "                if len(contours_fill[i][j][:, 1]) > 2: \n",
    "                    poly = Polygon(list(zip(x_min+contours_fill[i][j][:, 1]*x_conv, y_max-contours_fill[i][j][:, 0]*y_conv))) \n",
    "                    polys += [poly]\n",
    "        for i in range(len(contours_drain)): \n",
    "            for j in range(len(contours_drain[i])):\n",
    "                if len(contours_drain[i][j][:, 1]) > 2: \n",
    "                    poly = Polygon(list(zip(x_min+contours_drain[i][j][:, 1]*x_conv, y_max-contours_drain[i][j][:, 0]*y_conv))) \n",
    "                    polys += [poly]\n",
    "        # start with baseline variable outline area of zero\n",
    "        variable_area = 0\n",
    "        # if polygons are present at time step, \n",
    "        if len(polys) > 0: \n",
    "            # clip data to polygons (first set crs)\n",
    "            # dhdt.rio.write_crs(3031, inplace=True) # done earlier in code, may not be needed here\n",
    "            dhdt_clip = dhdt.rio.clip(polys, drop=False, invert=False)\n",
    "            # then calculate on-lake averages of dh/dt\n",
    "            avg_lk_dhdt = np.nanmean(dhdt_clip)\n",
    "            # occasionally small polygons will completely clip data resulting in nan's for lake avg. dh/dt\n",
    "            # replace with zeros\n",
    "            if math.isnan(avg_lk_dhdt): \n",
    "                avg_lk_dhdt = 0\n",
    "                lkavgdhdt_var += [avg_lk_dhdt]\n",
    "            else:\n",
    "                lkavgdhdt_var += [avg_lk_dhdt]                \n",
    "            # and dv/dt\n",
    "            for i in range(len(polys)):\n",
    "                variable_area = variable_area + polys[i].area # CHANGE TO GEODESIC AREA\n",
    "            vol_var = avg_lk_dhdt*variable_area\n",
    "            vols_var += [vol_var]\n",
    "            # store areas in list \n",
    "            areas_var += [variable_area]\n",
    "        else: \n",
    "            avg_lk_dhdt = 0\n",
    "            lkavgdhdt_var += [avg_lk_dhdt]\n",
    "            vol_var = avg_lk_dhdt*variable_area\n",
    "            vols_var += [vol_var]\n",
    "            # store areas in list \n",
    "            areas_var += [variable_area]\n",
    "    # create colorbar axis\n",
    "    fig, axes = plt.subplots(1,3, figsize=(31,10))\n",
    "    fig.subplots_adjust(wspace=0.3)\n",
    "    # fig.suptitle('{} outline and dVol comparison'.format(lakename_S23), fontsize=24)\n",
    "    # fig.suptitle('Mercer outline, areal extent, and $\\Delta$volume comparison', fontsize=30)\n",
    "    divider = make_axes_locatable(axes[0])\n",
    "    cax = divider.append_axes('right', size='5%', pad=0.2)\n",
    "    # create empty list to store animation im(age)s\n",
    "    ani = animation.PillowWriter(fps=1)\n",
    "    if dataset.fileName == 'mos_2010.5_2021.5.h5':\n",
    "        ani.setup(fig, '/Users/Wilson/Documents/0-code/1-lakeshores/output_dhdvdt-using-variable-outlines/S09SF18varoutlines_dhdadvdt_anim/S09SF18varoutlines_dhdadvdt_anim-{}-{}.gif'.format(lakename_S23, 'CS2'), dpi=300)\n",
    "    elif dataset.fileName == 'ATL15_AA_0311_01km_001_01.nc':    \n",
    "        ani.setup(fig, '/Users/Wilson/Documents/0-code/1-lakeshores/output_dhdvdt-using-variable-outlines/S09SF18varoutlines_dhdadvdt_anim/S09SF18varoutlines_dhdadvdt_anim-{}-{}.gif'.format(lakename_S23, 'IS2'), dpi=300)\n",
    "    for idx in range(len(ds_sub.delta_h)-1): \n",
    "        dhdt = ds_sub.delta_h[idx+1,:,:]-ds_sub.delta_h[idx,:,:]\n",
    "        img = axes[0].imshow(dhdt, extent=[x_min, x_max, y_min, y_max],\n",
    "            origin='upper', cmap=cmocean.cm.balance_r, vmin=-v, vmax=v)\n",
    "        # create contours of ice surface elevation height changes to delineate lake outlines\n",
    "        contours_fill = []\n",
    "        contours_drain = []\n",
    "        contour = measure.find_contours(dhdt.values, thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_fill += [contour]\n",
    "        contour = measure.find_contours(dhdt.values, -thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_drain += [contour]\n",
    "        # subplot 0: plot variable outlines found in this time slice\n",
    "        for i in range(len(contours_fill)): \n",
    "            for j in range(len(contours_fill[i])):\n",
    "                axes[0].plot(x_min+contours_fill[i][j][:, 1]*x_conv, y_max-contours_fill[i][j][:, 0]*y_conv, color='mediumblue', linestyle='dashdot', linewidth=2)\n",
    "        for i in range(len(contours_drain)): \n",
    "            for j in range(len(contours_drain[i])):\n",
    "                axes[0].plot(x_min+contours_drain[i][j][:, 1]*x_conv, y_max-contours_drain[i][j][:, 0]*y_conv, color='maroon', linestyle=(0, (3, 1, 1, 1)), linewidth=2)\n",
    "        # Change polar stereographic m to km\n",
    "        km_scale = 1e3\n",
    "        ticks_x = ticker.FuncFormatter(lambda x, pos: '{0:g}'.format(x/km_scale))\n",
    "        axes[0].xaxis.set_major_formatter(ticks_x)\n",
    "        ticks_y = ticker.FuncFormatter(lambda x, pos: '{0:g}'.format(x/km_scale))\n",
    "        axes[0].yaxis.set_major_formatter(ticks_y)  \n",
    "        # adjust ticks\n",
    "        axes[0].set_xticks(np.arange(x_min,x_max,5000))\n",
    "        axes[0].set_yticks(np.arange(y_min,y_max,5000))\n",
    "        axes[0].set(xlim=(x_min, x_max), ylim=(y_min, y_max))\n",
    "        axes[0].set_xlabel('x [km]', size=15)\n",
    "        axes[0].set_ylabel('y [km]', size=15)\n",
    "        axes[0].set_title('dh $h_{'+dates[idx].strftime('%m/%Y')+'} - h_{'+dates[idx-1].strftime('%m/%Y')+'}$', pad=7.5, fontsize=17.5)\n",
    "        fig.colorbar(img, cax=cax).set_label('Height (h) change [m]', size=15)\n",
    "        # overlay published outlines for visual comparison \n",
    "        Smith2009_outlines.boundary.plot(ax=axes[0], color='k', linestyle='--', linewidth=1)\n",
    "        SiegfriedFricker2018_outlines[SiegfriedFricker2018_outlines['cite'] != 'Smith and others, 2009, J. Glac., doi:10.3189/002214309789470879']\\\n",
    "            .boundary.plot(ax=axes[0], color='k', linestyle='-', linewidth=1)\n",
    "        Smith2009 = plt.Line2D((0, 1), (0, 0), color='k', linestyle='--', linewidth=2)\n",
    "        SiegfriedFricker2018 = plt.Line2D((0, 1), (0, 0), color='k', linestyle='-', linewidth=2)\n",
    "        uplift = plt.Line2D((0, 1), (0, 0), color='mediumblue', linestyle='dashdot', linewidth=2)\n",
    "        subsidence = plt.Line2D((0, 1), (0, 0), color='maroon', linestyle=(0, (3, 1, 1, 1)), linewidth=2)\n",
    "        axes[0].legend([Smith2009,\n",
    "            # SiegfriedFricker2018,\n",
    "            uplift, subsidence],\n",
    "            ['Smith and others, 2009 static outline',\n",
    "            # 'Siegfried & Fricker, 2018 static outline',\n",
    "            ('+'+str(thres)+' m uplift (filling) variable outline'), 'â€“'+str(thres)+' m subsidence (draining) variable outline'], \n",
    "            loc='upper right')\n",
    "        # plot inset map to show location \n",
    "        axIns = axes[0].inset_axes([0.001, -0.01, 0.25, 0.25])\n",
    "        axIns.patch.set_facecolor('lightskyblue')\n",
    "        axIns.set_aspect('equal')\n",
    "        axIns.scatter(((x_max+x_min)/2), ((y_max+y_min)/2), marker='*', \n",
    "            linewidth=1, edgecolor='k', facecolor='r', s=100, zorder=3)\n",
    "        Scripps_gl.plot(ax=axIns, color='ghostwhite', edgecolor='k', linewidth=0.5, zorder=2)\n",
    "        SiegfriedFricker2018_outlines.boundary.plot(ax=axIns, color='k', linestyle=(0, (1, 1)), linewidth=1)\n",
    "        axIns.axis('off')\n",
    "        # suplot 1: plot area change time series\n",
    "        # axes[1].axhline(np.divide(Smith2009_outlines[Smith2009_outlines['Name'] == lakename_S09].area.values[0], 1e6), color='k', linestyle='--')\n",
    "        axes[1].axhline(np.divide(SiegfriedFricker2018_outlines[SiegfriedFricker2018_outlines['name'] == lakename_S23]['area (m^2)'].values[0], 1e6), color='k', linestyle='-')\n",
    "        axes[1].plot(dates[:idx+1], np.divide(areas_var[:idx+1], 1e6), color='darkturquoise', linestyle='dashdot')\n",
    "        locator = mdates.AutoDateLocator(minticks=1, maxticks=7)\n",
    "        formatter = mdates.ConciseDateFormatter(locator)\n",
    "        axes[1].xaxis.set_major_locator(locator)\n",
    "        axes[1].xaxis.set_major_formatter(formatter)\n",
    "        min_area = min(#Smith2009_outlines[Smith2009_outlines['Name'] == lakename_S09].area.values[0], \n",
    "                        #SiegfriedFricker2018_outlines[SiegfriedFricker2018_outlines['name'] == lakename_S23]['area (m^2)'].values[0], \n",
    "                    #   min(\n",
    "                        np.divide(np.cumsum(areas_var),1e6))\n",
    "        max_area = max(#Smith2009_outlines[Smith2009_outlines['Name'] == lakename_S09].area.values[0], \n",
    "                        #SiegfriedFricker2018_outlines[SiegfriedFricker2018_outlines['name'] == lakename_S23]['area (m^2)'].values[0], \n",
    "                    #   max(\n",
    "                        np.divide(np.cumsum(areas_var),1e6))\n",
    "        if dataset.fileName == 'mos_2010.5_2021.5.h5':\n",
    "            axes[1].set(xlim=(datetime.datetime(int(ds_sub.time.values[0]), 1, 1) + datetime.timedelta(days = (ds_sub.time.values[0] % 1) * 365.25), \n",
    "                                datetime.datetime(int(ds_sub.time.values[-1]), 1, 1) + datetime.timedelta(days = (ds_sub.time.values[-1] % 1) * 365.25)), \n",
    "                        ylim=((0,#min_area - (max_area - min_area)*0.05),\n",
    "                                (max_area + (max_area - min_area)*0.05))))\n",
    "        elif dataset.fileName == 'ATL15_AA_0311_01km_001_01.nc':    \n",
    "            axes[1].set(xlim=(date_time_obj + datetime.timedelta(days=ds_sub.time.values[1]),\n",
    "                                date_time_obj + datetime.timedelta(days=ds_sub.time.values[-1])), \n",
    "                        ylim=(0,np.divide(200000000,1e6)))#(min_area - (max_area - min_area)*0.05), \n",
    "                            #   (max_area + (max_area - min_area)*0.05)))\n",
    "        # axes[1].set_title('{} dVol'.format(lakename_S23), pad=7.5, fontsize=17.5)\n",
    "        axes[1].set_xlabel('Year', size=15)\n",
    "        axes[1].set_ylabel('Areal extent [km$^2$]', size=15)\n",
    "        axes[1].yaxis.tick_right()\n",
    "        axes[1].yaxis.set_label_position(\"right\")\n",
    "        variable_outlines = plt.Line2D((0, 1), (0, 0), color='darkturquoise', linestyle='dashdot', linewidth=2)\n",
    "        axes[1].legend([Smith2009,\n",
    "            # SiegfriedFricker2018,\n",
    "            variable_outlines],\n",
    "                        ['Smith and others, 2009 static outline',\n",
    "            # 'Siegfried & Fricker, 2018 static outline',\n",
    "            'Â±{} m variable outlines'.format(thres)], \n",
    "                        loc='upper left')\n",
    "        # suplot 2: plot volume change time series\n",
    "        axes[2].plot(dates[:idx+1], np.divide(np.cumsum(vols_S09[:idx+1]), 1e+9), color='k', linestyle='--')\n",
    "        # axes[2].plot(dates[:idx+1], np.divide(np.cumsum(vols_SF18[:idx+1]), 1e+9), color='k', linestyle='-')\n",
    "        axes[2].plot(dates[:idx+1], np.divide(np.cumsum(vols_var[:idx+1]), 1e+9), color='darkturquoise', linestyle='dashdot')\n",
    "        locator = mdates.AutoDateLocator(minticks=1, maxticks=7)\n",
    "        formatter = mdates.ConciseDateFormatter(locator)\n",
    "        axes[2].xaxis.set_major_locator(locator)\n",
    "        axes[2].xaxis.set_major_formatter(formatter)\n",
    "        min_vol = min(np.divide(min(np.cumsum(vols_S09)), 1e+9), \n",
    "                    #   np.divide(min(np.cumsum(vols_SF18)), 1e+9), \n",
    "                        np.divide(min(np.cumsum(vols_var)), 1e+9))\n",
    "        max_vol = max(np.divide(max(np.cumsum(vols_S09)), 1e+9), \n",
    "                    #   np.divide(max(np.cumsum(vols_SF18)), 1e+9), \n",
    "                        np.divide(max(np.cumsum(vols_var)), 1e+9))\n",
    "        if dataset.fileName == 'mos_2010.5_2021.5.h5':\n",
    "            axes[2].set(xlim=(datetime.datetime(int(ds_sub.time.values[0]), 1, 1) + datetime.timedelta(days = (ds_sub.time.values[0] % 1) * 365.25), \n",
    "                                datetime.datetime(int(ds_sub.time.values[-1]), 1, 1) + datetime.timedelta(days = (ds_sub.time.values[-1] % 1) * 365.25)), \n",
    "                        ylim=((min_vol - (max_vol - min_vol)*0.05),\n",
    "                                (max_vol + (max_vol - min_vol)*0.05)))\n",
    "        elif dataset.fileName == 'ATL15_AA_0311_01km_001_01.nc':    \n",
    "            axes[2].set(xlim=(date_time_obj + datetime.timedelta(days=ds_sub.time.values[1]),\n",
    "                                date_time_obj + datetime.timedelta(days=ds_sub.time.values[-1])), \n",
    "                        ylim=((min_vol - (max_vol - min_vol)*0.05), \n",
    "                                (max_vol + (max_vol - min_vol)*0.05)))\n",
    "        # axes[1].set_title('{} dVol'.format(lakename_S23), pad=7.5, fontsize=17.5)\n",
    "        axes[2].set_xlabel('Year', size=15)\n",
    "        axes[2].set_ylabel('Volume change [km$^3$]', size=15)\n",
    "        axes[2].yaxis.tick_right()\n",
    "        axes[2].yaxis.set_label_position(\"right\")\n",
    "        # variable_outlines = plt.Line2D((0, 1), (0, 0), color='darkturquoise', linestyle='dashdot', linewidth=2)\n",
    "        # axes[2].legend([Smith2009,\n",
    "        #     SiegfriedFricker2018,variable_outlines],\n",
    "        #                 ['Smith and others, 2009 static outline',\n",
    "        #     'Siegfried & Fricker, 2018 static outline',\n",
    "        #     'Â±{} m variable outlines'.format(thres)], \n",
    "        #                 loc='upper left')\n",
    "        # append im(age) to ims list\n",
    "        ani.grab_frame()\n",
    "        axes[0].clear()\n",
    "    # create animation and save, adjust interval\n",
    "    ani.finish()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test function working using one lake\n",
    "# Strange error:\n",
    "# S09SF18varoutlines_dhdadvdt_anim_coords(-3.05e5,-2.8e5,-4.85e5,-5.12e5, 'Mercer_2', 'MercerSubglacialLake', 10000, 0.5, CS2_dh) \n",
    "# not saving file:\n",
    "S09SF18varoutlines_dhdadvdt_anim_coords(-5.65e5,-5.3e5,-5.1e5,-4.9e5, 'Whillans_7', 'Whillans_7', 10000, 0.5, ATL15_dh)\n",
    "# S09SF18varoutlines_dhdadvdt_anim_coords(-3.05e5,-2.79e5,-5.12e5,-4.82e5, 'Mercer_2', 'MercerSubglacialLake', 10000, 0.5, ATL15_dh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run func on all lakes\n",
    "for idx in range(len(SiegfriedFricker2018_outlines)-1):\n",
    "    lakename = SiegfriedFricker2018_outlines['name'][idx]\n",
    "    S09SF18varoutlines_dhdadvdt_anim_coords(lakename, 7500, 0.75, CS2_dh)\n",
    "    S09SF18varoutlines_dhdadvdt_anim_coords(lakename, 7500, 0.75, ATL15_dh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "# Func S09SF18S23_dhdt_plot_anim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def S09SF18S23_dhdt_plot_anim(lakename_S23, buffer, thres, dataset): \n",
    "    '''\n",
    "    Create planview dh/dt plots of ice surface height changes using geopandas buffer created bounding box around known lakes in \n",
    "    Siegfried and Fricker, 2018 (SF18) inventory.\n",
    "    Create time-variable outlines using skimage contour to plot variable outline alongside published outlines for comparison. \n",
    "    Inputs: \n",
    "        lakename: lake of interest from SiegfriedFricker2018_outlines inventory\n",
    "        buffer: horizontal distance in meters away from SF18 lake outline used to create bounding box that is displayed around lake of interest\n",
    "        thres(hold): vertical distance in meters to delineate ice surface deformation contour\n",
    "        dataset: dataset to be analyzed (CS2_dh or ATL15_dh)\n",
    "    Outputs: \n",
    "        Sequence of planview dh/dt visuals of CryoSat-2 or ICESat-2 ATL15 with variable ice surface deformation contours plotted to delineate time-variable lake boundary.\n",
    "    '''\n",
    "    # isolate individual lake using gpd buffer\n",
    "    lake_gpd = Sauthoff2023_outlines.loc[Sauthoff2023_outlines['name'] == lakename_S23]  \n",
    "    lake_buffer = lake_gpd.buffer(buffer)\n",
    "    # define lake bounding box\n",
    "    x_min = lake_buffer.bounds.values[0,0]; x_max = lake_buffer.bounds.values[0,2]\n",
    "    y_min = lake_buffer.bounds.values[0,1]; y_max = lake_buffer.bounds.values[0,3]\n",
    "    # subset ATL15 data set to region of interest\n",
    "    mask_x = (dataset.x >= x_min) & (dataset.x <= x_max)\n",
    "    mask_y = (dataset.y >= y_min) & (dataset.y <= y_max)\n",
    "    ds_sub = dataset.where(mask_x & mask_y, drop=True)\n",
    "    # find magnitude of ice surface deformation in bounding box / find appropriate color map scale\n",
    "    height_anom_pos = []\n",
    "    height_anom_neg = []\n",
    "    for cyc in range(len(ds_sub.time)-1):\n",
    "        pos = np.nanmax(ds_sub.delta_h[cyc+1,:,:]-ds_sub.delta_h[cyc,:,:])\n",
    "        neg = np.nanmin(ds_sub.delta_h[cyc+1,:,:]-ds_sub.delta_h[cyc,:,:])\n",
    "        height_anom_pos += [pos]\n",
    "        height_anom_neg += [neg]\n",
    "    max_height_anom_pos = max(height_anom_pos)\n",
    "    max_height_anom_neg = min(height_anom_neg)\n",
    "    max_height_anom_abs = max(max_height_anom_pos,abs(max_height_anom_neg))\n",
    "    v = np.round(max_height_anom_abs)\n",
    "    # create fig, ax, colorbar\n",
    "    fig, ax = plt.subplots(figsize=(8,8))\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes('right', size='5%', pad=0.2)\n",
    "    # create empty list to store animation im(age)s\n",
    "    ani = animation.PillowWriter(fps=1)\n",
    "    if dataset.fileName == 'mos_2010.5_2021.5.h5':\n",
    "        ani.setup(fig, OUTPUT_DIR + \n",
    "                  '/dhdvdt-using-variable-outlines/S09SF18S23_dhdt_plot_anim/anim/S09SF18S23_dhdt_anim-{}-{}.gif'\n",
    "                  .format(lakename_S23, 'CS2'), dpi=300)\n",
    "    elif dataset.fileName == 'ATL15_AA_0314_01km_002_02.nc':    \n",
    "        ani.setup(fig, OUTPUT_DIR + \n",
    "                  '/dhdvdt-using-variable-outlines/S09SF18S23_dhdt_plot_anim/anim/S09SF18S23_dhdt_anim-{}-{}.gif'\n",
    "                  .format(lakename_S23, 'IS2'), dpi=300)\n",
    "    dates = []\n",
    "    for idx in range(len(ds_sub.time)-1): \n",
    "        dhdt = ds_sub.delta_h[idx+1,:,:]-ds_sub.delta_h[idx,:,:]\n",
    "        # calculate mid-cycle dates for plotting\n",
    "        if dataset.fileName == 'mos_2010.5_2021.5.h5':\n",
    "            newdate = datetime.datetime(int(ds_sub.time.values[idx]), 1, 1) + datetime.timedelta(days = (ds_sub.time.values[idx] % 1) * 365.25)\n",
    "            newdate1 = datetime.datetime(int(ds_sub.time.values[idx+1]), 1, 1) + datetime.timedelta(days = (ds_sub.time.values[idx+1] % 1) * 365.25)\n",
    "            midcycdays = newdate1 - newdate\n",
    "            midcycdate = newdate + midcycdays/2\n",
    "            dates += [midcycdate]\n",
    "        elif dataset.fileName == 'ATL15_AA_0311_01km_001_01.nc':    \n",
    "            date_time_str = '18-01-01'\n",
    "            date_time_obj = datetime.datetime.strptime(date_time_str, '%y-%m-%d')\n",
    "            newdate = date_time_obj + datetime.timedelta(days=ds_sub.time.values[idx])\n",
    "            newdate1 = date_time_obj + datetime.timedelta(days=ds_sub.time.values[idx+1])\n",
    "            midcycdays = newdate1 - newdate\n",
    "            midcycdate = newdate + midcycdays/2\n",
    "            dates += [midcycdate]\n",
    "        # plot figure\n",
    "        dhdt = ds_sub.delta_h[idx+1,:,:]-ds_sub.delta_h[idx,:,:]\n",
    "        img = ax.imshow(dhdt, extent=[x_min, x_max, y_min, y_max], \n",
    "            origin='upper', cmap=cmocean.cm.balance_r, vmin=-v, vmax=v)\n",
    "        # create contours of ice surface elevation height changes to delineate lake outlines\n",
    "        contours_fill = []\n",
    "        contours_drain = []\n",
    "        contour = measure.find_contours(dhdt.values, thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_fill += [contour]\n",
    "        contour = measure.find_contours(dhdt.values, -thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_drain += [contour]\n",
    "        # create mapping conversion factor to map array location to polar stereographic x,y\n",
    "        x_conv = (x_max-x_min)/dhdt.shape[1]\n",
    "        y_conv = (y_max-y_min)/dhdt.shape[0]\n",
    "        # plot variable outlines found in this time slice\n",
    "        for i in range(len(contours_fill)): \n",
    "            for j in range(len(contours_fill[i])):\n",
    "                ax.plot(x_min+contours_fill[i][j][:, 1]*x_conv, y_max-contours_fill[i][j][:, 0]*y_conv, color='mediumblue', linestyle='dashdot', linewidth=2)\n",
    "        for i in range(len(contours_drain)): \n",
    "            for j in range(len(contours_drain[i])):\n",
    "                ax.plot(x_min+contours_drain[i][j][:, 1]*x_conv, y_max-contours_drain[i][j][:, 0]*y_conv, color='maroon', linestyle=(0, (3, 1, 1, 1)), linewidth=2)\n",
    "        ax.set(xlim=(x_min, x_max), ylim=(y_min, y_max))\n",
    "        # change polar stereographic m to km\n",
    "        km_scale = 1e3\n",
    "        ticks_x = ticker.FuncFormatter(lambda x, pos: '{0:g}'.format(x/km_scale))\n",
    "        ax.xaxis.set_major_formatter(ticks_x)\n",
    "        ticks_y = ticker.FuncFormatter(lambda x, pos: '{0:g}'.format(x/km_scale))\n",
    "        ax.yaxis.set_major_formatter(ticks_y)  \n",
    "        # adjust ticks\n",
    "        ax.set_xticks(np.arange(np.round(x_min, decimals = -3),np.round(x_max, decimals = -3),5000))\n",
    "        ax.set_yticks(np.arange(np.round(y_min, decimals = -3),np.round(y_max, decimals = -3),5000))\n",
    "        # label axes\n",
    "        ax.set_xlabel('x [km]', size=15)\n",
    "        ax.set_ylabel('y [km]', size=15)\n",
    "        # add plot title and colorbar\n",
    "        ax.set_title(lakename_S23+' dh/dt + outline comparison \\n$h_{'+newdate1.strftime('%m/%Y')+'} - h_{'+newdate.strftime('%m/%Y')+'}$', pad=7.5, fontsize=17.5)\n",
    "        fig.colorbar(img, cax=cax).set_label('Height (h) change [m]', size=15)\n",
    "        # overlay published outlines for visual comparison \n",
    "        Smith2009_outlines.boundary.plot(ax=ax, color='k', linestyle='--', linewidth=1)\n",
    "        SiegfriedFricker2018_outlines.boundary.plot(ax=ax, color='k', linestyle='-', linewidth=1)\n",
    "        Smith2009 = plt.Line2D((0, 1), (0, 0), color='k', linestyle='--', linewidth=2)\n",
    "        SiegfriedFricker2018 = plt.Line2D((0, 1), (0, 0), color='k', linestyle='-', linewidth=2)\n",
    "        uplift = plt.Line2D((0, 1), (0, 0), color='mediumblue', linestyle='dashdot', linewidth=2)\n",
    "        subsidence = plt.Line2D((0, 1), (0, 0), color='maroon', linestyle=(0, (3, 1, 1, 1)), linewidth=2)\n",
    "        ax.legend([Smith2009,SiegfriedFricker2018,uplift, subsidence],\n",
    "            ['Smith and others, 2009 outline','Siegfried & Fricker, 2018 outline',\n",
    "            ('+'+str(thres)+' m uplift (filling) variable outline'), 'â€“'+str(thres)+' m subsidence (draining) variable outline'], \n",
    "            loc='best')\n",
    "        # Plot inset map to show location \n",
    "        axIns = ax.inset_axes([0.01, 0.01, 0.25, 0.25]) # [left, bottom, width, height] (fractional axes coordinates)\n",
    "        axIns.set_aspect('equal')\n",
    "        moa_2009_coastline.plot(ax=axIns, color='gray', edgecolor='k', linewidth=0.1, zorder=3)\n",
    "        moa_2009_groundingline.plot(ax=axIns, color='ghostwhite', edgecolor='k', linewidth=0.1, zorder=3)\n",
    "        rect = Rectangle((x_min, y_min), (x_max-x_min), (y_max-y_min), fill=False, linewidth=2, color='k', zorder=3)\n",
    "        axIns.add_artist(rect) \n",
    "        axIns.axis('off')\n",
    "        # Save and close figure\n",
    "        if dataset.fileName == 'mos_2010.5_2021.5.h5':\n",
    "            plt.savefig(OUTPUT_DIR + \n",
    "                        '/dhdvdt-using-variable-outlines/S09SF18S23_dhdt_plot_anim/plot/S09SF18S23_dhdt_plot-{}-{}-{}.png'\n",
    "                        .format(lakename_S23,'CS2',midcycdate.strftime('%Y-%m')), dpi=300, bbox_inches = \"tight\")\n",
    "        elif dataset.fileName == 'ATL15_AA_0314_01km_002_02.nc':    \n",
    "            plt.savefig(OUTPUT_DIR + \n",
    "                        '/dhdvdt-using-variable-outlines/S09SF18S23_dhdt_plot_anim/plot/S09SF18S23_dhdt_plot-{}-{}-{}.png'\n",
    "                        .format(lakename_S23,'IS2',midcycdate.strftime('%Y-%m')), dpi=300, bbox_inches = \"tight\")     \n",
    "        # append im(age) to ims list\n",
    "        ani.grab_frame()\n",
    "        ax.clear()\n",
    "    # finish animation\n",
    "    ani.finish()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test function working using one lake\n",
    "S09SF18S23_dhdt_plot_anim('EngelhardtSubglacialLake', 10000, 0.5, CS2_dh)\n",
    "# S09SF18varoutlines_dhdt_plot_anim('ConwaySubglacialLake', 10000, 0.5, ATL15_dh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run func on all lakes from S23 inventory\n",
    "for idx in range(len(SiegfriedFricker2018_outlines)-1):\n",
    "    lakename = SiegfriedFricker2018_outlines['name'][idx]\n",
    "    S09SF18S23_dhdt_plot_anim(lakename, 7500, 0.5, CS2_dh)\n",
    "    S09SF18S23_dhdt_plot_anim(lakename, 7500, 0.5, ATL15_dh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "# Func S09SF18S23_dhdt_centroid_plot_anim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding polygon creation to plot moving centroid\n",
    "def S09SF18S23_dhdt_centroid_plot_anim(lakename_S23, buffer, thres, dataset): \n",
    "    '''\n",
    "    Create planview dh/dt plots of ice surface height changes using geopandas buffer created bounding box around known lakes in \n",
    "    Siegfried and Fricker, 2018 (SF18) inventory.\n",
    "    Create time-variable outlines using skimage contour to plot variable outline alongside published outlines for comparison. \n",
    "    Inputs: \n",
    "        lakename: lake of interest from SiegfriedFricker2018_outlines inventory\n",
    "        buffer: horizontal distance in meters away from SF18 lake outline used to create bounding box that is displayed around lake of interest\n",
    "        thres(hold): vertical distance in meters to delineate ice surface deformation contour\n",
    "        dataset: dataset to be analyzed (CS2_dh or ATL15_dh)\n",
    "    Outputs: \n",
    "        Sequence of planview dh/dt visuals of CryoSat-2 or ICESat-2 ATL15 with variable ice surface deformation contours plotted to delineate time-variable lake boundary.\n",
    "    '''\n",
    "    # Isolate individual lake using gpd buffer\n",
    "    lake_gpd = Sauthoff2023_outlines.loc[Sauthoff2023_outlines['name'] == lakename_S23]  \n",
    "    lake_buffer = lake_gpd.buffer(buffer)\n",
    "    # Define lake bounding box\n",
    "    x_min = lake_buffer.bounds.values[0,0]; x_max = lake_buffer.bounds.values[0,2]\n",
    "    y_min = lake_buffer.bounds.values[0,1]; y_max = lake_buffer.bounds.values[0,3]\n",
    "    # Subset ATL15 data set to region of interest\n",
    "    mask_x = (dataset.x >= x_min) & (dataset.x <= x_max)\n",
    "    mask_y = (dataset.y >= y_min) & (dataset.y <= y_max)\n",
    "    ds_sub = dataset.where(mask_x & mask_y, drop=True)\n",
    "    # Find magnitude of ice surface deformation in bounding box / find appropriate color map scale\n",
    "    height_anom_pos = []\n",
    "    height_anom_neg = []\n",
    "    for cyc in range(len(ds_sub.time)-1):\n",
    "        pos = np.nanmax(ds_sub.delta_h[cyc+1,:,:]-ds_sub.delta_h[cyc,:,:])\n",
    "        neg = np.nanmin(ds_sub.delta_h[cyc+1,:,:]-ds_sub.delta_h[cyc,:,:])\n",
    "        height_anom_pos += [pos]\n",
    "        height_anom_neg += [neg]\n",
    "    max_height_anom_pos = max(height_anom_pos)\n",
    "    max_height_anom_neg = min(height_anom_neg)\n",
    "    max_height_anom_abs = max(max_height_anom_pos,abs(max_height_anom_neg))\n",
    "    v = np.round(max_height_anom_abs)\n",
    "    # Create fig, ax, colorbar\n",
    "    fig, ax = plt.subplots(figsize=(8,8))\n",
    "    cmap = plt.get_cmap('CMRmap')\n",
    "    norm = plt.Normalize(ds_sub.time.values[0],ds_sub.time.values[-1])    \n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes('right', size='5%', pad=0.2)\n",
    "    # Create empty list to store animation im(age)s\n",
    "    ani = animation.PillowWriter(fps=2)\n",
    "    if dataset.fileName == 'mos_2010.5_2021.5.h5':\n",
    "        ani.setup(fig, '/Users/Wilson/Documents/0-code/1-lakeshores/output_dhdvdt-using-variable-outlines/S09SF18S23_dhdt_centroid_plot_anim/anim/S09SF18S23_dhdt_centroid_anim-{}-{}.gif'.format(lakename_S23, 'CS2'), dpi=300)\n",
    "    elif dataset.fileName == 'ATL15_AA_0311_01km_001_01.nc':    \n",
    "        ani.setup(fig, '/Users/Wilson/Documents/0-code/1-lakeshores/output_dhdvdt-using-variable-outlines/S09SF18S23_dhdt_centroid_plot_anim/anim/S09SF18S23_dhdt_centroid_anim-{}-{}.gif'.format(lakename_S23, 'IS2'), dpi=300)\n",
    "    dates = []\n",
    "    for idx in range(len(ds_sub.time)-1): \n",
    "        dhdt = ds_sub.delta_h[idx+1,:,:]-ds_sub.delta_h[idx,:,:]\n",
    "        # Calculate mid-cycle dates for plotting\n",
    "        if dataset.fileName == 'mos_2010.5_2021.5.h5':\n",
    "            newdate = datetime.datetime(int(ds_sub.time.values[idx]), 1, 1) + datetime.timedelta(days = (ds_sub.time.values[idx] % 1) * 365.25)\n",
    "            newdate1 = datetime.datetime(int(ds_sub.time.values[idx+1]), 1, 1) + datetime.timedelta(days = (ds_sub.time.values[idx+1] % 1) * 365.25)\n",
    "            midcycdays = newdate1 - newdate\n",
    "            midcycdate = newdate + midcycdays/2\n",
    "            dates += [midcycdate]\n",
    "        elif dataset.fileName == 'ATL15_AA_0311_01km_001_01.nc':    \n",
    "            date_time_str = '18-01-01'\n",
    "            date_time_obj = datetime.datetime.strptime(date_time_str, '%y-%m-%d')\n",
    "            newdate = date_time_obj + datetime.timedelta(days=ds_sub.time.values[idx])\n",
    "            newdate1 = date_time_obj + datetime.timedelta(days=ds_sub.time.values[idx+1])\n",
    "            midcycdays = newdate1 - newdate\n",
    "            midcycdate = newdate + midcycdays/2\n",
    "            dates += [midcycdate]\n",
    "        # Plot figure\n",
    "        dhdt = ds_sub.delta_h[idx+1,:,:]-ds_sub.delta_h[idx,:,:]\n",
    "        img = ax.imshow(dhdt, extent=[x_min, x_max, y_min, y_max], \n",
    "            origin='upper', cmap=cmocean.cm.balance_r, vmin=-v, vmax=v)\n",
    "        # Create contours of ice surface elevation height changes to delineate lake outlines\n",
    "        contours_fill = []\n",
    "        contours_drain = []\n",
    "        polys = []\n",
    "        contour = measure.find_contours(dhdt.values, thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_fill += [contour]\n",
    "        contour = measure.find_contours(dhdt.values, -thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_drain += [contour]\n",
    "        # Create mapping conversion factor to map array location to polar stereographic x,y\n",
    "        x_conv = (x_max-x_min)/dhdt.shape[1]\n",
    "        y_conv = (y_max-y_min)/dhdt.shape[0]\n",
    "        # Plot variable outlines found in this time slice\n",
    "        for i in range(len(contours_fill)): \n",
    "            for j in range(len(contours_fill[i])):\n",
    "                ax.plot(x_min+contours_fill[i][j][:, 1]*x_conv, y_max-contours_fill[i][j][:, 0]*y_conv, \n",
    "                color='mediumblue', linestyle='dashdot', linewidth=1)\n",
    "                # Make polygons from variable outlines\n",
    "                if len(contours_fill[i][j][:, 1]) > 2: \n",
    "                    poly = Polygon(list(zip(contours_fill[i][j][:, 1]*x_conv+x_min, y_max-contours_fill[i][j][:, 0]*y_conv))) \n",
    "                    ax.plot(poly.centroid.coords[0][0], poly.centroid.coords[0][1], marker='+', color='mediumblue', markersize=10)\n",
    "                    polys += [poly]\n",
    "        for i in range(len(contours_drain)): \n",
    "            for j in range(len(contours_drain[i])):\n",
    "                ax.plot(x_min+contours_drain[i][j][:, 1]*x_conv, y_max-contours_drain[i][j][:, 0]*y_conv, color='maroon', linestyle=(0, (3, 1, 1, 1)), linewidth=1)\n",
    "                if len(contours_drain[i][j][:, 1]) > 2: \n",
    "                    poly = Polygon(list(zip(contours_drain[i][j][:, 1]*x_conv+x_min, y_max-contours_drain[i][j][:, 0]*y_conv))) \n",
    "                    ax.plot(poly.centroid.coords[0][0], poly.centroid.coords[0][1], marker='+', color='maroon', markersize=10)\n",
    "                    polys += [poly]\n",
    "        ax.set(xlim=(x_min, x_max), ylim=(y_min, y_max))\n",
    "        # Change polar stereographic m to km for cleaner-looking axes labels\n",
    "        km_scale = 1e3\n",
    "        ticks_x = ticker.FuncFormatter(lambda x, pos: '{0:g}'.format(x/km_scale))\n",
    "        ax.xaxis.set_major_formatter(ticks_x)\n",
    "        ticks_y = ticker.FuncFormatter(lambda x, pos: '{0:g}'.format(x/km_scale))\n",
    "        ax.yaxis.set_major_formatter(ticks_y) \n",
    "        # Label axes\n",
    "        ax.set_xlabel('x [km]', size=15)\n",
    "        ax.set_ylabel('y [km]', size=15)\n",
    "        # Set title and add colorbar\n",
    "        ax.set_title(lakename_S23+' dh/dt and outline comparison \\n$h_{'+newdate1.strftime('%m/%Y')+'} - h_{'+newdate.strftime('%m/%Y')+'}$', pad=7.5, fontsize=17.5)\n",
    "        fig.colorbar(img, cax=cax).set_label('Height (h) change [m]', size=15)\n",
    "        # Overlay published outlines for visual comparison \n",
    "        Smith2009_outlines.boundary.plot(ax=ax, color='k', linestyle='--', linewidth=1)\n",
    "        SiegfriedFricker2018_outlines.boundary.plot(ax=ax, color='k', linestyle='-', linewidth=1)\n",
    "        Smith2009 = plt.Line2D((0, 1), (0, 0), color='k', linestyle='--', linewidth=2)\n",
    "        SiegfriedFricker2018 = plt.Line2D((0, 1), (0, 0), color='k', linestyle='-', linewidth=2)\n",
    "        uplift = plt.Line2D((0, 1), (0, 0), color='mediumblue', linestyle='dashdot', linewidth=2)\n",
    "        subsidence = plt.Line2D((0, 1), (0, 0), color='maroon', linestyle=(0, (3, 1, 1, 1)), linewidth=2)\n",
    "        ax.legend([Smith2009,SiegfriedFricker2018,uplift, subsidence],\n",
    "            ['Smith and others, 2009 outline','Siegfried & Fricker, 2018 outline',\n",
    "            ('+'+str(thres)+' m uplift (filling) variable outline'), 'â€“'+str(thres)+' m subsidence (draining) variable outline'], \n",
    "            loc='best')\n",
    "        # Plot inset map to show location \n",
    "        axIns = ax.inset_axes([0.01, 0.01, 0.25, 0.25]) # [left, bottom, width, height] (fractional axes coordinates)\n",
    "        axIns.set_aspect('equal')\n",
    "        moa_2009_coastline.plot(ax=axIns, color='gray', edgecolor='k', linewidth=0.1, zorder=3)\n",
    "        moa_2009_groundingline.plot(ax=axIns, color='ghostwhite', edgecolor='k', linewidth=0.1, zorder=3)\n",
    "        rect = Rectangle((x_min, y_min), (x_max-x_min), (y_max-y_min), fill=False, linewidth=2, color='k', zorder=3)\n",
    "        axIns.add_artist(rect) \n",
    "        axIns.axis('off')\n",
    "        # Save and close figure\n",
    "        if dataset.fileName == 'mos_2010.5_2021.5.h5':\n",
    "            plt.savefig('/Users/Wilson/Documents/0-code/1-lakeshores/output_dhdvdt-using-variable-outlines/S09SF18S23_dhdt_centroid_plot_anim/plot/S09SF18S23_dhdt_centroid_plot_anim-{}-{}-{}.png'.format(lakename_S23,'CS2',midcycdate.strftime('%Y-%m')), dpi=300, bbox_inches = \"tight\")\n",
    "        elif dataset.fileName == 'ATL15_AA_0311_01km_001_01.nc':    \n",
    "            plt.savefig('/Users/Wilson/Documents/0-code/1-lakeshores/output_dhdvdt-using-variable-outlines/S09SF18S23_dhdt_centroid_plot_anim/plot/S09SF18S23_dhdt_centroid_plot_anim-{}-{}-{}.png'.format(lakename_S23,'IS2',midcycdate.strftime('%Y-%m')), dpi=300, bbox_inches = \"tight\")      \n",
    "        # Append image to animation list\n",
    "        ani.grab_frame()\n",
    "        ax.clear()\n",
    "    # Finish animation\n",
    "    ani.finish()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test function working using one lake\n",
    "# S09SF18S23_dhdt_centroid_plot_anim('Slessor_23', 10000, 0.5, CS2_dh)\n",
    "# S09SF18varoutlines_dhdt_plot_anim('Slessor_23', 10000, 0.5, ATL15_dh)\n",
    "S09SF18varoutlines_dhdt_plot_anim('Whillans_7', 10000, 0.75, ATL15_dh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run func on all lakes from SF23 inventory\n",
    "for idx in range(len(SiegfriedFricker2018_outlines)-1):\n",
    "    lakename = SiegfriedFricker2018_outlines['name'][idx]\n",
    "    S09SF18varoutlines_dhdt_plot_anim(lakename, 7500, 0.75, CS2_dh)\n",
    "    S09SF18varoutlines_dhdt_plot_anim(lakename, 7500, 0.75, ATL15_dh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "# Func S09SF18S23_agg_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def S09SF18S23_agg_plot(lakename_S23, buffer, thres, dataset): \n",
    "    '''\n",
    "    Create planview plot of an aggregated times series of variable outlines compared to known lakes. Uses geopandas buffer created bounding box \n",
    "    around known lakes in Siegfried and Fricker, 2018 (SF18) inventory.\n",
    "    Create time-variable outlines using skimage contour to plot variable outline alongside published outlines for comparison. \n",
    "    Inputs: \n",
    "        lakename_S23: lake of interest from SiegfriedFricker2018_outlines inventory\n",
    "        buffer: horizontal distance in meters away from SF18 lake outline used to create bounding box that is displayed around lake of interest\n",
    "        thres(hold): vertical distance in meters to delineate ice surface deformation contour\n",
    "        dataset: dataset to be analyzed (CS2_dh or ATL15_dh)\n",
    "    Outputs: \n",
    "        Aggregated time-variable lake outlines in regions of known lakes using CryoSat-2 or ICESat-2 ATL15 dh/dt data.\n",
    "    '''\n",
    "    # isolate individual lake using gpd buffer\n",
    "    lake_gpd = Sauthoff2023_outlines.loc[Sauthoff2023_outlines['name'] == lakename_S23]  \n",
    "    lake_buffer = lake_gpd.buffer(buffer)\n",
    "    # define lake bounding box\n",
    "    x_min = lake_buffer.bounds.values[0,0]; x_max = lake_buffer.bounds.values[0,2]\n",
    "    y_min = lake_buffer.bounds.values[0,1]; y_max = lake_buffer.bounds.values[0,3]\n",
    "    # subset ATL15 data set to region of interest\n",
    "    mask_x = (dataset.x >= x_min) & (dataset.x <= x_max)\n",
    "    mask_y = (dataset.y >= y_min) & (dataset.y <= y_max)\n",
    "    ds_sub = dataset.where(mask_x & mask_y, drop=True)\n",
    "    # find magnitude of ice surface deformation in bounding box / find appropriate color map scale\n",
    "    height_anom_pos = []\n",
    "    height_anom_neg = []\n",
    "    for cyc in range(len(ds_sub.time)-1):\n",
    "        pos = np.nanmax(ds_sub.delta_h[cyc+1,:,:]-ds_sub.delta_h[cyc,:,:])\n",
    "        neg = np.nanmin(ds_sub.delta_h[cyc+1,:,:]-ds_sub.delta_h[cyc,:,:])\n",
    "        height_anom_pos += [pos]\n",
    "        height_anom_neg += [neg]\n",
    "    max_height_anom_pos = max(height_anom_pos)\n",
    "    max_height_anom_neg = min(height_anom_neg)\n",
    "    max_height_anom_abs = max(max_height_anom_pos,abs(max_height_anom_neg))\n",
    "    v = np.round(max_height_anom_abs)\n",
    "    # create empty list to store dates\n",
    "    dates = []\n",
    "    # plot figure\n",
    "    fig, ax = plt.subplots(figsize=(10,10))\n",
    "    cmap = plt.get_cmap('CMRmap')\n",
    "    norm = plt.Normalize(ds_sub.time.values[0],ds_sub.time.values[-1])    \n",
    "    for idx in range(len(ds_sub.time)-1): \n",
    "        # subset data to dhdt diff between orbital cycles of delta_h\n",
    "        dhdt = ds_sub.delta_h[idx+1,:,:]-ds_sub.delta_h[idx,:,:]\n",
    "        # calculate mid-cycle dates for plotting\n",
    "        if dataset.fileName == 'mos_2010.5_2021.5.h5':\n",
    "            newdate = datetime.datetime(int(ds_sub.time.values[idx]), 1, 1) + datetime.timedelta(days = (ds_sub.time.values[idx] % 1) * 365.25)\n",
    "            newdate1 = datetime.datetime(int(ds_sub.time.values[idx+1]), 1, 1) + datetime.timedelta(days = (ds_sub.time.values[idx+1] % 1) * 365.25)\n",
    "            midcycdays = newdate1 - newdate\n",
    "            midcycdate = newdate + midcycdays/2\n",
    "            dates += [midcycdate]\n",
    "        elif dataset.fileName == 'ATL15_AA_0311_01km_001_01.nc':    \n",
    "            date_time_str = '18-01-01'\n",
    "            date_time_obj = datetime.datetime.strptime(date_time_str, '%y-%m-%d')\n",
    "            newdate = date_time_obj + datetime.timedelta(days=ds_sub.time.values[idx])\n",
    "            newdate1 = date_time_obj + datetime.timedelta(days=ds_sub.time.values[idx+1])\n",
    "            midcycdays = newdate1 - newdate\n",
    "            midcycdate = newdate + midcycdays/2\n",
    "            dates += [midcycdate]\n",
    "        # create contours of ice surface elevation height changes to delineate variable lake outlines       \n",
    "        contours_fill = []\n",
    "        contours_drain = []\n",
    "        contour = measure.find_contours(dhdt.values, thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_fill += [contour]\n",
    "        contour = measure.find_contours(dhdt.values, -thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_drain += [contour]\n",
    "        # create mapping conversion factor to map array location to polar stereographic x,y\n",
    "        x_conv = (x_max-x_min)/dhdt.shape[1]\n",
    "        y_conv = (y_max-y_min)/dhdt.shape[0]\n",
    "        # plot variable outlines found in this time slice\n",
    "        for i in range(len(contours_fill)): \n",
    "            for j in range(len(contours_fill[i])):\n",
    "                ax.plot(x_min+contours_fill[i][j][:, 1]*x_conv, y_max-contours_fill[i][j][:, 0]*y_conv, \n",
    "                color=cmap(norm(ds_sub.time.values[idx])), linestyle=(0, (3, 1, 1, 1)), linewidth=1) \n",
    "        for i in range(len(contours_drain)): \n",
    "            for j in range(len(contours_drain[i])):\n",
    "                ax.plot(x_min+contours_drain[i][j][:, 1]*x_conv, y_max-contours_drain[i][j][:, 0]*y_conv, \n",
    "                color=cmap(norm(ds_sub.time.values[idx])), linestyle=(0, (5, 1)), linewidth=1)\n",
    "    ax.set(xlim=(x_min, x_max), ylim=(y_min, y_max))\n",
    "    # change polar stereographic m to km for cleaner-looking axes labels\n",
    "    km_scale = 1e3\n",
    "    ticks_x = ticker.FuncFormatter(lambda x, pos: '{0:g}'.format(x/km_scale))\n",
    "    ax.xaxis.set_major_formatter(ticks_x)\n",
    "    ticks_y = ticker.FuncFormatter(lambda x, pos: '{0:g}'.format(x/km_scale))\n",
    "    ax.yaxis.set_major_formatter(ticks_y)  \n",
    "    ax.set_xlabel('x [km]', size=15)\n",
    "    ax.set_ylabel('y [km]', size=15)\n",
    "    ax.set_title(lakename_S23+ '\\noutline comparison', pad=7.5, fontsize=17.5)\n",
    "    m = plt.cm.ScalarMappable(cmap=cmap)\n",
    "    m.set_array(np.array([datetime2fracyear(date) for date in dates[0:-1]]))\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes('right', size='5%', pad=0.2)\n",
    "    if dataset.fileName == 'mos_2010.5_2021.5.h5': \n",
    "        fig.colorbar(m, cax=cax).set_label('Year', size=15)\n",
    "    if dataset.fileName == 'ATL15_AA_0311_01km_001_01.nc':    \n",
    "        clb = fig.colorbar(m, ticks=np.array([2019,2020,2021]),  cax=cax)\n",
    "    # overlay published outlines for visual comparison \n",
    "    Smith2009_outlines.boundary.plot(ax=ax, color='k', linestyle=(0, (1, 5)), linewidth=1)\n",
    "    SiegfriedFricker2018_outlines.boundary.plot(ax=ax, color='k', linestyle=(0, (1, 1)), linewidth=1)\n",
    "    Smith2009 = plt.Line2D((0, 1), (0, 0), color='k', linestyle=(0, (1, 5)), linewidth=2)\n",
    "    SiegfriedFricker2018 = plt.Line2D((0, 1), (0, 0), color='k', linestyle=(0, (1, 1)), linewidth=2)\n",
    "    uplift = plt.Line2D((0, 1), (0, 0), color='k', linestyle=(0, (3, 1, 1, 1)), linewidth=2)\n",
    "    subsidence = plt.Line2D((0, 1), (0, 0), color='k', linestyle=(0, (5, 1)), linewidth=1)\n",
    "    ax.legend([Smith2009,SiegfriedFricker2018,uplift, subsidence],\n",
    "        ['Smith and others, 2009 outline','Siegfried & Fricker, 2018 outline',\n",
    "        ('+'+str(thres)+' m uplift (filling) variable outline'), 'â€“'+str(thres)+' m subsidence (draining) variable outline'], \n",
    "        loc='best')\n",
    "    # plot inset map to show location \n",
    "    axIns = ax.inset_axes([0.05, 0.001, 0.25, 0.25])\n",
    "    axIns.patch.set_facecolor('lightskyblue')\n",
    "    axIns.set_aspect('equal')\n",
    "    axIns.scatter(((x_max+x_min)/2), ((y_max+y_min)/2), marker='*', \n",
    "        linewidth=1, edgecolor='k', facecolor='r', s=100, zorder=3)\n",
    "    Scripps_gl.plot(ax=axIns, color='ghostwhite', edgecolor='k', linewidth=0.5, zorder=2)\n",
    "    axIns.axis('off')\n",
    "    # save and close figure\n",
    "    if dataset.fileName == 'mos_2010.5_2021.5.h5':\n",
    "        plt.savefig('/Users/Wilson/Documents/0-code/1-lakeshores/output_dhdvdt-using-variable-outlines/S09SF18varoutlines_agg_plot/S09SF18varoutlines_agg-{}-{}.png'.format(lakename_S23,'CS2'), dpi=300, bbox_inches = \"tight\")\n",
    "    elif dataset.fileName == 'ATL15_AA_0311_01km_001_01.nc':    \n",
    "        plt.savefig('/Users/Wilson/Documents/0-code/1-lakeshores/output_dhdvdt-using-variable-outlines/S09SF18varoutlines_agg_plot/S09SF18varoutlines_agg-{}-{}.png'.format(lakename_S23,'IS2'), dpi=300, bbox_inches = \"tight\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test function working using one lake\n",
    "S09SF18varoutlines_agg_plot('Mac1', 10000, 0.5, CS2_dh)\n",
    "S09SF18varoutlines_agg_plot('Mac1', 10000, 0.5, ATL15_dh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run func on all lakes from SF18 inventory\n",
    "for idx in range(len(SiegfriedFricker2018_outlines)-1):\n",
    "    lakename = SiegfriedFricker2018_outlines['name'][idx]\n",
    "    S09SF18varoutlines_agg_plot(lakename, 7500, 0.75, CS2_dh)\n",
    "    S09SF18varoutlines_agg_plot(lakename, 7500, 0.75, ATL15_dh)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "# Func S09SF18S23_agg_centroid_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def S09SF18S23_agg_centroid_plot(lakename_S23, buffer, thres, dataset): \n",
    "    '''\n",
    "    Create planview plot of an aggregated times series of variable outlines compared to known lakes. Uses geopandas buffer created bounding box \n",
    "    around known lakes in Siegfried and Fricker, 2018 (SF18) inventory.\n",
    "    Create time-variable outlines using skimage contour to plot variable outline alongside published outlines for comparison. \n",
    "    Inputs: \n",
    "        lakename_S23: lake of interest from SiegfriedFricker2018_outlines inventory\n",
    "        buffer: horizontal distance in meters away from SF18 lake outline used to create bounding box that is displayed around lake of interest\n",
    "        thres(hold): vertical distance in meters to delineate ice surface deformation contour\n",
    "        dataset: dataset to be analyzed (CS2_dh or ATL15_dh)\n",
    "    Outputs: \n",
    "        1x2 plot with aggregated time-variable lake outlines in left panel and migrating lake centroid in right panel.\n",
    "    '''\n",
    "    # isolate individual lake using gpd buffer\n",
    "    #lake_gpd = Smith2009_outlines.loc[Smith2009_outlines['Name'] == lakename_S23]\n",
    "    lake_gpd = Sauthoff2023_outlines.loc[Sauthoff2023_outlines['name'] == lakename_S23]  \n",
    "    lake_buffer = lake_gpd.buffer(buffer)\n",
    "    # define lake bounding box\n",
    "    x_min = lake_buffer.bounds.values[0,0]; x_max = lake_buffer.bounds.values[0,2]\n",
    "    y_min = lake_buffer.bounds.values[0,1]; y_max = lake_buffer.bounds.values[0,3]\n",
    "    # subset ATL15 data set to region of interest\n",
    "    mask_x = (dataset.x >= x_min) & (dataset.x <= x_max)\n",
    "    mask_y = (dataset.y >= y_min) & (dataset.y <= y_max)\n",
    "    ds_sub = dataset.where(mask_x & mask_y, drop=True)\n",
    "    # find magnitude of ice surface deformation in bounding box / find appropriate color map scale\n",
    "    height_anom_pos = []\n",
    "    height_anom_neg = []\n",
    "    for cyc in range(len(ds_sub.time)-1):\n",
    "        pos = np.nanmax(ds_sub.delta_h[cyc+1,:,:]-ds_sub.delta_h[cyc,:,:])\n",
    "        neg = np.nanmin(ds_sub.delta_h[cyc+1,:,:]-ds_sub.delta_h[cyc,:,:])\n",
    "        height_anom_pos += [pos]\n",
    "        height_anom_neg += [neg]\n",
    "    max_height_anom_pos = max(height_anom_pos)\n",
    "    max_height_anom_neg = min(height_anom_neg)\n",
    "    max_height_anom_abs = max(max_height_anom_pos,abs(max_height_anom_neg))\n",
    "    v = np.round(max_height_anom_abs)\n",
    "    # create contours of ice surface elevation height changes to delineate lake outlines\n",
    "    dates = []\n",
    "    # plot figure\n",
    "    fig, axes = plt.subplots(1,2, sharey=True, figsize=(15,10))\n",
    "    cmap = plt.get_cmap('CMRmap')\n",
    "    norm = plt.Normalize(ds_sub.time.values[0],ds_sub.time.values[-1])    \n",
    "    for idx in range(len(ds_sub.time)-1): \n",
    "        # subset data to dhdt diff between orbital cycles of delta_h\n",
    "        dhdt = ds_sub.delta_h[idx+1,:,:]-ds_sub.delta_h[idx,:,:]\n",
    "        # calculate mid-cycle dates for plotting\n",
    "        if dataset.fileName == 'mos_2010.5_2021.5.h5':\n",
    "            newdate = datetime.datetime(int(ds_sub.time.values[idx]), 1, 1) + datetime.timedelta(days = (ds_sub.time.values[idx] % 1) * 365.25)\n",
    "            newdate1 = datetime.datetime(int(ds_sub.time.values[idx+1]), 1, 1) + datetime.timedelta(days = (ds_sub.time.values[idx+1] % 1) * 365.25)\n",
    "            midcycdays = newdate1 - newdate\n",
    "            midcycdate = newdate + midcycdays/2\n",
    "            dates += [midcycdate]\n",
    "        elif dataset.fileName == 'ATL15_AA_0311_01km_001_01.nc':    \n",
    "            date_time_str = '18-01-01'\n",
    "            date_time_obj = datetime.datetime.strptime(date_time_str, '%y-%m-%d')\n",
    "            newdate = date_time_obj + datetime.timedelta(days=ds_sub.time.values[idx])\n",
    "            newdate1 = date_time_obj + datetime.timedelta(days=ds_sub.time.values[idx+1])\n",
    "            midcycdays = newdate1 - newdate\n",
    "            midcycdate = newdate + midcycdays/2\n",
    "            dates += [midcycdate]\n",
    "        # create contours of ice surface elevation height changes to delineate variable lake outlines       \n",
    "        contours_fill = []\n",
    "        contours_drain = []\n",
    "        polys = []\n",
    "        contour = measure.find_contours(dhdt.values, thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_fill += [contour]\n",
    "        contour = measure.find_contours(dhdt.values, -thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_drain += [contour]\n",
    "        # create mapping conversion factor to map array location to polar stereographic x,y\n",
    "        x_conv = (x_max-x_min)/dhdt.shape[1]\n",
    "        y_conv = (y_max-y_min)/dhdt.shape[0]\n",
    "        # plot variable outlines found in this time slice\n",
    "        for i in range(len(contours_fill)): \n",
    "            for j in range(len(contours_fill[i])):\n",
    "                axes[0].plot(x_min+contours_fill[i][j][:, 1]*x_conv, y_max-contours_fill[i][j][:, 0]*y_conv, \n",
    "                color=cmap(norm(ds_sub.time.values[idx])), linestyle=(0, (3, 1, 1, 1)), linewidth=1)\n",
    "                if len(contours_fill[i][j][:, 1]) > 2: \n",
    "                    poly = Polygon(list(zip(contours_fill[i][j][:, 1]*x_conv+x_min, y_max-contours_fill[i][j][:, 0]*y_conv))) \n",
    "                    axes[1].plot(poly.centroid.coords[0][0], poly.centroid.coords[0][1], marker='+', color=cmap(norm(ds_sub.time.values[idx])), markersize=10)\n",
    "                    polys += [poly]\n",
    "        for i in range(len(contours_drain)): \n",
    "            for j in range(len(contours_drain[i])):\n",
    "                axes[0].plot(x_min+contours_drain[i][j][:, 1]*x_conv, y_max-contours_drain[i][j][:, 0]*y_conv, \n",
    "                color=cmap(norm(ds_sub.time.values[idx])), linestyle=(0, (5, 1)), linewidth=1)\n",
    "                if len(contours_drain[i][j][:, 1]) > 2: \n",
    "                    poly = Polygon(list(zip(contours_drain[i][j][:, 1]*x_conv+x_min, y_max-contours_drain[i][j][:, 0]*y_conv))) \n",
    "                    axes[1].plot(poly.centroid.coords[0][0], poly.centroid.coords[0][1], marker='+', color=cmap(norm(ds_sub.time.values[idx])), markersize=10)\n",
    "                    polys += [poly]\n",
    "    # Change polar stereographic m to km\n",
    "    km_scale = 1e3\n",
    "    ticks_x = ticker.FuncFormatter(lambda x, pos: '{0:g}'.format(x/km_scale))\n",
    "    axes[0].xaxis.set_major_formatter(ticks_x)\n",
    "    axes[1].xaxis.set_major_formatter(ticks_x)\n",
    "    ticks_y = ticker.FuncFormatter(lambda x, pos: '{0:g}'.format(x/km_scale))\n",
    "    axes[0].yaxis.set_major_formatter(ticks_y)  \n",
    "    axes[0].set(xlim=(x_min, x_max), ylim=(y_min, y_max))\n",
    "    axes[1].set(xlim=(x_min, x_max), ylim=(y_min, y_max))\n",
    "    axes[0].set_xlabel('x [km]', size=15)\n",
    "    axes[1].set_xlabel('x [km]', size=15)\n",
    "    axes[0].set_ylabel('y [km]', size=15)\n",
    "    # axes[0].ticklabel_format(axis='both',scilimits=(0,0))\n",
    "    axes[0].set_title(lakename_S23+ '\\nvariable outline time series', pad=7.5, fontsize=17.5)\n",
    "    axes[1].set_title(lakename_S23+ '\\ncentroid migration time series', pad=7.5, fontsize=17.5)\n",
    "    m = plt.cm.ScalarMappable(cmap=cmap)\n",
    "    m.set_array(np.array([datetime2fracyear(date) for date in dates[0:-1]]))\n",
    "    divider = make_axes_locatable(axes[1])\n",
    "    cax = divider.append_axes('right', size='5%', pad=0.2)\n",
    "    fig.colorbar(m, cax=cax).set_label('Year', size=15) # arg for whole number years later: format=\"%d\", must find way to control no. ticks so that same year is not repeated multiple ticks\n",
    "    # overlay published outlines for visual comparison \n",
    "    Smith2009_outlines.boundary.plot(ax=axes[0], color='k', linestyle=(0, (1, 5)), linewidth=1)\n",
    "    SiegfriedFricker2018_outlines.boundary.plot(ax=axes[0], color='k', linestyle=(0, (1, 1)), linewidth=1)\n",
    "    Smith2009_outlines.boundary.plot(ax=axes[1], color='k', linestyle=(0, (1, 5)), linewidth=1)\n",
    "    SiegfriedFricker2018_outlines.boundary.plot(ax=axes[1], color='k', linestyle=(0, (1, 1)), linewidth=1)\n",
    "    Smith2009 = plt.Line2D((0, 1), (0, 0), color='k', linestyle=(0, (1, 5)), linewidth=2)\n",
    "    SiegfriedFricker2018 = plt.Line2D((0, 1), (0, 0), color='k', linestyle=(0, (1, 1)), linewidth=2)\n",
    "    uplift = plt.Line2D((0, 1), (0, 0), color='k', linestyle=(0, (3, 1, 1, 1)), linewidth=2)\n",
    "    subsidence = plt.Line2D((0, 1), (0, 0), color='k', linestyle=(0, (5, 1)), linewidth=1)\n",
    "    axes[0].legend([Smith2009,SiegfriedFricker2018,uplift, subsidence],\n",
    "        ['Smith and others, 2009 outline','Siegfried & Fricker, 2018 outline',\n",
    "        ('+'+str(thres)+' m uplift (filling) variable outline'), 'â€“'+str(thres)+' m subsidence (draining) variable outline'], \n",
    "        loc='best')\n",
    "    # plot inset map to show location \n",
    "    axIns = axes[0].inset_axes([0.001, 0.68, 0.3, 0.3])\n",
    "    axIns.patch.set_facecolor('lightskyblue')\n",
    "    axIns.set_aspect('equal')\n",
    "    axIns.scatter(((x_max+x_min)/2), ((y_max+y_min)/2), marker='*', \n",
    "        linewidth=1, edgecolor='k', facecolor='r', s=100, zorder=3)\n",
    "    Scripps_gl.plot(ax=axIns, color='ghostwhite', edgecolor='k', linewidth=0.5, zorder=2)\n",
    "    axIns.axis('off')\n",
    "    # save and close figure\n",
    "    if dataset.fileName == 'mos_2010.5_2021.5.h5':\n",
    "        plt.savefig('/Users/Wilson/Documents/0-code/1-lakeshores/output_dhdvdt-using-variable-outlines/S09SF18varoutlines_agg_plot_centroid/S09SF18varoutlines_agg_centroid-{}-{}.png'.format(lakename_S23,'CS2'), dpi=300, bbox_inches = \"tight\")\n",
    "    elif dataset.fileName == 'ATL15_AA_0311_01km_001_01.nc':    \n",
    "        plt.savefig('/Users/Wilson/Documents/0-code/1-lakeshores/output_dhdvdt-using-variable-outlines/S09SF18varoutlines_agg_plot_centroid/S09SF18varoutlines_agg_centroid-{}-{}.png'.format(lakename_S23,'IS2'), dpi=300, bbox_inches = \"tight\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test function working using one lake\n",
    "S09SF18S23_agg_centroid_plot(x_min, x_max, y_min, y_max, 'Slessor_23', 10000, 0.5, CS2_dh)\n",
    "# S09SF18S23_agg_centroid_plot('Slessor_23', 10000, 0.5, ATL15_dh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run func on all lakes from SF18 inventory\n",
    "for idx in range(len(SiegfriedFricker2018_outlines)-1):\n",
    "    lakename = SiegfriedFricker2018_outlines['name'][idx]\n",
    "    S09SF18S23_agg_centroid_plot(lakename, 7500, 0.75, CS2_dh)\n",
    "    S09SF18S23_agg_centroid_plot(lakename, 7500, 0.75, ATL15_dh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# redo a few plots that need larger buffer\n",
    "S09SF18S23_agg_centroid_plot('UpperSubglacialLakeConway', 8500, 0.75, CS2_dh)\n",
    "\n",
    "S09SF18S23_agg_centroid_plot('MercerSubglacialLake', 5500, 0.75, CS2_dh)\n",
    "S09SF18S23_agg_centroid_plot('MercerSubglacialLake', 5500, 0.75, ATL15_dh)\n",
    "\n",
    "S09SF18S23_agg_centroid_plot('Slessor_23', 8500, 0.75, CS2_dh)\n",
    "S09SF18S23_agg_centroid_plot('Slessor_23', 8500, 0.75, ATL15_dh)\n",
    "\n",
    "S09SF18S23_agg_centroid_plot('Lambert_1', 9000, 0.75, CS2_dh)\n",
    "S09SF18S23_agg_centroid_plot('Lambert_1', 9000, 0.75, ATL15_dh)\n",
    "\n",
    "S09SF18S23_agg_centroid_plot('Whillans_7', 9000, 0.75, ATL15_dh)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "# Func S09SF18S23_agg_dvdt_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Incorporate finding area around lake that is some multiple of the lake area to minimize edge effects\n",
    "    lake_gpd = Sauthoff2023_outlines.loc[Sauthoff2023_outlines['name'] == lakename_S23]\n",
    "    lake_area = lake_gpd['area (m^2)'].values[0]\n",
    "    # Find length of bounding box side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def S09SF18S23_agg_dvdt_plot(lakename_S23, buffer, thres, dataset): \n",
    "    '''\n",
    "    Create 1x2 plot of planview aggregated times series of variable outlines compared to known lakes alongside dv time series. \n",
    "    * uses geopandas buffer created bounding box around known lakes in Siegfried and Fricker, 2018 (SF18) inventory. \n",
    "    * creates time-variable outlines using skimage contour to plot variable outline alongside published outlines for comparison. \n",
    "    * creates dv time series by clipping dh data to either static outline or variable outline for each time slice.\n",
    "    TODO: subtract off off-lake height change\n",
    "    Inputs: \n",
    "        lakename_S23: lake of interest from SiegfriedFricker2018_outlines inventory\n",
    "        buffer: horizontal distance in meters away from SF18 lake outline used to create bounding box that is displayed around lake of interest\n",
    "        thres(hold): vertical distance in meters to delineate ice surface deformation contour\n",
    "        dataset: dataset to be analyzed (CS2_dh or ATL15_dh)\n",
    "    Outputs: \n",
    "        Aggregated time-variable lake outlines in regions of known lakes using CryoSat-2 or ICESat-2 ATL15 dh/dt data alongside dv/dt time series.\n",
    "    '''\n",
    "    # isolate individual lake using gpd buffer\n",
    "    lake_gpd = Sauthoff2023_outlines.loc[Sauthoff2023_outlines['name'] == lakename_S23]  \n",
    "    lake_buffer = lake_gpd.buffer(buffer)\n",
    "    # define lake bounding box\n",
    "    x_min = lake_buffer.bounds.values[0,0]; x_max = lake_buffer.bounds.values[0,2]\n",
    "    y_min = lake_buffer.bounds.values[0,1]; y_max = lake_buffer.bounds.values[0,3]\n",
    "    # subset ATL15 data set to region of interest\n",
    "    mask_x = (dataset.x >= x_min) & (dataset.x <= x_max)\n",
    "    mask_y = (dataset.y >= y_min) & (dataset.y <= y_max)\n",
    "    ds_sub = dataset.where(mask_x & mask_y, drop=True)\n",
    "    # find magnitude of ice surface deformation in bounding box / find appropriate color map scale\n",
    "    height_anom_pos = []\n",
    "    height_anom_neg = []\n",
    "    for cyc in range(len(ds_sub.time)-1):\n",
    "        pos = np.nanmax(ds_sub.delta_h[cyc+1,:,:]-ds_sub.delta_h[cyc,:,:])\n",
    "        neg = np.nanmin(ds_sub.delta_h[cyc+1,:,:]-ds_sub.delta_h[cyc,:,:])\n",
    "        height_anom_pos += [pos]\n",
    "        height_anom_neg += [neg]\n",
    "    max_height_anom_pos = max(height_anom_pos)\n",
    "    max_height_anom_neg = min(height_anom_neg)\n",
    "    max_height_anom_abs = max(max_height_anom_pos,abs(max_height_anom_neg))\n",
    "    v = np.round(max_height_anom_abs)\n",
    "    # create empty lists to store data\n",
    "    dates = []\n",
    "    lkavgdhdt_SF18 = []\n",
    "    lkavgdhdt_var = []\n",
    "    vols_SF18 = []\n",
    "    vols_var = []\n",
    "    # plot figure\n",
    "    fig, axes = plt.subplots(1,2, figsize=(20,10))\n",
    "    plt.subplots_adjust(wspace=0.15)\n",
    "    cmap = plt.get_cmap('CMRmap')\n",
    "    norm = plt.Normalize(ds_sub.time.values[0],ds_sub.time.values[-1])    \n",
    "    for idx in range(len(ds_sub.time)-1): \n",
    "        dhdt = ds_sub.delta_h[idx+1,:,:]-ds_sub.delta_h[idx,:,:]\n",
    "        # calculate mid-cycle dates for plotting\n",
    "        if dataset.fileName == 'mos_2010.5_2021.5.h5':\n",
    "            newdate = datetime.datetime(int(ds_sub.time.values[idx]), 1, 1) + datetime.timedelta(days = (ds_sub.time.values[idx] % 1) * 365.25)\n",
    "            newdate1 = datetime.datetime(int(ds_sub.time.values[idx+1]), 1, 1) + datetime.timedelta(days = (ds_sub.time.values[idx+1] % 1) * 365.25)\n",
    "            midcycdays = newdate1 - newdate\n",
    "            midcycdate = newdate + midcycdays/2\n",
    "            dates += [midcycdate]\n",
    "        elif dataset.fileName == 'ATL15_AA_0311_01km_001_01.nc':    \n",
    "            date_time_str = '18-01-01'\n",
    "            date_time_obj = datetime.datetime.strptime(date_time_str, '%y-%m-%d')\n",
    "            newdate = date_time_obj + datetime.timedelta(days=ds_sub.time.values[idx])\n",
    "            newdate1 = date_time_obj + datetime.timedelta(days=ds_sub.time.values[idx+1])\n",
    "            midcycdays = newdate1 - newdate\n",
    "            midcycdate = newdate + midcycdays/2\n",
    "            dates += [midcycdate]\n",
    "        # subset data to dhdt diff between orbital cycles of delta_h\n",
    "        dhdt = ds_sub.delta_h[idx+1,:,:]-ds_sub.delta_h[idx,:,:]\n",
    "        # clip ATL15 data to just show (first set crs)\n",
    "        dhdt.rio.write_crs(3031, inplace=True)\n",
    "        dhdt_clip_SF18 = dhdt.rio.clip(lake_gpd.geometry.values, lake_gpd.crs, drop=False, invert=False)\n",
    "        # calculate lake avg. dh/dt and dv/dt time series using published stationary outlines\n",
    "        avg_lk_dhdt_SF18 = np.nanmean(dhdt_clip_SF18)\n",
    "        lkavgdhdt_SF18 += [avg_lk_dhdt_SF18]\n",
    "        vol_SF18 = avg_lk_dhdt_SF18*SiegfriedFricker2018_outlines[SiegfriedFricker2018_outlines['name'] == lakename_S23]['area (m^2)']\n",
    "        vols_SF18 += [vol_SF18.values[0]]\n",
    "        # create contours of ice surface elevation height changes to delineate variable lake outlines\n",
    "        contours_fill = []\n",
    "        contours_drain = []   \n",
    "        polys = []\n",
    "        contour = measure.find_contours(dhdt.values, thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_fill += [contour]\n",
    "        contour = measure.find_contours(dhdt.values, -thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_drain += [contour]\n",
    "        # create mapping conversion factor to map array location to polar stereographic x,y\n",
    "        x_conv = (x_max-x_min)/dhdt.shape[1]\n",
    "        y_conv = (y_max-y_min)/dhdt.shape[0]\n",
    "        # plot variable outlines found in this time slice\n",
    "        # make polygons from variable outlines\n",
    "        for i in range(len(contours_fill)): \n",
    "            for j in range(len(contours_fill[i])):\n",
    "                axes[0].plot(x_min+contours_fill[i][j][:, 1]*x_conv, y_max-contours_fill[i][j][:, 0]*y_conv, \n",
    "                color=cmap(norm(ds_sub.time.values[idx])), linestyle=(0, (3, 1, 1, 1)), linewidth=1)\n",
    "                if len(contours_fill[i][j][:, 1]) > 2: \n",
    "                    poly = Polygon(list(zip(contours_fill[i][j][:, 1]*x_conv+x_min, y_max-contours_fill[i][j][:, 0]*y_conv))) \n",
    "                    polys += [poly]\n",
    "        for i in range(len(contours_drain)): \n",
    "            for j in range(len(contours_drain[i])):\n",
    "                axes[0].plot(x_min+contours_drain[i][j][:, 1]*x_conv, y_max-contours_drain[i][j][:, 0]*y_conv, color=cmap(norm(ds_sub.time.values[idx])), linestyle=(0, (5, 1)), linewidth=1)\n",
    "                if len(contours_drain[i][j][:, 1]) > 2: \n",
    "                    poly = Polygon(list(zip(contours_drain[i][j][:, 1]*x_conv+x_min, y_max-contours_drain[i][j][:, 0]*y_conv))) \n",
    "                    polys += [poly]\n",
    "        # set area to zero each time step\n",
    "        variable_area = 0\n",
    "        # if polygons are present at time step, \n",
    "        if len(polys) > 0: \n",
    "            # clip data to polygons\n",
    "            dhdt_clip = dhdt.rio.clip(polys, drop=False, invert=False)\n",
    "            # then calculate on-lake averages of dh/dt\n",
    "            avg_lk_dhdt = np.nanmean(dhdt_clip)\n",
    "            # occasionally small polygons will completely clip data resulting in nan's for lake avg. dh/dt\n",
    "            # replace with zeros\n",
    "            if math.isnan(avg_lk_dhdt): \n",
    "                avg_lk_dhdt = 0\n",
    "                lkavgdhdt_var += [avg_lk_dhdt]\n",
    "            else:\n",
    "                lkavgdhdt_var += [avg_lk_dhdt]\n",
    "                # and dv/dt\n",
    "            for i in range(len(polys)):\n",
    "                variable_area = variable_area + polys[i].area\n",
    "            vol_var = avg_lk_dhdt*variable_area\n",
    "            vols_var += [vol_var]\n",
    "        else: \n",
    "            variable_area = 0\n",
    "            avg_lk_dhdt = 0\n",
    "            lkavgdhdt_var += [avg_lk_dhdt]\n",
    "            vol_var = avg_lk_dhdt*variable_area\n",
    "            vols_var += [vol_var]\n",
    "    axes[0].set(xlim=(x_min, x_max), ylim=(y_min, y_max))\n",
    "    # change polar stereographic m to km\n",
    "    km_scale = 1e3\n",
    "    ticks_x = ticker.FuncFormatter(lambda x, pos: '{0:g}'.format(x/km_scale))\n",
    "    axes[0].xaxis.set_major_formatter(ticks_x)\n",
    "    ticks_y = ticker.FuncFormatter(lambda x, pos: '{0:g}'.format(x/km_scale))\n",
    "    axes[0].yaxis.set_major_formatter(ticks_y)  \n",
    "    # adjust ticks\n",
    "    axes[0].set_xticks(np.arange(np.round(x_min, decimals = -3),np.round(x_max, decimals = -3),5000))\n",
    "    axes[0].set_yticks(np.arange(np.round(y_min, decimals = -3),np.round(y_max, decimals = -3),5000))\n",
    "    # label axes\n",
    "    axes[0].set_xlabel('x [km]', size=15)\n",
    "    axes[0].set_ylabel('y [km]', size=15)\n",
    "    # add title and colorbar\n",
    "    axes[0].set_title(lakename_S23+ ' outline comparison', pad=7.5, fontsize=17.5)\n",
    "    m = plt.cm.ScalarMappable(cmap=cmap)\n",
    "    m.set_array(np.array([datetime2fracyear(date) for date in dates[0:-1]]))\n",
    "    divider = make_axes_locatable(axes[0])\n",
    "    cax = divider.append_axes('right', size='5%', pad=0.2)\n",
    "    if dataset.fileName == 'mos_2010.5_2021.5.h5': \n",
    "        fig.colorbar(m, cax=cax).set_label('Year', size=15)\n",
    "    if dataset.fileName == 'ATL15_AA_0311_01km_001_01.nc':    \n",
    "        clb = fig.colorbar(m, ticks=np.array([2019,2020,2021]),  cax=cax).set_label('Year', size=15)\n",
    "    # overlay published outlines for visual comparison \n",
    "    Smith2009_outlines.boundary.plot(ax=axes[0], color='k', linestyle=(0, (1, 5)), linewidth=1)\n",
    "    SiegfriedFricker2018_outlines.boundary.plot(ax=axes[0], color='k', linestyle=(0, (1, 1)), linewidth=1)\n",
    "    Smith2009 = plt.Line2D((0, 1), (0, 0), color='k', linestyle=(0, (1, 5)), linewidth=2)\n",
    "    SiegfriedFricker2018 = plt.Line2D((0, 1), (0, 0), color='k', linestyle=(0, (1, 1)), linewidth=2)\n",
    "    uplift = plt.Line2D((0, 1), (0, 0), color='k', linestyle=(0, (3, 1, 1, 1)), linewidth=2)\n",
    "    subsidence = plt.Line2D((0, 1), (0, 0), color='k', linestyle=(0, (5, 1)), linewidth=1)\n",
    "    variable_outlines = plt.Line2D((0, 1), (0, 0), color='darkturquoise', linestyle='dashdot', linewidth=2)\n",
    "    axes[0].legend([Smith2009,SiegfriedFricker2018,uplift, subsidence],\n",
    "        ['Smith and others, 2009 static outline','Siegfried & Fricker, 2018 static outline',\n",
    "        ('+'+str(thres)+' m uplift (filling) variable outline'), 'â€“'+str(thres)+' m subsidence (draining) variable outline'], \n",
    "        loc='upper right')\n",
    "    # plot inset map to show location \n",
    "    axIns = axes[0].inset_axes([0.05, 0.001, 0.25, 0.25])\n",
    "    axIns.patch.set_facecolor('lightskyblue')\n",
    "    axIns.set_aspect('equal')\n",
    "    axIns.scatter(((x_max+x_min)/2), ((y_max+y_min)/2), marker='*', \n",
    "        linewidth=1, edgecolor='k', facecolor='r', s=100, zorder=3)\n",
    "    Scripps_gl.plot(ax=axIns, color='ghostwhite', edgecolor='k', linewidth=0.5, zorder=2)\n",
    "    axIns.axis('off')\n",
    "    # plot dvdt subplot\n",
    "    axes[1].plot(dates, np.divide(np.cumsum(vols_SF18), 1e+9), color='k', linestyle='dashed')\n",
    "    axes[1].plot(dates, np.divide(np.cumsum(vols_var), 1e+9), color='darkturquoise', linestyle='dashdot')\n",
    "    locator = mdates.AutoDateLocator(minticks=1, maxticks=7)\n",
    "    formatter = mdates.ConciseDateFormatter(locator)\n",
    "    axes[1].xaxis.set_major_locator(locator)\n",
    "    axes[1].xaxis.set_major_formatter(formatter)\n",
    "    # axes[1].set_title('{} volume change time series'.format(lakename_S23), fontsize=17.5)\n",
    "    axes[1].set_xlabel('Year', size=15)\n",
    "    axes[1].set_ylabel('Volume change [km$^3$]', size=15)\n",
    "    axes[1].yaxis.tick_right()\n",
    "    axes[1].yaxis.set_label_position(\"right\")\n",
    "    axes[1].legend([SiegfriedFricker2018,variable_outlines],\n",
    "        ['Siegfried & Fricker, 2018',\n",
    "        'Â±{} m variable outlines'.format(thres)], \n",
    "        loc='best')  \n",
    "    # save and close figure\n",
    "    if dataset.fileName == 'mos_2010.5_2021.5.h5':\n",
    "        plt.savefig('/Users/Wilson/Documents/0-code/1-lakeshores/output_dhdvdt-using-variable-outlines/S09SF18varoutlines_agg_dvdt_plot/S09SF18varoutlines_agg_dvdt_plot-{}-{}.png'\\\n",
    "            .format(lakename_S23, 'CS2'), dpi=300, bbox_inches = \"tight\")\n",
    "    elif dataset.fileName == 'ATL15_AA_0311_01km_001_01.nc':    \n",
    "        plt.savefig('/Users/Wilson/Documents/0-code/1-lakeshores/output_dhdvdt-using-variable-outlines/S09SF18varoutlines_agg_dvdt_plot/S09SF18varoutlines_agg_dvdt_plot-{}-{}.png'\\\n",
    "            .format(lakename_S23, 'IS2'), dpi=300, bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test function working using one lake\n",
    "# S09SF18S23_agg_dvdt_plot('Whillans_7', 10000, 0.5, CS2_dh)\n",
    "S09SF18S23_agg_dvdt_plot('Whillans_7', 13000, 0.5, ATL15_dh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run func on all lakes from SF18 inventory that have CS2 InSAR coverage\n",
    "for idx in range(len(SiegfriedFricker2018_CS2InSAR)-1):\n",
    "    lakename = SiegfriedFricker2018_CS2InSAR['name'][idx]\n",
    "    S09SF18S23_agg_dvdt_plot(lakename, 7500, 0.5, CS2_dh)\n",
    "    S09SF18S23_agg_dvdt_plot(lakename, 7500, 0.5, ATL15_dh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "# Func S09SF18S23_agg_dvdt_CS2vsIS2_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def S09SF18S23_agg_dvdt_CS2vsIS2_plot(lakename_S23, buffer, thres, dataset1, dataset2): \n",
    "    '''\n",
    "    Create planview plot of an aggregated times series of variable outlines compared to known lakes alongside dv/dt time series. Uses geopandas buffer created bounding box around known lakes in Siegfried and Fricker, 2018 (SF18) inventory. Creates time-variable outlines using skimage contour to plot variable outline alongside published outlines for comparison. \n",
    "    Inputs: \n",
    "        lakename_S23: lake of interest from SiegfriedFricker2018_outlines inventory\n",
    "        buffer: horizontal distance in meters away from SF18 lake outline used to create bounding box that is displayed around lake of interest\n",
    "        thres(hold): vertical distance in meters to delineate ice surface deformation contour\n",
    "        dataset: dataset to be analyzed (CS2_dh or ATL15_dh)\n",
    "    Outputs: \n",
    "        2x2 of aggregated variable outlines and dVol time series.\n",
    "    '''\n",
    "    # isolate individual lake using gpd buffer\n",
    "    lake_S23 = Sauthoff2023_outlines.loc[Sauthoff2023_outlines['name'] == lakename_S23]\n",
    "    lake_buffer = lake_SF18.buffer(buffer)\n",
    "    # define lake bounding box\n",
    "    x_min = lake_buffer.bounds.values[0,0]; x_max = lake_buffer.bounds.values[0,2]\n",
    "    y_min = lake_buffer.bounds.values[0,1]; y_max = lake_buffer.bounds.values[0,3]\n",
    "    # subset ATL15 data set to region of interest\n",
    "    mask_x = (dataset1.x >= x_min) & (dataset1.x <= x_max)\n",
    "    mask_y = (dataset1.y >= y_min) & (dataset1.y <= y_max)\n",
    "    ds_sub = dataset1.where(mask_x & mask_y, drop=True)\n",
    "    # find magnitude of ice surface deformation in bounding box / find appropriate color map scale\n",
    "    height_anom_pos = []\n",
    "    height_anom_neg = []\n",
    "    for cyc in range(len(ds_sub.time)-1):\n",
    "        pos = np.nanmax(ds_sub.delta_h[cyc+1,:,:]-ds_sub.delta_h[cyc,:,:])\n",
    "        neg = np.nanmin(ds_sub.delta_h[cyc+1,:,:]-ds_sub.delta_h[cyc,:,:])\n",
    "        height_anom_pos += [pos]\n",
    "        height_anom_neg += [neg]\n",
    "    max_height_anom_pos = max(height_anom_pos)\n",
    "    max_height_anom_neg = min(height_anom_neg)\n",
    "    max_height_anom_abs = max(max_height_anom_pos,abs(max_height_anom_neg))\n",
    "    v = np.round(max_height_anom_abs)\n",
    "    # create empty lists to store data\n",
    "    dates = []\n",
    "    lkavgdhdt_SF18 = []\n",
    "    lkavgdhdt_var = []\n",
    "    vols_SF18 = []\n",
    "    vols_var = []\n",
    "    # plot figure\n",
    "    fig, axes = plt.subplots(2,2, figsize=(20,20))\n",
    "    # fig.suptitle('{} outline and dVol comparison'.format(lakename_S23), fontsize=24)\n",
    "    # fig.suptitle('Whillans$_7$ outline and $\\Delta$volume comparison', fontsize=30)\n",
    "    plt.subplots_adjust(wspace=0.15, hspace = 0.1)\n",
    "    cmap = plt.get_cmap('CMRmap')\n",
    "    norm = plt.Normalize(ds_sub.time.values[0],ds_sub.time.values[-1])    \n",
    "    for idx in range(len(ds_sub.time)-1): \n",
    "        dhdt = ds_sub.delta_h[idx+1,:,:]-ds_sub.delta_h[idx,:,:]\n",
    "        # calculate mid-cycle dates for plotting\n",
    "        if dataset1.fileName == 'mos_2010.5_2021.5.h5':\n",
    "            newdate = datetime.datetime(int(ds_sub.time.values[idx]), 1, 1) + datetime.timedelta(days = (ds_sub.time.values[idx] % 1) * 365.25)\n",
    "            newdate1 = datetime.datetime(int(ds_sub.time.values[idx+1]), 1, 1) + datetime.timedelta(days = (ds_sub.time.values[idx+1] % 1) * 365.25)\n",
    "            midcycdays = newdate1 - newdate\n",
    "            midcycdate = newdate + midcycdays/2\n",
    "            dates += [midcycdate]\n",
    "        elif dataset1.fileName == 'ATL15_AA_0311_01km_001_01.nc':    \n",
    "            date_time_str = '18-01-01'\n",
    "            date_time_obj = datetime.datetime.strptime(date_time_str, '%y-%m-%d')\n",
    "            newdate = date_time_obj + datetime.timedelta(days=ds_sub.time.values[idx])\n",
    "            newdate1 = date_time_obj + datetime.timedelta(days=ds_sub.time.values[idx+1])\n",
    "            midcycdays = newdate1 - newdate\n",
    "            midcycdate = newdate + midcycdays/2\n",
    "            dates += [midcycdate]\n",
    "        # subset data to dhdt diff between orbital cycles of delta_h\n",
    "        dhdt = ds_sub.delta_h[idx+1,:,:]-ds_sub.delta_h[idx,:,:]\n",
    "        # clip ATL15 data to just show (first set crs)\n",
    "        dhdt.rio.write_crs(3031, inplace=True)\n",
    "        dhdt_clip_SF18 = dhdt.rio.clip(lake_SF18.geometry.values, lake_SF18.crs, drop=False, invert=False)\n",
    "        # calculate lake avg. dh/dt and dv/dt time series using published static outlines\n",
    "        avg_lk_dhdt_SF18 = np.nanmean(dhdt_clip_SF18)\n",
    "        lkavgdhdt_SF18 += [avg_lk_dhdt_SF18]\n",
    "        vol_SF18 = avg_lk_dhdt_SF18*SiegfriedFricker2018_outlines[SiegfriedFricker2018_outlines['name'] == lakename_S23]['area (m^2)']\n",
    "        vols_SF18 += [vol_SF18.values[0]]\n",
    "        # create contours of ice surface elevation height changes to delineate variable lake outlines\n",
    "        contours_fill = []\n",
    "        contours_drain = []   \n",
    "        polys = []\n",
    "        contour = measure.find_contours(dhdt.values, thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_fill += [contour]\n",
    "        contour = measure.find_contours(dhdt.values, -thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_drain += [contour]\n",
    "        # create mapping conversion factor to map array location to polar stereographic x,y\n",
    "        x_conv = (x_max-x_min)/dhdt.shape[1]\n",
    "        y_conv = (y_max-y_min)/dhdt.shape[0]\n",
    "        # plot variable outlines found in this time slice\n",
    "        # make polygons from variable outlines\n",
    "        for i in range(len(contours_fill)): \n",
    "            for j in range(len(contours_fill[i])):\n",
    "                axes[0,0].plot(x_min+contours_fill[i][j][:, 1]*x_conv, y_max-contours_fill[i][j][:, 0]*y_conv, \n",
    "                color=cmap(norm(ds_sub.time.values[idx])), linestyle=(0, (3, 1, 1, 1)), linewidth=1)\n",
    "                if len(contours_fill[i][j][:, 1]) > 2: \n",
    "                    poly = Polygon(list(zip(contours_fill[i][j][:, 1]*x_conv+x_min, y_max-contours_fill[i][j][:, 0]*y_conv))) \n",
    "                    polys += [poly]\n",
    "        for i in range(len(contours_drain)): \n",
    "            for j in range(len(contours_drain[i])):\n",
    "                axes[0,0].plot(x_min+contours_drain[i][j][:, 1]*x_conv, y_max-contours_drain[i][j][:, 0]*y_conv, color=cmap(norm(ds_sub.time.values[idx])), linestyle=(0, (5, 1)), linewidth=1)\n",
    "                if len(contours_drain[i][j][:, 1]) > 2: \n",
    "                    poly = Polygon(list(zip(contours_drain[i][j][:, 1]*x_conv+x_min, y_max-contours_drain[i][j][:, 0]*y_conv))) \n",
    "                    polys += [poly]\n",
    "        # set area to zero each time step\n",
    "        variable_area = 0\n",
    "        # if polygons are present at time step, \n",
    "        if len(polys) > 0: \n",
    "            # clip data to polygons\n",
    "            dhdt_clip = dhdt.rio.clip(polys, drop=False, invert=False)\n",
    "            # then calculate on-lake averages of dh/dt\n",
    "            avg_lk_dhdt = np.nanmean(dhdt_clip)\n",
    "            # occasionally small polygons will completely clip data resulting in nan's for lake avg. dh/dt\n",
    "            # replace with zeros\n",
    "            if math.isnan(avg_lk_dhdt): \n",
    "                avg_lk_dhdt = 0\n",
    "                lkavgdhdt_var += [avg_lk_dhdt]\n",
    "            else:\n",
    "                lkavgdhdt_var += [avg_lk_dhdt]\n",
    "                # and dv/dt\n",
    "            for i in range(len(polys)):\n",
    "                variable_area = variable_area + polys[i].area\n",
    "            vol_var = avg_lk_dhdt*variable_area\n",
    "            vols_var += [vol_var]\n",
    "        else: \n",
    "            variable_area = 0\n",
    "            avg_lk_dhdt = 0\n",
    "            lkavgdhdt_var += [avg_lk_dhdt]\n",
    "            vol_var = avg_lk_dhdt*variable_area\n",
    "            vols_var += [vol_var]\n",
    "    axes[0,0].set(xlim=(x_min, x_max), ylim=(y_min, y_max))\n",
    "    # change polar stereographic m to km\n",
    "    km_scale = 1e3\n",
    "    ticks_x = ticker.FuncFormatter(lambda x, pos: '{0:g}'.format(x/km_scale))\n",
    "    axes[0,0].xaxis.set_major_formatter(ticks_x)\n",
    "    ticks_y = ticker.FuncFormatter(lambda x, pos: '{0:g}'.format(x/km_scale))\n",
    "    axes[0,0].yaxis.set_major_formatter(ticks_y)  \n",
    "    # adjust ticks\n",
    "    axes[0,0].set_xticks(np.arange(np.round(x_min, decimals = -3),np.round(x_max, decimals = -3),5000))\n",
    "    axes[0,0].set_yticks(np.arange(np.round(y_min, decimals = -3),np.round(y_max, decimals = -3),5000))\n",
    "    # label axes\n",
    "    axes[0,0].set_xlabel('x [km]', size=15)\n",
    "    axes[0,0].set_ylabel('y [km]', size=15)\n",
    "    # add title and colorbar\n",
    "    # axes[0].set_title('outline comparison', pad=7.5, fontsize=17.5)\n",
    "    m = plt.cm.ScalarMappable(cmap=cmap)\n",
    "    m.set_array(np.array([datetime2fracyear(date_idx) for date_idx in dates[0:-1]]))\n",
    "    divider = make_axes_locatable(axes[0,0])\n",
    "    cax = divider.append_axes('right', size='5%', pad=0.2)\n",
    "    clb = fig.colorbar(m, cax=cax)\n",
    "    clb.ax.set_title('Year')\n",
    "    # display MOA visual imagery\n",
    "    # axes[0,0].imshow(mpimg.imread('Whillans_7.png'), extent=[x_min1,x_max1,y_min1,y_max1], alpha=1)\n",
    "    # overlay published outlines for visual comparison \n",
    "    Smith2009_outlines.boundary.plot(ax=axes[0,0], color='k', linestyle=(0, (1, 5)), linewidth=1)\n",
    "    SiegfriedFricker2018_SF18outlines.boundary.plot(ax=axes[0,0], color='k', linestyle=(0, (1, 1)), linewidth=1)\n",
    "    Smith2009 = plt.Line2D((0, 1), (0, 0), color='k', linestyle=(0, (1, 5)), linewidth=2)\n",
    "    SiegfriedFricker2018 = plt.Line2D((0, 1), (0, 0), color='k', linestyle=(0, (1, 1)), linewidth=2)\n",
    "    uplift = plt.Line2D((0, 1), (0, 0), color='k', linestyle=(0, (3, 1, 1, 1)), linewidth=2)\n",
    "    subsidence = plt.Line2D((0, 1), (0, 0), color='k', linestyle=(0, (5, 1)), linewidth=1)\n",
    "    variable_outlines = plt.Line2D((0, 1), (0, 0), color='darkturquoise', linestyle='dashdot', linewidth=2)\n",
    "    axes[0,0].legend([Smith2009,\n",
    "    SiegfriedFricker2018,\n",
    "    uplift, subsidence],\n",
    "        ['Smith and others, 2009 static outline',\n",
    "        'Siegfried & Fricker, 2018 static outline',\n",
    "        ('+'+str(thres)+' m uplift (filling) variable outline'), 'â€“'+str(thres)+' m subsidence (draining) variable outline'], \n",
    "        loc='upper right')\n",
    "    # plot inset map to show location \n",
    "    axIns = axes[0,0].inset_axes([0.005, -0.03, 0.3, 0.3])\n",
    "    axIns.patch.set_facecolor('lightskyblue')\n",
    "    axIns.set_aspect('equal')\n",
    "    axIns.scatter(((x_max+x_min)/2), ((y_max+y_min)/2), marker='*', \n",
    "        linewidth=1, edgecolor='k', facecolor='r', s=100, zorder=3)\n",
    "    Scripps_gl.plot(ax=axIns, color='ghostwhite', edgecolor='k', linewidth=0.5, zorder=2)\n",
    "    # SiegfriedFricker2018_outlines.boundary.plot(ax=axIns, color='k', linestyle=(0, (1, 1)), linewidth=1)\n",
    "    axIns.axis('off')\n",
    "    # plot dv subplot\n",
    "    axes[0,1].plot(dates[:idx+1], np.divide(np.cumsum(vols_SF18[:idx+1]), 1e+9), color='k', linestyle=(0, (1, 1)))\n",
    "    axes[0,1].plot(dates[:idx+1], np.divide(np.cumsum(vols_var[:idx+1]), 1e+9), color='darkturquoise', linestyle='dashdot')\n",
    "    locator = mdates.AutoDateLocator(minticks=1, maxticks=7)\n",
    "    formatter = mdates.ConciseDateFormatter(locator)\n",
    "    axes[0,1].xaxis.set_major_locator(locator)\n",
    "    axes[0,1].xaxis.set_major_formatter(formatter)\n",
    "    #axes[1].set_title('dVol', fontsize=17.5)\n",
    "    axes[0,1].set_xlabel('Year', size=15)\n",
    "    axes[0,1].set_ylabel('Volume change [km$^3$]', size=15)\n",
    "    axes[0,1].yaxis.tick_right()\n",
    "    axes[0,1].yaxis.set_label_position(\"right\")\n",
    "    axes[0,1].legend([SiegfriedFricker2018,variable_outlines],\n",
    "        ['Siegfried & Fricker, 2018 static outline',\n",
    "        'Â±{} m variable outlines'.format(thres)], \n",
    "        loc='best') \n",
    "\n",
    "    # subset ATL15 data set to region of interest\n",
    "    mask_x = (dataset2.x >= x_min) & (dataset2.x <= x_max)\n",
    "    mask_y = (dataset2.y >= y_min) & (dataset2.y <= y_max)\n",
    "    ds_sub = dataset2.where(mask_x & mask_y, drop=True)\n",
    "    # find magnitude of ice surface deformation in bounding box / find appropriate color map scale\n",
    "    height_anom_pos = []\n",
    "    height_anom_neg = []\n",
    "    for cyc in range(len(ds_sub.time)-1):\n",
    "        pos = np.nanmax(ds_sub.delta_h[cyc+1,:,:]-ds_sub.delta_h[cyc,:,:])\n",
    "        neg = np.nanmin(ds_sub.delta_h[cyc+1,:,:]-ds_sub.delta_h[cyc,:,:])\n",
    "        height_anom_pos += [pos]\n",
    "        height_anom_neg += [neg]\n",
    "    max_height_anom_pos = max(height_anom_pos)\n",
    "    max_height_anom_neg = min(height_anom_neg)\n",
    "    max_height_anom_abs = max(max_height_anom_pos,abs(max_height_anom_neg))\n",
    "    v = np.round(max_height_anom_abs)\n",
    "    # create empty lists to store data\n",
    "    dates = []\n",
    "    lkavgdhdt_SF18 = []\n",
    "    lkavgdhdt_var = []\n",
    "    vols_SF18 = []\n",
    "    vols_var = []\n",
    "    # plot figure\n",
    "    norm = plt.Normalize(ds_sub.time.values[0],ds_sub.time.values[-1])    \n",
    "    for idx in range(len(ds_sub.time)-1): \n",
    "        dhdt = ds_sub.delta_h[idx+1,:,:]-ds_sub.delta_h[idx,:,:]\n",
    "        # calculate mid-cycle dates for plotting\n",
    "        if dataset2.fileName == 'mos_2010.5_2021.5.h5':\n",
    "            newdate = datetime.datetime(int(ds_sub.time.values[idx]), 1, 1) + datetime.timedelta(days = (ds_sub.time.values[idx] % 1) * 365.25)\n",
    "            newdate1 = datetime.datetime(int(ds_sub.time.values[idx+1]), 1, 1) + datetime.timedelta(days = (ds_sub.time.values[idx+1] % 1) * 365.25)\n",
    "            midcycdays = newdate1 - newdate\n",
    "            midcycdate = newdate + midcycdays/2\n",
    "            dates += [midcycdate]\n",
    "        elif dataset2.fileName == 'ATL15_AA_0311_01km_001_01.nc':    \n",
    "            date_time_str = '18-01-01'\n",
    "            date_time_obj = datetime.datetime.strptime(date_time_str, '%y-%m-%d')\n",
    "            newdate = date_time_obj + datetime.timedelta(days=ds_sub.time.values[idx])\n",
    "            newdate1 = date_time_obj + datetime.timedelta(days=ds_sub.time.values[idx+1])\n",
    "            midcycdays = newdate1 - newdate\n",
    "            midcycdate = newdate + midcycdays/2\n",
    "            dates += [midcycdate]\n",
    "        # subset data to dhdt diff between orbital cycles of delta_h\n",
    "        dhdt = ds_sub.delta_h[idx+1,:,:]-ds_sub.delta_h[idx,:,:]\n",
    "        # clip data to lake area (first set crs)\n",
    "        dhdt.rio.write_crs(3031, inplace=True)\n",
    "        dhdt_clip_SF18 = dhdt.rio.clip(lake_SF18.geometry.values, lake_SF18.crs, drop=False, invert=False)\n",
    "        # calculate lake avg. dh/dt and dv/dt time series using published static outlines\n",
    "        avg_lk_dhdt_SF18 = np.nanmean(dhdt_clip_SF18)\n",
    "        lkavgdhdt_SF18 += [avg_lk_dhdt_SF18]\n",
    "        vol_SF18 = avg_lk_dhdt_SF18*SiegfriedFricker2018_outlines[SiegfriedFricker2018_outlines['name'] == lakename_S23]['area (m^2)']\n",
    "        vols_SF18 += [vol_SF18.values[0]]\n",
    "        # create contours of ice surface elevation height changes to delineate variable lake outlines\n",
    "        contours_fill = []\n",
    "        contours_drain = []   \n",
    "        polys = []\n",
    "        contour = measure.find_contours(dhdt.values, thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_fill += [contour]\n",
    "        contour = measure.find_contours(dhdt.values, -thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_drain += [contour]\n",
    "        # create mapping conversion factor to map array location to polar stereographic x,y\n",
    "        x_conv = (x_max-x_min)/dhdt.shape[1]\n",
    "        y_conv = (y_max-y_min)/dhdt.shape[0]\n",
    "        # plot variable outlines found in this time slice\n",
    "        # make polygons from variable outlines\n",
    "        for i in range(len(contours_fill)): \n",
    "            for j in range(len(contours_fill[i])):\n",
    "                axes[1,0].plot(x_min+contours_fill[i][j][:, 1]*x_conv, y_max-contours_fill[i][j][:, 0]*y_conv, \n",
    "                color=cmap(norm(ds_sub.time.values[idx])), linestyle=(0, (3, 1, 1, 1)), linewidth=1)\n",
    "                if len(contours_fill[i][j][:, 1]) > 2: \n",
    "                    poly = Polygon(list(zip(contours_fill[i][j][:, 1]*x_conv+x_min, y_max-contours_fill[i][j][:, 0]*y_conv))) \n",
    "                    polys += [poly]\n",
    "        for i in range(len(contours_drain)): \n",
    "            for j in range(len(contours_drain[i])):\n",
    "                axes[1,0].plot(x_min+contours_drain[i][j][:, 1]*x_conv, y_max-contours_drain[i][j][:, 0]*y_conv, color=cmap(norm(ds_sub.time.values[idx])), linestyle=(0, (5, 1)), linewidth=1)\n",
    "                if len(contours_drain[i][j][:, 1]) > 2: \n",
    "                    poly = Polygon(list(zip(contours_drain[i][j][:, 1]*x_conv+x_min, y_max-contours_drain[i][j][:, 0]*y_conv))) \n",
    "                    polys += [poly]\n",
    "        # set area to zero each time step\n",
    "        variable_area = 0\n",
    "        # if polygons are present at time step, \n",
    "        if len(polys) > 0: \n",
    "            # clip data to polygons\n",
    "            dhdt_clip = dhdt.rio.clip(polys, drop=False, invert=False)\n",
    "            # then calculate on-lake averages of dh/dt\n",
    "            avg_lk_dhdt = np.nanmean(dhdt_clip)\n",
    "            # occasionally small polygons will completely clip data resulting in nan's for lake avg. dh/dt\n",
    "            # replace with zeros\n",
    "            if math.isnan(avg_lk_dhdt): \n",
    "                avg_lk_dhdt = 0\n",
    "                lkavgdhdt_var += [avg_lk_dhdt]\n",
    "            else:\n",
    "                lkavgdhdt_var += [avg_lk_dhdt]\n",
    "                # and dv/dt\n",
    "            for i in range(len(polys)):\n",
    "                variable_area = variable_area + polys[i].area\n",
    "            vol_var = avg_lk_dhdt*variable_area\n",
    "            vols_var += [vol_var]\n",
    "        else: \n",
    "            variable_area = 0\n",
    "            avg_lk_dhdt = 0\n",
    "            lkavgdhdt_var += [avg_lk_dhdt]\n",
    "            vol_var = avg_lk_dhdt*variable_area\n",
    "            vols_var += [vol_var]\n",
    "    axes[1,0].set(xlim=(x_min, x_max), ylim=(y_min, y_max))\n",
    "    # change polar stereographic m to km\n",
    "    km_scale = 1e3\n",
    "    ticks_x = ticker.FuncFormatter(lambda x, pos: '{0:g}'.format(x/km_scale))\n",
    "    axes[1,0].xaxis.set_major_formatter(ticks_x)\n",
    "    ticks_y = ticker.FuncFormatter(lambda x, pos: '{0:g}'.format(x/km_scale))\n",
    "    axes[1,0].yaxis.set_major_formatter(ticks_y)  \n",
    "    # adjust ticks\n",
    "    axes[1,0].set_xticks(np.arange(np.round(x_min, decimals = -3),np.round(x_max, decimals = -3),5000))\n",
    "    axes[1,0].set_yticks(np.arange(np.round(y_min, decimals = -3),np.round(y_max, decimals = -3),5000))\n",
    "    # label axes\n",
    "    axes[1,0].set_xlabel('x [km]', size=15)\n",
    "    axes[1,0].set_ylabel('y [km]', size=15)\n",
    "    # add title and colorbar\n",
    "    # axes[0].set_title('outline comparison', pad=7.5, fontsize=17.5)\n",
    "    m = plt.cm.ScalarMappable(cmap=cmap)\n",
    "    m.set_array(np.array([datetime2fracyear(date_idx) for date_idx in dates[0:-1]]))\n",
    "    divider = make_axes_locatable(axes[1,0])\n",
    "    cax = divider.append_axes('right', size='5%', pad=0.2)\n",
    "    clb = fig.colorbar(m, ticks=np.array([2019,2020,2021]),  cax=cax)\n",
    "    clb.ax.set_title('Year')\n",
    "    # overlay published outlines for visual comparison \n",
    "    Smith2009_outlines.boundary.plot(ax=axes[1,0], color='k', linestyle=(0, (1, 5)), linewidth=1)\n",
    "    SiegfriedFricker2018_SF18outlines.boundary.plot(ax=axes[1,0], color='k', linestyle=(0, (1, 1)), linewidth=1)\n",
    "    Smith2009 = plt.Line2D((0, 1), (0, 0), color='k', linestyle=(0, (1, 5)), linewidth=2)\n",
    "    SiegfriedFricker2018 = plt.Line2D((0, 1), (0, 0), color='k', linestyle=(0, (1, 1)), linewidth=2)\n",
    "    uplift = plt.Line2D((0, 1), (0, 0), color='k', linestyle=(0, (3, 1, 1, 1)), linewidth=2)\n",
    "    subsidence = plt.Line2D((0, 1), (0, 0), color='k', linestyle=(0, (5, 1)), linewidth=1)\n",
    "    variable_outlines = plt.Line2D((0, 1), (0, 0), color='darkturquoise', linestyle='dashdot', linewidth=2)\n",
    "    axes[1,0].legend([Smith2009,\n",
    "    SiegfriedFricker2018,\n",
    "    uplift, subsidence],\n",
    "        ['Smith and others, 2009 static outline',\n",
    "        'Siegfried & Fricker, 2018 static outline',\n",
    "        ('+'+str(thres)+' m uplift (filling) variable outline'), 'â€“'+str(thres)+' m subsidence (draining) variable outline'], \n",
    "        loc='upper right')\n",
    "    # plot inset map to show location \n",
    "    axIns = axes[1,0].inset_axes([0.005, -0.03, 0.3, 0.3])\n",
    "    axIns.patch.set_facecolor('lightskyblue')\n",
    "    axIns.set_aspect('equal')\n",
    "    axIns.scatter(((x_max+x_min)/2), ((y_max+y_min)/2), marker='*', \n",
    "        linewidth=1, edgecolor='k', facecolor='r', s=100, zorder=3)\n",
    "    Scripps_gl.plot(ax=axIns, color='ghostwhite', edgecolor='k', linewidth=0.5, zorder=2)\n",
    "    # SiegfriedFricker2018_outlines.boundary.plot(ax=axIns, color='k', linestyle=(0, (1, 1)), linewidth=1)\n",
    "    axIns.axis('off')\n",
    "    # plot dvdt subplot\n",
    "    axes[1,1].plot(dates[:idx+1], np.divide(np.cumsum(vols_SF18[:idx+1]), 1e+9), color='k', linestyle=(0, (1, 1)))\n",
    "    axes[1,1].plot(dates[:idx+1], np.divide(np.cumsum(vols_var[:idx+1]), 1e+9), color='darkturquoise', linestyle='dashdot')\n",
    "    locator = mdates.AutoDateLocator(minticks=1, maxticks=7)\n",
    "    formatter = mdates.ConciseDateFormatter(locator)\n",
    "    axes[1,1].xaxis.set_major_locator(locator)\n",
    "    axes[1,1].xaxis.set_major_formatter(formatter)\n",
    "    min_vol = min(np.divide(min(np.cumsum(vols_SF18)), 1e+9), \n",
    "                    np.divide(min(np.cumsum(vols_var)), 1e+9))\n",
    "    max_vol = max(np.divide(max(np.cumsum(vols_SF18)), 1e+9), \n",
    "                    np.divide(max(np.cumsum(vols_var)), 1e+9))\n",
    "    if dataset2.fileName == 'mos_2010.5_2021.5.h5':\n",
    "        axes[1,1].set(xlim=(datetime.datetime(int(ds_sub.time.values[0]), 1, 1) + datetime.timedelta(days = (ds_sub.time.values[0] % 1) * 365.25), \n",
    "                            datetime.datetime(int(ds_sub.time.values[-1]), 1, 1) + datetime.timedelta(days = (ds_sub.time.values[-1] % 1) * 365.25)), \n",
    "                    ylim=((min_vol - (max_vol - min_vol)*0.05),\n",
    "                            (max_vol + (max_vol - min_vol)*0.05)))\n",
    "    elif dataset2.fileName == 'ATL15_AA_0311_01km_001_01.nc':    \n",
    "        axes[1,1].set(xlim=(date_time_obj + datetime.timedelta(days=ds_sub.time.values[1]),\n",
    "                            date_time_obj + datetime.timedelta(days=ds_sub.time.values[-1])), \n",
    "                    ylim=((min_vol - (max_vol - min_vol)*0.05), \n",
    "                            (max_vol + (max_vol - min_vol)*0.05)))\n",
    "    # axes[1].set_title('{} dVol'.format(lakename_S23), pad=7.5, fontsize=17.5)\n",
    "    axes[1,1].set_xlabel('Year', size=15)\n",
    "    axes[1,1].set_ylabel('Volume change [km$^3$]', size=15)\n",
    "    axes[1,1].yaxis.tick_right()\n",
    "    axes[1,1].yaxis.set_label_position(\"right\")\n",
    "    variable_outlines = plt.Line2D((0, 1), (0, 0), color='darkturquoise', linestyle='dashdot', linewidth=2)\n",
    "    axes[1,1].legend([Smith2009,\n",
    "        SiegfriedFricker2018,variable_outlines],\n",
    "                    ['Smith and others, 2009 static outline',\n",
    "        'Siegfried & Fricker, 2018 static outline',\n",
    "        'Â±{} m variable outlines'.format(thres)], \n",
    "                    loc='upper right')\n",
    "    # save and close figure\n",
    "    plt.savefig('/Users/Wilson/Documents/0-code/1-lakeshores/output_dhdvdt-using-variable-outlines/S09SF18varoutlines_agg_dvdt_plot/S09SF18varoutlines_agg_dvdt_plot-{}.png'\\\n",
    "        .format(lakename_S23), dpi=300, bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on one lake to ensure working\n",
    "S09SF18S23_agg_dvdt_CS2vsIS2_plot('Thw_170', 10000, 0.5, CS2_dh, ATL15_dh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run func on all lakes\n",
    "for idx in range(len(Sauthoff2023_outlines)):\n",
    "    lakename = Sauthoff2023_outlines['name'][idx]\n",
    "    S09SF18S23_agg_dvdt_CS2vsIS2_plot(lakename, 10000, 0.5, CS2_dh, ATL15_dh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S09SF18S23_agg_dvdt_CS2vsIS2_plot('Thw_70', 10000, 0.7, CS2_dh, ATL15_dh)\n",
    "S09SF18S23_agg_dvdt_CS2vsIS2_plot('Thw_124', 10000, 0.7, CS2_dh, ATL15_dh)\n",
    "S09SF18S23_agg_dvdt_CS2vsIS2_plot('Thw_142', 10000, 0.7, CS2_dh, ATL15_dh)\n",
    "# S09SF18S23_agg_dvdt_CS2vsIS2_plot('Thw_170', 10000, 0.6, CS2_dh, ATL15_dh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Func S09SF18S23_agg_dvdt_redelineated_compare_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare one S09 to one SF18 lakes (one redelineated)\n",
    "def S09SF18S23_agg_dvdt_redelineated_compare_plot(lakename_S09, lakename_S23, buffer, thres, dataset1, dataset2): \n",
    "    '''\n",
    "    Create planview plot of an aggregated times series of variable outlines compared to known lakes alongside dv/dt time series. Uses geopandas buffer created bounding box around known lakes in Siegfried and Fricker, 2018 (SF18) inventory. Creates time-variable outlines using skimage contour to plot variable outline alongside published outlines for comparison. \n",
    "    Inputs: \n",
    "        lakename_S23: lake of interest from SiegfriedFricker2018_outlines inventory\n",
    "        buffer: horizontal distance in meters away from SF18 lake outline used to create bounding box that is displayed around lake of interest\n",
    "        thres(hold): vertical distance in meters to delineate ice surface deformation contour\n",
    "        dataset: dataset to be analyzed (CS2_dh or ATL15_dh)\n",
    "    Outputs: \n",
    "        Aggregated time-variable lake outlines in regions of known lakes using CryoSat-2 or ICESat-2 ATL15 dh/dt data alongside dVol time series.\n",
    "    '''\n",
    "    # isolate individual lake using gpd buffer\n",
    "    #lake_gpd = Smith2009_outlines.loc[Smith2009_outlines['Name'] == lakename_S23]\n",
    "    lake_S09 = Smith2009_outlines.loc[Smith2009_outlines['Name'] == lakename_S09]\n",
    "    lake_SF18 = SiegfriedFricker2018_outlines.loc[SiegfriedFricker2018_outlines['name'] == lakename_S23]\n",
    "    lake_buffer = lake_SF18.buffer(buffer)\n",
    "    # define lake bounding box\n",
    "    x_min = lake_buffer.bounds.values[0,0]; x_max = lake_buffer.bounds.values[0,2]\n",
    "    y_min = lake_buffer.bounds.values[0,1]; y_max = lake_buffer.bounds.values[0,3]\n",
    "    # subset ATL15 data set to region of interest\n",
    "    mask_x = (dataset1.x >= x_min) & (dataset1.x <= x_max)\n",
    "    mask_y = (dataset1.y >= y_min) & (dataset1.y <= y_max)\n",
    "    ds_sub = dataset1.where(mask_x & mask_y, drop=True)\n",
    "    # find magnitude of ice surface deformation in bounding box / find appropriate color map scale\n",
    "    height_anom_pos = []\n",
    "    height_anom_neg = []\n",
    "    for cyc in range(len(ds_sub.time)-1):\n",
    "        pos = np.nanmax(ds_sub.delta_h[cyc+1,:,:]-ds_sub.delta_h[cyc,:,:])\n",
    "        neg = np.nanmin(ds_sub.delta_h[cyc+1,:,:]-ds_sub.delta_h[cyc,:,:])\n",
    "        height_anom_pos += [pos]\n",
    "        height_anom_neg += [neg]\n",
    "    max_height_anom_pos = max(height_anom_pos)\n",
    "    max_height_anom_neg = min(height_anom_neg)\n",
    "    max_height_anom_abs = max(max_height_anom_pos,abs(max_height_anom_neg))\n",
    "    v = np.round(max_height_anom_abs)\n",
    "    dates = []\n",
    "    lkavgdhdt_SF18 = []\n",
    "    lkavgdhdt_var = []\n",
    "    vols_S09 = []\n",
    "    vols_SF18 = []\n",
    "    vols_var = []\n",
    "    # plot figure\n",
    "    fig, axes = plt.subplots(2,2, figsize=(15,15))\n",
    "    # fig.suptitle('{} outline and dVol comparison'.format(lakename_S23), fontsize=24)\n",
    "    # fig.suptitle('Whillans$_7$ outline and $\\Delta$volume comparison', fontsize=30)\n",
    "    plt.subplots_adjust(wspace=0.10, hspace = 0.1)\n",
    "    cmap = plt.get_cmap('CMRmap')\n",
    "    norm = plt.Normalize(ds_sub.time.values[0],ds_sub.time.values[-1])    \n",
    "    for idx in range(len(ds_sub.time)-1): \n",
    "        dhdt = ds_sub.delta_h[idx+1,:,:]-ds_sub.delta_h[idx,:,:]\n",
    "        # calculate mid-cycle dates for plotting\n",
    "        if dataset1.fileName == 'mos_2010.5_2021.5.h5':\n",
    "            newdate = datetime.datetime(int(ds_sub.time.values[idx]), 1, 1) + datetime.timedelta(days = (ds_sub.time.values[idx] % 1) * 365.25)\n",
    "            newdate1 = datetime.datetime(int(ds_sub.time.values[idx+1]), 1, 1) + datetime.timedelta(days = (ds_sub.time.values[idx+1] % 1) * 365.25)\n",
    "            midcycdays = newdate1 - newdate\n",
    "            midcycdate = newdate + midcycdays/2\n",
    "            dates += [midcycdate]\n",
    "        elif dataset1.fileName == 'ATL15_AA_0311_01km_001_01.nc':    \n",
    "            date_time_str = '18-01-01'\n",
    "            date_time_obj = datetime.datetime.strptime(date_time_str, '%y-%m-%d')\n",
    "            newdate = date_time_obj + datetime.timedelta(days=ds_sub.time.values[idx])\n",
    "            newdate1 = date_time_obj + datetime.timedelta(days=ds_sub.time.values[idx+1])\n",
    "            midcycdays = newdate1 - newdate\n",
    "            midcycdate = newdate + midcycdays/2\n",
    "            dates += [midcycdate]\n",
    "        # subset data to dhdt diff between orbital cycles of delta_h\n",
    "        dhdt = ds_sub.delta_h[idx+1,:,:]-ds_sub.delta_h[idx,:,:]\n",
    "        # clip ATL15 data to just show (first set crs)\n",
    "        dhdt.rio.write_crs(3031, inplace=True)\n",
    "        dhdt_clip_S09 = dhdt.rio.clip(lake_S09.geometry.values, lake_S09.crs, drop=False, invert=False)\n",
    "        dhdt_clip_SF18 = dhdt.rio.clip(lake_SF18.geometry.values, lake_SF18.crs, drop=False, invert=False)\n",
    "        # calculate lake avg. dh/dt and dv/dt time series using published static outlines\n",
    "        avg_lk_dhdt_S09 = np.nanmean(dhdt_clip_S09)\n",
    "        avg_lk_dhdt_SF18 = np.nanmean(dhdt_clip_SF18)\n",
    "        lkavgdhdt_SF18 += [avg_lk_dhdt_SF18]\n",
    "        vol_S09 = avg_lk_dhdt_S09*Smith2009_outlines[Smith2009_outlines['Name'] == lakename_S09].area\n",
    "        vol_SF18 = avg_lk_dhdt_SF18*SiegfriedFricker2018_outlines[SiegfriedFricker2018_outlines['name'] == lakename_S23]['area (m^2)']\n",
    "        vols_S09 += [vol_S09.values[0]]\n",
    "        vols_SF18 += [vol_SF18.values[0]]\n",
    "        # create contours of ice surface elevation height changes to delineate variable lake outlines\n",
    "        contours_fill = []\n",
    "        contours_drain = []   \n",
    "        polys = []\n",
    "        contour = measure.find_contours(dhdt.values, thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_fill += [contour]\n",
    "        contour = measure.find_contours(dhdt.values, -thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_drain += [contour]\n",
    "        # create mapping conversion factor to map array location to polar stereographic x,y\n",
    "        x_conv = (x_max-x_min)/dhdt.shape[1]\n",
    "        y_conv = (y_max-y_min)/dhdt.shape[0]\n",
    "        # plot variable outlines found in this time slice\n",
    "        # make polygons from variable outlines\n",
    "        for i in range(len(contours_fill)): \n",
    "            for j in range(len(contours_fill[i])):\n",
    "                axes[0,0].plot(x_min+contours_fill[i][j][:, 1]*x_conv, y_max-contours_fill[i][j][:, 0]*y_conv, \n",
    "                color=cmap(norm(ds_sub.time.values[idx])), linestyle=(0, (3, 1, 1, 1)), linewidth=1)\n",
    "                if len(contours_fill[i][j][:, 1]) > 2: \n",
    "                    poly = Polygon(list(zip(contours_fill[i][j][:, 1]*x_conv+x_min, y_max-contours_fill[i][j][:, 0]*y_conv))) \n",
    "                    polys += [poly]\n",
    "        for i in range(len(contours_drain)): \n",
    "            for j in range(len(contours_drain[i])):\n",
    "                axes[0,0].plot(x_min+contours_drain[i][j][:, 1]*x_conv, y_max-contours_drain[i][j][:, 0]*y_conv, color=cmap(norm(ds_sub.time.values[idx])), linestyle=(0, (5, 1)), linewidth=1)\n",
    "                if len(contours_drain[i][j][:, 1]) > 2: \n",
    "                    poly = Polygon(list(zip(contours_drain[i][j][:, 1]*x_conv+x_min, y_max-contours_drain[i][j][:, 0]*y_conv))) \n",
    "                    polys += [poly]\n",
    "        # set area to zero each time step\n",
    "        variable_area = 0\n",
    "        # if polygons are present at time step, \n",
    "        if len(polys) > 0: \n",
    "            # clip data to polygons\n",
    "            dhdt_clip = dhdt.rio.clip(polys, drop=False, invert=False)\n",
    "            # then calculate on-lake averages of dh/dt\n",
    "            avg_lk_dhdt = np.nanmean(dhdt_clip)\n",
    "            # occasionally small polygons will completely clip data resulting in nan's for lake avg. dh/dt\n",
    "            # replace with zeros\n",
    "            if math.isnan(avg_lk_dhdt): \n",
    "                avg_lk_dhdt = 0\n",
    "                lkavgdhdt_var += [avg_lk_dhdt]\n",
    "            else:\n",
    "                lkavgdhdt_var += [avg_lk_dhdt]\n",
    "                # and dv/dt\n",
    "            for i in range(len(polys)):\n",
    "                variable_area = variable_area + polys[i].area\n",
    "            vol_var = avg_lk_dhdt*variable_area\n",
    "            vols_var += [vol_var]\n",
    "        else: \n",
    "            variable_area = 0\n",
    "            avg_lk_dhdt = 0\n",
    "            lkavgdhdt_var += [avg_lk_dhdt]\n",
    "            vol_var = avg_lk_dhdt*variable_area\n",
    "            vols_var += [vol_var]\n",
    "    # Change polar stereographic m to km\n",
    "    km_scale = 1e3\n",
    "    ticks_x = ticker.FuncFormatter(lambda x, pos: '{0:g}'.format(x/km_scale))\n",
    "    axes[0,0].xaxis.set_major_formatter(ticks_x)\n",
    "    ticks_y = ticker.FuncFormatter(lambda y, pos: '{0:g}'.format(y/km_scale))\n",
    "    axes[0,0].yaxis.set_major_formatter(ticks_y)\n",
    "    axes[0,0].set_xticks(np.arange(y_min,y_max,5000))\n",
    "    # adjust ticks\n",
    "    axes[0,0].set_yticks(np.arange(y_min,y_max,5000))\n",
    "    # display MOA visual imagery\n",
    "    # axes[0,0].imshow(mpimg.imread('Whillans_7.png'), extent=[x_min1,x_max1,y_min1,y_max1], alpha=1)\n",
    "    axes[0,0].set(xlim=(x_min, x_max), ylim=(y_min, y_max))\n",
    "    axes[0,0].set_xlabel('x [km]', size=15)\n",
    "    axes[0,0].set_ylabel('y [km]', size=15)\n",
    "    # axes[0].ticklabel_format(axis='both',scilimits=(0,0))\n",
    "    # axes[0].set_title('outline comparison', pad=7.5, fontsize=17.5)\n",
    "    m = plt.cm.ScalarMappable(cmap=cmap)\n",
    "    m.set_array(np.array([datetime2fracyear(date_idx) for date_idx in dates[0:-1]]))\n",
    "    divider = make_axes_locatable(axes[0,0])\n",
    "    cax = divider.append_axes('right', size='5%', pad=0.2)\n",
    "    clb = fig.colorbar(m, cax=cax)\n",
    "    clb.ax.set_title('Year')\n",
    "    # overlay published outlines for visual comparison \n",
    "    Smith2009_outlines.boundary.plot(ax=axes[0,0], color='k', linestyle=(0, (1, 5)), linewidth=1)\n",
    "    SiegfriedFricker2018_outlines.boundary.plot(ax=axes[0,0], color='k', linestyle=(0, (1, 1)), linewidth=1)\n",
    "    Smith2009 = plt.Line2D((0, 1), (0, 0), color='k', linestyle=(0, (1, 5)), linewidth=2)\n",
    "    SiegfriedFricker2018 = plt.Line2D((0, 1), (0, 0), color='k', linestyle=(0, (1, 1)), linewidth=2)\n",
    "    uplift = plt.Line2D((0, 1), (0, 0), color='k', linestyle=(0, (3, 1, 1, 1)), linewidth=2)\n",
    "    subsidence = plt.Line2D((0, 1), (0, 0), color='k', linestyle=(0, (5, 1)), linewidth=1)\n",
    "    variable_outlines = plt.Line2D((0, 1), (0, 0), color='darkturquoise', linestyle='dashdot', linewidth=2)\n",
    "    axes[0,0].legend([Smith2009,\n",
    "    SiegfriedFricker2018,\n",
    "    uplift, subsidence],\n",
    "        ['Smith and others, 2009 static outline',\n",
    "        'Siegfried & Fricker, 2018 outline',\n",
    "        ('+'+str(thres)+' m uplift (filling) variable outline'), 'â€“'+str(thres)+' m subsidence (draining) variable outline'], \n",
    "        loc='upper right')\n",
    "    # plot inset map to show location \n",
    "    axIns = axes[0,0].inset_axes([0.005, -0.03, 0.3, 0.3])\n",
    "    axIns.patch.set_facecolor('lightskyblue')\n",
    "    axIns.set_aspect('equal')\n",
    "    axIns.scatter(((x_max+x_min)/2), ((y_max+y_min)/2), marker='*', \n",
    "        linewidth=1, edgecolor='k', facecolor='r', s=100, zorder=3)\n",
    "    Scripps_gl.plot(ax=axIns, color='ghostwhite', edgecolor='k', linewidth=0.5, zorder=2)\n",
    "    # SiegfriedFricker2018_outlines.boundary.plot(ax=axIns, color='k', linestyle=(0, (1, 1)), linewidth=1)\n",
    "    axIns.axis('off')\n",
    "    # plot dvdt subplot\n",
    "    # axes[0,1].plot(dates, np.divide(np.cumsum(vols_S09), 1e+9), color='k', linestyle=(0, (1, 5)))\n",
    "    # axes[0,1].plot(dates, np.divide(np.cumsum(vols_SF18), 1e+9), color='k', linestyle=(0, (1, 5)))\n",
    "    # axes[0,1].plot(dates, np.divide(np.cumsum(vols_var), 1e+9), color='darkturquoise', linestyle='dashdot')\n",
    "    axes[0,1].plot(dates[:idx+1], np.divide(np.cumsum(vols_S09[:idx+1]), 1e+9), color='k', linestyle=(0, (1, 5)))\n",
    "    axes[0,1].plot(dates[:idx+1], np.divide(np.cumsum(vols_SF18[:idx+1]), 1e+9), color='k', linestyle=(0, (1, 1)))\n",
    "    axes[0,1].plot(dates[:idx+1], np.divide(np.cumsum(vols_var[:idx+1]), 1e+9), color='darkturquoise', linestyle='dashdot')\n",
    "    locator = mdates.AutoDateLocator(minticks=1, maxticks=7)\n",
    "    formatter = mdates.ConciseDateFormatter(locator)\n",
    "    axes[0,1].xaxis.set_major_locator(locator)\n",
    "    axes[0,1].xaxis.set_major_formatter(formatter)\n",
    "    #axes[1].set_title('dVol', fontsize=17.5)\n",
    "    axes[0,1].set_xlabel('Year', size=15)\n",
    "    axes[0,1].set_ylabel('Volume change [km$^3$]', size=15)\n",
    "    axes[0,1].yaxis.tick_right()\n",
    "    axes[0,1].yaxis.set_label_position(\"right\")\n",
    "    axes[0,1].legend([Smith2009,SiegfriedFricker2018,variable_outlines],\n",
    "        ['Smith and others, 2009 static outline', 'Siegfried & Fricker, 2018 static outline',\n",
    "        'Â±{} m variable outlines'.format(thres)], \n",
    "        loc='best') \n",
    "\n",
    "# isolate individual lake using gpd buffer\n",
    "# lake_S09_1 = Smith2009_outlines.loc[Smith2009_outlines['Name'] == lakename1_S09]\n",
    "# lake_S09_2 = Smith2009_outlines.loc[Smith2009_outlines['Name'] == lakename2_S09]\n",
    "# lake_SF18 = SiegfriedFricker2018_outlines.loc[SiegfriedFricker2018_outlines['name'] == lakename_S23]\n",
    "# lake_buffer = lake_SF18.buffer(buffer)\n",
    "# define lake bounding box\n",
    "# x_min = lake_buffer.bounds.values[0,0]; x_max = lake_buffer.bounds.values[0,2]\n",
    "# y_min = lake_buffer.bounds.values[0,1]; y_max = lake_buffer.bounds.values[0,3]\n",
    "# subset ATL15 data set to region of interest\n",
    "mask_x = (dataset2.x >= x_min) & (dataset2.x <= x_max)\n",
    "mask_y = (dataset2.y >= y_min) & (dataset2.y <= y_max)\n",
    "ds_sub = dataset2.where(mask_x & mask_y, drop=True)\n",
    "# find magnitude of ice surface deformation in bounding box / find appropriate color map scale\n",
    "height_anom_pos = []\n",
    "height_anom_neg = []\n",
    "for cyc in range(len(ds_sub.time)-1):\n",
    "    pos = np.nanmax(ds_sub.delta_h[cyc+1,:,:]-ds_sub.delta_h[cyc,:,:])\n",
    "    neg = np.nanmin(ds_sub.delta_h[cyc+1,:,:]-ds_sub.delta_h[cyc,:,:])\n",
    "    height_anom_pos += [pos]\n",
    "    height_anom_neg += [neg]\n",
    "max_height_anom_pos = max(height_anom_pos)\n",
    "max_height_anom_neg = min(height_anom_neg)\n",
    "max_height_anom_abs = max(max_height_anom_pos,abs(max_height_anom_neg))\n",
    "v = np.round(max_height_anom_abs)\n",
    "dates = []\n",
    "lkavgdhdt_SF18 = []\n",
    "lkavgdhdt_var = []\n",
    "vols_S09 = []\n",
    "vols_SF18 = []\n",
    "vols_var = []\n",
    "# plot figure\n",
    "# fig, axes = plt.subplots(1,2, figsize=(21,7))\n",
    "# # fig.suptitle('{} outline and dVol comparison'.format(lakename_S23), fontsize=24)\n",
    "# # fig.suptitle('Whillans$_7$ outline and $\\Delta$volume comparison', fontsize=30)\n",
    "# plt.subplots_adjust(wspace=0.10)\n",
    "# cmap = plt.get_cmap('CMRmap')\n",
    "norm = plt.Normalize(ds_sub.time.values[0],ds_sub.time.values[-1])    \n",
    "for idx in range(len(ds_sub.time)-1): \n",
    "    dhdt = ds_sub.delta_h[idx+1,:,:]-ds_sub.delta_h[idx,:,:]\n",
    "    # calculate mid-cycle dates for plotting\n",
    "    if dataset2.fileName == 'mos_2010.5_2021.5.h5':\n",
    "        newdate = datetime.datetime(int(ds_sub.time.values[idx]), 1, 1) + datetime.timedelta(days = (ds_sub.time.values[idx] % 1) * 365.25)\n",
    "        newdate1 = datetime.datetime(int(ds_sub.time.values[idx+1]), 1, 1) + datetime.timedelta(days = (ds_sub.time.values[idx+1] % 1) * 365.25)\n",
    "        midcycdays = newdate1 - newdate\n",
    "        midcycdate = newdate + midcycdays/2\n",
    "        dates += [midcycdate]\n",
    "    elif dataset2.fileName == 'ATL15_AA_0311_01km_001_01.nc':    \n",
    "        date_time_str = '18-01-01'\n",
    "        date_time_obj = datetime.datetime.strptime(date_time_str, '%y-%m-%d')\n",
    "        newdate = date_time_obj + datetime.timedelta(days=ds_sub.time.values[idx])\n",
    "        newdate1 = date_time_obj + datetime.timedelta(days=ds_sub.time.values[idx+1])\n",
    "        midcycdays = newdate1 - newdate\n",
    "        midcycdate = newdate + midcycdays/2\n",
    "        dates += [midcycdate]\n",
    "    # subset data to dhdt diff between orbital cycles of delta_h\n",
    "    dhdt = ds_sub.delta_h[idx+1,:,:]-ds_sub.delta_h[idx,:,:]\n",
    "    # clip data to lake area (first set crs)\n",
    "    dhdt.rio.write_crs(3031, inplace=True)\n",
    "    dhdt_clip_S09 = dhdt.rio.clip(lake_S09.geometry.values, lake_S09.crs, drop=False, invert=False)\n",
    "    dhdt_clip_SF18 = dhdt.rio.clip(lake_SF18.geometry.values, lake_SF18.crs, drop=False, invert=False)\n",
    "    # calculate lake avg. dh/dt and dv/dt time series using published static outlines\n",
    "    avg_lk_dhdt_S09 = np.nanmean(dhdt_clip_S09)\n",
    "    avg_lk_dhdt_SF18 = np.nanmean(dhdt_clip_SF18)\n",
    "    lkavgdhdt_SF18 += [avg_lk_dhdt_SF18]\n",
    "    vol_S09 = avg_lk_dhdt_S09*Smith2009_outlines[Smith2009_outlines['Name'] == lakename_S09].area\n",
    "    vol_SF18 = avg_lk_dhdt_SF18*SiegfriedFricker2018_outlines[SiegfriedFricker2018_outlines['name'] == lakename_S23]['area (m^2)']\n",
    "    vols_S09 += [vol_S09.values[0]]\n",
    "    vols_SF18 += [vol_SF18.values[0]]\n",
    "    # create contours of ice surface elevation height changes to delineate variable lake outlines\n",
    "    contours_fill = []\n",
    "    contours_drain = []   \n",
    "    polys = []\n",
    "    contour = measure.find_contours(dhdt.values, thres)\n",
    "    if len(contour) > 0: \n",
    "        contours_fill += [contour]\n",
    "    contour = measure.find_contours(dhdt.values, -thres)\n",
    "    if len(contour) > 0: \n",
    "        contours_drain += [contour]\n",
    "    # create mapping conversion factor to map array location to polar stereographic x,y\n",
    "    x_conv = (x_max-x_min)/dhdt.shape[1]\n",
    "    y_conv = (y_max-y_min)/dhdt.shape[0]\n",
    "    # plot variable outlines found in this time slice\n",
    "    # make polygons from variable outlines\n",
    "    for i in range(len(contours_fill)): \n",
    "        for j in range(len(contours_fill[i])):\n",
    "            axes[1,0].plot(x_min+contours_fill[i][j][:, 1]*x_conv, y_max-contours_fill[i][j][:, 0]*y_conv, \n",
    "            color=cmap(norm(ds_sub.time.values[idx])), linestyle=(0, (3, 1, 1, 1)), linewidth=1)\n",
    "            if len(contours_fill[i][j][:, 1]) > 2: \n",
    "                poly = Polygon(list(zip(contours_fill[i][j][:, 1]*x_conv+x_min, y_max-contours_fill[i][j][:, 0]*y_conv))) \n",
    "                polys += [poly]\n",
    "    for i in range(len(contours_drain)): \n",
    "        for j in range(len(contours_drain[i])):\n",
    "            axes[1,0].plot(x_min+contours_drain[i][j][:, 1]*x_conv, y_max-contours_drain[i][j][:, 0]*y_conv, color=cmap(norm(ds_sub.time.values[idx])), linestyle=(0, (5, 1)), linewidth=1)\n",
    "            if len(contours_drain[i][j][:, 1]) > 2: \n",
    "                poly = Polygon(list(zip(contours_drain[i][j][:, 1]*x_conv+x_min, y_max-contours_drain[i][j][:, 0]*y_conv))) \n",
    "                polys += [poly]\n",
    "    # set area to zero each time step\n",
    "    variable_area = 0\n",
    "    # if polygons are present at time step, \n",
    "    if len(polys) > 0: \n",
    "        # clip data to polygons\n",
    "        dhdt_clip = dhdt.rio.clip(polys, drop=False, invert=False)\n",
    "        # then calculate on-lake averages of dh/dt\n",
    "        avg_lk_dhdt = np.nanmean(dhdt_clip)\n",
    "        # occasionally small polygons will completely clip data resulting in nan's for lake avg. dh/dt\n",
    "        # replace with zeros\n",
    "        if math.isnan(avg_lk_dhdt): \n",
    "            avg_lk_dhdt = 0\n",
    "            lkavgdhdt_var += [avg_lk_dhdt]\n",
    "        else:\n",
    "            lkavgdhdt_var += [avg_lk_dhdt]\n",
    "            # and dv/dt\n",
    "        for i in range(len(polys)):\n",
    "            variable_area = variable_area + polys[i].area\n",
    "        vol_var = avg_lk_dhdt*variable_area\n",
    "        vols_var += [vol_var]\n",
    "    else: \n",
    "        variable_area = 0\n",
    "        avg_lk_dhdt = 0\n",
    "        lkavgdhdt_var += [avg_lk_dhdt]\n",
    "        vol_var = avg_lk_dhdt*variable_area\n",
    "        vols_var += [vol_var]\n",
    "# Change polar stereographic m to km\n",
    "km_scale = 1e3\n",
    "ticks_x = ticker.FuncFormatter(lambda x, pos: '{0:g}'.format(x/km_scale))\n",
    "axes[1,0].xaxis.set_major_formatter(ticks_x)\n",
    "ticks_y = ticker.FuncFormatter(lambda x, pos: '{0:g}'.format(x/km_scale))\n",
    "axes[1,0].yaxis.set_major_formatter(ticks_y)  \n",
    "# adjust ticks\n",
    "axes[1,0].set_yticks(np.arange(y_min,y_max,5000))\n",
    "axes[1,0].set_xticks(np.arange(y_min,y_max,5000))\n",
    "# display MOA visual imagery\n",
    "# axes[1,0].imshow(mpimg.imread('Slessor23.png'), extent=[x_min,x_max,y_min,y_max], alpha=1)\n",
    "axes[1,0].set(xlim=(x_min, x_max), ylim=(y_min, y_max))\n",
    "axes[1,0].set_xlabel('x [km]', size=15)\n",
    "axes[1,0].set_ylabel('y [km]', size=15)\n",
    "# axes[0].ticklabel_format(axis='both',scilimits=(0,0))\n",
    "# axes[0].set_title('outline comparison', pad=7.5, fontsize=17.5)\n",
    "m = plt.cm.ScalarMappable(cmap=cmap)\n",
    "m.set_array(np.array([datetime2fracyear(date_idx) for date_idx in dates[0:-1]]))\n",
    "divider = make_axes_locatable(axes[1,0])\n",
    "cax = divider.append_axes('right', size='5%', pad=0.2)\n",
    "clb = fig.colorbar(m, ticks=np.array([2019,2020,2021]),  cax=cax)\n",
    "clb.ax.set_title('Year')\n",
    "# overlay published outlines for visual comparison \n",
    "Smith2009_outlines.boundary.plot(ax=axes[1,0], color='k', linestyle=(0, (1, 5)), linewidth=1)\n",
    "SiegfriedFricker2018_SF18outlines.boundary.plot(ax=axes[1,0], color='k', linestyle=(0, (1, 1)), linewidth=1)\n",
    "Smith2009 = plt.Line2D((0, 1), (0, 0), color='k', linestyle=(0, (1, 5)), linewidth=2)\n",
    "SiegfriedFricker2018 = plt.Line2D((0, 1), (0, 0), color='k', linestyle=(0, (1, 1)), linewidth=2)\n",
    "uplift = plt.Line2D((0, 1), (0, 0), color='k', linestyle=(0, (3, 1, 1, 1)), linewidth=2)\n",
    "subsidence = plt.Line2D((0, 1), (0, 0), color='k', linestyle=(0, (5, 1)), linewidth=1)\n",
    "variable_outlines = plt.Line2D((0, 1), (0, 0), color='darkturquoise', linestyle='dashdot', linewidth=2)\n",
    "axes[1,0].legend([Smith2009,\n",
    "SiegfriedFricker2018,\n",
    "uplift, subsidence],\n",
    "    ['Smith and others, 2009 static outline',\n",
    "    'Siegfried & Fricker, 2018 static outline',\n",
    "    ('+'+str(thres)+' m uplift (filling) variable outline'), 'â€“'+str(thres)+' m subsidence (draining) variable outline'], \n",
    "    loc='upper right')\n",
    "# plot inset map to show location \n",
    "axIns = axes[1,0].inset_axes([0.005, -0.03, 0.3, 0.3])\n",
    "axIns.patch.set_facecolor('lightskyblue')\n",
    "axIns.set_aspect('equal')\n",
    "axIns.scatter(((x_max+x_min)/2), ((y_max+y_min)/2), marker='*', \n",
    "    linewidth=1, edgecolor='k', facecolor='r', s=100, zorder=3)\n",
    "Scripps_gl.plot(ax=axIns, color='ghostwhite', edgecolor='k', linewidth=0.5, zorder=2)\n",
    "# SiegfriedFricker2018_outlines.boundary.plot(ax=axIns, color='k', linestyle=(0, (1, 1)), linewidth=1)\n",
    "axIns.axis('off')\n",
    "# plot dvdt subplot\n",
    "axes[1,1].plot(dates[:idx+1], np.divide(np.cumsum(vols_S09[:idx+1]), 1e+9), color='k', linestyle=(0, (1, 5)))\n",
    "axes[1,1].plot(dates[:idx+1], np.divide(np.cumsum(vols_SF18[:idx+1]), 1e+9), color='k', linestyle=(0, (1, 1)))\n",
    "axes[1,1].plot(dates[:idx+1], np.divide(np.cumsum(vols_var[:idx+1]), 1e+9), color='darkturquoise', linestyle='dashdot')\n",
    "locator = mdates.AutoDateLocator(minticks=1, maxticks=7)\n",
    "formatter = mdates.ConciseDateFormatter(locator)\n",
    "axes[1,1].xaxis.set_major_locator(locator)\n",
    "axes[1,1].xaxis.set_major_formatter(formatter)\n",
    "min_vol = min(np.divide(min(np.cumsum(vols_S09)), 1e+9), \n",
    "                np.divide(min(np.cumsum(vols_SF18)), 1e+9), \n",
    "                np.divide(min(np.cumsum(vols_var)), 1e+9))\n",
    "max_vol = max(np.divide(max(np.cumsum(vols_S09)), 1e+9), \n",
    "                np.divide(max(np.cumsum(vols_SF18)), 1e+9), \n",
    "                np.divide(max(np.cumsum(vols_var)), 1e+9))\n",
    "if dataset2.fileName == 'mos_2010.5_2021.5.h5':\n",
    "    axes[1,1].set(xlim=(datetime.datetime(int(ds_sub.time.values[0]), 1, 1) + datetime.timedelta(days = (ds_sub.time.values[0] % 1) * 365.25), \n",
    "                        datetime.datetime(int(ds_sub.time.values[-1]), 1, 1) + datetime.timedelta(days = (ds_sub.time.values[-1] % 1) * 365.25)), \n",
    "                ylim=((min_vol - (max_vol - min_vol)*0.05),\n",
    "                        (max_vol + (max_vol - min_vol)*0.05)))\n",
    "elif dataset2.fileName == 'ATL15_AA_0311_01km_001_01.nc':    \n",
    "    axes[1,1].set(xlim=(date_time_obj + datetime.timedelta(days=ds_sub.time.values[1]),\n",
    "                        date_time_obj + datetime.timedelta(days=ds_sub.time.values[-1])), \n",
    "                ylim=((min_vol - (max_vol - min_vol)*0.05), \n",
    "                        (max_vol + (max_vol - min_vol)*0.05)))\n",
    "# axes[1].set_title('{} dVol'.format(lakename_S23), pad=7.5, fontsize=17.5)\n",
    "axes[1,1].set_xlabel('Year', size=15)\n",
    "axes[1,1].set_ylabel('Volume change [km$^3$]', size=15)\n",
    "axes[1,1].yaxis.tick_right()\n",
    "axes[1,1].yaxis.set_label_position(\"right\")\n",
    "variable_outlines = plt.Line2D((0, 1), (0, 0), color='darkturquoise', linestyle='dashdot', linewidth=2)\n",
    "axes[1,1].legend([Smith2009,\n",
    "    SiegfriedFricker2018,variable_outlines],\n",
    "                ['Smith and others, 2009 static outline',\n",
    "    'Siegfried & Fricker, 2018 static outline',\n",
    "    'Â±{} m variable outlines'.format(thres)], \n",
    "                loc='upper right')\n",
    "# save and close figure\n",
    "plt.savefig('/Users/Wilson/Documents/0-code/1-lakeshores/output_dhdvdt-using-variable-outlines/S09SF18varoutlines_agg_dvdt_plot/S09SF18varoutlines_agg_dvdt_plot-{}.png'\\\n",
    "    .format(lakename_S23), dpi=300, bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cycle through list to generate plots using function\n",
    "for idx in range(len(S09_SF18_compare_1to1)):\n",
    "    S09SF18varoutlines_agg_dvdt_plot(S09_SF18_compare_1to1[idx][0],S09_SF18_compare_1to1[idx][1], 10000, 0.5, CS2_dh, ATL15_dh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Func S09SF18S23_dhdvdt_anim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def S09SF18S23_dhdvdt_anim(lakename_S09, lakename_S23, buffer, thres, dataset): \n",
    "    '''\n",
    "    Create dh/dt plots ice surface height changes using geopandas buffer created bounding box around known lakes in Siegfried and Fricker, 2018 inventory.\n",
    "    Create time-variable outlines using skimage contour to plot variable outline alongside published outlines for comparison. \n",
    "    Use time-variable outlines to calculate dv/dt.\n",
    "    Save images together into GIF animation.\n",
    "    Inputs: \n",
    "        lakename: lake of interest from SiegfriedFricker2018_outlines inventory\n",
    "        buffer: horizontal distance in meters to create bounding box around lake of interest\n",
    "        thres(hold): vertical distance in meters to delineate ice surface deformation contour\n",
    "        dataset: dataset to be analyzed (CS2_dh or ATL15_dh)\n",
    "    Outputs: \n",
    "        Animations of planview dh/dt visuals with variable ice surface deformation contours plotted to delineate time-variable lake boundary alongside \n",
    "        2-D line plots of cumulative dVol using static and variable outlines that updates simultaneously to planview dh/dt animation.\n",
    "    '''\n",
    "    # isolate individual lake using gpd buffer\n",
    "    #lake_gpd = Smith2009_outlines.loc[Smith2009_outlines['Name'] == lakename]\n",
    "    lake_S09 = Smith2009_outlines.loc[Smith2009_outlines['Name'] == lakename_S09]\n",
    "    lake_SF18 = SiegfriedFricker2018_outlines.loc[SiegfriedFricker2018_outlines['name'] == lakename_S23]\n",
    "    lake_buffer = lake_SF18.buffer(buffer)\n",
    "    # define lake bounding box\n",
    "    x_min = lake_buffer.bounds.values[0,0]; x_max = lake_buffer.bounds.values[0,2]\n",
    "    y_min = lake_buffer.bounds.values[0,1]; y_max = lake_buffer.bounds.values[0,3]\n",
    "    # subset ATL15 data set to region of interest\n",
    "    mask_x = (dataset.x >= x_min) & (dataset.x <= x_max)\n",
    "    mask_y = (dataset.y >= y_min) & (dataset.y <= y_max)\n",
    "    ds_sub = dataset.where(mask_x & mask_y, drop=True)\n",
    "    # find magnitude of ice surface deformation in bounding box / find appropriate color map scale\n",
    "    height_anom_pos = []\n",
    "    height_anom_neg = []\n",
    "    for cyc in range(len(ds_sub.time)-1):\n",
    "        pos = np.nanmax(ds_sub.delta_h[cyc+1,:,:]-ds_sub.delta_h[cyc,:,:])\n",
    "        neg = np.nanmin(ds_sub.delta_h[cyc+1,:,:]-ds_sub.delta_h[cyc,:,:])\n",
    "        height_anom_pos += [pos]\n",
    "        height_anom_neg += [neg]\n",
    "    max_height_anom_pos = max(height_anom_pos)\n",
    "    max_height_anom_neg = min(height_anom_neg)\n",
    "    max_height_anom_abs = max(max_height_anom_pos,abs(max_height_anom_neg))\n",
    "    v = np.round(max_height_anom_abs)\n",
    "    # create empty lists to store calculated data\n",
    "    dates = []\n",
    "    lkavgdhdt_SF18 = []\n",
    "    lkavgdhdt_var = []\n",
    "    vols_S09 = []\n",
    "    vols_SF18 = []\n",
    "    vols_var = []\n",
    "    for idx in range(len(ds_sub.delta_h)-1): \n",
    "        dhdt = ds_sub.delta_h[idx+1,:,:]-ds_sub.delta_h[idx,:,:]\n",
    "        # calculate mid-cycle dates for plotting\n",
    "        if dataset.fileName == 'mos_2010.5_2021.5.h5':\n",
    "            newdate = datetime.datetime(int(ds_sub.time.values[idx]), 1, 1) + datetime.timedelta(days = (ds_sub.time.values[idx] % 1) * 365.25)\n",
    "            newdate1 = datetime.datetime(int(ds_sub.time.values[idx+1]), 1, 1) + datetime.timedelta(days = (ds_sub.time.values[idx+1] % 1) * 365.25)\n",
    "            midcycdays = newdate1 - newdate\n",
    "            midcycdate = newdate + midcycdays/2\n",
    "            dates += [midcycdate]\n",
    "        elif dataset.fileName == 'ATL15_AA_0311_01km_001_01.nc':    \n",
    "            date_time_str = '18-01-01'\n",
    "            date_time_obj = datetime.datetime.strptime(date_time_str, '%y-%m-%d')\n",
    "            newdate = date_time_obj + datetime.timedelta(days=ds_sub.time.values[idx])\n",
    "            newdate1 = date_time_obj + datetime.timedelta(days=ds_sub.time.values[idx+1])\n",
    "            midcycdays = newdate1 - newdate\n",
    "            midcycdate = newdate + midcycdays/2\n",
    "            dates += [midcycdate]\n",
    "        # clip ATL15 data to just show (first set crs)\n",
    "        dhdt.rio.write_crs(3031, inplace=True)\n",
    "        dhdt_clip_S09 = dhdt.rio.clip(lake_S09.geometry.values, lake_S09.crs, drop=False, invert=False)\n",
    "        dhdt_clip_SF18 = dhdt.rio.clip(lake_SF18.geometry.values, lake_SF18.crs, drop=False, invert=False)\n",
    "        # calculate lake avg. dh/dt and dv/dt time series using published stationary outlines\n",
    "        avg_lk_dhdt_S09 = np.nanmean(dhdt_clip_S09)\n",
    "        avg_lk_dhdt_SF18 = np.nanmean(dhdt_clip_SF18)\n",
    "        lkavgdhdt_SF18 += [avg_lk_dhdt_SF18]\n",
    "        vol_S09 = avg_lk_dhdt_S09*Smith2009_outlines[Smith2009_outlines['Name'] == lakename_S09].area\n",
    "        vol_SF18 = avg_lk_dhdt_SF18*SiegfriedFricker2018_outlines[SiegfriedFricker2018_outlines['name'] == lakename_S23]['area (m^2)']\n",
    "        vols_S09 += [vol_S09.values[0]]\n",
    "        vols_SF18 += [vol_SF18.values[0]]\n",
    "        # create contours of ice surface elevation height changes to delineate lake outlines\n",
    "        contours_fill = []\n",
    "        contours_drain = []\n",
    "        polys = []\n",
    "        contour = measure.find_contours(dhdt.values, thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_fill += [contour]\n",
    "        contour = measure.find_contours(dhdt.values, -thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_drain += [contour]\n",
    "        # create mapping conversion factor to map array location to polar stereographic x,y\n",
    "        x_conv = (x_max-x_min)/dhdt.shape[1]\n",
    "        y_conv = (y_max-y_min)/dhdt.shape[0]\n",
    "        # make polygons from variable outlines\n",
    "        for i in range(len(contours_fill)): \n",
    "            for j in range(len(contours_fill[i])):\n",
    "                if len(contours_fill[i][j][:, 1]) > 2: \n",
    "                    poly = Polygon(list(zip(x_min+contours_fill[i][j][:, 1]*x_conv, y_max-contours_fill[i][j][:, 0]*y_conv))) \n",
    "                    polys += [poly]\n",
    "        for i in range(len(contours_drain)): \n",
    "            for j in range(len(contours_drain[i])):\n",
    "                if len(contours_drain[i][j][:, 1]) > 2: \n",
    "                    poly = Polygon(list(zip(x_min+contours_drain[i][j][:, 1]*x_conv, y_max-contours_drain[i][j][:, 0]*y_conv))) \n",
    "                    polys += [poly]\n",
    "        # start with baseline variable outline area of zero\n",
    "        variable_area = 0\n",
    "        # if polygons are present at time step, \n",
    "        if len(polys) > 0: \n",
    "            # clip data to polygons (first set crs)\n",
    "            # dhdt.rio.write_crs(3031, inplace=True) # done earlier in code, may not be needed here\n",
    "            dhdt_clip = dhdt.rio.clip(polys, drop=False, invert=False)\n",
    "            # then calculate on-lake averages of dh/dt\n",
    "            avg_lk_dhdt = np.nanmean(dhdt_clip)\n",
    "            # occasionally small polygons will completely clip data resulting in nan's for lake avg. dh/dt\n",
    "            # replace with zeros\n",
    "            if math.isnan(avg_lk_dhdt): \n",
    "                avg_lk_dhdt = 0\n",
    "                lkavgdhdt_var += [avg_lk_dhdt]\n",
    "            else:\n",
    "                lkavgdhdt_var += [avg_lk_dhdt]\n",
    "            # and dv/dt\n",
    "            for i in range(len(polys)):\n",
    "                variable_area = variable_area + polys[i].area # CHANGE TO GEODESIC AREA\n",
    "            vol_var = avg_lk_dhdt*variable_area\n",
    "            vols_var += [vol_var]\n",
    "        else: \n",
    "            avg_lk_dhdt = 0\n",
    "            lkavgdhdt_var += [avg_lk_dhdt]\n",
    "            vol_var = avg_lk_dhdt*variable_area\n",
    "            vols_var += [vol_var]\n",
    "    # create colorbar axis\n",
    "    fig, axes = plt.subplots(1,2, figsize=(20,10))\n",
    "    # fig.suptitle('{} outline and dVol comparison'.format(lakename_S23), fontsize=24)\n",
    "    fig.suptitle('Mercer outline and $\\Delta$volume comparison', fontsize=30)\n",
    "    divider = make_axes_locatable(axes[0])\n",
    "    cax = divider.append_axes('right', size='5%', pad=0.2)\n",
    "    # create empty list to store animation im(age)s\n",
    "    ani = animation.PillowWriter(fps=1)\n",
    "    if dataset.fileName == 'mos_2010.5_2021.5.h5':\n",
    "        ani.setup(fig, '/Users/Wilson/Documents/0-code/1-lakeshores/output_dhdvdt-using-variable-outlines/S09SF18varoutlines_dhdvdt_anim/S09SF18varoutlines_dhdvdt_anim-{}-{}.gif'.format(lakename_S23, 'CS2'), dpi=300)\n",
    "    elif dataset.fileName == 'ATL15_AA_0311_01km_001_01.nc':    \n",
    "        ani.setup(fig, '/Users/Wilson/Documents/0-code/1-lakeshores/output_dhdvdt-using-variable-outlines/S09SF18varoutlines_dhdvdt_anim/S09SF18varoutlines_dhdvdt_anim-{}-{}.gif'.format(lakename_S23, 'IS2'), dpi=300)\n",
    "    for idx in range(len(ds_sub.delta_h)-1): \n",
    "        dhdt = ds_sub.delta_h[idx+1,:,:]-ds_sub.delta_h[idx,:,:]\n",
    "        img = axes[0].imshow(dhdt, extent=[x_min, x_max, y_min, y_max], \n",
    "            origin='upper', cmap=cmocean.cm.balance_r, vmin=-v, vmax=v)\n",
    "        # create contours of ice surface elevation height changes to delineate lake outlines\n",
    "        contours_fill = []\n",
    "        contours_drain = []\n",
    "        contour = measure.find_contours(dhdt.values, thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_fill += [contour]\n",
    "        contour = measure.find_contours(dhdt.values, -thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_drain += [contour]\n",
    "        # subplot 1: plot variable outlines found in this time slice\n",
    "        for i in range(len(contours_fill)): \n",
    "            for j in range(len(contours_fill[i])):\n",
    "                axes[0].plot(x_min+contours_fill[i][j][:, 1]*x_conv, y_max-contours_fill[i][j][:, 0]*y_conv, color='mediumblue', linestyle='dashdot', linewidth=2)\n",
    "        for i in range(len(contours_drain)): \n",
    "            for j in range(len(contours_drain[i])):\n",
    "                axes[0].plot(x_min+contours_drain[i][j][:, 1]*x_conv, y_max-contours_drain[i][j][:, 0]*y_conv, color='maroon', linestyle=(0, (3, 1, 1, 1)), linewidth=2)\n",
    "        axes[0].set(xlim=(x_min, x_max), ylim=(y_min, y_max))\n",
    "        axes[0].set_xlabel('polar stereographic x [m]', size=15)\n",
    "        axes[0].set_ylabel('polar stereographic y [m]', size=15)\n",
    "        axes[0].ticklabel_format(axis='both',scilimits=(0,0))\n",
    "        axes[0].set_title('dh/dt $h_{'+dates[idx].strftime('%m/%Y')+'} - h_{'+dates[idx-1].strftime('%m/%Y')+'}$', pad=7.5, fontsize=17.5)\n",
    "        fig.colorbar(img, cax=cax).set_label('Height (h) change [m]', size=15)\n",
    "        # overlay published outlines for visual comparison \n",
    "        Smith2009_outlines.boundary.plot(ax=axes[0], color='k', linestyle='--', linewidth=1)\n",
    "        SiegfriedFricker2018_outlines[SiegfriedFricker2018_outlines['cite'] != 'Smith and others, 2009, J. Glac., doi:10.3189/002214309789470879']\\\n",
    "            .boundary.plot(ax=axes[0], color='k', linestyle='-', linewidth=1)\n",
    "        Smith2009 = plt.Line2D((0, 1), (0, 0), color='k', linestyle='--', linewidth=2)\n",
    "        SiegfriedFricker2018 = plt.Line2D((0, 1), (0, 0), color='k', linestyle='-', linewidth=2)\n",
    "        uplift = plt.Line2D((0, 1), (0, 0), color='mediumblue', linestyle='dashdot', linewidth=2)\n",
    "        subsidence = plt.Line2D((0, 1), (0, 0), color='maroon', linestyle=(0, (3, 1, 1, 1)), linewidth=2)\n",
    "        axes[0].legend([Smith2009,SiegfriedFricker2018,uplift, subsidence],\n",
    "            ['Smith and others, 2009 static outline','Siegfried & Fricker, 2018 static outline',\n",
    "            ('+'+str(thres)+' m uplift (filling) variable outline'), 'â€“'+str(thres)+' m subsidence (draining) variable outline'], \n",
    "            loc='upper right')\n",
    "        # plot inset map to show location \n",
    "        axIns = axes[0].inset_axes([0.001, 0.77, 0.25, 0.25])\n",
    "        axIns.patch.set_facecolor('lightskyblue')\n",
    "        axIns.set_aspect('equal')\n",
    "        axIns.scatter(((x_max+x_min)/2), ((y_max+y_min)/2), marker='*', \n",
    "            linewidth=1, edgecolor='k', facecolor='r', s=100, zorder=3)\n",
    "        Scripps_gl.plot(ax=axIns, color='ghostwhite', edgecolor='k', linewidth=0.5, zorder=2)\n",
    "        SiegfriedFricker2018_outlines.boundary.plot(ax=axIns, color='k', linestyle=(0, (1, 1)), linewidth=1)\n",
    "        axIns.axis('off')\n",
    "        # suplot 2: plot volume change time series\n",
    "        axes[1].plot(dates[:idx+1], np.divide(np.cumsum(vols_S09[:idx+1]), 1e+9), color='k', linestyle='--')\n",
    "        axes[1].plot(dates[:idx+1], np.divide(np.cumsum(vols_SF18[:idx+1]), 1e+9), color='k', linestyle='-')\n",
    "        axes[1].plot(dates[:idx+1], np.divide(np.cumsum(vols_var[:idx+1]), 1e+9), color='darkturquoise', linestyle='dashdot')\n",
    "        locator = mdates.AutoDateLocator(minticks=1, maxticks=7)\n",
    "        formatter = mdates.ConciseDateFormatter(locator)\n",
    "        axes[1].xaxis.set_major_locator(locator)\n",
    "        axes[1].xaxis.set_major_formatter(formatter)\n",
    "        min_vol = min(np.divide(min(np.cumsum(vols_S09)), 1e+9), \n",
    "                        np.divide(min(np.cumsum(vols_SF18)), 1e+9), \n",
    "                        np.divide(min(np.cumsum(vols_var)), 1e+9))\n",
    "        max_vol = max(np.divide(max(np.cumsum(vols_S09)), 1e+9), \n",
    "                        np.divide(max(np.cumsum(vols_SF18)), 1e+9), \n",
    "                        np.divide(max(np.cumsum(vols_var)), 1e+9))\n",
    "        if dataset.fileName == 'mos_2010.5_2021.5.h5':\n",
    "            axes[1].set(xlim=(datetime.datetime(int(ds_sub.time.values[0]), 1, 1) + datetime.timedelta(days = (ds_sub.time.values[0] % 1) * 365.25), \n",
    "                                datetime.datetime(int(ds_sub.time.values[-1]), 1, 1) + datetime.timedelta(days = (ds_sub.time.values[-1] % 1) * 365.25)), \n",
    "                        ylim=((min_vol - (max_vol - min_vol)*0.05),\n",
    "                                (max_vol + (max_vol - min_vol)*0.05)))\n",
    "        elif dataset.fileName == 'ATL15_AA_0311_01km_001_01.nc':    \n",
    "            axes[1].set(xlim=(date_time_obj + datetime.timedelta(days=ds_sub.time.values[1]),\n",
    "                                date_time_obj + datetime.timedelta(days=ds_sub.time.values[-1])), \n",
    "                        ylim=((min_vol - (max_vol - min_vol)*0.05), \n",
    "                                (max_vol + (max_vol - min_vol)*0.05)))\n",
    "        # axes[1].set_title('{} dVol'.format(lakename_S23), pad=7.5, fontsize=17.5)\n",
    "        axes[1].set_xlabel('Year', size=15)\n",
    "        axes[1].set_ylabel('Volume change [km$^3$]', size=15)\n",
    "        axes[1].yaxis.tick_right()\n",
    "        axes[1].yaxis.set_label_position(\"right\")\n",
    "        variable_outlines = plt.Line2D((0, 1), (0, 0), color='darkturquoise', linestyle='dashdot', linewidth=2)\n",
    "        axes[1].legend([Smith2009,\n",
    "            SiegfriedFricker2018,variable_outlines],\n",
    "                        ['Smith and others, 2009 static outline',\n",
    "            'Siegfried & Fricker, 2018 static outline',\n",
    "            'Â±{} m variable outlines'.format(thres)], \n",
    "                        loc='upper left')\n",
    "        # Append im(image to animation list\n",
    "        ani.grab_frame()\n",
    "        axes[0].clear()\n",
    "    # create animation and save, adjust interval\n",
    "    ani.finish()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Func S09SF18S23_dhdvdt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def S09SF18S23_dhdvdt(lakename_S23, buffer, thres, dataset): \n",
    "    '''\n",
    "    Function to calculate the lake avg. dh/dt and dv/dt using static and time-variable subglacial\n",
    "    lake outlines from the latest published lake inventories and a time-variable method to create outlines\n",
    "    based on contours of ice surface height anomalies. \n",
    "    Lake avg. dh/dt and dv/dt are plotted as 2D line plots for comparison.\n",
    "    Inputs: \n",
    "        lakename_S23: lake of interest from SiegfriedFricker2018_outlines inventory\n",
    "        buffer: horizontal distance in meters to create bounding box around lakes of interest\n",
    "        thres(hold): vertical distance in meters to delineate ice surface deformation contour\n",
    "        dataset: dataset to be analyzed (CS2_dh or ATL15_dh)\n",
    "    Outputs: \n",
    "        Exported 2-D line plots of lake avg. dh/dt and dv/dt and lakes delineated \n",
    "        using outlines from two compilations in available in literature and \n",
    "        time-variable outlines created from ice surface deformation contours.\n",
    "    '''\n",
    "    # isolate individual lake using gpd buffer\n",
    "    #lake_S09 = Smith2009_outlines.loc[Smith2009_outlines['Name'] == lakename_S09]\n",
    "    lake_SF18 = SiegfriedFricker2018_outlines.loc[SiegfriedFricker2018_outlines['name'] == lakename_S23]\n",
    "    lake_buffer_SF18 = lake_SF18.buffer(buffer)\n",
    "    # define lake bounding box\n",
    "    x_min = lake_buffer_SF18.bounds.values[0,0]\n",
    "    x_max = lake_buffer_SF18.bounds.values[0,2]\n",
    "    y_min = lake_buffer_SF18.bounds.values[0,1]\n",
    "    y_max = lake_buffer_SF18.bounds.values[0,3]\n",
    "    # subset ATL15 data set to region of interest\n",
    "    mask_x = (dataset.x >= x_min) & (dataset.x <= x_max)\n",
    "    mask_y = (dataset.y >= y_min) & (dataset.y <= y_max)\n",
    "    ds_sub = dataset.where(mask_x & mask_y, drop=True)\n",
    "    # find magnitude of ice surface deformation in bounding box\n",
    "    height_anom_pos = []\n",
    "    height_anom_neg = []\n",
    "    for cyc in range(len(ds_sub.time)-1):\n",
    "        pos = np.nanmax(ds_sub.delta_h[cyc+1,:,:]-ds_sub.delta_h[cyc,:,:])\n",
    "        neg = np.nanmin(ds_sub.delta_h[cyc+1,:,:]-ds_sub.delta_h[cyc,:,:])\n",
    "        height_anom_pos += [pos]\n",
    "        height_anom_neg += [neg]\n",
    "    max_height_anom_pos = max(height_anom_pos)\n",
    "    max_height_anom_neg = min(height_anom_neg)\n",
    "    max_height_anom_abs = max(max_height_anom_pos,abs(max_height_anom_neg))\n",
    "    v = np.round(max_height_anom_abs)\n",
    "    # create empty lists to store calculated data\n",
    "    dates = []\n",
    "    lkavgdhdt_SF18 = []\n",
    "    lkavgdhdt_var = []\n",
    "    vols_SF18 = []\n",
    "    vols_var = []\n",
    "    for idx in range(len(ds_sub.delta_h)-1): \n",
    "        # calculate mid-cycle dates for plotting\n",
    "        if dataset.fileName == 'mos_2010.5_2021.5.h5':\n",
    "            newdate = datetime.datetime(int(ds_sub.time.values[idx]), 1, 1) + datetime.timedelta(days = (ds_sub.time.values[idx] % 1) * 365.25)\n",
    "            newdate1 = datetime.datetime(int(ds_sub.time.values[idx+1]), 1, 1) + datetime.timedelta(days = (ds_sub.time.values[idx+1] % 1) * 365.25)\n",
    "            midcycdays = newdate1 - newdate\n",
    "            midcycdate = newdate + midcycdays/2\n",
    "            dates += [midcycdate]\n",
    "        elif dataset.fileName == 'ATL15_AA_0311_01km_001_01.nc':    \n",
    "            date_time_str = '18-01-01'\n",
    "            date_time_obj = datetime.datetime.strptime(date_time_str, '%y-%m-%d')\n",
    "            newdate = date_time_obj + datetime.timedelta(days=ds_sub.time.values[idx])\n",
    "            newdate1 = date_time_obj + datetime.timedelta(days=ds_sub.time.values[idx+1])\n",
    "            midcycdays = newdate1 - newdate\n",
    "            midcycdate = newdate + midcycdays/2\n",
    "            dates += [midcycdate]\n",
    "        # subset data to dhdt diff between orbital cycles of delta_h\n",
    "        dhdt = ds_sub.delta_h[idx+1,:,:]-ds_sub.delta_h[idx,:,:]\n",
    "        # clip ATL15 data to just show (first set crs)\n",
    "        dhdt.rio.write_crs(3031, inplace=True)\n",
    "        dhdt_clip_SF18 = dhdt.rio.clip(lake_SF18.geometry.values, lake_SF18.crs, drop=False, invert=False)\n",
    "        # calculate lake avg. dh/dt and dv/dt time series using published stationary outlines\n",
    "        avg_lk_dhdt_SF18 = np.nanmean(dhdt_clip_SF18)\n",
    "        lkavgdhdt_SF18 += [avg_lk_dhdt_SF18]\n",
    "        vol_SF18 = avg_lk_dhdt_SF18*SiegfriedFricker2018_outlines[SiegfriedFricker2018_outlines['name'] == lakename_S23]['area (m^2)']\n",
    "        vols_SF18 += [vol_SF18.values[0]]\n",
    "        # create contours of ice surface elevation height changes to delineate lake outlines using time-variable method\n",
    "        contours_fill = []\n",
    "        contours_drain = []\n",
    "        contour = measure.find_contours(dhdt.values, thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_fill += [contour]\n",
    "        contour = measure.find_contours(dhdt.values, -thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_drain += [contour]\n",
    "        # create mapping conversion factor to map array location to polar stereographic x,y\n",
    "        x_conv = (x_max-x_min)/dhdt.shape[1]\n",
    "        y_conv = (y_max-y_min)/dhdt.shape[0]\n",
    "        polys = []\n",
    "        for i in range(len(contours_fill)): \n",
    "            for j in range(len(contours_fill[i])):\n",
    "                if len(contours_fill[i][j][:, 1]) > 2: \n",
    "                    poly = Polygon(list(zip(contours_fill[i][j][:, 1]*x_conv+x_min, y_max-contours_fill[i][j][:, 0]*y_conv))) \n",
    "                    polys += [poly]\n",
    "        for i in range(len(contours_drain)): \n",
    "            for j in range(len(contours_drain[i])):\n",
    "                if len(contours_drain[i][j][:, 1]) > 2: \n",
    "                    poly = Polygon(list(zip(contours_drain[i][j][:, 1]*x_conv+x_min, y_max-contours_drain[i][j][:, 0]*y_conv))) \n",
    "                    polys += [poly]\n",
    "        # if polygons are present at time step, \n",
    "        variable_area = 0\n",
    "        if len(polys) > 0: \n",
    "            # clip data to polygons (first set crs)\n",
    "            # dhdt.rio.write_crs(3031, inplace=True) # done earlier in code, may not be needed here\n",
    "            dhdt_clip = dhdt.rio.clip(polys, drop=False, invert=False)\n",
    "            # then calculate on-lake averages of dh/dt\n",
    "            avg_lk_dhdt = np.nanmean(dhdt_clip)\n",
    "            # occasionally small polygons will completely clip data resulting in nan's for lake avg. dh/dt\n",
    "            # replay with zeros\n",
    "            if math.isnan(avg_lk_dhdt): \n",
    "                avg_lk_dhdt = 0\n",
    "                lkavgdhdt_var += [avg_lk_dhdt]\n",
    "            else:\n",
    "                lkavgdhdt_var += [avg_lk_dhdt]\n",
    "                # and dv/dt\n",
    "            for i in range(len(polys)):\n",
    "                variable_area = variable_area + polys[i].area\n",
    "            vol_var = avg_lk_dhdt*variable_area\n",
    "            vols_var += [vol_var]\n",
    "        else: \n",
    "            avg_lk_dhdt = 0\n",
    "            lkavgdhdt_var += [avg_lk_dhdt]\n",
    "            vol_var = avg_lk_dhdt*variable_area\n",
    "            vols_var += [vol_var]\n",
    "    # plot lake avg. height time series\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(dates, lkavgdhdt_SF18, color='k', linestyle='dashed')   \n",
    "    ax.plot(dates, lkavgdhdt_var, color='darkturquoise', linestyle='dashdot')\n",
    "    locator = mdates.AutoDateLocator(minticks=1, maxticks=7)\n",
    "    formatter = mdates.ConciseDateFormatter(locator)\n",
    "    ax.xaxis.set_major_locator(locator)\n",
    "    ax.xaxis.set_major_formatter(formatter)\n",
    "    ax.set_title('{} vs. variable outlines \\nlake average dh/dt'.format(lakename_S23))\n",
    "    ax.set_xlabel('Year')\n",
    "    ax.set_ylabel('Avg. height change from previous cycle [m]')\n",
    "    Smith2009 = plt.Line2D((0, 1), (0, 0), color='k', linestyle='dotted', linewidth=2)\n",
    "    SiegfriedFricker2018 = plt.Line2D((0, 1), (0, 0), color='k', linestyle='dashed', linewidth=2)\n",
    "    variable_outlines = plt.Line2D((0, 1), (0, 0), color='darkturquoise', linestyle='dashdot', linewidth=2)\n",
    "    ax.legend([SiegfriedFricker2018,variable_outlines],\n",
    "        ['Siegfried & Fricker, 2018',\n",
    "        'Â±{} m variable outlines'.format(thres)], \n",
    "        loc='best')          \n",
    "    if dataset.fileName == 'mos_2010.5_2021.5.h5':\n",
    "        plt.savefig('/Users/Wilson/Documents/0-code/1-lakeshores/output_dhdvdt-using-variable-outlines/S09SF18varoutlines_dhdvdt/S09SF18varoutlines_dhdt-{}-{}.png'\\\n",
    "            .format(lakename_S23, 'CS2'), dpi=300, bbox_inches = \"tight\")\n",
    "    elif dataset.fileName == 'ATL15_AA_0311_01km_001_01.nc':    \n",
    "        plt.savefig('/Users/Wilson/Documents/0-code/1-lakeshores/output_dhdvdt-using-variable-outlines/S09SF18varoutlines_dhdvdt/S09SF18varoutlines_dhdt-{}-{}.png'\\\n",
    "            .format(lakename_S23, 'IS2'), dpi=300, bbox_inches = \"tight\")\n",
    "    plt.close()\n",
    "    # plot volume change time series\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(dates, np.divide(np.cumsum(vols_SF18), 1e+9), color='k', linestyle='dashed')\n",
    "    ax.plot(dates, np.divide(np.cumsum(vols_var), 1e+9), color='darkturquoise', linestyle='dashdot')\n",
    "    locator = mdates.AutoDateLocator(minticks=1, maxticks=7)\n",
    "    formatter = mdates.ConciseDateFormatter(locator)\n",
    "    ax.xaxis.set_major_locator(locator)\n",
    "    ax.xaxis.set_major_formatter(formatter)\n",
    "    # ax.set_title('{} vs. variable outlines \\nvolume change time series'.format(lakename_S23))\n",
    "    ax.set_xlabel('Year')\n",
    "    ax.set_ylabel('Volume change from previous cycle [km$^3$]')\n",
    "    ax.legend([SiegfriedFricker2018,variable_outlines],\n",
    "        ['Siegfried & Fricker, 2018',\n",
    "        'Â±{} m variable outlines'.format(thres)], \n",
    "        loc='best')  \n",
    "    if dataset.fileName == 'mos_2010.5_2021.5.h5':\n",
    "        plt.savefig('/Users/Wilson/Documents/0-code/1-lakeshores/output_dhdvdt-using-variable-outlines/S09SF18varoutlines_dhdvdt/S09SF18varoutlines_dvdt-{}-{}.png'\\\n",
    "            .format(lakename_S23, 'CS2'), dpi=300, bbox_inches = \"tight\")\n",
    "    elif dataset.fileName == 'ATL15_AA_0311_01km_001_01.nc':    \n",
    "        plt.savefig('/Users/Wilson/Documents/0-code/1-lakeshores/output_dhdvdt-using-variable-outlines/S09SF18varoutlines_dhdvdt/S09SF18varoutlines_dvdt-{}-{}.png'\\\n",
    "            .format(lakename_S23, 'IS2'), dpi=300, bbox_inches = \"tight\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test function working using one lake\n",
    "# S09SF18varoutlines_dhdvdt('Whillans_7', 10000, 0.75, CS2_dh)\n",
    "S09SF18varoutlines_dhdvdt('Whillans_7', 10000, 0.75, ATL15_dh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# may make more sense do this function on individual lakes after seeing their dhdt plot to confirm all of variable outline is capture in bounding box\n",
    "# for idx in range(len(SiegfriedFricker2018_outlines)-1):\n",
    "#     lakename=SiegfriedFricker2018_outlines['name'][idx]\n",
    "#     S09SF18varoutlines_dhdvdt(lakename, 5000, 0.75, CS2_dh)\n",
    "#     # S09SF18varoutlines_dhdvdt(lakename, 5000, 0.75, ATL15_dh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# increase buffer for one lake\n",
    "dhdvdt_compare_static_variable_outlines('Slessor_23', 7500, 0.75, CS2_dh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ATL15_dhdvdt_compare_2static_variable_outlines(lakename_S09, lakename_S23, buffer, thres): \n",
    "    '''\n",
    "    Function to calculate the lake avg. dh/dt and dv/dt using static and time-variable subglacial\n",
    "    lake outlines from two lake inventories and a time-variable method to create outlines. Lake avg. \n",
    "    dh/dt and dv/dt are plotted as 2D line plots for comparison.\n",
    "    Inputs: \n",
    "        lakename_S09: lake of interest from Smith2009_outlines inventory\n",
    "        lakename_S23: co-located lake of interest from SiegfriedFricker2018_outlines inventory\n",
    "        buffer: horizontal distance in meters to create bounding box around lakes of interest\n",
    "        thres(hold): vertical distance in meters to delineate ice surface deformation contour\n",
    "    Outputs: \n",
    "        Exported 2-D line plots of lake avg. dh/dt and dv/dt using ICESat-2 ATL15 data and \n",
    "        lakes delineated using outlines from two compilations in available in literature and \n",
    "        time-variable outlines created from ice surface deformation contours.\n",
    "    '''\n",
    "    # isolate individual lake using gpd buffer\n",
    "    lake_S09 = Smith2009_outlines.loc[Smith2009_outlines['Name'] == lakename_S09]\n",
    "    lake_SF18 = SiegfriedFricker2018_outlines.loc[SiegfriedFricker2018_outlines['name'] == lakename_S23]\n",
    "    lake_buffer_S09 = lake_S09.buffer(buffer)\n",
    "    lake_buffer_SF18 = lake_SF18.buffer(buffer)\n",
    "    # define lake bounding box\n",
    "    x_min = min(lake_buffer_S09.bounds.values[0,0],lake_buffer_SF18.bounds.values[0,0])\n",
    "    x_max = max(lake_buffer_S09.bounds.values[0,2],lake_buffer_SF18.bounds.values[0,2])\n",
    "    y_min = min(lake_buffer_S09.bounds.values[0,1],lake_buffer_SF18.bounds.values[0,1])\n",
    "    y_max = max(lake_buffer_S09.bounds.values[0,3],lake_buffer_SF18.bounds.values[0,3])\n",
    "    # subset ATL15 data set to region of interest\n",
    "    mask_x = (ATL15_dh.x >= x_min) & (ATL15_dh.x <= x_max)\n",
    "    mask_y = (ATL15_dh.y >= y_min) & (ATL15_dh.y <= y_max)\n",
    "    ATL15_dh_sub = ATL15_dh.where(mask_x & mask_y, drop=True)\n",
    "    # find magnitude of ice surface deformation in bounding box\n",
    "    height_anom_pos = []\n",
    "    height_anom_neg = []\n",
    "    for cyc in range(len(ATL15_dh_sub.time)-1):\n",
    "        pos = np.nanmax(ATL15_dh_sub.delta_h[cyc+1,:,:]-ATL15_dh_sub.delta_h[cyc,:,:])\n",
    "        neg = np.nanmin(ATL15_dh_sub.delta_h[cyc+1,:,:]-ATL15_dh_sub.delta_h[cyc,:,:])\n",
    "        height_anom_pos += [pos]\n",
    "        height_anom_neg += [neg]\n",
    "    max_height_anom_pos = max(height_anom_pos)\n",
    "    max_height_anom_neg = min(height_anom_neg)\n",
    "    max_height_anom_abs = max(max_height_anom_pos,abs(max_height_anom_neg))\n",
    "    v = np.round(max_height_anom_abs)\n",
    "    # create empty lists to store calculated data\n",
    "    IS2_dates = []\n",
    "    IS2_lkavgdhdt_S09 = []\n",
    "    IS2_lkavgdhdt_SF18 = []\n",
    "    IS2_lkavgdhdt = []\n",
    "    IS2_vols_S09 = []\n",
    "    IS2_vols_SF18 = []\n",
    "    IS2_vols = []\n",
    "    for idx in range(len(ATL15_dh_sub.delta_h)-1): \n",
    "        # calculate mid-cycle dates for plotting\n",
    "        date_time_str = '18-01-01'\n",
    "        date_time_obj = datetime.datetime.strptime(date_time_str, '%y-%m-%d')\n",
    "        newdate = date_time_obj + datetime.timedelta(days=ATL15_dh_sub.time.values[idx])\n",
    "        newdate1 = date_time_obj + datetime.timedelta(days=ATL15_dh_sub.time.values[idx+1])\n",
    "        midcycdays = newdate1 - newdate\n",
    "        midcycdate = newdate + midcycdays/2\n",
    "        IS2_dates += [midcycdate]\n",
    "        # subset data to dhdt diff between orbital cycles of delta_h\n",
    "        dhdt = ATL15_dh_sub.delta_h[idx+1,:,:]-ATL15_dh_sub.delta_h[idx,:,:]\n",
    "        # clip ATL15 data to just show (first set crs)\n",
    "        dhdt.rio.write_crs(3031, inplace=True)\n",
    "        dhdt_clip_S09 = dhdt.rio.clip(lake_S09.geometry.values, lake_S09.crs, drop=False, invert=False)\n",
    "        dhdt_clip_SF18 = dhdt.rio.clip(lake_SF18.geometry.values, lake_SF18.crs, drop=False, invert=False)\n",
    "        # calculate lake avg. dh/dt and dv/dt time series using published stationary outlines\n",
    "        avg_lk_dhdt_S09 = np.ma.average(np.ma.MaskedArray(dhdt_clip_S09, mask=np.isnan(dhdt_clip_S09)))\n",
    "        IS2_lkavgdhdt_S09 += [avg_lk_dhdt_S09]\n",
    "        vol_S09 = avg_lk_dhdt_S09*Smith2009_outlines[Smith2009_outlines['Name'] == lakename_S09].area\n",
    "        IS2_vols_S09 += [vol_S09.values[0]]\n",
    "        avg_lk_dhdt_SF18 = np.ma.average(np.ma.MaskedArray(dhdt_clip_SF18, mask=np.isnan(dhdt_clip_SF18)))\n",
    "        IS2_lkavgdhdt_SF18 += [avg_lk_dhdt_SF18]\n",
    "        vol_SF18 = avg_lk_dhdt_SF18*SiegfriedFricker2018_outlines[SiegfriedFricker2018_outlines['name'] == lakename_S23]['area (m^2)']\n",
    "        IS2_vols_SF18 += [vol_SF18.values[0]]\n",
    "        # create contours of ice surface elevation height changes to delineate lake outlines using time-variable method\n",
    "        contours_fill = []\n",
    "        contours_drain = []\n",
    "        contour = measure.find_contours(dhdt.values, thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_fill += [contour]\n",
    "        contour = measure.find_contours(dhdt.values, -thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_drain += [contour]\n",
    "        # create mapping conversion factor to map array location to polar stereographic x,y\n",
    "        x_conv = (x_max-x_min)/dhdt.shape[1]\n",
    "        y_conv = (y_max-y_min)/dhdt.shape[0]\n",
    "        # make polygons from contours\n",
    "        polys = []\n",
    "        for i in range(len(contours_fill)): \n",
    "            for j in range(len(contours_fill[i])):\n",
    "                if len(contours_fill[i][j][:, 1]) > 2: \n",
    "                    poly = Polygon(list(zip(contours_fill[i][j][:, 1]*x_conv+x_min, y_max-contours_fill[i][j][:, 0]*y_conv))) \n",
    "                    polys += [poly]\n",
    "        for i in range(len(contours_drain)): \n",
    "            for j in range(len(contours_drain[i])):\n",
    "                if len(contours_drain[i][j][:, 1]) > 2: \n",
    "                    poly = Polygon(list(zip(contours_drain[i][j][:, 1]*x_conv+x_min, y_max-contours_drain[i][j][:, 0]*y_conv))) \n",
    "                    polys += [poly]\n",
    "        # if polygons are present at time step, \n",
    "        variable_area = 0\n",
    "        if len(polys) > 0: \n",
    "            # clip data to polygons (first set crs)\n",
    "            # dhdt.rio.write_crs(3031, inplace=True) # done earlier in code, may not be needed here\n",
    "            dhdt_clip = dhdt.rio.clip(polys, drop=False, invert=False)\n",
    "            # then calculate on-lake averages of dh/dt\n",
    "            avg_lk_dhdt = np.nanmean(dhdt_clip)\n",
    "            # occaisionally small polygons will completely clip data resulting in nan's for lake avg. dh/dt\n",
    "            # replay with zeros\n",
    "            if math.isnan(avg_lk_dhdt): \n",
    "                avg_lk_dhdt = 0\n",
    "                IS2_lkavgdhdt += [avg_lk_dhdt]\n",
    "            else:\n",
    "                IS2_lkavgdhdt += [avg_lk_dhdt]\n",
    "                # and dv/dt\n",
    "            for i in range(len(polys)):\n",
    "                variable_area = variable_area + polys[i].area\n",
    "            vol = avg_lk_dhdt*variable_area\n",
    "            IS2_vols += [vol]\n",
    "        else: \n",
    "            avg_lk_dhdt = 0\n",
    "            IS2_lkavgdhdt += [avg_lk_dhdt]\n",
    "            vol = avg_lk_dhdt*variable_area\n",
    "            IS2_vols += [vol]\n",
    "\n",
    "    # plot lake avg. height time series\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(IS2_dates, IS2_lkavgdhdt_S09, color='k', linestyle='dotted')\n",
    "    ax.plot(IS2_dates, IS2_lkavgdhdt_SF18, color='k', linestyle='dashed')   \n",
    "    ax.plot(IS2_dates, IS2_lkavgdhdt, color='darkturquoise', linestyle='dashdot')\n",
    "    locator = mdates.AutoDateLocator(minticks=1, maxticks=7)\n",
    "    formatter = mdates.ConciseDateFormatter(locator)\n",
    "    ax.xaxis.set_major_locator(locator)\n",
    "    ax.xaxis.set_major_formatter(formatter)\n",
    "    ax.set_title('{} vs. {} vs. variable outlines \\nlake average dh/dt'.format(lakename_S09, lakename_S23))\n",
    "    ax.set_xlabel('Year')\n",
    "    ax.set_ylabel('Avg. height change from previous cycle [m]')\n",
    "    Smith2009 = plt.Line2D((0, 1), (0, 0), color='k', linestyle='dotted', linewidth=2)\n",
    "    SiegfriedFricker2018 = plt.Line2D((0, 1), (0, 0), color='k', linestyle='dashed', linewidth=2)\n",
    "    variable_outlines = plt.Line2D((0, 1), (0, 0), color='darkturquoise', linestyle='dashdot', linewidth=2)\n",
    "    ax.legend([Smith2009,SiegfriedFricker2018,variable_outlines],\n",
    "        ['Smith and others, 2009','Siegfried & Fricker, 2018',\n",
    "        'variable outlines'], \n",
    "        loc='best')          \n",
    "    plt.savefig('/Users/Wilson/Documents/0-code/1-lakeshores/output_dhdvdt-using-variable-outlines/IS2-outlinecompare-lineplots/IS2-avglkdhdt-{}vs{}.png'\\\n",
    "    .format(lakename_S09, lakename_S23), dpi=300, bbox_inches = \"tight\")\n",
    "    plt.close()\n",
    "    # plot volume change time series\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(IS2_dates, np.divide(np.cumsum(IS2_vols_S09), 1e+9), color='k', linestyle='dotted')\n",
    "    ax.plot(IS2_dates, np.divide(np.cumsum(IS2_vols_SF18), 1e+9), color='k', linestyle='dashed')\n",
    "    ax.plot(IS2_dates, np.divide(np.cumsum(IS2_vols), 1e+9), color='darkturquoise', linestyle='dashdot')\n",
    "    locator = mdates.AutoDateLocator(minticks=1, maxticks=7)\n",
    "    formatter = mdates.ConciseDateFormatter(locator)\n",
    "    ax.xaxis.set_major_locator(locator)\n",
    "    ax.xaxis.set_major_formatter(formatter)\n",
    "    ax.set_title('{} vs. {} vs. variable outlines \\ndv/dt'.format(lakename_S09, lakename_S23))\n",
    "    ax.set_xlabel('Year')\n",
    "    ax.set_ylabel('Volume change from previous cycle [km$^3$]')\n",
    "    ax.legend([Smith2009,SiegfriedFricker2018,variable_outlines],\n",
    "        ['Smith and others, 2009','Siegfried & Fricker, 2018',\n",
    "        'variable outlines'], \n",
    "        loc='best')  \n",
    "    plt.savefig('/Users/Wilson/Documents/0-code/1-lakeshores/output_dhdvdt-using-variable-outlines/IS2-outlinecompare-lineplots/IS2-dvdt-{}vs{}.png'\\\n",
    "    .format(lakename_S09, lakename_S23), dpi=300, bbox_inches = \"tight\")\n",
    "    plt.close()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cycle through list to generate plots using function\n",
    "for idx in range(len(S09_SF18_compare)):\n",
    "    ATL15_dhdvdt_compare_2static_variable_outlines(S09_SF18_compare[idx][0],S09_SF18_compare[idx][1], 1000, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recently added dataset kwarg but haven't debugged yet\n",
    "def dhdvdt_compare_2to1static_variable_outlines(lakename1_S09, lakename2_S09, lakename_S23, buffer, thres, dataset): \n",
    "    '''\n",
    "    Function to calculate the lake avg. dh/dt and dv/dt using static and time-variable subglacial\n",
    "    lake outlines from two lake inventories (where 2 lakes were redelineated as 1) and a time-variable \n",
    "    method to create outlines. Lake avg. dh/dt and dv/dt are plotted as 2D line plots for comparison.\n",
    "    Inputs: \n",
    "        lakename1_S09: first lake of interest from Smith2009_outlines inventory\n",
    "        lakename2_S09: second lake of interest from Smith2009_outlines inventory\n",
    "        lakename_S23: co-located lake of interest from SiegfriedFricker2018_outlines inventory\n",
    "        buffer: horizontal distance in meters to create bounding box around lakes of interest\n",
    "        thres(hold): vertical distance in meters to delineate ice surface deformation contour\n",
    "    Outputs: \n",
    "        Exported 2-D line plots of lake avg. dh/dt and dv/dt using ICESat-2 ATL15 data and \n",
    "        lakes delineated using outlines from two compilations in available in literature and \n",
    "        time-variable outlines created from ice surface deformation contours.\n",
    "    '''\n",
    "    # isolate individual lake using gpd buffer\n",
    "    lake1_S09 = Smith2009_outlines.loc[Smith2009_outlines['Name'] == lakename1_S09]\n",
    "    lake2_S09 = Smith2009_outlines.loc[Smith2009_outlines['Name'] == lakename2_S09]\n",
    "    lake_SF18 = SiegfriedFricker2018_outlines.loc[SiegfriedFricker2018_outlines['name'] == lakename_S23]\n",
    "    lake1_buffer_S09 = lake1_S09.buffer(buffer)\n",
    "    lake2_buffer_S09 = lake2_S09.buffer(buffer)\n",
    "    lake_buffer_SF18 = lake_SF18.buffer(buffer)\n",
    "    # define lake bounding box\n",
    "    x_min = min(lake1_buffer_S09.bounds.values[0,0],lake2_buffer_S09.bounds.values[0,0],lake_buffer_SF18.bounds.values[0,0])\n",
    "    x_max = max(lake1_buffer_S09.bounds.values[0,2],lake2_buffer_S09.bounds.values[0,2],lake_buffer_SF18.bounds.values[0,2])\n",
    "    y_min = min(lake1_buffer_S09.bounds.values[0,1],lake2_buffer_S09.bounds.values[0,1],lake_buffer_SF18.bounds.values[0,1])\n",
    "    y_max = max(lake1_buffer_S09.bounds.values[0,3],lake2_buffer_S09.bounds.values[0,3],lake_buffer_SF18.bounds.values[0,3])\n",
    "    # subset ATL15 data set to region of interest\n",
    "    mask_x = (dataset.x >= x_min) & (dataset.x <= x_max)\n",
    "    mask_y = (dataset.y >= y_min) & (dataset.y <= y_max)\n",
    "    ds_sub = dataset.where(mask_x & mask_y, drop=True)\n",
    "    # find magnitude of ice surface deformation in bounding box\n",
    "    height_anom_pos = []\n",
    "    height_anom_neg = []\n",
    "    for cyc in range(len(ds_sub.time)-1):\n",
    "        pos = np.nanmax(ds_sub.delta_h[cyc+1,:,:]-ds_sub.delta_h[cyc,:,:])\n",
    "        neg = np.nanmin(ds_sub.delta_h[cyc+1,:,:]-ds_sub.delta_h[cyc,:,:])\n",
    "        height_anom_pos += [pos]\n",
    "        height_anom_neg += [neg]\n",
    "    max_height_anom_pos = max(height_anom_pos)\n",
    "    max_height_anom_neg = min(height_anom_neg)\n",
    "    max_height_anom_abs = max(max_height_anom_pos,abs(max_height_anom_neg))\n",
    "    v = np.round(max_height_anom_abs)\n",
    "    # create empty lists to store calculated data\n",
    "    IS2_dates = []\n",
    "    IS2_lkavgdhdt_S09_lake1 = []\n",
    "    IS2_lkavgdhdt_S09_lake2 = []\n",
    "    IS2_lkavgdhdt_SF18 = []\n",
    "    IS2_lkavgdhdt = []\n",
    "    IS2_vols_S09_lake1 = []\n",
    "    IS2_vols_S09_lake2 = []\n",
    "    IS2_vols_S09 = []\n",
    "    IS2_vols_SF18 = []\n",
    "    IS2_vols = []\n",
    "    for idx in range(len(ds_sub.delta_h)-1): \n",
    "        # subset data to dhdt diff between orbital cycles of delta_h\n",
    "        dhdt = ds_sub.delta_h[idx+1,:,:]-ds_sub.delta_h[idx,:,:]\n",
    "        # calculate mid-cycle dates for plotting\n",
    "        if dataset.fileName == 'mos_2010.5_2021.5.h5':\n",
    "            newdate = datetime.datetime(int(ds_sub.time.values[idx]), 1, 1) + datetime.timedelta(days = (ds_sub.time.values[idx] % 1) * 365.25)\n",
    "            newdate1 = datetime.datetime(int(ds_sub.time.values[idx+1]), 1, 1) + datetime.timedelta(days = (ds_sub.time.values[idx+1] % 1) * 365.25)\n",
    "            midcycdays = newdate1 - newdate\n",
    "            midcycdate = newdate + midcycdays/2\n",
    "            dates += [midcycdate]\n",
    "        elif dataset.fileName == 'ATL15_AA_0311_01km_001_01.nc':    \n",
    "            date_time_str = '18-01-01'\n",
    "            date_time_obj = datetime.datetime.strptime(date_time_str, '%y-%m-%d')\n",
    "            newdate = date_time_obj + datetime.timedelta(days=ds_sub.time.values[idx])\n",
    "            newdate1 = date_time_obj + datetime.timedelta(days=ds_sub.time.values[idx+1])\n",
    "            midcycdays = newdate1 - newdate\n",
    "            midcycdate = newdate + midcycdays/2\n",
    "            dates += [midcycdate]\n",
    "        # clip ATL15 data to just show (first set crs)\n",
    "        dhdt.rio.write_crs(3031, inplace=True)\n",
    "        dhdt_clip_S09_lake1 = dhdt.rio.clip(lake1_S09.geometry.values, lake1_S09.crs, drop=False, invert=False)\n",
    "        dhdt_clip_S09_lake2 = dhdt.rio.clip(lake2_S09.geometry.values, lake2_S09.crs, drop=False, invert=False)\n",
    "        dhdt_clip_SF18 = dhdt.rio.clip(lake_SF18.geometry.values, lake_SF18.crs, drop=False, invert=False)\n",
    "        # calculate lake avg. dh/dt and dv/dt time series using published stationary outlines\n",
    "        avg_lk_dhdt_S09_lake1 = np.ma.average(np.ma.MaskedArray(dhdt_clip_S09_lake1, mask=np.isnan(dhdt_clip_S09_lake1)))\n",
    "        IS2_lkavgdhdt_S09_lake1 += [avg_lk_dhdt_S09_lake1]\n",
    "        vol_S09_lake1 = avg_lk_dhdt_S09_lake1*Smith2009_outlines[Smith2009_outlines['Name'] == lakename1_S09].area\n",
    "        IS2_vols_S09_lake1 += [vol_S09_lake1.values[0]]\n",
    "        avg_lk_dhdt_S09_lake2 = np.ma.average(np.ma.MaskedArray(dhdt_clip_S09_lake2, mask=np.isnan(dhdt_clip_S09_lake2)))\n",
    "        IS2_lkavgdhdt_S09_lake2 += [avg_lk_dhdt_S09_lake2]\n",
    "        vol_S09_lake2 = avg_lk_dhdt_S09_lake2*Smith2009_outlines[Smith2009_outlines['Name'] == lakename2_S09].area\n",
    "        IS2_vols_S09_lake2 += [vol_S09_lake2.values[0]]\n",
    "        avg_lk_dhdt_SF18 = np.ma.average(np.ma.MaskedArray(dhdt_clip_SF18, mask=np.isnan(dhdt_clip_SF18)))\n",
    "        IS2_lkavgdhdt_SF18 += [avg_lk_dhdt_SF18]\n",
    "        vol_SF18 = avg_lk_dhdt_SF18*SiegfriedFricker2018_outlines[SiegfriedFricker2018_outlines['name'] == lakename_S23]['area (m^2)']\n",
    "        IS2_vols_SF18 += [vol_SF18.values[0]]\n",
    "        # create contours of ice surface elevation height changes to delineate lake outlines using time-variable method\n",
    "        contours_fill = []\n",
    "        contours_drain = []\n",
    "        contour = measure.find_contours(dhdt.values, thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_fill += [contour]\n",
    "        contour = measure.find_contours(dhdt.values, -thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_drain += [contour]\n",
    "        # create mapping conversion factor to map array location to polar stereographic x,y\n",
    "        x_conv = (x_max-x_min)/dhdt.shape[1]\n",
    "        y_conv = (y_max-y_min)/dhdt.shape[0]\n",
    "        # make polygons from contours\n",
    "        polys = []\n",
    "        for i in range(len(contours_fill)): \n",
    "            for j in range(len(contours_fill[i])):\n",
    "                if len(contours_fill[i][j][:, 1]) > 2: \n",
    "                    poly = Polygon(list(zip(contours_fill[i][j][:, 1]*x_conv+x_min, y_max-contours_fill[i][j][:, 0]*y_conv))) \n",
    "                    polys += [poly]\n",
    "        for i in range(len(contours_drain)): \n",
    "            for j in range(len(contours_drain[i])):\n",
    "                if len(contours_drain[i][j][:, 1]) > 2: \n",
    "                    poly = Polygon(list(zip(contours_drain[i][j][:, 1]*x_conv+x_min, y_max-contours_drain[i][j][:, 0]*y_conv))) \n",
    "                    polys += [poly]\n",
    "        # if polygons are present at time step, \n",
    "        variable_area = 0\n",
    "        if len(polys) > 0: \n",
    "            # clip data to polygons (first set crs)\n",
    "            # dhdt.rio.write_crs(3031, inplace=True) # done earlier in code, may not be needed here\n",
    "            dhdt_clip = dhdt.rio.clip(polys, drop=False, invert=False)\n",
    "            # then calculate on-lake averages of dh/dt\n",
    "            avg_lk_dhdt = np.nanmean(dhdt_clip)\n",
    "            # occaisionally small polygons will completely clip data resulting in nan's for lake avg. dh/dt\n",
    "            # replay with zeros\n",
    "            if math.isnan(avg_lk_dhdt): \n",
    "                avg_lk_dhdt = 0\n",
    "                IS2_lkavgdhdt += [avg_lk_dhdt]\n",
    "            else:\n",
    "                IS2_lkavgdhdt += [avg_lk_dhdt]\n",
    "                # and dv/dt\n",
    "            for i in range(len(polys)):\n",
    "                variable_area = variable_area + polys[i].area\n",
    "            vol = avg_lk_dhdt*variable_area\n",
    "            IS2_vols += [vol]\n",
    "        else: \n",
    "            avg_lk_dhdt = 0\n",
    "            IS2_lkavgdhdt += [avg_lk_dhdt]\n",
    "            vol = avg_lk_dhdt*variable_area\n",
    "            IS2_vols += [vol]\n",
    "\n",
    "    # plot lake avg. height time series\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(IS2_dates, [sum(x) for x in zip(IS2_lkavgdhdt_S09_lake1, IS2_lkavgdhdt_S09_lake2)], color='k', linestyle='dotted')\n",
    "    ax.plot(IS2_dates, IS2_lkavgdhdt_SF18, color='k', linestyle='dashed')   \n",
    "    ax.plot(IS2_dates, IS2_lkavgdhdt, color='darkturquoise', linestyle='dashdot')\n",
    "    locator = mdates.AutoDateLocator(minticks=1, maxticks=7)\n",
    "    formatter = mdates.ConciseDateFormatter(locator)\n",
    "    ax.xaxis.set_major_locator(locator)\n",
    "    ax.xaxis.set_major_formatter(formatter)\n",
    "    ax.set_title('{}+{} vs. {} vs. variable outlines \\nlake average dh/dt'.format(lakename1_S09, lakename2_S09, lakename_S23))\n",
    "    ax.set_xlabel('Year')\n",
    "    ax.set_ylabel('Avg. height change from previous cycle [m]')\n",
    "    Smith2009 = plt.Line2D((0, 1), (0, 0), color='k', linestyle='dotted', linewidth=2)\n",
    "    SiegfriedFricker2018 = plt.Line2D((0, 1), (0, 0), color='k', linestyle='dashed', linewidth=2)\n",
    "    variable_outlines = plt.Line2D((0, 1), (0, 0), color='darkturquoise', linestyle='dashdot', linewidth=2)\n",
    "    ax.legend([Smith2009,SiegfriedFricker2018,variable_outlines],\n",
    "        ['Smith and others, 2009','Siegfried & Fricker, 2018',\n",
    "        'variable outlines'], \n",
    "        loc='best')          \n",
    "    plt.savefig('/Users/Wilson/Documents/0-code/1-lakeshores/output_dhdvdt-using-variable-outlines/IS2-outlinecompare-lineplots/IS2-avglkdhdt-{}+{}vs{}vs-var-outline.png'\\\n",
    "    .format(lakename1_S09, lakename2_S09, lakename_S23), dpi=300, bbox_inches = \"tight\")\n",
    "    plt.close()\n",
    "    # plot volume change time series\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(IS2_dates, np.divide([sum(x) for x in zip(IS2_vols_S09_lake1, IS2_vols_S09_lake2)], 1e+9), color='k', linestyle='dotted')\n",
    "    ax.plot(IS2_dates, np.divide(np.cumsum(IS2_vols_SF18), 1e+9), color='k', linestyle='dashed')\n",
    "    ax.plot(IS2_dates, np.divide(np.cumsum(IS2_vols), 1e+9), color='darkturquoise', linestyle='dashdot')\n",
    "    locator = mdates.AutoDateLocator(minticks=1, maxticks=7)\n",
    "    formatter = mdates.ConciseDateFormatter(locator)\n",
    "    ax.xaxis.set_major_locator(locator)\n",
    "    ax.xaxis.set_major_formatter(formatter)\n",
    "    ax.set_title('{}+{} vs. {} vs. variable outlines \\nvolume change time series'.format(lakename1_S09, lakename2_S09, lakename_S23))\n",
    "    ax.set_xlabel('Year')\n",
    "    ax.set_ylabel('Volume change from previous cycle [km$^3$]')\n",
    "    ax.legend([Smith2009,SiegfriedFricker2018,variable_outlines],\n",
    "        ['Smith and others, 2009','Siegfried & Fricker, 2018',\n",
    "        'variable outlines'], \n",
    "        loc='best')  \n",
    "    plt.savefig('/Users/Wilson/Documents/0-code/1-lakeshores/output_dhdvdt-using-variable-outlines/IS2-outlinecompare-lineplots/IS2-dvdt-{}+{}vs{}vs-var-outline.png'\\\n",
    "    .format(lakename1_S09, lakename2_S09, lakename_S23), dpi=300, bbox_inches = \"tight\")\n",
    "    plt.close()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cycle through list to generate plots using function\n",
    "for idx in range(len(S09_SF18_compare_2to1)):\n",
    "    ATL15_dhdvdt_compare_2to1static_variable_outlines(S09_SF18_compare_2to1[idx][0],S09_SF18_compare_2to1[idx][1],S09_SF18_compare_2to1[idx][2],1000,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function for 1 S09 converted to 2 SF18 lakes\n",
    "def dhdvdt_compare_1to2static_variable_outlines(lakename1_S09, lakename1_SF18, lakename2_SF18, buffer, thres, dataset): \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cycle through list to generate plots using function\n",
    "for idx in range(len(S09_SF18_compare_2to1)):\n",
    "    dhdvdt_compare_1to2static_variable_outlines(S09_SF18_compare_1to2[idx][0],S09_SF18_compare_1to2[idx][1],S09_SF18_compare_1to2[idx][2],1000,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine date of first IS-2 cycle to compare to CS-2\n",
    "cyc_dates = []\n",
    "midcyc_dates = []\n",
    "for idx in range(len(ATL15_dh.time)-1): \n",
    "    date_time_str = '18-01-01'\n",
    "    date_time_obj = datetime.datetime.strptime(date_time_str, '%y-%m-%d')\n",
    "    newdate = date_time_obj + datetime.timedelta(days=ATL15_dh.time.values[idx])\n",
    "    cyc_dates += [newdate]\n",
    "    newdate1 = date_time_obj + datetime.timedelta(days=ATL15_dh.time.values[idx+1])\n",
    "    midcycdays = newdate1 - newdate\n",
    "    midcycdate = newdate + midcycdays/2\n",
    "    midcyc_dates += [midcycdate]\n",
    "datetime2fracyear(cyc_dates[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "# Func S09SF18S23_dhdt_CS2vsIS2_anim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparison of CS2 and IS2\n",
    "# modifying to plot just dhdt and diff\n",
    "def S09SF18S23_dhdt_CS2vsIS2_anim(lakename_S23, buffer, thres): \n",
    "    '''\n",
    "    Create CryoSat-2 (CS2) and ICESat-2 (IS2) dh/dt plots of ice surface height changes using geopandas buffer created bounding box around known lakes in Siegfried and Fricker, 2018 inventory.\n",
    "    Create time-variable outlines using skimage contour to plot variable outline alongside published outlines for comparison. \n",
    "    Use statis and time-variable outlines to calculate dv/dt in both CryoSat-2 and ICESat-2.\n",
    "    Save images together into GIF animation.\n",
    "    Inputs: \n",
    "        lakename: lake of interest from SiegfriedFricker2018_outlines inventory\n",
    "        buffer: horizontal distance in meters to create bounding box around lake of interest\n",
    "        thres(hold): vertical distance in meters to delineate ice surface deformation contour\n",
    "    Outputs: \n",
    "        Animations of planview dh/dt visuals with variable ice surface deformation contours plotted to delineate time-variable lake boundary \n",
    "        alongside 2-D line plots of cumulative dv/dt using static and variable outlines that updates simultaneously to planview dh/dt animation.\n",
    "    '''\n",
    "    # isolate individual lake using gpd buffer\n",
    "    #lake_gpd = Smith2009_outlines.loc[Smith2009_outlines['Name'] == lakename]\n",
    "    lake_SF18 = SiegfriedFricker2018_outlines.loc[SiegfriedFricker2018_outlines['name'] == lakename_S23]\n",
    "    lake_buffer = lake_SF18.buffer(buffer)\n",
    "    # define lake bounding box\n",
    "    x_min = lake_buffer.bounds.values[0,0]; x_max = lake_buffer.bounds.values[0,2]\n",
    "    y_min = lake_buffer.bounds.values[0,1]; y_max = lake_buffer.bounds.values[0,3]\n",
    "    # subset CS2 data set to region of interest\n",
    "    dataset = CS2_dh\n",
    "    mask_x = (dataset.x >= x_min) & (dataset.x <= x_max)\n",
    "    mask_y = (dataset.y >= y_min) & (dataset.y <= y_max)\n",
    "    mask_t = (dataset.time >= 2018.75)\n",
    "    CS2_dh_sub = dataset.where(mask_x & mask_y & mask_t, drop=True)\n",
    "    # subset ATL15 data set to region of interest\n",
    "    dataset = ATL15_dh\n",
    "    mask_x = (dataset.x >= x_min) & (dataset.x <= x_max)\n",
    "    mask_y = (dataset.y >= y_min) & (dataset.y <= y_max)\n",
    "    ATL15_dh_sub = dataset.where(mask_x & mask_y, drop=True)\n",
    "    # find magnitude of ice surface deformation in bounding box / find appropriate color map scale\n",
    "    height_anom_pos = []\n",
    "    height_anom_neg = []\n",
    "    for cyc in range(len(CS2_dh_sub)-1):\n",
    "        pos = np.nanmax(CS2_dh_sub.delta_h[cyc+1,:,:]-CS2_dh_sub.delta_h[cyc,:,:])\n",
    "        neg = np.nanmin(CS2_dh_sub.delta_h[cyc+1,:,:]-CS2_dh_sub.delta_h[cyc,:,:])\n",
    "        height_anom_pos += [pos]\n",
    "        height_anom_neg += [neg]\n",
    "    for cyc in range(len(ATL15_dh_sub.time)-1):\n",
    "        pos = np.nanmax(ATL15_dh_sub.delta_h[cyc+1,:,:]-ATL15_dh_sub.delta_h[cyc,:,:])\n",
    "        neg = np.nanmin(ATL15_dh_sub.delta_h[cyc+1,:,:]-ATL15_dh_sub.delta_h[cyc,:,:])\n",
    "        height_anom_pos += [pos]\n",
    "        height_anom_neg += [neg]\n",
    "    max_height_anom_pos = max(height_anom_pos)\n",
    "    max_height_anom_neg = min(height_anom_neg)\n",
    "    max_height_anom_abs = max(max_height_anom_pos,abs(max_height_anom_neg))\n",
    "    v = np.round(max_height_anom_abs)\n",
    "    # create empty lists to store calculated data\n",
    "    dates_CS2 = []\n",
    "    dates_IS2 = []\n",
    "    dhdt_onlakeavg_SF18_CS2 = []\n",
    "    dhdt_onlakeavg_SF18_IS2 = []\n",
    "    dvdt_SF18_CS2 = []\n",
    "    dvdt_SF18_IS2 = []\n",
    "    dhdt_onlakeavg_var_CS2 = []\n",
    "    dhdt_onlakeavg_var_IS2 = []\n",
    "    dvdt_var_CS2 = []\n",
    "    dvdt_var_IS2 = []\n",
    "    for idx in range(len(CS2_dh_sub.delta_h)-1): \n",
    "        dhdt_CS2 = CS2_dh_sub.delta_h[idx+1,:,:]-CS2_dh_sub.delta_h[idx,:,:]\n",
    "        dhdt_IS2 = ATL15_dh_sub.delta_h[idx+1,:,:]-ATL15_dh_sub.delta_h[idx,:,:]\n",
    "        # calculate mid-cycle dates for plotting\n",
    "        # CryoSat-2\n",
    "        newdate = datetime.datetime(int(CS2_dh_sub.time.values[idx]), 1, 1) + datetime.timedelta(days = (CS2_dh_sub.time.values[idx] % 1) * 365.25)\n",
    "        newdate1 = datetime.datetime(int(CS2_dh_sub.time.values[idx+1]), 1, 1) + datetime.timedelta(days = (CS2_dh_sub.time.values[idx+1] % 1) * 365.25)\n",
    "        midcycdays = newdate1 - newdate\n",
    "        midcycdate = newdate + midcycdays/2\n",
    "        dates_CS2 += [midcycdate]\n",
    "        # ICESat-2\n",
    "        date_time_str = '18-01-01'\n",
    "        date_time_obj = datetime.datetime.strptime(date_time_str, '%y-%m-%d')\n",
    "        newdate = date_time_obj + datetime.timedelta(days=ATL15_dh_sub.time.values[idx])\n",
    "        newdate1 = date_time_obj + datetime.timedelta(days=ATL15_dh_sub.time.values[idx+1])\n",
    "        midcycdays = newdate1 - newdate\n",
    "        midcycdate = newdate + midcycdays/2\n",
    "        dates_IS2 += [midcycdate]\n",
    "        # clip ATL15 data to just show (first set crs)\n",
    "        dhdt_CS2.rio.write_crs(3031, inplace=True)\n",
    "        dhdt_IS2.rio.write_crs(3031, inplace=True)\n",
    "        dhdt_CS2_clip_SF18 = dhdt_CS2.rio.clip(lake_SF18.geometry.values, lake_SF18.crs, drop=False, invert=False)\n",
    "        dhdt_IS2_clip_SF18 = dhdt_IS2.rio.clip(lake_SF18.geometry.values, lake_SF18.crs, drop=False, invert=False)\n",
    "        # calculate lake avg. dh/dt and dv/dt time series using published stationary outlines\n",
    "        dhdt_CS2_lkavg_SF18 = np.nanmean(dhdt_CS2_clip_SF18)\n",
    "        dhdt_IS2_lkavg_SF18 = np.nanmean(dhdt_IS2_clip_SF18)\n",
    "        dhdt_onlakeavg_SF18_CS2 += [dhdt_CS2_lkavg_SF18]\n",
    "        dhdt_onlakeavg_SF18_IS2 += [dhdt_IS2_lkavg_SF18]\n",
    "        dhdt_CS2_vol_SF18 = dhdt_CS2_lkavg_SF18 * SiegfriedFricker2018_outlines[SiegfriedFricker2018_outlines['name'] == lakename_S23]['area (m^2)']\n",
    "        dhdt_IS2_vol_SF18 = dhdt_IS2_lkavg_SF18 * SiegfriedFricker2018_outlines[SiegfriedFricker2018_outlines['name'] == lakename_S23]['area (m^2)']\n",
    "        dvdt_SF18_CS2 += [dhdt_CS2_vol_SF18.values[0]]\n",
    "        dvdt_SF18_IS2 += [dhdt_IS2_vol_SF18.values[0]]\n",
    "        # create contours of ice surface elevation height changes to delineate lake outlines\n",
    "        contours_fill_CS2 = []\n",
    "        contours_drain_CS2 = []\n",
    "        contours_fill_IS2 = []\n",
    "        contours_drain_IS2 = []\n",
    "        # create CryoSat-2 variable outliens\n",
    "        contour = measure.find_contours(dhdt_CS2.values, thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_fill_CS2 += [contour]\n",
    "        contour = measure.find_contours(dhdt_CS2.values, -thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_drain_CS2 += [contour]\n",
    "        # create mapping conversion factor to map array location to polar stereographic x,y\n",
    "        x_conv = (x_max-x_min)/dhdt_CS2.shape[1] # CONSIDER MOVING OUT OF DHDT FOR LOOP SO THAT THIS CONSTANT CONVERSION FACTOR IS NOT CALCULATED EACH LOOP\n",
    "        y_conv = (y_max-y_min)/dhdt_CS2.shape[0]\n",
    "        # make polygons from variable outlines\n",
    "        polys_CS2 = []\n",
    "        for i in range(len(contours_fill_CS2)): \n",
    "            for j in range(len(contours_fill_CS2[i])):\n",
    "                if len(contours_fill_CS2[i][j][:, 1]) > 2: \n",
    "                    poly = Polygon(list(zip(x_min+contours_fill_CS2[i][j][:, 1]*x_conv, y_max-contours_fill_CS2[i][j][:, 0]*y_conv))) \n",
    "                    polys_CS2 += [poly]\n",
    "        for i in range(len(contours_drain_CS2)): \n",
    "            for j in range(len(contours_drain_CS2[i])):\n",
    "                if len(contours_drain_CS2[i][j][:, 1]) > 2: \n",
    "                    poly = Polygon(list(zip(x_min+contours_drain_CS2[i][j][:, 1]*x_conv, y_max-contours_drain_CS2[i][j][:, 0]*y_conv))) \n",
    "                    polys_CS2 += [poly]\n",
    "        # create ICESat-2 variable outlines\n",
    "        contour = measure.find_contours(dhdt_IS2.values, thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_fill_IS2 += [contour]\n",
    "        contour = measure.find_contours(dhdt_IS2.values, -thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_drain_IS2 += [contour]\n",
    "        # create mapping conversion factor to map array location to polar stereographic x,y\n",
    "        x_conv = (x_max-x_min)/dhdt_IS2.shape[1]\n",
    "        y_conv = (y_max-y_min)/dhdt_IS2.shape[0]\n",
    "        # make polygons from variable outlines\n",
    "        polys_IS2 = []  \n",
    "        for i in range(len(contours_fill_IS2)): \n",
    "            for j in range(len(contours_fill_IS2[i])):\n",
    "                if len(contours_fill_IS2[i][j][:, 1]) > 2: \n",
    "                    poly = Polygon(list(zip(x_min+contours_fill_IS2[i][j][:,1]*x_conv, y_max-contours_fill_IS2[i][j][:,0]*y_conv))) \n",
    "                    polys_IS2 += [poly]\n",
    "        for i in range(len(contours_drain_IS2)): \n",
    "            for j in range(len(contours_drain_IS2[i])):\n",
    "                if len(contours_drain_IS2[i][j][:, 1]) > 2: \n",
    "                    poly = Polygon(list(zip(x_min+contours_drain_IS2[i][j][:,1]*x_conv, y_max-contours_drain_IS2[i][j][:,0]*y_conv))) \n",
    "                    polys_IS2 += [poly]\n",
    "        # start with baseline variable outline area of zero\n",
    "        variable_area = 0\n",
    "        # CryoSat-2\n",
    "        # if polygons are present at time step, \n",
    "        if len(polys_CS2) > 0: \n",
    "            # clip data to polygons\n",
    "            dhdt_clip = dhdt_CS2.rio.clip(polys_CS2, drop=False, invert=False)\n",
    "            # then calculate on-lake averages of dh/dt\n",
    "            avg_lk_dhdt = np.nanmean(dhdt_clip)\n",
    "            # occasionally small polygons will completely clip data resulting in nan's for lake avg. dh/dt; replace with zeros\n",
    "            if math.isnan(avg_lk_dhdt): \n",
    "                avg_lk_dhdt = 0\n",
    "                dhdt_onlakeavg_var_CS2 += [avg_lk_dhdt]\n",
    "            else:\n",
    "                dhdt_onlakeavg_var_CS2 += [avg_lk_dhdt]\n",
    "            # and dv/dt\n",
    "            for i in range(len(polys_CS2)):\n",
    "                variable_area = variable_area + polys_CS2[i].area # CHANGE TO GEODESIC AREA\n",
    "            vol_var = avg_lk_dhdt*variable_area\n",
    "            dvdt_var_CS2 += [vol_var]\n",
    "        else: \n",
    "            avg_lk_dhdt = 0\n",
    "            dhdt_onlakeavg_var_CS2 += [avg_lk_dhdt]\n",
    "            vol_var = avg_lk_dhdt*variable_area\n",
    "            dvdt_var_CS2 += [vol_var]\n",
    "        # ICESat-2\n",
    "        # if polygons are present at time step, \n",
    "        if len(polys_IS2) > 0: \n",
    "            # clip data to polygons\n",
    "            dhdt_clip = dhdt_IS2.rio.clip(polys_IS2, drop=False, invert=False)\n",
    "            # then calculate on-lake averages of dh/dt\n",
    "            avg_lk_dhdt = np.nanmean(dhdt_clip)\n",
    "            # occasionally small polygons will completely clip data resulting in nan's for lake avg. dh/dt\n",
    "            # replace with zeros\n",
    "            if math.isnan(avg_lk_dhdt): \n",
    "                avg_lk_dhdt = 0\n",
    "                dhdt_onlakeavg_var_IS2 += [avg_lk_dhdt]\n",
    "            else:\n",
    "                dhdt_onlakeavg_var_IS2 += [avg_lk_dhdt]\n",
    "            # and dv/dt\n",
    "            for i in range(len(polys_IS2)):\n",
    "                variable_area = variable_area + polys_IS2[i].area # CHANGE TO GEODESIC AREA\n",
    "            vol_var = avg_lk_dhdt*variable_area\n",
    "            dvdt_var_IS2 += [vol_var]\n",
    "        else: \n",
    "            avg_lk_dhdt = 0\n",
    "            dhdt_onlakeavg_var_IS2 += [avg_lk_dhdt]\n",
    "            vol_var = avg_lk_dhdt*variable_area\n",
    "            dvdt_var_IS2 += [vol_var]\n",
    "    # create fig, axes\n",
    "    fig, axes = plt.subplots(1,3, sharey=True, figsize=(25,7))\n",
    "    # create colorbar axes for dh/dt subplots\n",
    "    # divider0 = make_axes_locatable(axes[0,0])\n",
    "    # cax0 = divider0.append_axes('right', size='5%', pad=0.2)\n",
    "    # create empty list to store animation im(age)s\n",
    "    ani = animation.PillowWriter(fps=1)\n",
    "    ani.setup(fig, '/Users/Wilson/Documents/0-code/1-lakeshores/output_dhdvdt-using-variable-outlines/S09SF18varoutlines_dhdt_CS2vsIS2_anim/S09SF18varoutlines_dhdt_CS2vsIS2_anim-{}.gif'.format(lakename_S23), dpi=300)\n",
    "    # for loop through dh/dt acquisition cycles to construct animation\n",
    "    for idx in range(len(CS2_dh_sub.delta_h)-1): \n",
    "        dhdt_CS2 = CS2_dh_sub.delta_h[idx+1,:,:]-CS2_dh_sub.delta_h[idx,:,:]\n",
    "        dhdt_IS2 = ATL15_dh_sub.delta_h[idx+1,:,:]-ATL15_dh_sub.delta_h[idx,:,:]\n",
    "        # create contours of ice surface elevation height changes to delineate lake outlines\n",
    "        contours_fill_CS2 = []\n",
    "        contours_drain_CS2 = []\n",
    "        contours_fill_IS2 = []\n",
    "        contours_drain_IS2 = []\n",
    "        # create CryoSat-2 variable outliens\n",
    "        contour = measure.find_contours(dhdt_CS2.values, thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_fill_CS2 += [contour]\n",
    "        contour = measure.find_contours(dhdt_CS2.values, -thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_drain_CS2 += [contour]\n",
    "        # create ICESat-2 variable outlines\n",
    "        contour = measure.find_contours(dhdt_IS2.values, thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_fill_IS2 += [contour]\n",
    "        contour = measure.find_contours(dhdt_IS2.values, -thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_drain_IS2 += [contour]\n",
    "        # subplot 0: plot planview dhdt and variable outlines found in CryoSat-2 time slice\n",
    "        img0 = axes[0].imshow(dhdt_CS2, extent=[x_min, x_max, y_min, y_max], \n",
    "            origin='upper', cmap=cmocean.cm.balance_r, vmin=-v, vmax=v)\n",
    "        divider0 = make_axes_locatable(axes[0])\n",
    "        cax0 = divider0.append_axes('right', size='5%', pad=0.2)\n",
    "        cax0.axis('off')            \n",
    "        for i in range(len(contours_fill_CS2)): \n",
    "            for j in range(len(contours_fill_CS2[i])):\n",
    "                axes[0].plot(x_min+contours_fill_CS2[i][j][:, 1]*x_conv, y_max-contours_fill_CS2[i][j][:, 0]*y_conv, color='mediumblue', linestyle='dashdot', linewidth=2)\n",
    "        for i in range(len(contours_drain_CS2)): \n",
    "            for j in range(len(contours_drain_CS2[i])):\n",
    "                axes[0].plot(x_min+contours_drain_CS2[i][j][:, 1]*x_conv, y_max-contours_drain_CS2[i][j][:, 0]*y_conv, color='maroon', linestyle=(0, (3, 1, 1, 1)), linewidth=2)\n",
    "        axes[0].set(xlim=(x_min, x_max), ylim=(y_min, y_max))\n",
    "        # change polar stereographic m to km for cleaner-looking axes labels\n",
    "        km_scale = 1e3\n",
    "        ticks_x = ticker.FuncFormatter(lambda x, pos: '{0:g}'.format(x/km_scale))\n",
    "        ax.xaxis.set_major_formatter(ticks_x)\n",
    "        ticks_y = ticker.FuncFormatter(lambda x, pos: '{0:g}'.format(x/km_scale))\n",
    "        ax.yaxis.set_major_formatter(ticks_y)  \n",
    "        ax.set_xlabel('x [km]', size=15)\n",
    "        ax.set_ylabel('y [km]', size=15)\n",
    "        axes[0].set_title('CryoSat-2 dh', fontsize=17.5)\n",
    "        fig.suptitle(lakename_S23+' dh $h_{'+dates_CS2[idx].strftime('%m/%Y')+'} - h_{'+dates_CS2[idx-1].strftime('%m/%Y')+'}$', fontsize=24)\n",
    "        # ax.set_title(lakename_S23+' dh/dt + outline comparison \\n$h_{'+newdate1.strftime('%m/%Y')+'} - h_{'+newdate.strftime('%m/%Y')+'}$', pad=7.5, fontsize=17.5)\n",
    "        plt.subplots_adjust(wspace=0.001)\n",
    "        # fig.colorbar(img0, cax=cax0).set_label('Height (h) change [m]', size=15)\n",
    "        # overlay published outlines for visual comparison \n",
    "        Smith2009_outlines.boundary.plot(ax=axes[0], color='k', linestyle='--', linewidth=1)\n",
    "        SiegfriedFricker2018_outlines[SiegfriedFricker2018_outlines['cite'] \\\n",
    "            != 'Smith and others, 2009, J. Glac., doi:10.3189/002214309789470879'] \\\n",
    "            .boundary.plot(ax=axes[0], color='k', linestyle='-', linewidth=1)\n",
    "        # create 2D lines for legend\n",
    "        Smith2009 = plt.Line2D((0, 1), (0, 0), color='k', linestyle='--', linewidth=2)\n",
    "        SiegfriedFricker2018 = plt.Line2D((0, 1), (0, 0), color='k', linestyle='-', linewidth=2)\n",
    "        uplift = plt.Line2D((0, 1), (0, 0), color='mediumblue', linestyle='dashdot', linewidth=2)\n",
    "        subsidence = plt.Line2D((0, 1), (0, 0), color='maroon', linestyle=(0, (3, 1, 1, 1)), linewidth=2)\n",
    "        axes[0].legend([Smith2009, SiegfriedFricker2018, uplift, subsidence],\n",
    "            ['Smith and others, 2009 static outline','Siegfried & Fricker, 2018 static outline',\n",
    "            ('+'+str(thres)+' m uplift (filling) variable outline'), 'â€“'+str(thres)+' m subsidence (draining) variable outline'], \n",
    "            loc='upper left')\n",
    "        # subplot 1: plot planview dhdt and variable outlines found in ICESat-2 time slice\n",
    "        divider1 = make_axes_locatable(axes[1])\n",
    "        cax1 = divider1.append_axes('right', size='5%', pad=0.2)\n",
    "        cax1.axis('off')\n",
    "        img1 = axes[1].imshow(dhdt_IS2, extent=[x_min, x_max, y_min, y_max], \n",
    "            origin='upper', cmap=cmocean.cm.balance_r, vmin=-v, vmax=v)\n",
    "        for i in range(len(contours_fill_IS2)): \n",
    "            for j in range(len(contours_fill_IS2[i])):\n",
    "                axes[1].plot(x_min+contours_fill_IS2[i][j][:, 1]*x_conv, y_max-contours_fill_IS2[i][j][:, 0]*y_conv, color='mediumblue', linestyle='dashdot', linewidth=2)\n",
    "        for i in range(len(contours_drain_IS2)): \n",
    "            for j in range(len(contours_drain_IS2[i])):\n",
    "                axes[1].plot(x_min+contours_drain_IS2[i][j][:, 1]*x_conv, y_max-contours_drain_IS2[i][j][:, 0]*y_conv, color='maroon', linestyle=(0, (3, 1, 1, 1)), linewidth=2)\n",
    "        axes[1].set(xlim=(x_min, x_max), ylim=(y_min, y_max))\n",
    "        axes[1].set_xlabel('polar stereographic x [m]', size=15)\n",
    "        axes[1].ticklabel_format(axis='both', scilimits=(0,0))\n",
    "        axes[1].set_title('ICESat-2 dh', fontsize=17.5)\n",
    "        # fig.colorbar(img1, cax=cax1).set_label('Height (h) change [m]', size=15)\n",
    "        # overlay published outlines for visual comparison \n",
    "        Smith2009_outlines.boundary.plot(ax=axes[1], color='k', linestyle='--', linewidth=1)\n",
    "        SiegfriedFricker2018_outlines[SiegfriedFricker2018_outlines['cite'] \\\n",
    "            != 'Smith and others, 2009, J. Glac., doi:10.3189/002214309789470879'] \\\n",
    "            .boundary.plot(ax=axes[1], color='k', linestyle='-', linewidth=1)\n",
    "        # axes[1].legend([Smith2009, SiegfriedFricker2018, uplift, subsidence],\n",
    "        #     ['Smith and others, 2009 static outline','Siegfried & Fricker, 2018 static outline',\n",
    "        #     ('+'+str(thres)+' m uplift (filling) variable outline'), 'â€“'+str(thres)+' m subsidence (draining) variable outline'], \n",
    "        #     loc='upper left')\n",
    "        # plot inset map to show location \n",
    "        axIns = axes[1].inset_axes([0.02, 0.71, 0.29, 0.29])\n",
    "        axIns.patch.set_facecolor('lightskyblue')\n",
    "        axIns.set_aspect('equal')\n",
    "        axIns.scatter(((x_max+x_min)/2), ((y_max+y_min)/2), marker='*', \n",
    "            linewidth=1, edgecolor='k', facecolor='r', s=100, zorder=3)\n",
    "        Scripps_gl.plot(ax=axIns, color='ghostwhite', edgecolor='k', linewidth=0.5, zorder=2)\n",
    "        # SiegfriedFricker2018_outlines.boundary.plot(ax=axIns, color='k', linestyle='-', linewidth=1)\n",
    "        axIns.axis('off')\n",
    "        # subplot 2: plot difference: \n",
    "        img2 = axes[2].imshow(dhdt_CS2-dhdt_IS2, extent=[x_min, x_max, y_min, y_max], \n",
    "            origin='upper', cmap=cmocean.cm.balance_r, vmin=-v, vmax=v)\n",
    "        divider2 = make_axes_locatable(axes[2])\n",
    "        cax2 = divider2.append_axes('right', size='5%', pad=0.2)\n",
    "        # for i in range(len(contours_fill_IS2)): \n",
    "        #     for j in range(len(contours_fill_IS2[i])):\n",
    "        #         axes[1].plot(x_min+contours_fill_IS2[i][j][:, 1]*x_conv, y_max-contours_fill_IS2[i][j][:, 0]*y_conv, color='mediumblue', linestyle='dashdot', linewidth=2)\n",
    "        # for i in range(len(contours_drain_IS2)): \n",
    "        #     for j in range(len(contours_drain_IS2[i])):\n",
    "        #         axes[1].plot(x_min+contours_drain_IS2[i][j][:, 1]*x_conv, y_max-contours_drain_IS2[i][j][:, 0]*y_conv, color='maroon', linestyle=(0, (3, 1, 1, 1)), linewidth=2)\n",
    "        axes[2].set(xlim=(x_min, x_max), ylim=(y_min, y_max))\n",
    "        axes[2].set_xlabel('polar stereographic x [m]', size=15)\n",
    "        axes[2].ticklabel_format(axis='both',scilimits=(0,0))\n",
    "        axes[2].set_title('CryoSat-2 - ICESat-2 dh', fontsize=17.5)\n",
    "        # overlay published outlines for visual comparison \n",
    "        Smith2009_outlines.boundary.plot(ax=axes[2], color='k', linestyle='--', linewidth=1)\n",
    "        SiegfriedFricker2018_outlines[SiegfriedFricker2018_outlines['cite'] \\\n",
    "            != 'Smith and others, 2009, J. Glac., doi:10.3189/002214309789470879'] \\\n",
    "            .boundary.plot(ax=axes[2], color='k', linestyle='-', linewidth=1)\n",
    "        # axes[2].legend([Smith2009, SiegfriedFricker2018, uplift, subsidence],\n",
    "        #     ['Smith and others, 2009 static outline','Siegfried & Fricker, 2018 static outline',\n",
    "        #     ('+'+str(thres)+' m uplift (filling) variable outline'), 'â€“'+str(thres)+' m subsidence (draining) variable outline'], \n",
    "        #     loc='upper left')\n",
    "        fig.colorbar(img2, cax=cax2).set_label('Height (h) difference [m]', size=15)\n",
    "        # # suplot 2: plot CS2 dvdt time series\n",
    "        # axes[1,0].plot(dates_CS2[:idx+1], np.divide(np.cumsum(dvdt_SF18_CS2[:idx+1]), 1e+9), color='k', linestyle='dashed')\n",
    "        # axes[1,0].plot(dates_CS2[:idx+1], np.divide(np.cumsum(dvdt_var_CS2[:idx+1]), 1e+9), color='darkturquoise', linestyle='dashdot')\n",
    "        # locator = mdates.AutoDateLocator(minticks=1, maxticks=7)\n",
    "        # formatter = mdates.ConciseDateFormatter(locator)\n",
    "        # axes[1,0].xaxis.set_major_locator(locator)\n",
    "        # axes[1,0].xaxis.set_major_formatter(formatter)\n",
    "        # # CONSIDER MOVING OUT OF FOR LOOP SO IT'S NOT CALCULATING CONSTANTS EVERY LOOP\n",
    "        # dvdt_min = min(np.divide(min(np.cumsum(dvdt_SF18_CS2)), 1e+9), np.divide(min(np.cumsum(dvdt_var_CS2)), 1e+9), np.divide(min(np.cumsum(dvdt_SF18_IS2)), 1e+9), np.divide(min(np.cumsum(dvdt_var_IS2)), 1e+9))\n",
    "        # dvdt_max = max(np.divide(max(np.cumsum(dvdt_SF18_CS2)), 1e+9), np.divide(max(np.cumsum(dvdt_var_CS2)), 1e+9), np.divide(max(np.cumsum(dvdt_SF18_IS2)), 1e+9), np.divide(max(np.cumsum(dvdt_var_IS2)), 1e+9))\n",
    "        # dvdt_range = dvdt_max - dvdt_min\n",
    "        # ylim_min = dvdt_min - (dvdt_range * 0.1)\n",
    "        # ylim_max = dvdt_max + (dvdt_range * 0.1)\n",
    "        # axes[1,0].set(xlim=(\n",
    "        #     datetime.datetime(int(CS2_dh_sub.time.values[0]), 1, 1) + datetime.timedelta(days = (CS2_dh_sub.time.values[0] % 1) * 365.25), \n",
    "        #     datetime.datetime(int(CS2_dh_sub.time.values[-1]), 1, 1) + datetime.timedelta(days = (CS2_dh_sub.time.values[-1] % 1) * 365.25)), \n",
    "        #     ylim=(ylim_min, ylim_max))\n",
    "        # axes[1,0].set_title('{} CryoSat-2 volume change time series'.format(lakename_S23), pad=7.5, fontsize=17.5)\n",
    "        # axes[1,0].set_xlabel('Year', size=15)\n",
    "        # axes[1,0].set_ylabel('Volume change [km$^3$]', size=15)\n",
    "        # variable_outlines = plt.Line2D((0, 1), (0, 0), color='darkturquoise', linestyle='dashdot', linewidth=2)\n",
    "        # axes[1,0].legend([#Smith2009,\n",
    "        #     SiegfriedFricker2018, variable_outlines],\n",
    "        #     [#'Smith and others, 2009',\n",
    "        #     'Siegfried & Fricker, 2018',\n",
    "        #     'Â±{} m variable outlines'.format(thres)], \n",
    "        #     loc='upper left')\n",
    "        # # suplot 3: plot IS2 dvdt time series\n",
    "        # axes[1,1].plot(dates_IS2[:idx+1], np.divide(np.cumsum(dvdt_SF18_IS2[:idx+1]), 1e+9), color='k', linestyle='dashed')\n",
    "        # axes[1,1].plot(dates_IS2[:idx+1], np.divide(np.cumsum(dvdt_var_IS2[:idx+1]), 1e+9), color='darkturquoise', linestyle='dashdot')\n",
    "        # locator = mdates.AutoDateLocator(minticks=1, maxticks=7)\n",
    "        # formatter = mdates.ConciseDateFormatter(locator)\n",
    "        # axes[1,1].xaxis.set_major_locator(locator)\n",
    "        # axes[1,1].xaxis.set_major_formatter(formatter)\n",
    "        # axes[1,1].set(xlim=(\n",
    "        #     date_time_obj + datetime.timedelta(days=ATL15_dh_sub.time.values[0]),\n",
    "        #     date_time_obj + datetime.timedelta(days=ATL15_dh_sub.time.values[-1])), \n",
    "        #     ylim=(ylim_min, ylim_max))\n",
    "        # axes[1,1].set_title('{} ICESat-2 volume change time series'.format(lakename_S23), pad=7.5, fontsize=17.5)\n",
    "        # axes[1,1].set_xlabel('Year', size=15)\n",
    "        # axes[1,1].set_ylabel('Volume change [km$^3$]', size=15)\n",
    "        # variable_outlines = plt.Line2D((0, 1), (0, 0), color='darkturquoise', linestyle='dashdot', linewidth=2)\n",
    "        # axes[1,1].legend([#Smith2009,\n",
    "        #     SiegfriedFricker2018, variable_outlines],\n",
    "        #     [#'Smith and others, 2009',\n",
    "        #     'Siegfried & Fricker, 2018',\n",
    "        #     'Â±{} m variable outlines'.format(thres)], \n",
    "        #     loc='upper left')\n",
    "        # append im(age) to ims list\n",
    "        ani.grab_frame()\n",
    "        axes[0].clear()\n",
    "        axes[1].clear()\n",
    "        axes[2].clear()\n",
    "    # create animation and save, adjust interval\n",
    "    ani.finish()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test function working using one lake\n",
    "S09SF18varoutlines_dhdt_CS2vsIS2_anim('Bindschadler_1', 7500, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run func on all lakes from SF18 inventory\n",
    "for idx in range(len(SiegfriedFricker2018_outlines)-1):\n",
    "    lakename = SiegfriedFricker2018_outlines['name'][idx]\n",
    "    S09SF18varoutlines_dhdt_CS2vsIS2_anim(lakename, 7500, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def S09SF18varoutlines_dhdvdt_CS2vsIS2_anim(lakename_S23, buffer, thres): \n",
    "    '''\n",
    "    Create CryoSat-2 (CS2) and ICESat-2 (IS2) dh/dt plots of ice surface height changes using geopandas buffer created bounding box around known lakes in Siegfried and Fricker, 2018 inventory.\n",
    "    Create time-variable outlines using skimage contour to plot variable outline alongside published outlines for comparison. \n",
    "    Use static and time-variable outlines to calculate dv/dt in both CryoSat-2 and ICESat-2.\n",
    "    Save images together into GIF animation.\n",
    "    Inputs: \n",
    "        lakename: lake of interest from SiegfriedFricker2018_outlines inventory\n",
    "        buffer: horizontal distance in meters to create bounding box around lake of interest\n",
    "        thres(hold): vertical distance in meters to delineate ice surface deformation contour\n",
    "    Outputs: \n",
    "        Animations of planview dh/dt visuals with variable ice surface deformation contours plotted to delineate time-variable lake boundary \n",
    "        alongside 2-D line plots of cumulative dv/dt using static and variable outlines that updates simultaneously to planview dh/dt animation.\n",
    "    '''\n",
    "    # isolate individual lake using gpd buffer\n",
    "    #lake_gpd = Smith2009_outlines.loc[Smith2009_outlines['Name'] == lakename]\n",
    "    lake_SF18 = SiegfriedFricker2018_outlines.loc[SiegfriedFricker2018_outlines['name'] == lakename_S23]\n",
    "    lake_buffer = lake_SF18.buffer(buffer)\n",
    "    # define lake bounding box\n",
    "    x_min = lake_buffer.bounds.values[0,0]; x_max = lake_buffer.bounds.values[0,2]\n",
    "    y_min = lake_buffer.bounds.values[0,1]; y_max = lake_buffer.bounds.values[0,3]\n",
    "    # subset CS2 data set to region of interest\n",
    "    dataset = CS2_dh\n",
    "    mask_x = (dataset.x >= x_min) & (dataset.x <= x_max)\n",
    "    mask_y = (dataset.y >= y_min) & (dataset.y <= y_max)\n",
    "    mask_t = (dataset.time >= 2018.75)\n",
    "    CS2_dh_sub = dataset.where(mask_x & mask_y & mask_t, drop=True)\n",
    "    # subset ATL15 data set to region of interest\n",
    "    dataset = ATL15_dh\n",
    "    mask_x = (dataset.x >= x_min) & (dataset.x <= x_max)\n",
    "    mask_y = (dataset.y >= y_min) & (dataset.y <= y_max)\n",
    "    ATL15_dh_sub = dataset.where(mask_x & mask_y, drop=True)\n",
    "    # find magnitude of ice surface deformation in bounding box / find appropriate color map scale\n",
    "    height_anom_pos = []\n",
    "    height_anom_neg = []\n",
    "    for cyc in range(len(CS2_dh_sub)-1): # SHOULD ONLY CLIP TO CYCS IN IS2 ERA\n",
    "        pos = np.nanmax(CS2_dh_sub.delta_h[cyc+1,:,:]-CS2_dh_sub.delta_h[cyc,:,:])\n",
    "        neg = np.nanmin(CS2_dh_sub.delta_h[cyc+1,:,:]-CS2_dh_sub.delta_h[cyc,:,:])\n",
    "        height_anom_pos += [pos]\n",
    "        height_anom_neg += [neg]\n",
    "    for cyc in range(len(ATL15_dh_sub.time)-1): \n",
    "        pos = np.nanmax(ATL15_dh_sub.delta_h[cyc+1,:,:]-ATL15_dh_sub.delta_h[cyc,:,:])\n",
    "        neg = np.nanmin(ATL15_dh_sub.delta_h[cyc+1,:,:]-ATL15_dh_sub.delta_h[cyc,:,:])\n",
    "        height_anom_pos += [pos]\n",
    "        height_anom_neg += [neg]\n",
    "    max_height_anom_pos = max(height_anom_pos)\n",
    "    max_height_anom_neg = min(height_anom_neg)\n",
    "    max_height_anom_abs = max(max_height_anom_pos,abs(max_height_anom_neg))\n",
    "    v = np.round(max_height_anom_abs)\n",
    "    # only plot lakes with signal above arbitrary background noise\n",
    "    # create empty lists to store calculated data\n",
    "    dates_CS2 = []\n",
    "    dates_IS2 = []\n",
    "    dhdt_onlakeavg_SF18_CS2 = []\n",
    "    dhdt_onlakeavg_SF18_IS2 = []\n",
    "    dvdt_SF18_CS2 = []\n",
    "    dvdt_SF18_IS2 = []\n",
    "    dhdt_onlakeavg_var_CS2 = []\n",
    "    dhdt_onlakeavg_var_IS2 = []\n",
    "    dvdt_var_CS2 = []\n",
    "    dvdt_var_IS2 = []\n",
    "    for idx in range(len(CS2_dh_sub.delta_h)-1): \n",
    "        dhdt_CS2 = CS2_dh_sub.delta_h[idx+1,:,:]-CS2_dh_sub.delta_h[idx,:,:]\n",
    "        dhdt_IS2 = ATL15_dh_sub.delta_h[idx+1,:,:]-ATL15_dh_sub.delta_h[idx,:,:]\n",
    "        # calculate mid-cycle dates for plotting\n",
    "        # CryoSat-2\n",
    "        newdate = datetime.datetime(int(CS2_dh_sub.time.values[idx]), 1, 1) + datetime.timedelta(days = (CS2_dh_sub.time.values[idx] % 1) * 365.25)\n",
    "        newdate1 = datetime.datetime(int(CS2_dh_sub.time.values[idx+1]), 1, 1) + datetime.timedelta(days = (CS2_dh_sub.time.values[idx+1] % 1) * 365.25)\n",
    "        midcycdays = newdate1 - newdate\n",
    "        midcycdate = newdate + midcycdays/2\n",
    "        dates_CS2 += [midcycdate]\n",
    "        # ICESat-2\n",
    "        date_time_str = '18-01-01'\n",
    "        date_time_obj = datetime.datetime.strptime(date_time_str, '%y-%m-%d')\n",
    "        newdate = date_time_obj + datetime.timedelta(days=ATL15_dh_sub.time.values[idx])\n",
    "        newdate1 = date_time_obj + datetime.timedelta(days=ATL15_dh_sub.time.values[idx+1])\n",
    "        midcycdays = newdate1 - newdate\n",
    "        midcycdate = newdate + midcycdays/2\n",
    "        dates_IS2 += [midcycdate]\n",
    "        # clip data to get lake stats (first set crs)\n",
    "        dhdt_CS2.rio.write_crs(3031, inplace=True)\n",
    "        dhdt_IS2.rio.write_crs(3031, inplace=True)\n",
    "        dhdt_CS2_clip_SF18 = dhdt_CS2.rio.clip(lake_SF18.geometry.values, lake_SF18.crs, drop=False, invert=False)\n",
    "        dhdt_IS2_clip_SF18 = dhdt_IS2.rio.clip(lake_SF18.geometry.values, lake_SF18.crs, drop=False, invert=False)\n",
    "        # calculate lake avg. dh/dt and dv/dt time series using published stationary outlines\n",
    "        dhdt_CS2_lkavg_SF18 = np.nanmean(dhdt_CS2_clip_SF18)\n",
    "        dhdt_IS2_lkavg_SF18 = np.nanmean(dhdt_IS2_clip_SF18)\n",
    "        dhdt_onlakeavg_SF18_CS2 += [dhdt_CS2_lkavg_SF18]\n",
    "        dhdt_onlakeavg_SF18_IS2 += [dhdt_IS2_lkavg_SF18]\n",
    "        dhdt_CS2_vol_SF18 = dhdt_CS2_lkavg_SF18 * SiegfriedFricker2018_outlines[SiegfriedFricker2018_outlines['name'] == lakename_S23]['area (m^2)']\n",
    "        dhdt_IS2_vol_SF18 = dhdt_IS2_lkavg_SF18 * SiegfriedFricker2018_outlines[SiegfriedFricker2018_outlines['name'] == lakename_S23]['area (m^2)']\n",
    "        dvdt_SF18_CS2 += [dhdt_CS2_vol_SF18.values[0]]\n",
    "        dvdt_SF18_IS2 += [dhdt_IS2_vol_SF18.values[0]]\n",
    "        # create contours of ice surface elevation height changes to delineate lake outlines\n",
    "        contours_fill_CS2 = []\n",
    "        contours_drain_CS2 = []\n",
    "        contours_fill_IS2 = []\n",
    "        contours_drain_IS2 = []\n",
    "        # create CryoSat-2 variable outliens\n",
    "        contour = measure.find_contours(dhdt_CS2.values, thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_fill_CS2 += [contour]\n",
    "        contour = measure.find_contours(dhdt_CS2.values, -thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_drain_CS2 += [contour]\n",
    "        # create mapping conversion factor to map array location to polar stereographic x,y\n",
    "        x_conv = (x_max-x_min)/dhdt_CS2.shape[1] # MOVE OUT OF DHDT FOR LOOP SO THAT THIS CONSTANT CONVERSION FACTOR IS NOT CALCULATED EACH LOOP\n",
    "        y_conv = (y_max-y_min)/dhdt_CS2.shape[0]\n",
    "        # make polygons from variable outlines\n",
    "        polys_CS2 = []\n",
    "        for i in range(len(contours_fill_CS2)): \n",
    "            for j in range(len(contours_fill_CS2[i])):\n",
    "                if len(contours_fill_CS2[i][j][:, 1]) > 2: \n",
    "                    poly = Polygon(list(zip(x_min+contours_fill_CS2[i][j][:, 1]*x_conv, y_max-contours_fill_CS2[i][j][:, 0]*y_conv))) \n",
    "                    polys_CS2 += [poly]\n",
    "        for i in range(len(contours_drain_CS2)): \n",
    "            for j in range(len(contours_drain_CS2[i])):\n",
    "                if len(contours_drain_CS2[i][j][:, 1]) > 2: \n",
    "                    poly = Polygon(list(zip(x_min+contours_drain_CS2[i][j][:, 1]*x_conv, y_max-contours_drain_CS2[i][j][:, 0]*y_conv))) \n",
    "                    polys_CS2 += [poly]\n",
    "        # create ICESat-2 variable outlines\n",
    "        contour = measure.find_contours(dhdt_IS2.values, thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_fill_IS2 += [contour]\n",
    "        contour = measure.find_contours(dhdt_IS2.values, -thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_drain_IS2 += [contour]\n",
    "        # create mapping conversion factor to map array location to polar stereographic x,y\n",
    "        x_conv = (x_max-x_min)/dhdt_IS2.shape[1]\n",
    "        y_conv = (y_max-y_min)/dhdt_IS2.shape[0]\n",
    "        # make polygons from variable outlines\n",
    "        polys_IS2 = []  \n",
    "        for i in range(len(contours_fill_IS2)): \n",
    "            for j in range(len(contours_fill_IS2[i])):\n",
    "                if len(contours_fill_IS2[i][j][:, 1]) > 2: \n",
    "                    poly = Polygon(list(zip(x_min+contours_fill_IS2[i][j][:, 1]*x_conv, y_max-contours_fill_IS2[i][j][:, 0]*y_conv))) \n",
    "                    polys_IS2 += [poly]\n",
    "        for i in range(len(contours_drain_IS2)): \n",
    "            for j in range(len(contours_drain_IS2[i])):\n",
    "                if len(contours_drain_IS2[i][j][:, 1]) > 2: \n",
    "                    poly = Polygon(list(zip(x_min+contours_drain_IS2[i][j][:, 1]*x_conv, y_max-contours_drain_IS2[i][j][:, 0]*y_conv))) \n",
    "                    polys_IS2 += [poly]\n",
    "        # start with baseline variable outline area of zero\n",
    "        variable_area = 0\n",
    "        # CryoSat-2\n",
    "        # if polygons are present at time step, \n",
    "        if len(polys_CS2) > 0: \n",
    "            # clip data to polygons\n",
    "            dhdt_clip = dhdt_CS2.rio.clip(polys_CS2, drop=False, invert=False)\n",
    "            # then calculate on-lake averages of dh/dt\n",
    "            avg_lk_dhdt = np.nanmean(dhdt_clip)\n",
    "            # occasionally small polygons will completely clip data resulting in nan's for lake avg. dh/dt; replace with zeros\n",
    "            if math.isnan(avg_lk_dhdt): \n",
    "                avg_lk_dhdt = 0\n",
    "                dhdt_onlakeavg_var_CS2 += [avg_lk_dhdt]\n",
    "            else:\n",
    "                dhdt_onlakeavg_var_CS2 += [avg_lk_dhdt]\n",
    "            # and dv/dt\n",
    "            for i in range(len(polys_CS2)):\n",
    "                variable_area = variable_area + polys_CS2[i].area # CHANGE TO GEODESIC AREA\n",
    "            vol_var = avg_lk_dhdt*variable_area\n",
    "            dvdt_var_CS2 += [vol_var]\n",
    "        else: \n",
    "            avg_lk_dhdt = 0\n",
    "            dhdt_onlakeavg_var_CS2 += [avg_lk_dhdt]\n",
    "            vol_var = avg_lk_dhdt*variable_area\n",
    "            dvdt_var_CS2 += [vol_var]\n",
    "        # ICESat-2\n",
    "        # if polygons are present at time step, \n",
    "        if len(polys_IS2) > 0: \n",
    "            # clip data to polygons\n",
    "            dhdt_clip = dhdt_IS2.rio.clip(polys_IS2, drop=False, invert=False)\n",
    "            # then calculate on-lake averages of dh/dt\n",
    "            avg_lk_dhdt = np.nanmean(dhdt_clip)\n",
    "            # occasionally small polygons will completely clip data resulting in nan's for lake avg. dh/dt\n",
    "            # replace with zeros\n",
    "            if math.isnan(avg_lk_dhdt): \n",
    "                avg_lk_dhdt = 0\n",
    "                dhdt_onlakeavg_var_IS2 += [avg_lk_dhdt]\n",
    "            else:\n",
    "                dhdt_onlakeavg_var_IS2 += [avg_lk_dhdt]\n",
    "            # and dv/dt\n",
    "            for i in range(len(polys_IS2)):\n",
    "                variable_area = variable_area + polys_IS2[i].area # CHANGE TO GEODESIC AREA\n",
    "            vol_var = avg_lk_dhdt*variable_area\n",
    "            dvdt_var_IS2 += [vol_var]\n",
    "        else: \n",
    "            avg_lk_dhdt = 0\n",
    "            dhdt_onlakeavg_var_IS2 += [avg_lk_dhdt]\n",
    "            vol_var = avg_lk_dhdt*variable_area\n",
    "            dvdt_var_IS2 += [vol_var]\n",
    "    # create fig, axes\n",
    "    fig, axes = plt.subplots(2,2, figsize=(20,20))\n",
    "    # create colorbar axes for dh/dt subplots\n",
    "    # divider0 = make_axes_locatable(axes[0,0])\n",
    "    # cax0 = divider0.append_axes('right', size='5%', pad=0.2)\n",
    "    divider1 = make_axes_locatable(axes[0,1])\n",
    "    cax1 = divider1.append_axes('right', size='5%', pad=0.2)\n",
    "    # create empty list to store animation im(age)s\n",
    "    ani = animation.PillowWriter(fps=1)\n",
    "    ani.setup(fig, '/Users/Wilson/Documents/0-code/1-lakeshores/output_dhdvdt-using-variable-outlines/S09SF18varoutlines_dhdvdt_CS2vsIS2_anim/anim/S09SF18varoutlines_dhdvdt_CS2vsIS2_anim-{}.gif'.format(lakename_S23), dpi=300)\n",
    "    # for loop through dh/dt acquisition cycles to construct animation\n",
    "    for idx in range(len(CS2_dh_sub.delta_h)-1): \n",
    "        dhdt_CS2 = CS2_dh_sub.delta_h[idx+1,:,:]-CS2_dh_sub.delta_h[idx,:,:]\n",
    "        dhdt_IS2 = ATL15_dh_sub.delta_h[idx+1,:,:]-ATL15_dh_sub.delta_h[idx,:,:]\n",
    "        # create contours of ice surface elevation height changes to delineate lake outlines\n",
    "        contours_fill_CS2 = []\n",
    "        contours_drain_CS2 = []\n",
    "        contours_fill_IS2 = []\n",
    "        contours_drain_IS2 = []\n",
    "        # create CryoSat-2 variable outliens\n",
    "        contour = measure.find_contours(dhdt_CS2.values, thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_fill_CS2 += [contour]\n",
    "        contour = measure.find_contours(dhdt_CS2.values, -thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_drain_CS2 += [contour]\n",
    "        # create ICESat-2 variable outlines\n",
    "        contour = measure.find_contours(dhdt_IS2.values, thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_fill_IS2 += [contour]\n",
    "        contour = measure.find_contours(dhdt_IS2.values, -thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_drain_IS2 += [contour]\n",
    "        # subplot 0: plot planview dhdt and variable outlines found in CryoSat-2 time slice\n",
    "        img0 = axes[0,0].imshow(dhdt_CS2, extent=[x_min, x_max, y_min, y_max], \n",
    "            origin='upper', cmap=cmocean.cm.balance_r, vmin=-v, vmax=v)\n",
    "        for i in range(len(contours_fill_CS2)): \n",
    "            for j in range(len(contours_fill_CS2[i])):\n",
    "                axes[0,0].plot(x_min+contours_fill_CS2[i][j][:, 1]*x_conv, y_max-contours_fill_CS2[i][j][:, 0]*y_conv, color='mediumblue', linestyle='dashdot', linewidth=2)\n",
    "        for i in range(len(contours_drain_CS2)): \n",
    "            for j in range(len(contours_drain_CS2[i])):\n",
    "                axes[0,0].plot(x_min+contours_drain_CS2[i][j][:, 1]*x_conv, y_max-contours_drain_CS2[i][j][:, 0]*y_conv, color='maroon', linestyle=(0, (3, 1, 1, 1)), linewidth=2)\n",
    "        axes[0,0].set(xlim=(x_min, x_max), ylim=(y_min, y_max))\n",
    "        # change polar stereographic m to km for cleaner-looking axes labels\n",
    "        km_scale = 1e3\n",
    "        ticks_x = ticker.FuncFormatter(lambda x, pos: '{0:g}'.format(x/km_scale))\n",
    "        axes[0,0].xaxis.set_major_formatter(ticks_x)\n",
    "        ticks_y = ticker.FuncFormatter(lambda x, pos: '{0:g}'.format(x/km_scale))\n",
    "        axes[0,0].yaxis.set_major_formatter(ticks_y)  \n",
    "        axes[0,0].set_xlabel('x [km]', size=15)\n",
    "        axes[0,0].set_ylabel('y [km]', size=15)\n",
    "        axes[0,0].set_title(lakename_S23+' CryoSat-2 dh \\n$h_{'+dates_CS2[idx].strftime('%m/%Y')+'} - h_{'+dates_CS2[idx-1].strftime('%m/%Y')+'}$', pad=7.5, fontsize=17.5)\n",
    "        # fig.colorbar(img0, cax=cax0).set_label('Height (h) change [m]', size=15)\n",
    "        # overlay published outlines for visual comparison \n",
    "        Smith2009_outlines.boundary.plot(ax=axes[0,0], color='k', linestyle='--', linewidth=1)\n",
    "        SiegfriedFricker2018_outlines[SiegfriedFricker2018_outlines['cite'] \\\n",
    "            != 'Smith and others, 2009, J. Glac., doi:10.3189/002214309789470879'] \\\n",
    "            .boundary.plot(ax=axes[0,0], color='k', linestyle='-', linewidth=1)\n",
    "        # create 2D lines for legend\n",
    "        Smith2009 = plt.Line2D((0, 1), (0, 0), color='k', linestyle='--', linewidth=2)\n",
    "        SiegfriedFricker2018 = plt.Line2D((0, 1), (0, 0), color='k', linestyle='-', linewidth=2)\n",
    "        uplift = plt.Line2D((0, 1), (0, 0), color='mediumblue', linestyle='dashdot', linewidth=2)\n",
    "        subsidence = plt.Line2D((0, 1), (0, 0), color='maroon', linestyle=(0, (3, 1, 1, 1)), linewidth=2)\n",
    "        axes[0,0].legend([Smith2009, SiegfriedFricker2018, uplift, subsidence],\n",
    "            ['Smith and others, 2009 static outline','Siegfried & Fricker, 2018 static outline',\n",
    "            ('+'+str(thres)+' m uplift (filling) variable outline'), 'â€“'+str(thres)+' m subsidence (draining) variable outline'], \n",
    "            loc='upper left')\n",
    "        # plot inset map to show location \n",
    "        axIns = axes[0,0].inset_axes([0.001, 0.001, 0.25, 0.25])\n",
    "        axIns.patch.set_facecolor('lightskyblue')\n",
    "        axIns.set_aspect('equal')\n",
    "        axIns.scatter(((x_max+x_min)/2), ((y_max+y_min)/2), marker='*', \n",
    "            linewidth=1, edgecolor='k', facecolor='r', s=100, zorder=3)\n",
    "        Scripps_gl.plot(ax=axIns, color='ghostwhite', edgecolor='k', linewidth=0.5, zorder=2)\n",
    "        axIns.axis('off')\n",
    "        \n",
    "        # subplot 1: plot planview dhdt and variable outlines found in ICESat-2 time slice\n",
    "        img1 = axes[0,1].imshow(dhdt_IS2, extent=[x_min, x_max, y_min, y_max], \n",
    "            origin='upper', cmap=cmocean.cm.balance_r, vmin=-v, vmax=v)\n",
    "        for i in range(len(contours_fill_IS2)): \n",
    "            for j in range(len(contours_fill_IS2[i])):\n",
    "                axes[0,1].plot(x_min+contours_fill_IS2[i][j][:, 1]*x_conv, y_max-contours_fill_IS2[i][j][:, 0]*y_conv, color='mediumblue', linestyle='dashdot', linewidth=2)\n",
    "        for i in range(len(contours_drain_IS2)): \n",
    "            for j in range(len(contours_drain_IS2[i])):\n",
    "                axes[0,1].plot(x_min+contours_drain_IS2[i][j][:, 1]*x_conv, y_max-contours_drain_IS2[i][j][:, 0]*y_conv, color='maroon', linestyle=(0, (3, 1, 1, 1)), linewidth=2)\n",
    "        axes[0,1].set(xlim=(x_min, x_max), ylim=(y_min, y_max))\n",
    "        # change polar stereographic m to km for cleaner-looking axes labels\n",
    "        km_scale = 1e3\n",
    "        ticks_x = ticker.FuncFormatter(lambda x, pos: '{0:g}'.format(x/km_scale))\n",
    "        axes[0,1].xaxis.set_major_formatter(ticks_x)\n",
    "        ticks_y = ticker.FuncFormatter(lambda x, pos: '{0:g}'.format(x/km_scale))\n",
    "        axes[0,1].yaxis.set_major_formatter(ticks_y)  \n",
    "        axes[0,1].set_xlabel('x [km]', size=15)\n",
    "        # ax.set_ylabel('y [km]', size=15)\n",
    "        axes[0,1].set_title(lakename_S23+' ICESat-2 dh \\n$h_{'+dates_IS2[idx].strftime('%m/%Y')+'} - h_{'+dates_IS2[idx-1].strftime('%m/%Y')+'}$', pad=7.5, fontsize=17.5)\n",
    "        fig.colorbar(img1, cax=cax1).set_label('Height change (dh) [m]', size=15)\n",
    "        # overlay published outlines for visual comparison \n",
    "        Smith2009_outlines.boundary.plot(ax=axes[0,1], color='k', linestyle='--', linewidth=1)\n",
    "        SiegfriedFricker2018_outlines[SiegfriedFricker2018_outlines['cite'] \\\n",
    "            != 'Smith and others, 2009, J. Glac., doi:10.3189/002214309789470879'] \\\n",
    "            .boundary.plot(ax=axes[0,1], color='k', linestyle='-', linewidth=1)\n",
    "        axes[0,1].legend([Smith2009, SiegfriedFricker2018, uplift, subsidence],\n",
    "            ['Smith and others, 2009 static outline','Siegfried & Fricker, 2018 static outline',\n",
    "            ('+'+str(thres)+' m uplift (filling) variable outline'), 'â€“'+str(thres)+' m subsidence (draining) variable outline'], \n",
    "            loc='upper left')\n",
    "\n",
    "        # suplot 2: plot CS2 dvdt time series\n",
    "        axes[1,0].plot(dates_CS2[:idx+1], np.divide(np.cumsum(dvdt_SF18_CS2[:idx+1]), 1e+9), color='k', linestyle='dashed')\n",
    "        axes[1,0].plot(dates_CS2[:idx+1], np.divide(np.cumsum(dvdt_var_CS2[:idx+1]), 1e+9), color='darkturquoise', linestyle='dashdot')\n",
    "        locator = mdates.AutoDateLocator(minticks=1, maxticks=7)\n",
    "        formatter = mdates.ConciseDateFormatter(locator)\n",
    "        axes[1,0].xaxis.set_major_locator(locator)\n",
    "        axes[1,0].xaxis.set_major_formatter(formatter)\n",
    "        # CONSIDER MOVING OUT OF FOR LOOP SO IT'S NOT CALCULATING CONSTANTS EVERY LOOP\n",
    "        dvdt_min = min(np.divide(min(np.cumsum(dvdt_SF18_CS2)), 1e+9), np.divide(min(np.cumsum(dvdt_var_CS2)), 1e+9), np.divide(min(np.cumsum(dvdt_SF18_IS2)), 1e+9), np.divide(min(np.cumsum(dvdt_var_IS2)), 1e+9))\n",
    "        dvdt_max = max(np.divide(max(np.cumsum(dvdt_SF18_CS2)), 1e+9), np.divide(max(np.cumsum(dvdt_var_CS2)), 1e+9), np.divide(max(np.cumsum(dvdt_SF18_IS2)), 1e+9), np.divide(max(np.cumsum(dvdt_var_IS2)), 1e+9))\n",
    "        dvdt_range = dvdt_max - dvdt_min\n",
    "        ylim_min = dvdt_min - (dvdt_range * 0.1)\n",
    "        ylim_max = dvdt_max + (dvdt_range * 0.1)\n",
    "        axes[1,0].set(xlim=(\n",
    "            datetime.datetime(int(CS2_dh_sub.time.values[0]), 1, 1) + datetime.timedelta(days = (CS2_dh_sub.time.values[0] % 1) * 365.25), \n",
    "            datetime.datetime(int(CS2_dh_sub.time.values[-1]), 1, 1) + datetime.timedelta(days = (CS2_dh_sub.time.values[-1] % 1) * 365.25)), \n",
    "            ylim=(ylim_min, ylim_max))\n",
    "        axes[1,0].set_title('{} CryoSat-2 dv'.format(lakename_S23), pad=7.5, fontsize=17.5)\n",
    "        axes[1,0].set_xlabel('Year', size=15)\n",
    "        axes[1,0].set_ylabel('Volume change [km$^3$]', size=15)\n",
    "        variable_outlines = plt.Line2D((0, 1), (0, 0), color='darkturquoise', linestyle='dashdot', linewidth=2)\n",
    "        axes[1,0].legend([#Smith2009,\n",
    "            SiegfriedFricker2018, variable_outlines],\n",
    "            [#'Smith and others, 2009',\n",
    "            'Siegfried & Fricker, 2018',\n",
    "            'Â±{} m variable outlines'.format(thres)], \n",
    "            loc='upper left')\n",
    "\n",
    "        # suplot 3: plot IS2 dvdt time series\n",
    "        axes[1,1].plot(dates_IS2[:idx+1], np.divide(np.cumsum(dvdt_SF18_IS2[:idx+1]), 1e+9), color='k', linestyle='dashed')\n",
    "        axes[1,1].plot(dates_IS2[:idx+1], np.divide(np.cumsum(dvdt_var_IS2[:idx+1]), 1e+9), color='darkturquoise', linestyle='dashdot')\n",
    "        locator = mdates.AutoDateLocator(minticks=1, maxticks=7)\n",
    "        formatter = mdates.ConciseDateFormatter(locator)\n",
    "        axes[1,1].xaxis.set_major_locator(locator)\n",
    "        axes[1,1].xaxis.set_major_formatter(formatter)\n",
    "        axes[1,1].set(xlim=(\n",
    "            date_time_obj + datetime.timedelta(days=ATL15_dh_sub.time.values[0]),\n",
    "            date_time_obj + datetime.timedelta(days=ATL15_dh_sub.time.values[-1])), \n",
    "            ylim=(ylim_min, ylim_max))\n",
    "        axes[1,1].set_title('{} ICESat-2 dv'.format(lakename_S23), pad=7.5, fontsize=17.5)\n",
    "        axes[1,1].set_xlabel('Year', size=15)\n",
    "        axes[1,1].set_ylabel('Volume change [km$^3$]', size=15)\n",
    "        variable_outlines = plt.Line2D((0, 1), (0, 0), color='darkturquoise', linestyle='dashdot', linewidth=2)\n",
    "        axes[1,1].legend([#Smith2009,\n",
    "            SiegfriedFricker2018, variable_outlines],\n",
    "            [#'Smith and others, 2009',\n",
    "            'Siegfried & Fricker, 2018',\n",
    "            'Â±{} m variable outlines'.format(thres)], \n",
    "            loc='upper left')\n",
    "            \n",
    "        # save and close figure\n",
    "        plt.savefig('/Users/Wilson/Documents/0-code/1-lakeshores/output_dhdvdt-using-variable-outlines/S09SF18varoutlines_dhdvdt_CS2vsIS2_anim/plot/S09SF18varoutlines_dhdvdt_CS2vsIS2_anim-{}-dhdt-{}.png'.format(lakename_S23,midcycdate.strftime('%Y-%m')), dpi=300, bbox_inches = \"tight\")  \n",
    "        # append im(age) to ims list\n",
    "        ani.grab_frame()\n",
    "        axes[0,0].clear()\n",
    "        axes[0,1].clear()\n",
    "        axes[1,0].clear()\n",
    "        axes[1,1].clear()\n",
    "    # create animation and save, adjust interval\n",
    "    ani.finish()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test function working using one lake\n",
    "S09SF18varoutlines_dhdvdt_CS2vsIS2_anim('ConwaySubglacialLake', 12500, 0.5)\n",
    "# S09SF18varoutlines_dhdvdt_CS2vsIS2_anim('Whillans_7', 7500, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run func on all lakes from SF18 inventory\n",
    "for idx in range(len(SiegfriedFricker2018_outlines)-1):\n",
    "    lakename = SiegfriedFricker2018_outlines['name'][idx]\n",
    "    S09SF18varoutlines_dhdvdt_CS2vsIS2_anim(lakename, 7500, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding S09 to area calcs\n",
    "def S09SF18varoutlines_dhdvdt_CS2vsIS2_anim(lakename_S09, lakename_S23, buffer, thres): \n",
    "    '''\n",
    "    Create CryoSat-2 (CS2) and ICESat-2 (IS2) dh/dt plots of ice surface height changes using geopandas buffer created bounding box around known lakes in Siegfried and Fricker, 2018 inventory.\n",
    "    Create time-variable outlines using skimage contour to plot variable outline alongside published outlines for comparison. \n",
    "    Use static and time-variable outlines to calculate dv/dt in both CryoSat-2 and ICESat-2.\n",
    "    Save images together into GIF animation.\n",
    "    Inputs: \n",
    "        lakename: lake of interest from SiegfriedFricker2018_outlines inventory\n",
    "        buffer: horizontal distance in meters to create bounding box around lake of interest\n",
    "        thres(hold): vertical distance in meters to delineate ice surface deformation contour\n",
    "    Outputs: \n",
    "        Animations of planview dh/dt visuals with variable ice surface deformation contours plotted to delineate time-variable lake boundary \n",
    "        alongside 2-D line plots of cumulative dv/dt using static and variable outlines that updates simultaneously to planview dh/dt animation.\n",
    "    '''\n",
    "    # isolate individual lake using gpd buffer\n",
    "    lake_S09 = Smith2009_outlines.loc[Smith2009_outlines['Name'] == lakename_S09]\n",
    "    lake_SF18 = SiegfriedFricker2018_outlines.loc[SiegfriedFricker2018_outlines['name'] == lakename_S23]\n",
    "    lake_buffer = lake_SF18.buffer(buffer)\n",
    "    # define lake bounding box\n",
    "    x_min = lake_buffer.bounds.values[0,0]; x_max = lake_buffer.bounds.values[0,2]\n",
    "    y_min = lake_buffer.bounds.values[0,1]; y_max = lake_buffer.bounds.values[0,3]\n",
    "    # subset CS2 data set to region of interest\n",
    "    dataset = CS2_dh\n",
    "    mask_x = (dataset.x >= x_min) & (dataset.x <= x_max)\n",
    "    mask_y = (dataset.y >= y_min) & (dataset.y <= y_max)\n",
    "    mask_t = (dataset.time >= 2018.75)\n",
    "    CS2_dh_sub = dataset.where(mask_x & mask_y & mask_t, drop=True)\n",
    "    # subset ATL15 data set to region of interest\n",
    "    dataset = ATL15_dh\n",
    "    mask_x = (dataset.x >= x_min) & (dataset.x <= x_max)\n",
    "    mask_y = (dataset.y >= y_min) & (dataset.y <= y_max)\n",
    "    ATL15_dh_sub = dataset.where(mask_x & mask_y, drop=True)\n",
    "    # find magnitude of ice surface deformation in bounding box / find appropriate color map scale\n",
    "    height_anom_pos = []\n",
    "    height_anom_neg = []\n",
    "    for cyc in range(len(CS2_dh_sub)-1): # SHOULD ONLY CLIP TO CYCS IN IS2 ERA\n",
    "        pos = np.nanmax(CS2_dh_sub.delta_h[cyc+1,:,:]-CS2_dh_sub.delta_h[cyc,:,:])\n",
    "        neg = np.nanmin(CS2_dh_sub.delta_h[cyc+1,:,:]-CS2_dh_sub.delta_h[cyc,:,:])\n",
    "        height_anom_pos += [pos]\n",
    "        height_anom_neg += [neg]\n",
    "    for cyc in range(len(ATL15_dh_sub.time)-1): \n",
    "        pos = np.nanmax(ATL15_dh_sub.delta_h[cyc+1,:,:]-ATL15_dh_sub.delta_h[cyc,:,:])\n",
    "        neg = np.nanmin(ATL15_dh_sub.delta_h[cyc+1,:,:]-ATL15_dh_sub.delta_h[cyc,:,:])\n",
    "        height_anom_pos += [pos]\n",
    "        height_anom_neg += [neg]\n",
    "    max_height_anom_pos = max(height_anom_pos)\n",
    "    max_height_anom_neg = min(height_anom_neg)\n",
    "    max_height_anom_abs = max(max_height_anom_pos,abs(max_height_anom_neg))\n",
    "    v = np.round(max_height_anom_abs)\n",
    "    # create empty lists to store calculated data\n",
    "    dates_CS2 = []\n",
    "    dates_IS2 = []\n",
    "    dhdt_onlakeavg_S09_CS2 = []\n",
    "    dhdt_onlakeavg_S09_IS2 = []\n",
    "    dvdt_S09_CS2 = []\n",
    "    dvdt_S09_IS2 = []\n",
    "    dhdt_onlakeavg_SF18_CS2 = []\n",
    "    dhdt_onlakeavg_SF18_IS2 = []\n",
    "    dvdt_SF18_CS2 = []\n",
    "    dvdt_SF18_IS2 = []\n",
    "    dhdt_onlakeavg_var_CS2 = []\n",
    "    dhdt_onlakeavg_var_IS2 = []\n",
    "    dvdt_var_CS2 = []\n",
    "    dvdt_var_IS2 = []\n",
    "    for idx in range(len(CS2_dh_sub.delta_h)-1): \n",
    "        dhdt_CS2 = CS2_dh_sub.delta_h[idx+1,:,:]-CS2_dh_sub.delta_h[idx,:,:]\n",
    "        dhdt_IS2 = ATL15_dh_sub.delta_h[idx+1,:,:]-ATL15_dh_sub.delta_h[idx,:,:]\n",
    "        # calculate mid-cycle dates for plotting\n",
    "        # CryoSat-2\n",
    "        newdate = datetime.datetime(int(CS2_dh_sub.time.values[idx]), 1, 1) + datetime.timedelta(days = (CS2_dh_sub.time.values[idx] % 1) * 365.25)\n",
    "        newdate1 = datetime.datetime(int(CS2_dh_sub.time.values[idx+1]), 1, 1) + datetime.timedelta(days = (CS2_dh_sub.time.values[idx+1] % 1) * 365.25)\n",
    "        midcycdays = newdate1 - newdate\n",
    "        midcycdate = newdate + midcycdays/2\n",
    "        dates_CS2 += [midcycdate]\n",
    "        # ICESat-2\n",
    "        date_time_str = '18-01-01'\n",
    "        date_time_obj = datetime.datetime.strptime(date_time_str, '%y-%m-%d')\n",
    "        newdate = date_time_obj + datetime.timedelta(days=ATL15_dh_sub.time.values[idx])\n",
    "        newdate1 = date_time_obj + datetime.timedelta(days=ATL15_dh_sub.time.values[idx+1])\n",
    "        midcycdays = newdate1 - newdate\n",
    "        midcycdate = newdate + midcycdays/2\n",
    "        dates_IS2 += [midcycdate]\n",
    "        # clip data to get lake stats (first set crs)\n",
    "        dhdt_CS2.rio.write_crs(3031, inplace=True)\n",
    "        dhdt_IS2.rio.write_crs(3031, inplace=True)\n",
    "        dhdt_CS2_clip_S09 = dhdt_CS2.rio.clip(lake_S09.geometry.values, lake_SF18.crs, drop=False, invert=False)\n",
    "        dhdt_IS2_clip_S09 = dhdt_IS2.rio.clip(lake_S09.geometry.values, lake_SF18.crs, drop=False, invert=False)\n",
    "        dhdt_CS2_clip_SF18 = dhdt_CS2.rio.clip(lake_SF18.geometry.values, lake_SF18.crs, drop=False, invert=False)\n",
    "        dhdt_IS2_clip_SF18 = dhdt_IS2.rio.clip(lake_SF18.geometry.values, lake_SF18.crs, drop=False, invert=False)\n",
    "        # calculate lake avg. dh/dt and dv/dt time series using published stationary outlines\n",
    "        # S09\n",
    "        dhdt_CS2_lkavg_S09 = np.nanmean(dhdt_CS2_clip_S09)\n",
    "        dhdt_IS2_lkavg_S09 = np.nanmean(dhdt_IS2_clip_S09)\n",
    "        dhdt_onlakeavg_S09_CS2 += [dhdt_CS2_lkavg_S09]\n",
    "        dhdt_onlakeavg_S09_IS2 += [dhdt_IS2_lkavg_S09]\n",
    "        dhdt_CS2_vol_S09 = dhdt_CS2_lkavg_S09 * SiegfriedFricker2018_outlines[SiegfriedFricker2018_outlines['name'] == lakename_S23]['area (m^2)']\n",
    "        dhdt_IS2_vol_S09 = dhdt_IS2_lkavg_S09 * SiegfriedFricker2018_outlines[SiegfriedFricker2018_outlines['name'] == lakename_S23]['area (m^2)']\n",
    "        dvdt_S09_CS2 += [dhdt_CS2_vol_S09.values[0]]\n",
    "        dvdt_S09_IS2 += [dhdt_IS2_vol_S09.values[0]]\n",
    "        # SF18\n",
    "        dhdt_CS2_lkavg_SF18 = np.nanmean(dhdt_CS2_clip_SF18)\n",
    "        dhdt_IS2_lkavg_SF18 = np.nanmean(dhdt_IS2_clip_SF18)\n",
    "        dhdt_onlakeavg_SF18_CS2 += [dhdt_CS2_lkavg_SF18]\n",
    "        dhdt_onlakeavg_SF18_IS2 += [dhdt_IS2_lkavg_SF18]\n",
    "        dhdt_CS2_vol_SF18 = dhdt_CS2_lkavg_SF18 * SiegfriedFricker2018_outlines[SiegfriedFricker2018_outlines['name'] == lakename_S23]['area (m^2)']\n",
    "        dhdt_IS2_vol_SF18 = dhdt_IS2_lkavg_SF18 * SiegfriedFricker2018_outlines[SiegfriedFricker2018_outlines['name'] == lakename_S23]['area (m^2)']\n",
    "        dvdt_SF18_CS2 += [dhdt_CS2_vol_SF18.values[0]]\n",
    "        dvdt_SF18_IS2 += [dhdt_IS2_vol_SF18.values[0]]\n",
    "        # create contours of ice surface elevation height changes to delineate lake outlines\n",
    "        contours_fill_CS2 = []\n",
    "        contours_drain_CS2 = []\n",
    "        contours_fill_IS2 = []\n",
    "        contours_drain_IS2 = []\n",
    "        # create CryoSat-2 variable outliens\n",
    "        contour = measure.find_contours(dhdt_CS2.values, thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_fill_CS2 += [contour]\n",
    "        contour = measure.find_contours(dhdt_CS2.values, -thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_drain_CS2 += [contour]\n",
    "        # create mapping conversion factor to map array location to polar stereographic x,y\n",
    "        x_conv = (x_max-x_min)/dhdt_CS2.shape[1] # MOVE OUT OF DHDT FOR LOOP SO THAT THIS CONSTANT CONVERSION FACTOR IS NOT CALCULATED EACH LOOP\n",
    "        y_conv = (y_max-y_min)/dhdt_CS2.shape[0]\n",
    "        # make polygons from variable outlines\n",
    "        polys_CS2 = []\n",
    "        for i in range(len(contours_fill_CS2)): \n",
    "            for j in range(len(contours_fill_CS2[i])):\n",
    "                if len(contours_fill_CS2[i][j][:, 1]) > 2: \n",
    "                    poly = Polygon(list(zip(x_min+contours_fill_CS2[i][j][:, 1]*x_conv, y_max-contours_fill_CS2[i][j][:, 0]*y_conv))) \n",
    "                    polys_CS2 += [poly]\n",
    "        for i in range(len(contours_drain_CS2)): \n",
    "            for j in range(len(contours_drain_CS2[i])):\n",
    "                if len(contours_drain_CS2[i][j][:, 1]) > 2: \n",
    "                    poly = Polygon(list(zip(x_min+contours_drain_CS2[i][j][:, 1]*x_conv, y_max-contours_drain_CS2[i][j][:, 0]*y_conv))) \n",
    "                    polys_CS2 += [poly]\n",
    "        # create ICESat-2 variable outlines\n",
    "        contour = measure.find_contours(dhdt_IS2.values, thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_fill_IS2 += [contour]\n",
    "        contour = measure.find_contours(dhdt_IS2.values, -thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_drain_IS2 += [contour]\n",
    "        # create mapping conversion factor to map array location to polar stereographic x,y\n",
    "        x_conv = (x_max-x_min)/dhdt_IS2.shape[1]\n",
    "        y_conv = (y_max-y_min)/dhdt_IS2.shape[0]\n",
    "        # make polygons from variable outlines\n",
    "        polys_IS2 = []  \n",
    "        for i in range(len(contours_fill_IS2)): \n",
    "            for j in range(len(contours_fill_IS2[i])):\n",
    "                if len(contours_fill_IS2[i][j][:, 1]) > 2: \n",
    "                    poly = Polygon(list(zip(x_min+contours_fill_IS2[i][j][:, 1]*x_conv, y_max-contours_fill_IS2[i][j][:, 0]*y_conv))) \n",
    "                    polys_IS2 += [poly]\n",
    "        for i in range(len(contours_drain_IS2)): \n",
    "            for j in range(len(contours_drain_IS2[i])):\n",
    "                if len(contours_drain_IS2[i][j][:, 1]) > 2: \n",
    "                    poly = Polygon(list(zip(x_min+contours_drain_IS2[i][j][:, 1]*x_conv, y_max-contours_drain_IS2[i][j][:, 0]*y_conv))) \n",
    "                    polys_IS2 += [poly]\n",
    "        # start with baseline variable outline area of zero\n",
    "        variable_area = 0\n",
    "        # CryoSat-2\n",
    "        # if polygons are present at time step, \n",
    "        if len(polys_CS2) > 0: \n",
    "            # clip data to polygons\n",
    "            dhdt_clip = dhdt_CS2.rio.clip(polys_CS2, drop=False, invert=False)\n",
    "            # then calculate on-lake averages of dh/dt\n",
    "            avg_lk_dhdt = np.nanmean(dhdt_clip)\n",
    "            # occasionally small polygons will completely clip data resulting in nan's for lake avg. dh/dt; replace with zeros\n",
    "            if math.isnan(avg_lk_dhdt): \n",
    "                avg_lk_dhdt = 0\n",
    "                dhdt_onlakeavg_var_CS2 += [avg_lk_dhdt]\n",
    "            else:\n",
    "                dhdt_onlakeavg_var_CS2 += [avg_lk_dhdt]\n",
    "            # and dv/dt\n",
    "            for i in range(len(polys_CS2)):\n",
    "                variable_area = variable_area + polys_CS2[i].area # CHANGE TO GEODESIC AREA\n",
    "            vol_var = avg_lk_dhdt*variable_area\n",
    "            dvdt_var_CS2 += [vol_var]\n",
    "        else: \n",
    "            avg_lk_dhdt = 0\n",
    "            dhdt_onlakeavg_var_CS2 += [avg_lk_dhdt]\n",
    "            vol_var = avg_lk_dhdt*variable_area\n",
    "            dvdt_var_CS2 += [vol_var]\n",
    "        # ICESat-2\n",
    "        # if polygons are present at time step, \n",
    "        if len(polys_IS2) > 0: \n",
    "            # clip data to polygons\n",
    "            dhdt_clip = dhdt_IS2.rio.clip(polys_IS2, drop=False, invert=False)\n",
    "            # then calculate on-lake averages of dh/dt\n",
    "            avg_lk_dhdt = np.nanmean(dhdt_clip)\n",
    "            # occasionally small polygons will completely clip data resulting in nan's for lake avg. dh/dt\n",
    "            # replace with zeros\n",
    "            if math.isnan(avg_lk_dhdt): \n",
    "                avg_lk_dhdt = 0\n",
    "                dhdt_onlakeavg_var_IS2 += [avg_lk_dhdt]\n",
    "            else:\n",
    "                dhdt_onlakeavg_var_IS2 += [avg_lk_dhdt]\n",
    "            # and dv/dt\n",
    "            for i in range(len(polys_IS2)):\n",
    "                variable_area = variable_area + polys_IS2[i].area # CHANGE TO GEODESIC AREA\n",
    "            vol_var = avg_lk_dhdt*variable_area\n",
    "            dvdt_var_IS2 += [vol_var]\n",
    "        else: \n",
    "            avg_lk_dhdt = 0\n",
    "            dhdt_onlakeavg_var_IS2 += [avg_lk_dhdt]\n",
    "            vol_var = avg_lk_dhdt*variable_area\n",
    "            dvdt_var_IS2 += [vol_var]\n",
    "    # create fig, axes\n",
    "    fig, axes = plt.subplots(2,2, figsize=(20,20))\n",
    "    # create colorbar axes for dh/dt subplots\n",
    "    divider0 = make_axes_locatable(axes[0,0])\n",
    "    cax0 = divider0.append_axes('right', size='5%', pad=0.2)\n",
    "    divider1 = make_axes_locatable(axes[0,1])\n",
    "    cax1 = divider1.append_axes('right', size='5%', pad=0.2)\n",
    "    # create empty list to store animation im(age)s\n",
    "    ani = animation.PillowWriter(fps=1)\n",
    "    ani.setup(fig, '/Users/Wilson/Documents/0-code/1-lakeshores/output_dhdvdt-using-variable-outlines/S09SF18varoutlines_dhdt_CS2vsIS2_anim/S09SF18varoutlines_dhdt_CS2vsIS2_anim-{}.gif'.format(lakename_S23), dpi=300)\n",
    "    # for loop through dh/dt acquisition cycles to construct animation\n",
    "    for idx in range(len(CS2_dh_sub.delta_h)-1): \n",
    "        dhdt_CS2 = CS2_dh_sub.delta_h[idx+1,:,:]-CS2_dh_sub.delta_h[idx,:,:]\n",
    "        dhdt_IS2 = ATL15_dh_sub.delta_h[idx+1,:,:]-ATL15_dh_sub.delta_h[idx,:,:]\n",
    "        # create contours of ice surface elevation height changes to delineate lake outlines\n",
    "        contours_fill_CS2 = []\n",
    "        contours_drain_CS2 = []\n",
    "        contours_fill_IS2 = []\n",
    "        contours_drain_IS2 = []\n",
    "        # create CryoSat-2 variable outliens\n",
    "        contour = measure.find_contours(dhdt_CS2.values, thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_fill_CS2 += [contour]\n",
    "        contour = measure.find_contours(dhdt_CS2.values, -thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_drain_CS2 += [contour]\n",
    "        # create ICESat-2 variable outlines\n",
    "        contour = measure.find_contours(dhdt_IS2.values, thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_fill_IS2 += [contour]\n",
    "        contour = measure.find_contours(dhdt_IS2.values, -thres)\n",
    "        if len(contour) > 0: \n",
    "            contours_drain_IS2 += [contour]\n",
    "        # subplot 0: plot planview dhdt and variable outlines found in CryoSat-2 time slice\n",
    "        img0 = axes[0,0].imshow(dhdt_CS2, extent=[x_min, x_max, y_min, y_max], \n",
    "            origin='upper', cmap=cmocean.cm.balance_r, vmin=-v, vmax=v)\n",
    "        for i in range(len(contours_fill_CS2)): \n",
    "            for j in range(len(contours_fill_CS2[i])):\n",
    "                axes[0,0].plot(x_min+contours_fill_CS2[i][j][:, 1]*x_conv, y_max-contours_fill_CS2[i][j][:, 0]*y_conv, color='mediumblue', linestyle='dashdot', linewidth=2)\n",
    "        for i in range(len(contours_drain_CS2)): \n",
    "            for j in range(len(contours_drain_CS2[i])):\n",
    "                axes[0,0].plot(x_min+contours_drain_CS2[i][j][:, 1]*x_conv, y_max-contours_drain_CS2[i][j][:, 0]*y_conv, color='maroon', linestyle=(0, (3, 1, 1, 1)), linewidth=2)\n",
    "        axes[0,0].set(xlim=(x_min, x_max), ylim=(y_min, y_max))\n",
    "        axes[0,0].set_xlabel('polar stereographic x [m]', size=15)\n",
    "        axes[0,0].set_ylabel('polar stereographic y [m]', size=15)\n",
    "        axes[0,0].ticklabel_format(axis='both',scilimits=(0,0))\n",
    "        axes[0,0].set_title(lakename_S23+' CryoSat-2 dh \\n$h_{'+dates_CS2[idx].strftime('%m/%Y')+'} - h_{'+dates_CS2[idx-1].strftime('%m/%Y')+'}$', pad=7.5, fontsize=17.5)\n",
    "        # fig.colorbar(img0, cax=cax0).set_label('Height (h) change [m]', size=15)\n",
    "        # overlay published outlines for visual comparison \n",
    "        Smith2009_outlines.boundary.plot(ax=axes[0,0], color='k', linestyle='--', linewidth=1)\n",
    "        SiegfriedFricker2018_outlines[SiegfriedFricker2018_outlines['cite'] \\\n",
    "            != 'Smith and others, 2009, J. Glac., doi:10.3189/002214309789470879'] \\\n",
    "            .boundary.plot(ax=axes[0,0], color='k', linestyle='-', linewidth=1)\n",
    "        # create 2D lines for legend\n",
    "        Smith2009 = plt.Line2D((0, 1), (0, 0), color='k', linestyle='--', linewidth=2)\n",
    "        SiegfriedFricker2018 = plt.Line2D((0, 1), (0, 0), color='k', linestyle='-', linewidth=2)\n",
    "        uplift = plt.Line2D((0, 1), (0, 0), color='mediumblue', linestyle='dashdot', linewidth=2)\n",
    "        subsidence = plt.Line2D((0, 1), (0, 0), color='maroon', linestyle=(0, (3, 1, 1, 1)), linewidth=2)\n",
    "        axes[0,0].legend([Smith2009, SiegfriedFricker2018, uplift, subsidence],\n",
    "            ['Smith and others, 2009 static outline','Siegfried & Fricker, 2018 static outline',\n",
    "            ('+'+str(thres)+' m uplift (filling) variable outline'), 'â€“'+str(thres)+' m subsidence (draining) variable outline'], \n",
    "            loc='upper left')\n",
    "        # subplot 1: plot planview dhdt and variable outlines found in ICESat-2 time slice\n",
    "        img1 = axes[0,1].imshow(dhdt_IS2, extent=[x_min, x_max, y_min, y_max], \n",
    "            origin='upper', cmap=cmocean.cm.balance_r, vmin=-v, vmax=v)\n",
    "        for i in range(len(contours_fill_IS2)): \n",
    "            for j in range(len(contours_fill_IS2[i])):\n",
    "                axes[0,1].plot(x_min+contours_fill_IS2[i][j][:, 1]*x_conv, y_max-contours_fill_IS2[i][j][:, 0]*y_conv, color='mediumblue', linestyle='dashdot', linewidth=2)\n",
    "        for i in range(len(contours_drain_IS2)): \n",
    "            for j in range(len(contours_drain_IS2[i])):\n",
    "                axes[0,1].plot(x_min+contours_drain_IS2[i][j][:, 1]*x_conv, y_max-contours_drain_IS2[i][j][:, 0]*y_conv, color='maroon', linestyle=(0, (3, 1, 1, 1)), linewidth=2)\n",
    "        axes[0,1].set(xlim=(x_min, x_max), ylim=(y_min, y_max))\n",
    "        axes[0,1].set_xlabel('polar stereographic x [m]', size=15)\n",
    "        axes[0,1].ticklabel_format(axis='both',scilimits=(0,0))\n",
    "        axes[0,1].set_title(lakename_S23+' ICESat-2 dh \\n$h_{'+dates_IS2[idx].strftime('%m/%Y')+'} - h_{'+dates_IS2[idx-1].strftime('%m/%Y')+'}$', pad=7.5, fontsize=17.5)\n",
    "        fig.colorbar(img1, cax=cax1).set_label('Height change (dh) [m]', size=15)\n",
    "        # overlay published outlines for visual comparison \n",
    "        Smith2009_outlines.boundary.plot(ax=axes[0,1], color='k', linestyle='--', linewidth=1)\n",
    "        SiegfriedFricker2018_outlines[SiegfriedFricker2018_outlines['cite'] \\\n",
    "            != 'Smith and others, 2009, J. Glac., doi:10.3189/002214309789470879'] \\\n",
    "            .boundary.plot(ax=axes[0,1], color='k', linestyle='-', linewidth=1)\n",
    "        axes[0,1].legend([Smith2009, SiegfriedFricker2018, uplift, subsidence],\n",
    "            ['Smith and others, 2009 static outline','Siegfried & Fricker, 2018 static outline',\n",
    "            ('+'+str(thres)+' m uplift (filling) variable outline'), 'â€“'+str(thres)+' m subsidence (draining) variable outline'], \n",
    "            loc='upper left')\n",
    "        # suplot 2: plot CS2 dvdt time series\n",
    "        axes[1,0].plot(dates_CS2[:idx+1], np.divide(np.cumsum(dvdt_SF18_CS2[:idx+1]), 1e+9), color='k', linestyle='-')\n",
    "        axes[1,0].plot(dates_CS2[:idx+1], np.divide(np.cumsum(dvdt_S09_CS2[:idx+1]), 1e+9), color='k', linestyle='--')\n",
    "        axes[1,0].plot(dates_CS2[:idx+1], np.divide(np.cumsum(dvdt_var_CS2[:idx+1]), 1e+9), color='darkturquoise', linestyle='dashdot')\n",
    "        locator = mdates.AutoDateLocator(minticks=1, maxticks=7)\n",
    "        formatter = mdates.ConciseDateFormatter(locator)\n",
    "        axes[1,0].xaxis.set_major_locator(locator)\n",
    "        axes[1,0].xaxis.set_major_formatter(formatter)\n",
    "        # CONSIDER MOVING OUT OF FOR LOOP SO IT'S NOT CALCULATING CONSTANTS EVERY LOOP\n",
    "        dvdt_min = min(np.divide(min(np.cumsum(dvdt_SF18_CS2)), 1e+9), np.divide(min(np.cumsum(dvdt_var_CS2)), 1e+9), np.divide(min(np.cumsum(dvdt_SF18_IS2)), 1e+9), np.divide(min(np.cumsum(dvdt_var_IS2)), 1e+9))\n",
    "        dvdt_max = max(np.divide(max(np.cumsum(dvdt_SF18_CS2)), 1e+9), np.divide(max(np.cumsum(dvdt_var_CS2)), 1e+9), np.divide(max(np.cumsum(dvdt_SF18_IS2)), 1e+9), np.divide(max(np.cumsum(dvdt_var_IS2)), 1e+9))\n",
    "        dvdt_range = dvdt_max - dvdt_min\n",
    "        ylim_min = dvdt_min - (dvdt_range * 0.1)\n",
    "        ylim_max = dvdt_max + (dvdt_range * 0.1)\n",
    "        axes[1,0].set(xlim=(\n",
    "            datetime.datetime(int(CS2_dh_sub.time.values[0]), 1, 1) + datetime.timedelta(days = (CS2_dh_sub.time.values[0] % 1) * 365.25), \n",
    "            datetime.datetime(int(CS2_dh_sub.time.values[-1]), 1, 1) + datetime.timedelta(days = (CS2_dh_sub.time.values[-1] % 1) * 365.25)), \n",
    "            ylim=(ylim_min, ylim_max))\n",
    "        axes[1,0].set_title('{} CryoSat-2 dv'.format(lakename_S23), pad=7.5, fontsize=17.5)\n",
    "        axes[1,0].set_xlabel('Year', size=15)\n",
    "        axes[1,0].set_ylabel('Volume change [km$^3$]', size=15)\n",
    "        variable_outlines = plt.Line2D((0, 1), (0, 0), color='darkturquoise', linestyle='dashdot', linewidth=2)\n",
    "        axes[1,0].legend([Smith2009,\n",
    "            SiegfriedFricker2018, variable_outlines],\n",
    "            ['Smith and others, 2009',\n",
    "            'Siegfried & Fricker, 2018',\n",
    "            'Â±{} m variable outlines'.format(thres)], \n",
    "            loc='upper left')\n",
    "        # suplot 3: plot IS2 dvdt time series\n",
    "        axes[1,1].plot(dates_IS2[:idx+1], np.divide(np.cumsum(dvdt_SF18_IS2[:idx+1]), 1e+9), color='k', linestyle='-')\n",
    "        axes[1,1].plot(dates_IS2[:idx+1], np.divide(np.cumsum(dvdt_S09_IS2[:idx+1]), 1e+9), color='k', linestyle='--')\n",
    "        axes[1,1].plot(dates_IS2[:idx+1], np.divide(np.cumsum(dvdt_var_IS2[:idx+1]), 1e+9), color='darkturquoise', linestyle='dashdot')\n",
    "        locator = mdates.AutoDateLocator(minticks=1, maxticks=7)\n",
    "        formatter = mdates.ConciseDateFormatter(locator)\n",
    "        axes[1,1].xaxis.set_major_locator(locator)\n",
    "        axes[1,1].xaxis.set_major_formatter(formatter)\n",
    "        axes[1,1].set(xlim=(\n",
    "            date_time_obj + datetime.timedelta(days=ATL15_dh_sub.time.values[0]),\n",
    "            date_time_obj + datetime.timedelta(days=ATL15_dh_sub.time.values[-1])), \n",
    "            ylim=(ylim_min, ylim_max))\n",
    "        axes[1,1].set_title('{} ICESat-2 dv'.format(lakename_S23), pad=7.5, fontsize=17.5)\n",
    "        axes[1,1].set_xlabel('Year', size=15)\n",
    "        axes[1,1].set_ylabel('Volume change [km$^3$]', size=15)\n",
    "        variable_outlines = plt.Line2D((0, 1), (0, 0), color='darkturquoise', linestyle='dashdot', linewidth=2)\n",
    "        axes[1,1].legend([Smith2009,\n",
    "            SiegfriedFricker2018, variable_outlines],\n",
    "            ['Smith and others, 2009',\n",
    "            'Siegfried & Fricker, 2018',\n",
    "            'Â±{} m variable outlines'.format(thres)], \n",
    "            loc='upper left')\n",
    "        # append im(age) to ims list\n",
    "        ani.grab_frame()\n",
    "        axes[0,0].clear()\n",
    "        axes[0,1].clear()\n",
    "    # create animation and save, adjust interval\n",
    "    ani.finish()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mac5 breaks code S09SF18varoutlines_dhdvdt_CS2vsIS2_anim func; explore why\n",
    "lakename_S23 = 'Mac_5'\n",
    "#lake_gpd = Smith2009_outlines.loc[Smith2009_outlines['Name'] == lakename]\n",
    "lake_SF18 = SiegfriedFricker2018_outlines.loc[SiegfriedFricker2018_outlines['name'] == lakename_S23]\n",
    "lake_buffer = lake_SF18.buffer(buffer)\n",
    "# define lake bounding box\n",
    "x_min = lake_buffer.bounds.values[0,0]; x_max = lake_buffer.bounds.values[0,2]\n",
    "x_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find idx of Mac5 causing issue with func\n",
    "SiegfriedFricker2018_outlines[SiegfriedFricker2018_outlines['name'] == Mac5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run func on all lakes from SF18 inventory after Mac5 because it's causing issue\n",
    "for idx in np.arange(90,131):\n",
    "    lakename = SiegfriedFricker2018_outlines['name'][idx]\n",
    "    S09SF18varoutlines_dhdvdt_CS2vsIS2_anim(lakename, 7500, 0.75)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "5038e8bb49eb1923c23fc273b1aa630416e586fa7c50462a6108d15c8378e95d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
