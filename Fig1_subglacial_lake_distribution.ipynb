{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Notebook generates Fig. 1.\n",
    "\n",
    "Written 2023-07-06 by W. Sauthoff (sauthoff@mines.edu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup computing environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Install dependency not pre-installed in CryoCloud\n",
    "%pip install openpyxl --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import earthaccess\n",
    "import geopandas as gpd\n",
    "from math import radians\n",
    "from matplotlib.colors import LogNorm\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "import os\n",
    "import pandas as pd\n",
    "from pyproj import CRS, Transformer\n",
    "import rioxarray\n",
    "from shapely.geometry import Point, Polygon\n",
    "from shapely.ops import unary_union\n",
    "import xarray as xr\n",
    "\n",
    "# Magic functions\n",
    "%matplotlib widget\n",
    "# %matplotlib inline\n",
    "\n",
    "# Update the default font to Arial (and add backup if not found)\n",
    "plt.rcParams['font.family'] = ['sans-serif']\n",
    "\n",
    "# Define data directories dependent on home environment\n",
    "if os.getenv('HOME') == '/home/jovyan':\n",
    "    DATA_DIR = '/home/jovyan/data'\n",
    "    OUTPUT_DIR = '/home/jovyan/1_evolving_lakes/output'\n",
    "\n",
    "# Define utility function\n",
    "def ll2ps(lon, lat):\n",
    "    \"\"\"\n",
    "    Transform coordinates from geodetic coordinates (lon, lat)\n",
    "    to Antarctic Polar Stereograph coordinates (x, y)\n",
    "    x, y = ll2ps(lon, lat)\n",
    "    \"\"\"\n",
    "    crs_ll = CRS(\"EPSG:4326\")\n",
    "    crs_xy = CRS(\"EPSG:3031\")\n",
    "    ll_to_xy = Transformer.from_crs(crs_ll, crs_xy, always_xy = True)\n",
    "    x, y = ll_to_xy.transform(lon, lat)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_gdf_by_folder_contents(gdf, folder_path, exclude=True, prefix=None, suffix=None, suffix_pattern=None, file_extension=None):\n",
    "    '''\n",
    "    Filter the GeoDataFrame based on processed lake names from the folder contents.\n",
    "    \n",
    "    Args:\n",
    "    gdf: GeoDataFrame to be filtered.\n",
    "    folder_path: Path to the directory containing files and/or subdirectories.\n",
    "    exclude: If True, excludes rows where the 'name' is in the folder_path directories or files.\n",
    "             If False, includes only rows where the 'name' is in the folder_path directories or files.\n",
    "    prefix: Optional string to remove from the beginning of filenames.\n",
    "    suffix: Optional string to remove from the end of filenames.\n",
    "    suffix_pattern: Optional regex pattern to remove from the end of filenames.\n",
    "    file_extension: Optional string specifying the file extension to filter (e.g., 'png', 'txt').\n",
    "    \n",
    "    Returns:\n",
    "    GeoDataFrame filtered based on the presence of 'name' in folder_path.\n",
    "\n",
    "    # Example usage:\n",
    "    remaining_lakes = filter_gdf_by_folder_contents(\n",
    "        stationary_lakes_gdf, \n",
    "        folder_path,\n",
    "        prefix='plot_evolving_outlines_time_series_', \n",
    "        suffix_pattern=r'\\d+\\.\\d+m-level_\\d+x-with',\n",
    "        file_extension='txt'\n",
    "    )\n",
    "    '''\n",
    "    def process_name(name):\n",
    "        \"\"\"Helper function to remove prefix and suffix from a name\"\"\"\n",
    "        processed_name = name\n",
    "        \n",
    "        # First strip the file extension if it exists\n",
    "        processed_name = os.path.splitext(processed_name)[0]\n",
    "        \n",
    "        if prefix and processed_name.startswith(prefix):\n",
    "            processed_name = processed_name[len(prefix):]\n",
    "            \n",
    "        if suffix_pattern:\n",
    "            processed_name = re.sub(suffix_pattern + '$', '', processed_name)\n",
    "        elif suffix and processed_name.endswith(suffix):\n",
    "            processed_name = processed_name[:-len(suffix)]\n",
    "            \n",
    "        return processed_name.lower().strip()\n",
    "    \n",
    "    # Get all files and filter by extension if specified\n",
    "    all_files = os.listdir(folder_path)\n",
    "    if file_extension:\n",
    "        clean_extension = file_extension.lstrip('.')\n",
    "        all_files = [f for f in all_files if f.lower().endswith(f'.{clean_extension.lower()}')]\n",
    "    \n",
    "    # Process filenames to get lake names\n",
    "    names_in_folder = {\n",
    "        process_name(name)\n",
    "        for name in all_files\n",
    "    }\n",
    "    \n",
    "    # Filter without adding and then dropping a new column\n",
    "    gdf_filtered = gdf[gdf['name'].str.lower().str.strip().apply(\n",
    "        lambda x: (x not in names_in_folder) if exclude else (x in names_in_folder)\n",
    "    )]\n",
    "    \n",
    "    return gdf_filtered.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Find cloud-hosted MEaSUREs Phase-Based Antarctica Ice Velocity Map, Version 1\n",
    "# DOI from https://nsidc.org/data/NSIDC-0754/versions/1\n",
    "results = earthaccess.search_data(\n",
    "    doi='10.5067/PZ3NJ5RXRH10',\n",
    "    cloud_hosted=True,\n",
    "    bounding_box=(1, -89, -1, -89)  # (lower_left_lon, lower_left_lat , upper_right_lon, upper_right_lat))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Open data granules as s3 files to stream\n",
    "files = earthaccess.open(results)\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Open each file, which are quadrants in polar stereographic coordinations around the Geographic South Pole\n",
    "ice_vel = xr.open_dataset(files[0])\n",
    "ice_vel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Specify the variables to keep\n",
    "variables_to_keep = ['x', 'y', 'VX', 'VY']\n",
    "\n",
    "variables_to_drop = [var for var in ice_vel.variables if var not in variables_to_keep]\n",
    "\n",
    "# Drop variables to reduce memory consumption\n",
    "ice_vel = ice_vel.drop_vars(variables_to_drop)\n",
    "ice_vel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate velocity magnitude\n",
    "vel_mag = (ice_vel['VX']**2 + ice_vel['VY']**2)**0.5\n",
    "\n",
    "# Delete intermediary variable to conserve memory\n",
    "del ice_vel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vel_mag.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "10**3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Scripps Grounding Line (Depoorter and others, 2013)\n",
    "# https://doi.pangaea.de/10.1594/PANGAEA.819147\n",
    "Scripps_gl = gpd.read_file(DATA_DIR + '/boundaries/Depoorter2013/Antarctica_masks/scripps_antarctica_polygons_v1.shp')\n",
    "\n",
    "# Isolate land ice and ice shelf\n",
    "Scripps_landice = Scripps_gl[Scripps_gl['Id_text'] == 'Grounded ice or land']\n",
    "Scripps_iceshelf = Scripps_gl[Scripps_gl['Id_text'] == 'Ice shelf']\n",
    "Scripps_icerise = Scripps_gl[Scripps_gl['Id_text'] == 'Ice rise or connected island']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import stationary subglacial lake outlines\n",
    "stationary_lakes_gdf = gpd.read_file(os.path.join(os.getcwd(), 'output/lake_outlines/stationary_outlines/stationary_outlines_gdf.geojson'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import CryoSat-2 SARIn mode mask\n",
    "# See 0_preprocess_data.ipynb for data source and pre-processing steps\n",
    "gdf_SARIn_3_1 = gpd.read_file('output/CryoSat2_SARIn_mode_masks/gdf_SARIn_3_1.geojson')\n",
    "gdf_SARIn_3_1_3_6_diff= gpd.read_file('output/CryoSat2_SARIn_mode_masks/gdf_SARIn_3_1_3_6_diff.geojson')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fig. 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create filtered geodataframes of lakes based on whether they have evolving outlines\n",
    "folder_path = os.path.join ('output/lake_outlines/evolving_outlines')\n",
    "\n",
    "# Lakes with non-dynamic outlines (.txt)\n",
    "no_evolving_outlines_lakes = filter_gdf_by_folder_contents(stationary_lakes_gdf, folder_path, file_extension='txt', exclude=False)\n",
    "print('non-dynamic:',len(no_evolving_outlines_lakes))\n",
    "\n",
    "# Lakes with evolving outlines (.geojson)\n",
    "evolving_outlines_lakes = filter_gdf_by_folder_contents(stationary_lakes_gdf, folder_path, file_extension='geojson', exclude=False)\n",
    "\n",
    "# For the evolving_outlines_lakes, we must add the special case of Site_B_Site_C that are now a combined lake\n",
    "include_list = ['Site_B', 'Site_C']\n",
    "included_rows = stationary_lakes_gdf[stationary_lakes_gdf['name'].isin(include_list)]\n",
    "evolving_outlines_lakes = pd.concat([evolving_outlines_lakes, included_rows]).drop_duplicates()\n",
    "print('dynamic:',len(evolving_outlines_lakes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine both sets of lakes that meet either criterion\n",
    "valid_lakes = pd.concat([evolving_outlines_lakes, no_evolving_outlines_lakes]).drop_duplicates(subset='name')\n",
    "\n",
    "# Now filter out the valid lakes to find the ones that don't satisfy either criterion\n",
    "missing_lakes = stationary_lakes_gdf[~stationary_lakes_gdf['name'].isin(valid_lakes['name'])].reset_index(drop=True)\n",
    "missing_lakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stationary_lakes_gdf['CS2_SARIn_start'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: filter out Crane_Glacier\n",
    "filtered_gdf = stationary_lakes_gdf[stationary_lakes_gdf['name'] != 'Crane_Glacier']\n",
    "\n",
    "# Step 2a: count where CS2_SARIn_start is 2010.5 or 2013.75\n",
    "count_CS2 = filtered_gdf['CS2_SARIn_start'].isin(['2010.5', '2013.75']).sum()\n",
    "\n",
    "# Step 2b: count where CS2_SARIn_start == <NA>\n",
    "count_IS2 = filtered_gdf['CS2_SARIn_start'].isin(['<NA>']).sum()\n",
    "\n",
    "print(\"Rows with CS2_SARIn_start = 2010.5 or 2013.75:\", count_CS2)\n",
    "print(\"Rows with CS2_SARIn_start = <NA>:\", count_IS2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get the bounds of the CryoSat-2 SARIn mode mask GeoDataFrame\n",
    "bounds = gdf_SARIn_3_1.geometry.bounds\n",
    "\n",
    "# Extract the min and max x and y values from the bounds\n",
    "x_min, x_max = bounds['minx'].min(), bounds['maxx'].max()\n",
    "y_min, y_max = bounds['miny'].min(), bounds['maxy'].max()\n",
    "x_buffer, y_buffer = (x_max-x_min)*0.01, (y_max-y_min)*0.01, \n",
    "\n",
    "# Create fig and axes objects\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "\n",
    "# Plot ice-surface velocity\n",
    "# cax = vel_mag.plot(ax=ax, cmap='Greys_r', norm=LogNorm(vmin=vel_mag.min(), vmax=vel_mag.max()), zorder=2)\n",
    "cax = vel_mag.plot(ax=ax, cmap='Greys_r', norm=LogNorm(vmin=1, vmax=1000), zorder=1, add_colorbar=False)\n",
    "\n",
    "# Plot Scripps grounding line\n",
    "# Use black facecolor to fill in gaps in velocity array\n",
    "Scripps_landice.boundary.plot(ax=ax, linewidth=0.25, edgecolor='k', facecolor='k', zorder=0) \n",
    "Scripps_landice.boundary.plot(ax=ax, linewidth=0.25, edgecolor='k', facecolor=None, zorder=2) \n",
    "Scripps_iceshelf.boundary.plot(ax=ax, linewidth=0.25, edgecolor='k', facecolor=None, zorder=2) \n",
    "Scripps_icerise.boundary.plot(ax=ax, linewidth=0.25, edgecolor='k', facecolor=None, zorder=2) \n",
    "\n",
    "# Plot CryoSat-2 SARIn mode masks\n",
    "gdf_SARIn_3_1.plot(ax=ax, edgecolor='blue', facecolor='blue', alpha=0.1, zorder=3)\n",
    "gdf_SARIn_3_1.boundary.plot(ax=ax, color='blue', linewidth=0.5, zorder=3)\n",
    "gdf_SARIn_3_1_3_6_diff.plot(ax=ax, edgecolor='blue', facecolor='blue', alpha=0.1, zorder=3)\n",
    "gdf_SARIn_3_1_3_6_diff.boundary.plot(ax=ax, color='blue', linewidth=0.5, zorder=3)\n",
    "CS2_SARIn_union_polygon = unary_union([gdf_SARIn_3_1.geometry[0], gdf_SARIn_3_1_3_6_diff.geometry[0]])\n",
    "CS2_SARIn_union_gdf = gpd.GeoDataFrame({'id': [1], 'geometry': [CS2_SARIn_union_polygon]}, crs='EPSG:3031')\n",
    "CS2_SARIn_union_gdf = CS2_SARIn_union_gdf.to_crs(epsg=4326)\n",
    "\n",
    "# Create ICESat-2 pole hole geodataframe\n",
    "center_x, center_y = 0, 0  # Geographic South Pole\n",
    "x, y = ll2ps(0, -88)\n",
    "radius = y  # Radius from Geographic South Pole to -88 S latitude (ICESat-2's southernmost coverage)\n",
    "del x, y\n",
    "IS2_pole_hole_poly = Point(center_x, center_y).buffer(radius)\n",
    "IS2_pole_hole_gdf = gpd.GeoDataFrame(index=[0], geometry=[IS2_pole_hole_poly], crs=\"EPSG:3031\")\n",
    "IS2_pole_hole_gdf = IS2_pole_hole_gdf.to_crs(epsg=4326)\n",
    "\n",
    "# IS2 interior to CS2 SARIn mode coverage\n",
    "IS2_interior_poly = Polygon(shell=CS2_SARIn_union_gdf.geometry[0].interiors[0].coords, \n",
    "                            holes=[IS2_pole_hole_gdf.geometry[0].exterior.coords])\n",
    "IS2_interior_gdf = gpd.GeoDataFrame({'id': [1], 'geometry': [IS2_interior_poly]}, crs='EPSG:4326')\n",
    "IS2_interior_gdf = IS2_interior_gdf.to_crs(epsg=3031)\n",
    "IS2_interior_gdf.plot(ax=ax, edgecolor='green', facecolor='green', alpha=0.1, zorder=3)\n",
    "IS2_interior_gdf.boundary.plot(ax=ax, color='green', linewidth=0.5, zorder=3)\n",
    "\n",
    "# Overlay previously identified active subglacial lake stationary outlines\n",
    "stationary_lakes_color = 'turquoise'\n",
    "# stationary_lakes_gdf.boundary.plot(ax=ax, facecolor=stationary_lakes_color, \n",
    "#     edgecolor=stationary_lakes_color, linewidth=1, alpha=1, zorder=4)\n",
    "evolving_outlines_lakes.boundary.plot(ax=ax, facecolor=stationary_lakes_color, \n",
    "    edgecolor=stationary_lakes_color, linewidth=1, alpha=1, zorder=4)\n",
    "no_evolving_outlines_lakes.boundary.plot(ax=ax, facecolor='red', \n",
    "    edgecolor='red', linewidth=1, alpha=1, zorder=4)\n",
    "\n",
    "# Create patches for the two lake types\n",
    "evolving_lakes_patch = mpatches.Patch(\n",
    "    facecolor=stationary_lakes_color,\n",
    "    edgecolor=stationary_lakes_color,\n",
    "    label='Evolving outlines found'\n",
    ")\n",
    "no_evolving_outlines_lakes_patch = mpatches.Patch(\n",
    "    facecolor='red',\n",
    "    edgecolor='red',\n",
    "    label='Evolving outlines not found'\n",
    ")\n",
    "\n",
    "# Create patches for the other elements\n",
    "cs2_patch = mpatches.Patch(\n",
    "    facecolor=(0, 0, 1, 0.1),   # blue with 0.1 opacity\n",
    "    edgecolor='blue',\n",
    "    # alpha=0.1,\n",
    "    # label='CryoSat-2 SARIn and ICESat-2 coterminous coverage'\n",
    ")\n",
    "is2_patch = mpatches.Patch(\n",
    "    facecolor=(0, 1, 0, 0.1),   # green with 0.1 opacity\n",
    "    edgecolor='green',\n",
    "    linewidth=0.75,\n",
    "    # alpha=0.1,\n",
    "    # label='ICESat-2 coverage (CryoSat-2 SARIn unavailable)'\n",
    ")\n",
    "\n",
    "# Create the legend with grouping\n",
    "legend1 = ax.legend(\n",
    "    [evolving_lakes_patch, \n",
    "     no_evolving_outlines_lakes_patch],\n",
    "    [f'Evolving outlines found (n={len(evolving_outlines_lakes)})', \n",
    "     f'Evolving outlines not found (n={len(no_evolving_outlines_lakes)})'],\n",
    "    title='Re-examined active subglacial lakes',\n",
    "    loc='upper left',\n",
    "    bbox_to_anchor=(0, 0.225),\n",
    "    alignment='left',\n",
    "    frameon=False,\n",
    ")\n",
    "\n",
    "# Add the second legend for the coverage areas\n",
    "ax.add_artist(legend1)  # This keeps the first legend visible\n",
    "ax.legend(\n",
    "    [cs2_patch, \n",
    "     is2_patch],\n",
    "    [f'CryoSat-2 SARIn and ICESat-2 (n={count_CS2})', \n",
    "     f'ICESat-2 only (n={count_IS2})'],\n",
    "    title='Satellite/mode coverage',\n",
    "    loc='upper left',\n",
    "    bbox_to_anchor=(0, 0.118),\n",
    "    alignment='left',\n",
    "    frameon=False,\n",
    ")\n",
    "\n",
    "# Change polar stereographic m to km\n",
    "km_scale = 1e3\n",
    "ticks_x = ticker.FuncFormatter(lambda x, pos: '{0:g}'.format(x/km_scale))\n",
    "ax.xaxis.set_major_formatter(ticks_x)\n",
    "ticks_y = ticker.FuncFormatter(lambda x, pos: '{0:g}'.format(x/km_scale))\n",
    "ax.yaxis.set_major_formatter(ticks_y)  \n",
    "\n",
    "# Label axes\n",
    "ax.set_xlabel('x [km]', size=15)\n",
    "ax.set_ylabel('y [km]', size=15)\n",
    "\n",
    "# Set axes limits\n",
    "ax.set(xlim=(x_min-x_buffer, x_max+x_buffer), ylim=(y_min-y_buffer, y_max+y_buffer))\n",
    "\n",
    "# Plot colorbar\n",
    "axins = inset_axes(ax, width=\"50%\", height=\"2%\", loc='upper left',\n",
    "                   bbox_to_anchor=(0.07, -0.05, 0.5, 1),  # [left, bottom, width, height]\n",
    "                   bbox_transform=ax.transAxes,\n",
    "                   borderpad=0)\n",
    "fig.colorbar(cax, cax=axins, label='ice velocity [m a$^{-1}$]', orientation='horizontal', extend='max')\n",
    "\n",
    "# Save and close plot\n",
    "plt.savefig(OUTPUT_DIR + '/Fig1_subglacial_lake_distribution.jpg', dpi=300, bbox_inches='tight')\n",
    "\n",
    "# Preview plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
