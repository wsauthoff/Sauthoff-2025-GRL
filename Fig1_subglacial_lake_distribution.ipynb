{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# Confirm that pole hole generation technique is valid - plot with a time slice of ATL15 data to confirm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Code to generate Fig. 1 in Sauthoff and others, 202X, _Journal_.\n",
    "\n",
    "Written 2023-07-06 by W. Sauthoff (sauthoff@mines.edu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup computing environment\n",
    "\n",
    "This code requires a ~32 gb server instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Install dependency not pre-installed in CryoCloud\n",
    "%pip install openpyxl --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import earthaccess\n",
    "import geopandas as gpd\n",
    "from math import radians\n",
    "from matplotlib.colors import LogNorm\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "import os\n",
    "import pandas as pd\n",
    "import rioxarray\n",
    "from shapely.geometry import Point, Polygon\n",
    "from shapely.ops import unary_union\n",
    "import xarray as xr\n",
    "\n",
    "# Magic functions\n",
    "%matplotlib widget\n",
    "# %matplotlib inline\n",
    "\n",
    "# Update the default font to Arial (and add backup if not found)\n",
    "plt.rcParams['font.family'] = ['sans-serif']\n",
    "\n",
    "# Define data directories dependent on home environment\n",
    "# Replace with your directory file paths\n",
    "if os.getenv('HOME') == '/home/jovyan':\n",
    "    DATA_DIR = '/home/jovyan/data'\n",
    "    OUTPUT_DIR = '/home/jovyan/1_evolving_lakes/output/FigS1_lake_reexamination_methods.ipynb'\n",
    "    OUTPUT_DIR_GIT = '/home/jovyan/1_evolving_lakes/Sauthoff-202X-evolving-lakes/output'\n",
    "\n",
    "# Define utility function\n",
    "def ll2ps(lon, lat):\n",
    "    \"\"\"\n",
    "    Transform coordinates from geodetic coordinates (lon, lat)\n",
    "    to Antarctic Polar Stereograph coordinates (x, y)\n",
    "    x, y = ll2ps(lon, lat)\n",
    "    \"\"\"\n",
    "    crs_ll = CRS(\"EPSG:4326\")\n",
    "    crs_xy = CRS(\"EPSG:3031\")\n",
    "    ll_to_xy = Transformer.from_crs(crs_ll, crs_xy, always_xy = True)\n",
    "    x, y = ll_to_xy.transform(lon, lat)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_gdf_by_folder_contents(gdf, folder_path, exclude=True, prefix=None, suffix=None, suffix_pattern=None, file_extension=None):\n",
    "    '''\n",
    "    Filter the GeoDataFrame based on processed lake names from the folder contents.\n",
    "    \n",
    "    Args:\n",
    "    gdf: GeoDataFrame to be filtered.\n",
    "    folder_path: Path to the directory containing files and/or subdirectories.\n",
    "    exclude: If True, excludes rows where the 'name' is in the folder_path directories or files.\n",
    "             If False, includes only rows where the 'name' is in the folder_path directories or files.\n",
    "    prefix: Optional string to remove from the beginning of filenames.\n",
    "    suffix: Optional string to remove from the end of filenames.\n",
    "    suffix_pattern: Optional regex pattern to remove from the end of filenames.\n",
    "    file_extension: Optional string specifying the file extension to filter (e.g., 'png', 'txt').\n",
    "    \n",
    "    Returns:\n",
    "    GeoDataFrame filtered based on the presence of 'name' in folder_path.\n",
    "\n",
    "    # Example usage:\n",
    "    remaining_lakes = filter_gdf_by_folder_contents(\n",
    "        stationary_lakes_gdf, \n",
    "        folder_path,\n",
    "        prefix='plot_evolving_outlines_time_series_', \n",
    "        suffix_pattern=r'\\d+\\.\\d+m-level_\\d+x-with',\n",
    "        file_extension='txt'\n",
    "    )\n",
    "    '''\n",
    "    def process_name(name):\n",
    "        \"\"\"Helper function to remove prefix and suffix from a name\"\"\"\n",
    "        processed_name = name\n",
    "        \n",
    "        # First strip the file extension if it exists\n",
    "        processed_name = os.path.splitext(processed_name)[0]\n",
    "        \n",
    "        if prefix and processed_name.startswith(prefix):\n",
    "            processed_name = processed_name[len(prefix):]\n",
    "            \n",
    "        if suffix_pattern:\n",
    "            processed_name = re.sub(suffix_pattern + '$', '', processed_name)\n",
    "        elif suffix and processed_name.endswith(suffix):\n",
    "            processed_name = processed_name[:-len(suffix)]\n",
    "            \n",
    "        return processed_name.lower().strip()\n",
    "    \n",
    "    # Get all files and filter by extension if specified\n",
    "    all_files = os.listdir(folder_path)\n",
    "    if file_extension:\n",
    "        clean_extension = file_extension.lstrip('.')\n",
    "        all_files = [f for f in all_files if f.lower().endswith(f'.{clean_extension.lower()}')]\n",
    "    \n",
    "    # Process filenames to get lake names\n",
    "    names_in_folder = {\n",
    "        process_name(name)\n",
    "        for name in all_files\n",
    "    }\n",
    "    \n",
    "    # Filter without adding and then dropping a new column\n",
    "    gdf_filtered = gdf[gdf['name'].str.lower().str.strip().apply(\n",
    "        lambda x: (x not in names_in_folder) if exclude else (x in names_in_folder)\n",
    "    )]\n",
    "    \n",
    "    return gdf_filtered.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import MODIS Mosaic of Antarctica surface imagery\n",
    "# https://nsidc.org/data/nsidc-0730/versions/1\n",
    "moa_lowres = DATA_DIR + '/surface_imagery/MODIS_MOA/2014/moa750_2014_hp1_v01.tif' \n",
    "# moa_highres = DATA_DIR + '/surface_imagery/MODIS_MOA/2014/moa125_2014_hp1_v01.tif' \n",
    "\n",
    "# Open into an xarray.DataArray, convert to dataset, and display\n",
    "moa_da = rioxarray.open_rasterio(moa_lowres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import MODIS MOA 2009 and 2014 coastline and grounding line for plotting inset maps\n",
    "# # https://nsidc.org/data/nsidc-0593/versions/1\n",
    "# shp = DATA_DIR + '/boundaries/MODIS-MOA/2009/moa_2009_coastline_v02.0.shp' \n",
    "# moa_2009_coastline = gpd.read_file(shp)\n",
    "# shp = DATA_DIR + '/boundaries/MODIS-MOA/2009/moa_2009_groundingline_v02.0.shp' \n",
    "# moa_2009_groundingline = gpd.read_file(shp)\n",
    "\n",
    "# https://nsidc.org/data/nsidc-0730/versions/1\n",
    "shp = DATA_DIR + '/boundaries/MODIS_MOA/2014/moa2014_coastline_v01.shp' \n",
    "moa_2014_coastline = gpd.read_file(shp)\n",
    "shp = DATA_DIR + '/boundaries/MODIS_MOA/2014/moa2014_grounding_line_v01.shp' \n",
    "moa_2014_groundingline = gpd.read_file(shp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Find cloud-hosted MEaSUREs Phase-Based Antarctica Ice Velocity Map, Version 1\n",
    "# DOI from https://nsidc.org/data/NSIDC-0754/versions/1\n",
    "results = earthaccess.search_data(\n",
    "    doi='10.5067/PZ3NJ5RXRH10',\n",
    "    cloud_hosted=True,\n",
    "    bounding_box=(1, -89, -1, -89)  # (lower_left_lon, lower_left_lat , upper_right_lon, upper_right_lat))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Open data granules as s3 files to stream\n",
    "files = earthaccess.open(results)\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Open each file, which are quadrants in polar stereographic coordinations around the Geographic South Pole\n",
    "ice_vel = xr.open_dataset(files[0])\n",
    "ice_vel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Specify the variables to keep\n",
    "variables_to_keep = ['x', 'y', 'VX', 'VY']\n",
    "\n",
    "variables_to_drop = [var for var in ice_vel.variables if var not in variables_to_keep]\n",
    "\n",
    "# Drop variables to reduce memory consumption\n",
    "ice_vel = ice_vel.drop_vars(variables_to_drop)\n",
    "ice_vel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate velocity magnitude\n",
    "vel_mag = (ice_vel['VX']**2 + ice_vel['VY']**2)**0.5\n",
    "\n",
    "# Delete intermediary variable to conserve memory\n",
    "del ice_vel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Scripps Grounding Line (Depoorter and others, 2013)\n",
    "# https://doi.pangaea.de/10.1594/PANGAEA.819147\n",
    "Scripps_gl = gpd.read_file(DATA_DIR + '/boundaries/Depoorter2013/Antarctica_masks/scripps_antarctica_polygons_v1.shp')\n",
    "\n",
    "# Isolate land ice and ice shelf\n",
    "Scripps_landice = Scripps_gl[Scripps_gl['Id_text'] == 'Grounded ice or land']\n",
    "Scripps_iceshelf = Scripps_gl[Scripps_gl['Id_text'] == 'Ice shelf']\n",
    "Scripps_icerise = Scripps_gl[Scripps_gl['Id_text'] == 'Ice rise or connected island']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import stationary subglacial lake outlines\n",
    "stationary_lakes_gdf = gpd.read_file(os.path.join(os.getcwd(), 'output/lake_outlines/stationary_outlines/stationary_outlines_gdf.geojson'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import CryoSat-2 SARIn mode mask\n",
    "# See 0_preprocess_data.ipynb for data source and pre-processing steps\n",
    "gdf_SARIn_3_1 = gpd.read_file('output/CS2_SARIn_mode_masks/gdf_SARIn_3_1.geojson')\n",
    "gdf_SARIn_3_1_3_6_diff= gpd.read_file('output/CS2_SARIn_mode_masks/gdf_SARIn_3_1_3_6_diff.geojson')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fig. 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create filtered geodataframes of lakes based on whether they have evolving outlines\n",
    "folder_path = os.path.join (OUTPUT_DIR_GIT, 'lake_outlines/evolving_outlines')\n",
    "evolving_outlines_lakes = filter_gdf_by_folder_contents(stationary_lakes_gdf, folder_path, file_extension='geojson', exclude=False)\n",
    "quiescent_lakes = filter_gdf_by_folder_contents(stationary_lakes_gdf, folder_path, file_extension='txt', exclude=False)\n",
    "# For the evolving_outlines_lakes, we must add the special case of Site_B_Site_C that are now a combined lake\n",
    "include_list = ['Site_B', 'Site_C']\n",
    "included_rows = stationary_lakes_gdf[stationary_lakes_gdf['name'].isin(include_list)]\n",
    "evolving_outlines_lakes = pd.concat([evolving_outlines_lakes, included_rows]).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get the bounds of the CryoSat-2 SARIn mode mask GeoDataFrame\n",
    "bounds = gdf_SARIn_3_1.geometry.bounds\n",
    "\n",
    "# Extract the min and max x and y values from the bounds\n",
    "x_min, x_max = bounds['minx'].min(), bounds['maxx'].max()\n",
    "y_min, y_max = bounds['miny'].min(), bounds['maxy'].max()\n",
    "x_buffer, y_buffer = (x_max-x_min)*0.01, (y_max-y_min)*0.01, \n",
    "\n",
    "# Create fig and axes objects\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "\n",
    "# Plot MOA imagery  \n",
    "# ax.imshow(moa_da[0,:,:], cmap=\"gray\", clim=[13000, 17000], extent=[x_min, x_max, y_min, y_max])\n",
    "\n",
    "# Plot ice-surface velocity\n",
    "# cax = vel_mag.plot(ax=ax, cmap='Greys_r', norm=LogNorm(vmin=vel_mag.min(), vmax=vel_mag.max()), zorder=2)\n",
    "cax = vel_mag.plot(ax=ax, cmap='Greys_r', norm=LogNorm(vmin=1, vmax=1000), zorder=1, add_colorbar=False)\n",
    "\n",
    "# Plot Scripps grounding line\n",
    "# Use black facecolor to fill in gaps in velocity array\n",
    "Scripps_landice.boundary.plot(ax=ax, linewidth=0.5, edgecolor='k', facecolor='k', zorder=0) \n",
    "Scripps_landice.boundary.plot(ax=ax, linewidth=0.5, edgecolor='k', facecolor=None, zorder=2) \n",
    "Scripps_iceshelf.boundary.plot(ax=ax, linewidth=0.5, edgecolor='k', facecolor=None, zorder=2) \n",
    "Scripps_icerise.boundary.plot(ax=ax, linewidth=0.5, edgecolor='k', facecolor=None, zorder=2) \n",
    "\n",
    "# # Plot MOA coast and grounding lines  \n",
    "# moa_2014_coastline.plot(ax=ax, color='gray', edgecolor='k', linewidth=0.1, zorder=1)\n",
    "# moa_2014_groundingline.plot(ax=ax, color='ghostwhite', edgecolor='k', linewidth=0.1, zorder=1)\n",
    "\n",
    "# Plot CryoSat-2 SARIn mode masks\n",
    "gdf_SARIn_3_1.plot(ax=ax, edgecolor='purple', facecolor='purple', alpha=0.05, zorder=3)\n",
    "gdf_SARIn_3_1_3_6_diff.plot(ax=ax, edgecolor='purple', facecolor='purple', alpha=0.05, zorder=3)\n",
    "CS2_SARIn_union_polygon = unary_union([gdf_SARIn_3_1.geometry[0], gdf_SARIn_3_1_3_6_diff.geometry[0]])\n",
    "CS2_SARIn_union_gdf = gpd.GeoDataFrame({'id': [1], 'geometry': [CS2_SARIn_union_polygon]}, crs='EPSG:3031')\n",
    "CS2_SARIn_union_gdf = CS2_SARIn_union_gdf.to_crs(epsg=4326)\n",
    "\n",
    "# Create ICESat-2 pole hole geodataframe\n",
    "center_x, center_y = 0, 0  # Geographic South Pole\n",
    "x, y = ll2ps(0, -88)\n",
    "radius = y  # Radius from Geographic South Pole to -88 S latitude (ICESat-2's southernmost coverage)\n",
    "del x, y\n",
    "IS2_pole_hole_poly = Point(center_x, center_y).buffer(radius)\n",
    "IS2_pole_hole_gdf = gpd.GeoDataFrame(index=[0], geometry=[IS2_pole_hole_poly], crs=\"EPSG:3031\")\n",
    "IS2_pole_hole_gdf = IS2_pole_hole_gdf.to_crs(epsg=4326)\n",
    "\n",
    "# IS2 interior to CS2 SARIn mode coverage\n",
    "IS2_interior_poly = Polygon(shell=CS2_SARIn_union_gdf.geometry[0].interiors[0].coords, \n",
    "                            holes=[IS2_pole_hole_gdf.geometry[0].exterior.coords])\n",
    "IS2_interior_gdf = gpd.GeoDataFrame({'id': [1], 'geometry': [IS2_interior_poly]}, crs='EPSG:4326')\n",
    "IS2_interior_gdf = IS2_interior_gdf.to_crs(epsg=3031)\n",
    "IS2_interior_gdf.plot(ax=inset_ax, edgecolor='green', facecolor='green', alpha=0.25, zorder=3)\n",
    "\n",
    "# Overlay previously identified active subglacial lake stationary outlines\n",
    "stationary_lakes_color = 'turquoise'\n",
    "# stationary_lakes_gdf.boundary.plot(ax=ax, facecolor=stationary_lakes_color, \n",
    "#     edgecolor=stationary_lakes_color, linewidth=1, alpha=1, zorder=4)\n",
    "evolving_outlines_lakes.boundary.plot(ax=ax, facecolor=stationary_lakes_color, \n",
    "    edgecolor=stationary_lakes_color, linewidth=1, alpha=1, zorder=4)\n",
    "quiescent_lakes.boundary.plot(ax=ax, facecolor='red', \n",
    "    edgecolor='red', linewidth=1, alpha=1, zorder=4)\n",
    "\n",
    "# # Plot inset map to show where lakes with evolving outlines are found\n",
    "# axIns = ax.inset_axes([0, 0, 0.3, 0.3]) # [left, bottom, width, height] (fractional axes coordinates)\n",
    "# axIns.annotate('A', xy=(0.02, 0.98), xycoords='axes fraction', \n",
    "#                fontsize=12, fontweight='bold', va='top')\n",
    "# axIns.set_aspect('equal')\n",
    "# moa_2014_coastline.plot(ax=axIns, color='gray', edgecolor='k', linewidth=0.1, zorder=3)\n",
    "# moa_2014_groundingline.plot(ax=axIns, color='ghostwhite', edgecolor='k', linewidth=0.1, zorder=3)\n",
    "# evolving_outlines_lakes.boundary.plot(ax=axIns, facecolor=stationary_lakes_color, \n",
    "#     edgecolor=stationary_lakes_color, linewidth=1, alpha=1, zorder=4)\n",
    "# quiescent_lakes.boundary.plot(ax=axIns, facecolor=stationary_lakes_color, \n",
    "#     edgecolor='red', linewidth=1, alpha=1, zorder=4)\n",
    "# axIns.axis('off')\n",
    "\n",
    "# Create lines and patches for legend\n",
    "# Create an ellipse\n",
    "stationary_lakes_ellipse = mpatches.Ellipse((0.5, 0.5), 0.3, 0.1, edgecolor=stationary_lakes_color, facecolor=stationary_lakes_color, alpha=1)\n",
    "# stationary_lakes_line = plt.Line2D([], [], color=stationary_lakes_color, linestyle='solid', linewidth=2)\n",
    "CS2_SARIn_patch = mpatches.Patch(edgecolor='purple', facecolor='purple', alpha=0.05)\n",
    "IS2_patch = mpatches.Patch(edgecolor='green', facecolor='green', alpha=0.05)\n",
    "\n",
    "# # Create lines and patches for legend\n",
    "# # Create split-colored ellipse using two half-ellipses\n",
    "# ellipse_width, ellipse_height = 0.3, 0.1\n",
    "# # Create a diagonal split by using a polygon for each half\n",
    "# vertices1 = [(0.5-ellipse_width/2, 0.5), \n",
    "#             (0.5+ellipse_width/2, 0.5+ellipse_height/2),\n",
    "#             (0.5-ellipse_width/2, 0.5+ellipse_height/2)]\n",
    "# vertices2 = [(0.5-ellipse_width/2, 0.5),\n",
    "#             (0.5+ellipse_width/2, 0.5+ellipse_height/2),\n",
    "#             (0.5+ellipse_width/2, 0.5-ellipse_height/2),\n",
    "#             (0.5-ellipse_width/2, 0.5-ellipse_height/2)]\n",
    "\n",
    "# half_ellipse1 = mpatches.Polygon(vertices1, facecolor=stationary_lakes_color, edgecolor=stationary_lakes_color)\n",
    "# half_ellipse2 = mpatches.Polygon(vertices2, facecolor=stationary_lakes_color, edgecolor='red')\n",
    "\n",
    "# # Create a proxy artist for the legend that contains both patches\n",
    "# from matplotlib.offsetbox import AuxTransformBox, VPackedBox\n",
    "# box = AuxTransformBox(ax.transData)\n",
    "# box.add_artist(half_ellipse1)\n",
    "# box.add_artist(half_ellipse2)\n",
    "# packed_box = VPackedBox(children=[box])\n",
    "\n",
    "# Create legend\n",
    "ax.legend([stationary_lakes_ellipse, \n",
    "           # packed_box, \n",
    "           CS2_SARIn_patch, IS2_patch],\n",
    "    ['Previously identified active subglacial lakes', \n",
    "     'CryoSat-2 SARIn and ICESat-2 coterminous coverage', \n",
    "     'ICESat-2 coverage (CryoSat-2 SARIn unavailable)'], \n",
    "    loc='upper left',\n",
    "    bbox_to_anchor=(0, 0.1),)\n",
    "\n",
    "# Change polar stereographic m to km\n",
    "km_scale = 1e3\n",
    "ticks_x = ticker.FuncFormatter(lambda x, pos: '{0:g}'.format(x/km_scale))\n",
    "ax.xaxis.set_major_formatter(ticks_x)\n",
    "ticks_y = ticker.FuncFormatter(lambda x, pos: '{0:g}'.format(x/km_scale))\n",
    "ax.yaxis.set_major_formatter(ticks_y)  \n",
    "\n",
    "# Label axes\n",
    "ax.set_xlabel('x [km]', size=15)\n",
    "ax.set_ylabel('y [km]', size=15)\n",
    "\n",
    "# Set axes limits\n",
    "ax.set(xlim=(x_min-x_buffer, x_max+x_buffer), ylim=(y_min-y_buffer, y_max+y_buffer))\n",
    "\n",
    "# Plot colorbar\n",
    "axins = inset_axes(ax, width=\"50%\", height=\"2%\", loc='upper left',\n",
    "                   bbox_to_anchor=(0.09, -0.05, 0.5, 1),\n",
    "                   bbox_transform=ax.transAxes,\n",
    "                   borderpad=0)\n",
    "fig.colorbar(cax, cax=axins, label='ice velocity [m a$^{-1}$]', orientation='horizontal')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
